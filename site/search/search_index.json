{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Interview Docs","text":"<ul> <li>Languages</li> <li>Web Development</li> <li>MQ</li> <li>DevOps</li> <li>Database</li> <li>Design Pattern</li> <li>Algorithms</li> <li>QA</li> <li>Assessment</li> <li>Project</li> <li>Misc</li> </ul>","tags":["Home"]},{"location":"#languages","title":"Languages","text":"<ul> <li>Java</li> <li>Node.js</li> <li>Python</li> <li>Golang</li> </ul>","tags":["Home"]},{"location":"#web-development","title":"Web Development","text":"<ul> <li>Spring</li> <li>Microservices</li> <li>Angular</li> <li>React</li> </ul>","tags":["Home"]},{"location":"#mq","title":"MQ","text":"<ul> <li>Apache Kafka</li> <li>RabbitMQ</li> <li>Apache ActiveMQ</li> <li>Amazon SQS (Simple Queue Service)</li> <li>Microsoft Azure</li> <li>Google Cloud Pub/Sub</li> <li>Redis Pub/Sub</li> </ul>","tags":["Home"]},{"location":"#devops","title":"DevOps","text":"<ul> <li>AWS</li> <li>Azure</li> <li>GCP</li> <li>OpenShift</li> <li>VCS</li> <li>CI/CD</li> <li>Configuration Management</li> <li>Containerization and Orchestration</li> <li>Infrastructure as Code (IaC)</li> <li>Monitoring and Logging</li> <li>Container Registries</li> <li>Security Scanning and Compliance</li> <li>Artifact Repository</li> <li>GitOps</li> </ul>","tags":["Home"]},{"location":"#database","title":"Database","text":"<ul> <li>Cassandra</li> <li>Couchbase</li> <li>DynamoDB</li> <li>MongoDB</li> <li>Oracle</li> <li>PostgreSQL</li> <li>Redis</li> </ul>","tags":["Home"]},{"location":"#design-pattern","title":"Design Pattern","text":"<ul> <li>Behavioral Pattern</li> <li>Creational Pattern</li> <li>Structural Pattern</li> <li>Other Pattern</li> </ul>","tags":["Home"]},{"location":"#algorithms","title":"Algorithms","text":"<ul> <li>Data Structures</li> <li>Algorithms</li> </ul>","tags":["Home"]},{"location":"#qa","title":"QA","text":"<ul> <li>Cucumber</li> <li>Selenium</li> <li>Protractor</li> <li>Cypress</li> <li>WebdriverIO</li> <li>Apigee</li> <li>Jest</li> <li>Mocha/Chai</li> <li>Karate</li> <li>Postman</li> <li>Rest Assured</li> <li>TestNG</li> <li>Appium</li> <li>Robot Framework</li> <li>JMeter</li> </ul>","tags":["Home"]},{"location":"#assessment","title":"Assessment","text":"<ul> <li>Angular</li> <li>Java</li> <li>Spring</li> <li>React</li> <li>Node.js</li> <li>Python</li> </ul>","tags":["Home"]},{"location":"#project","title":"Project","text":"<ul> <li>Company</li> <li>Bank</li> <li>Healthcare</li> <li>Government &amp; Public</li> <li>IT Industry</li> <li>Retail and E-commerce</li> <li>Telecommunication</li> </ul>","tags":["Home"]},{"location":"#misc","title":"Misc","text":"<ul> <li>Agile Methodology</li> <li>Security Scan Tools</li> </ul>","tags":["Home"]},{"location":"#project-layout","title":"Project layout","text":"Tab Menu Languages Java Java 8 Java 17 Node.js Node.js Express.js Python Python Golang Golang Web Development Spring Spring Security Spring Boot Spring MVC Microservices SOLID Angular TypeScript React Lifecycle Methods Jest Enzyme ESLint Performance React Router Redux MQ Apache Kafka RabbitMQ Apache ActiveMQ Amazon SQS (Simple Queue Service) Microsoft Azure Google Cloud Pub/Sub Redis Pub/Sub DevOps DevOps AWS Azure GCP OpenShift VCS CI/CD Configuration Management Containerization and Orchestration Infrastructure as Code (IaC) Monitoring and Logging Container Registries Security Scanning and Compliance Artifact Repository GitOps Database Database Cassandra Couchbase DynamoDB MongoDB Oracle PostgreSql Redis Design Pattern Design Pattern Behavioral Pattern Creational Pattern Structural Pattern Other Pattern Algorithms Data Structures Algorithms QA Quality Assurance Cucumber Selenium Protractor Cypress WebdriverIO Apigee Cucumber Jest Mocha/Chai Karate Postman Rest Assured TestNG Appium Robot Framework JMeter Assessment Angular Java Spring React Node.js Python Project Company Bank Healthcare Government &amp; Public IT industry Retail and E-commerce Telecommunication Misc Agile methodology Security Scan Tools","tags":["Home"]},{"location":"angular/typescript/","title":"Typescript","text":""},{"location":"angular/typescript/#typescript_1","title":"Typescript","text":""},{"location":"assessment/angular/","title":"Angular Assessment","text":""},{"location":"assessment/angular/#expense-list-angular-14","title":"Expense List - Angular 14","text":""},{"location":"assessment/angular/#project-overview","title":"Project Overview","text":"<p>The objective of this code challenge is to test your understanding of Angular. In this problem, you are given a partially implemented Expense List Application, which you need to complete and make functional as desired.</p>"},{"location":"assessment/angular/#task","title":"Task","text":"<p>You have the following tasks: 1. Make Add to List button work. 2. The functionality to Edit an item is not working. It should be fixed. 3. Updating an entered item is not working. It should be fixed. 4. Removing an item from the list is not working. It should be fixed.</p>"},{"location":"assessment/angular/#relevant-project-files","title":"Relevant Project Files","text":"<ol> <li>/src/app/app.component.ts</li> </ol>"},{"location":"assessment/angular/#technology-stack","title":"Technology Stack","text":"<p>Front end: Angular</p>"},{"location":"assessment/angular/#how-to-use-the-environment","title":"How to Use the Environment","text":"<ul> <li>When you launch the workspace, the complete project will open with all the relevant files in multiple tabs. Review them carefully.</li> <li>To save your work, click on the [SAVE ALL] button. An unsaved file will show a green dot near the filename on the tab.</li> <li>To see the outcome of your work and interact with the application, click on the [LAUNCH APP] button. It will open the application on a new browser tab.</li> </ul>"},{"location":"assessment/angular/#expense-list-app-interface","title":"Expense List App Interface","text":""},{"location":"assessment/angular/#component-typescript-file","title":"Component TypeScript File","text":"<pre><code>import { Component } from '@angular/core';\n\ninterface ListExpense {\n  id: number;\n  name: string;\n  amount: number;\n}\n\n@Component({\n  selector: 'app-root',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.css']\n})\nexport class AppComponent {\n  title = 'Expense List App';\n  listExpenses: ListExpense[] = [];\n\n  newExpenseName: string = '';\n  newExpenseAmount: number = 0;\n\n  editingIndex: number | null = null; \n\n  addToList() {\n    if (this.newExpenseName &amp;&amp; this.newExpenseAmount &gt; 0) {\n      // Write your code here to add expenses to the list\n      this.listExpenses.push({\n        id: this.listExpenses.length + 1,\n        name: this.newExpenseName,\n        amount: this.newExpenseAmount\n      });\n      this.newExpenseName = '';\n      this.newExpenseAmount = 0;\n    }\n  }\n\n  removeFromList(index: number) {\n    // Write your code here to remove an expense from the list\n    this.listExpenses.splice(index, 1);\n  }\n\n  editExpense(index: number) {\n    // Write your code here to edit an expense\n    this.editingIndex = index;\n    this.newExpenseName = this.listExpenses[index].name;\n    this.newExpenseAmount = this.listExpenses[index].amount;\n  }\n\n  updateExpense() {\n    if (this.editingIndex !== null) {\n      // Write your code here to update an expense\n      this.listExpenses[this.editingIndex].name = this.newExpenseName;\n      this.listExpenses[this.editingIndex].amount = this.newExpenseAmount;\n      this.cancelEdit();\n    }\n  }\n\n  cancelEdit() {\n    this.editingIndex = null;\n    this.newExpenseName = '';\n    this.newExpenseAmount = 0;\n  }\n\n  calculateTotalAmount(): number {\n    let total = 0;\n    for (const expense of this.listExpenses) {\n      total += expense.amount;\n    }\n    return total;\n  }\n}\n</code></pre>"},{"location":"assessment/angular/#component-html-file-part-1","title":"Component HTML File (Part 1)","text":"<pre><code>&lt;!-- app.component.html --&gt;\n&lt;div class=\"container\"&gt;\n  &lt;h1&gt;\n    &lt;span class=\"title-icon\"&gt;&lt;/span&gt; {{ title }} &lt;span class=\"title-icon\"&gt;&lt;/span&gt;\n  &lt;/h1&gt;\n\n  &lt;div class=\"add-expense\"&gt;\n    &lt;h2&gt;{{ editingIndex == null ? 'Add Expense' : 'Edit Expense' }}&lt;/h2&gt;\n    &lt;div class=\"input-group\"&gt;\n      &lt;input type=\"text\" [(ngModel)]=\"newExpenseName\" placeholder=\"Expense Name\" /&gt;\n      &lt;input type=\"number\" [(ngModel)]=\"newExpenseAmount\" placeholder=\"Amount\" name=\"newExpenseAmount\" min=\"0\"/&gt;\n      &lt;button *ngIf=\"editingIndex == null\" (click)=\"addToList()\" class=\"add-button\"&gt;\n        {{ editingIndex == null ? 'Add to List' : 'Update' }}\n      &lt;/button&gt;\n    &lt;/div&gt;\n    &lt;div *ngIf=\"editingIndex != null\"&gt;\n      &lt;button (click)=\"updateExpense()\" class=\"update-button\"&gt;Update&lt;/button&gt;\n      &lt;button (click)=\"cancelEdit()\" class=\"cancel-button\"&gt;Cancel&lt;/button&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n</code></pre>"},{"location":"assessment/angular/#component-html-file-part-2","title":"Component HTML File (Part 2)","text":"<pre><code>  &lt;div class=\"list\"&gt;\n    &lt;h2&gt;\n      &lt;span class=\"heading-icon\"&gt;&lt;/span&gt; My Expense List &lt;span class=\"heading-icon\"&gt;&lt;/span&gt;\n    &lt;/h2&gt;\n    &lt;table&gt;\n      &lt;thead&gt;\n        &lt;tr&gt;\n          &lt;th&gt;Sl.No.&lt;/th&gt;\n          &lt;th&gt;Expense Name&lt;/th&gt;\n          &lt;th&gt;Amount&lt;/th&gt;\n          &lt;th&gt;Actions&lt;/th&gt;\n        &lt;/tr&gt;\n      &lt;/thead&gt;\n      &lt;tbody&gt;\n        &lt;tr *ngFor=\"let expense of listExpenses; let i = index\"&gt;\n          &lt;td&gt;{{ i + 1 }}&lt;/td&gt;\n          &lt;td&gt;{{ expense.name }}&lt;/td&gt;\n          &lt;td&gt;{{ expense.amount }}&lt;/td&gt;\n          &lt;td&gt;\n            &lt;button (click)=\"editExpense(i)\" class=\"edit-button\"&gt;Edit&lt;/button&gt;\n            &lt;button (click)=\"removeFromList(i)\" class=\"remove-button\"&gt;Remove&lt;/button&gt;\n          &lt;/td&gt;\n        &lt;/tr&gt;\n      &lt;/tbody&gt;\n    &lt;/table&gt;\n  &lt;/div&gt;\n  &lt;div class=\"total-amount\" style=\"margin-top: 20px; text-align: center;\"&gt;\n    &lt;h2 style=\"font-size: 1.2em;\"&gt;Total Expense Amount: {{ calculateTotalAmount() | currency:'USD':'symbol-narrow' }}&lt;/h2&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"assessment/angular/#module-typescript-file","title":"Module TypeScript File","text":"<pre><code>import { NgModule } from '@angular/core';\nimport { BrowserModule } from '@angular/platform-browser';\nimport { HttpClientModule } from '@angular/common/http';\nimport { FormsModule } from '@angular/forms';\n\nimport { AppComponent } from './app.component';\n\n@NgModule({\n  declarations: [\n    AppComponent\n  ],\n  imports: [\n    BrowserModule, HttpClientModule, FormsModule\n  ],\n  providers: [],\n  bootstrap: [AppComponent]\n})\nexport class AppModule { }\n</code></pre>"},{"location":"assessment/java/","title":"Java","text":""},{"location":"assessment/java/#perfect-number","title":"Perfect Number","text":"<p>Perfect Number: A (positive integer) number is called a perfect number, if the sum of all of its factors, except the number itself, is equal to the number itself, then that number is called a perfect number. For example, all the factors of number 6 are: 1, 2. 3, and 6. But, we have to remove 6 from that list; so if you add 1 + 2 + 3: you get 6! So, 6 is a perfect number.</p> <p>Problem Statement: Write a program to find all perfect numbers between 1 and given number N.</p>"},{"location":"assessment/java/#find-perfect-numbers-between-1-and-n","title":"Find Perfect Numbers Between 1 and N","text":"<p>Here's a Java program to find all perfect numbers between 1 and a given number N:</p> <pre><code>public class PerfectNumbers {\n\n    public static void main(String[] args) {\n        int n = 100; // Change this to your desired upper limit\n\n        for (int i = 1; i &lt;= n; i++) {\n            if (isPerfectNumber(i)) {\n                System.out.println(i + \" is a perfect number.\");\n            }\n        }\n    }\n\n    private static boolean isPerfectNumber(int n) {\n        int sumOfFactors = 0;\n        for (int i = 1; i &lt; n; i++) {\n            if (n % i == 0) {\n                sumOfFactors += i;\n            }\n        }\n        return sumOfFactors == n;\n    }\n}\n</code></pre>"},{"location":"assessment/java/#explanation","title":"Explanation:","text":"<ol> <li><code>main</code> method:<ul> <li>Sets the upper limit for finding perfect numbers (<code>n</code>) - replace 100 with your desired value.</li> <li>Loops through all numbers from 1 to <code>n</code>.</li> <li>Calls <code>isPerfectNumber(i)</code> for each number and checks if it returns true.</li> <li>If true, prints the number as a perfect number.</li> </ul> </li> <li><code>isPerfectNumber(n)</code> method:<ul> <li>Initializes a variable <code>sumOfFactors</code> to 0.</li> <li>Loops through all numbers from 1 to <code>n-1</code> (excluding <code>n</code> itself).</li> <li>Checks if the current number (<code>i</code>) is a factor of <code>n</code> using the modulo operator (<code>%</code>).</li> <li>If it is a factor, adds it to <code>sumOfFactors</code>.</li> <li>After the loop, checks if <code>sumOfFactors</code> is equal to <code>n</code>.</li> <li>If they are equal, the number is a perfect number and the method returns true. Otherwise, it returns false.</li> </ul> </li> </ol>"},{"location":"assessment/java/#brief-overview","title":"Brief Overview:","text":"<p>The task is to write a Java program to find all perfect numbers between 1 and a given number N. A perfect number is one where the sum of its factors (excluding the number itself) equals the number.</p> <p>Step-by-Step Plan: 1. Create a method to find all factors of a number and calculate their sum. 2. In the main method, iterate from 1 to N. 3. For each number, use the method from step 1 to check if it's a perfect number. 4. Collect and print all perfect numbers found.</p> <p>Code with Comments:</p> <pre><code>public class PerfectNumbers {\n\n    // Method to calculate the sum of factors of a number\n    private static int sumOfFactors(int number) {\n        int sum = 1; // Start with 1 because it is a factor of all numbers\n        // Iterate over possible factors up to half of the number\n        for (int i = 2; i &lt;= number / 2; i++) {\n            if (number % i == 0) {\n                sum += i; // If 'i' is a factor, add it to sum\n            }\n        }\n        return sum;\n    }\n\n    // Main method to execute the program\n    public static void main(String[] args) {\n        int N = 10000; // Example: Find perfect numbers up to 10,000\n        for (int i = 2; i &lt;= N; i++) {\n            if (sumOfFactors(i) == i) {\n                System.out.println(i + \" is a perfect number.\");\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"assessment/java/#complexity-analysis","title":"Complexity Analysis:","text":"<ul> <li>Time Complexity: O(n*sqrt(n)) because for each number up to N, we check up to its square root to find factors.</li> <li>Space Complexity: O(1) since we are not using any additional space that scales with the input size.</li> </ul>"},{"location":"assessment/java/#example-walkthrough","title":"Example Walkthrough:","text":"<p>Let's walk through the code with N = 28. - <code>sumOfFactors(2)</code> returns 1, which is not equal to 2, so it's not a perfect number. - This process repeats until <code>sumOfFactors(28)</code> which returns 1+2+4+7+14 = 28, so 28 is printed as a perfect number.</p>"},{"location":"devops/artifact/","title":"Artifact Repository","text":"","tags":["Nexus Repository","JFrog Artifactory"]},{"location":"devops/artifact/#nexus-repository","title":"Nexus Repository","text":"","tags":["Nexus Repository","JFrog Artifactory"]},{"location":"devops/artifact/#jfrog-artifactory","title":"JFrog Artifactory","text":"","tags":["Nexus Repository","JFrog Artifactory"]},{"location":"devops/cicd/","title":"Continuous Integration/Continuous Deployment (CI/CD)","text":"<p>Continuous Integration/Continuous Deployment (CI/CD):</p>","tags":["Jenkins","Travis CI","CircleCI","GitLab CI/CD","Azure DevOps","TeamCity","Bamboo"]},{"location":"devops/cicd/#jenkins","title":"Jenkins","text":"","tags":["Jenkins","Travis CI","CircleCI","GitLab CI/CD","Azure DevOps","TeamCity","Bamboo"]},{"location":"devops/cicd/#bamboo","title":"Bamboo","text":"","tags":["Jenkins","Travis CI","CircleCI","GitLab CI/CD","Azure DevOps","TeamCity","Bamboo"]},{"location":"devops/cicd/#travis-ci","title":"Travis CI","text":"","tags":["Jenkins","Travis CI","CircleCI","GitLab CI/CD","Azure DevOps","TeamCity","Bamboo"]},{"location":"devops/cicd/#circleci","title":"CircleCI","text":"","tags":["Jenkins","Travis CI","CircleCI","GitLab CI/CD","Azure DevOps","TeamCity","Bamboo"]},{"location":"devops/cicd/#gitlab-cicd","title":"GitLab CI/CD","text":"","tags":["Jenkins","Travis CI","CircleCI","GitLab CI/CD","Azure DevOps","TeamCity","Bamboo"]},{"location":"devops/cicd/#azure-devops","title":"Azure DevOps","text":"","tags":["Jenkins","Travis CI","CircleCI","GitLab CI/CD","Azure DevOps","TeamCity","Bamboo"]},{"location":"devops/cicd/#teamcity","title":"TeamCity","text":"","tags":["Jenkins","Travis CI","CircleCI","GitLab CI/CD","Azure DevOps","TeamCity","Bamboo"]},{"location":"devops/config/","title":"Configuration Management","text":"","tags":["Ansible","Puppet","Chef","Terraform"]},{"location":"devops/config/#ansible","title":"Ansible","text":"","tags":["Ansible","Puppet","Chef","Terraform"]},{"location":"devops/config/#puppet","title":"Puppet","text":"","tags":["Ansible","Puppet","Chef","Terraform"]},{"location":"devops/config/#terraform","title":"Terraform","text":"","tags":["Ansible","Puppet","Chef","Terraform"]},{"location":"devops/config/#chef","title":"Chef","text":"","tags":["Ansible","Puppet","Chef","Terraform"]},{"location":"devops/container/","title":"Container Registries","text":"","tags":["Docker Hub","Amazon ECR (Elastic Container Registry)","Google Container Registry (GCR)","Azure Container Registry (ACR)"]},{"location":"devops/container/#docker-hub","title":"Docker Hub","text":"","tags":["Docker Hub","Amazon ECR (Elastic Container Registry)","Google Container Registry (GCR)","Azure Container Registry (ACR)"]},{"location":"devops/container/#amazon-ecr-elastic-container-registry","title":"Amazon ECR (Elastic Container Registry)","text":"","tags":["Docker Hub","Amazon ECR (Elastic Container Registry)","Google Container Registry (GCR)","Azure Container Registry (ACR)"]},{"location":"devops/container/#google-container-registry-gcr","title":"Google Container Registry (GCR)","text":"","tags":["Docker Hub","Amazon ECR (Elastic Container Registry)","Google Container Registry (GCR)","Azure Container Registry (ACR)"]},{"location":"devops/container/#azure-container-registry-acr","title":"Azure Container Registry (ACR)","text":"","tags":["Docker Hub","Amazon ECR (Elastic Container Registry)","Google Container Registry (GCR)","Azure Container Registry (ACR)"]},{"location":"devops/gitops/","title":"GitOps","text":"","tags":["ArgoCD","FluxCD"]},{"location":"devops/gitops/#argocd","title":"ArgoCD","text":"","tags":["ArgoCD","FluxCD"]},{"location":"devops/gitops/#fluxcd","title":"FluxCD","text":"","tags":["ArgoCD","FluxCD"]},{"location":"devops/iac/","title":"Infrastructure as Code (IaC)","text":"","tags":["AWS CloudFormation","Azure Resource Manager (ARM) Templates","Google Cloud Deployment Manager","Terraform"]},{"location":"devops/iac/#terraform","title":"Terraform","text":"","tags":["AWS CloudFormation","Azure Resource Manager (ARM) Templates","Google Cloud Deployment Manager","Terraform"]},{"location":"devops/iac/#aws-cloudformation","title":"AWS CloudFormation","text":"","tags":["AWS CloudFormation","Azure Resource Manager (ARM) Templates","Google Cloud Deployment Manager","Terraform"]},{"location":"devops/iac/#azure-resource-manager-arm-templates","title":"Azure Resource Manager (ARM) Templates","text":"","tags":["AWS CloudFormation","Azure Resource Manager (ARM) Templates","Google Cloud Deployment Manager","Terraform"]},{"location":"devops/iac/#google-cloud-deployment-manager","title":"Google Cloud Deployment Manager","text":"","tags":["AWS CloudFormation","Azure Resource Manager (ARM) Templates","Google Cloud Deployment Manager","Terraform"]},{"location":"devops/logging/","title":"Monitoring and Logging","text":"","tags":["Prometheus","Grafana","ELK Stack (Elasticsearch, Logstash, Kibana)","Splunk","New Relic","Datadog"]},{"location":"devops/logging/#splunk","title":"Splunk","text":"","tags":["Prometheus","Grafana","ELK Stack (Elasticsearch, Logstash, Kibana)","Splunk","New Relic","Datadog"]},{"location":"devops/logging/#grafana","title":"Grafana","text":"","tags":["Prometheus","Grafana","ELK Stack (Elasticsearch, Logstash, Kibana)","Splunk","New Relic","Datadog"]},{"location":"devops/logging/#elk-stack-elasticsearch-logstash-kibana","title":"ELK Stack (Elasticsearch, Logstash, Kibana)","text":"","tags":["Prometheus","Grafana","ELK Stack (Elasticsearch, Logstash, Kibana)","Splunk","New Relic","Datadog"]},{"location":"devops/logging/#prometheus","title":"Prometheus","text":"","tags":["Prometheus","Grafana","ELK Stack (Elasticsearch, Logstash, Kibana)","Splunk","New Relic","Datadog"]},{"location":"devops/logging/#new-relic","title":"New Relic","text":"","tags":["Prometheus","Grafana","ELK Stack (Elasticsearch, Logstash, Kibana)","Splunk","New Relic","Datadog"]},{"location":"devops/logging/#datadog","title":"Datadog","text":"","tags":["Prometheus","Grafana","ELK Stack (Elasticsearch, Logstash, Kibana)","Splunk","New Relic","Datadog"]},{"location":"devops/orchestration/","title":"Containerization and Orchestration","text":"","tags":["Docker","Kubernetes","Docker Swarm","Amazon ECS (Elastic Container Service)","Google Kubernetes Engine (GKE)","Azure Kubernetes Service (AKS)"]},{"location":"devops/orchestration/#docker","title":"Docker","text":"","tags":["Docker","Kubernetes","Docker Swarm","Amazon ECS (Elastic Container Service)","Google Kubernetes Engine (GKE)","Azure Kubernetes Service (AKS)"]},{"location":"devops/orchestration/#kubernetes","title":"Kubernetes","text":"","tags":["Docker","Kubernetes","Docker Swarm","Amazon ECS (Elastic Container Service)","Google Kubernetes Engine (GKE)","Azure Kubernetes Service (AKS)"]},{"location":"devops/orchestration/#docker-swarm","title":"Docker Swarm","text":"","tags":["Docker","Kubernetes","Docker Swarm","Amazon ECS (Elastic Container Service)","Google Kubernetes Engine (GKE)","Azure Kubernetes Service (AKS)"]},{"location":"devops/orchestration/#amazon-ecs-elastic-container-service","title":"Amazon ECS (Elastic Container Service)","text":"","tags":["Docker","Kubernetes","Docker Swarm","Amazon ECS (Elastic Container Service)","Google Kubernetes Engine (GKE)","Azure Kubernetes Service (AKS)"]},{"location":"devops/orchestration/#google-kubernetes-engine-gke","title":"Google Kubernetes Engine (GKE)","text":"","tags":["Docker","Kubernetes","Docker Swarm","Amazon ECS (Elastic Container Service)","Google Kubernetes Engine (GKE)","Azure Kubernetes Service (AKS)"]},{"location":"devops/orchestration/#azure-kubernetes-service-aks","title":"Azure Kubernetes Service (AKS)","text":"","tags":["Docker","Kubernetes","Docker Swarm","Amazon ECS (Elastic Container Service)","Google Kubernetes Engine (GKE)","Azure Kubernetes Service (AKS)"]},{"location":"devops/scanning/","title":"Security Scanning and Compliance","text":"","tags":["SonarQube","OWASP ZAP (Zed Attack Proxy)","Checkmarx","Nessus","Qualys"]},{"location":"devops/scanning/#sonarqube","title":"SonarQube","text":"","tags":["SonarQube","OWASP ZAP (Zed Attack Proxy)","Checkmarx","Nessus","Qualys"]},{"location":"devops/scanning/#checkmarx","title":"Checkmarx","text":"","tags":["SonarQube","OWASP ZAP (Zed Attack Proxy)","Checkmarx","Nessus","Qualys"]},{"location":"devops/scanning/#nessus","title":"Nessus","text":"","tags":["SonarQube","OWASP ZAP (Zed Attack Proxy)","Checkmarx","Nessus","Qualys"]},{"location":"devops/scanning/#qualys","title":"Qualys","text":"","tags":["SonarQube","OWASP ZAP (Zed Attack Proxy)","Checkmarx","Nessus","Qualys"]},{"location":"devops/scanning/#owasp-zap-zed-attack-proxy","title":"OWASP ZAP (Zed Attack Proxy)","text":"","tags":["SonarQube","OWASP ZAP (Zed Attack Proxy)","Checkmarx","Nessus","Qualys"]},{"location":"devops/vcs/","title":"Version Control Systems (VCS)","text":"","tags":["Git","GitHub","GitLab","Bitbucket"]},{"location":"devops/vcs/#bitbucket","title":"Bitbucket","text":"","tags":["Git","GitHub","GitLab","Bitbucket"]},{"location":"devops/vcs/#git","title":"Git","text":"","tags":["Git","GitHub","GitLab","Bitbucket"]},{"location":"devops/vcs/#github","title":"GitHub","text":"","tags":["Git","GitHub","GitLab","Bitbucket"]},{"location":"devops/vcs/#gitlab","title":"GitLab","text":"","tags":["Git","GitHub","GitLab","Bitbucket"]},{"location":"ds-algo/algorithms/","title":"Algorithms","text":""},{"location":"ds-algo/algorithms/#algorithms_1","title":"Algorithms","text":""},{"location":"java/","title":"Java","text":"<p>Java is a general-purpose, class-based, object-oriented programming language designed for having lesser implementation dependencies. It is a computing platform for application development. Java is fast, secure, and reliable, therefore. It is widely used for developing Java applications in laptops, data centers, game consoles, scientific supercomputers, cell phones, etc.</p>","tags":["Java"]},{"location":"java/#java-features","title":"Java Features","text":"<p>Here are some important Java features:</p> <ul> <li>It is one of the easy-to-use programming languages to learn.</li> <li>Write code once and run it on almost any computing platform.</li> <li>Java is platform-independent. Some programs developed in one machine can be executed in another machine.</li> <li>It is designed for building object-oriented applications.</li> <li>It is a multithreaded language with automatic memory management.</li> <li>It is created for the distributed environment of the Internet.</li> <li>Facilitates distributed computing as its network-centric.</li> </ul>","tags":["Java"]},{"location":"java/#components-of-java","title":"Components Of Java","text":"<p>A Java Programmer writes a program in a human-readable language called Source Code. Therefore, the CPU or Chips never understand the source code written in any programming language.</p>","tags":["Java"]},{"location":"java/#java-development-kit-jdk","title":"Java Development kit (JDK)","text":"<p>JDK is a software development environment used for making applets and Java applications. The full form of JDK is Java Development Kit. Java developers can use it on Windows, macOS, Solaris, and Linux. JDK helps them to code and run Java programs. It is possible to install more than one JDK version on the same computer.</p> <p>Why use JDK?</p> <p>Here are the main reasons for using JDK:</p> <p>JDK contains tools required to write Java programs and JRE to execute them. It includes a compiler, Java application launcher, Appletviewer, etc. Compiler converts code written in Java into byte code. Java application launcher opens a JRE, loads the necessary class, and executes its main method.</p>","tags":["Java"]},{"location":"java/#java-virtual-machine-jvm","title":"Java Virtual Machine (JVM)","text":"<p>Java Virtual Machine (JVM) is an engine that provides a runtime environment to drive the Java Code or applications. It converts Java bytecode into machine language. JVM is a part of the Java Run Environment (JRE). In other programming languages, the compiler produces machine code for a particular system. However, the Java compiler produces code for a Virtual Machine known as Java Virtual Machine.</p> <p>Why JVM?</p> <p>Here are the important reasons of using JVM:</p> <p>JVM provides a platform-independent way of executing Java source code. It has numerous libraries, tools, and frameworks. Once you run a Java program, you can run on any platform and save lots of time. JVM comes with JIT (Just-in-Time) compiler that converts Java source code into low-level machine language. Hence, it runs faster than a regular application.</p>","tags":["Java"]},{"location":"java/#java-runtime-environment-jre","title":"Java Runtime Environment (JRE)","text":"<p>JRE is a piece of software that is designed to run other software. It contains the class libraries, loader class, and JVM. In simple terms, if you want to run a Java program, you need JRE. If you are not a programmer, you don\u2019t need to install JDK, but just JRE to run Java programs.</p> <p>Why use JRE?</p> <p>Here are the main reasons of using JRE:</p> <p>JRE contains class libraries, JVM, and other supporting files. It does not include any tool for Java development like a debugger, compiler, etc. It uses important package classes like math, swing, util, lang, awt, and runtime libraries. If you have to run Java applets, then JRE must be installed in your system.</p>","tags":["Java"]},{"location":"java/#java-performance-troubleshooting","title":"Java performance troubleshooting","text":"<p>Java performance troubleshooting is the process of identifying and resolving performance issues in Java applications. Here are a few steps that can be taken to troubleshoot performance issues in Java:</p>","tags":["Java"]},{"location":"java/#profiling","title":"Profiling","text":"<p>Use a profiler to identify performance bottlenecks in the application. Profilers can provide detailed information about the performance of the application, including information about CPU usage, memory usage, and thread activity. Popular profilers for Java include VisualVM, JProfiler, and YourKit.</p>","tags":["Java"]},{"location":"java/#logging","title":"Logging","text":"<p>Add logging statements to the application to track the flow of execution. This can help identify where the application is spending most of its time and can help identify the source of performance issues.</p>","tags":["Java"]},{"location":"java/#monitoring","title":"Monitoring","text":"<p>Use monitoring tools to track the performance of the application in production. These tools can provide information about resource usage, response times, and errors. Popular monitoring tools for Java include JMX, JConsole, and JavaMelody.</p>","tags":["Java"]},{"location":"java/#thread-dump","title":"Thread dump","text":"<p>Thread dump is a snapshot of all threads that are running in a java process. Thread dump can be captured using jstack command in linux or jcmd command in windows. Thread dump analysis can help to identify the blocked threads, deadlock, resource contention and more.</p>","tags":["Java"]},{"location":"java/#memory-dump","title":"Memory dump","text":"<p>Memory dump is a snapshot of the heap memory of a java process. Memory dump can be captured using jmap command in linux or jcmd command in windows. Memory dump analysis can help to identify memory leaks, object retention, and more.</p>","tags":["Java"]},{"location":"java/#code-review","title":"Code review","text":"<p>Review the application's code to identify any potential performance issues. Look for common performance anti-patterns such as poor caching strategy, unnecessary object creation, and inefficient algorithms.</p>","tags":["Java"]},{"location":"java/#testing","title":"Testing","text":"<p>Test the application under different load conditions to identify performance issues that may not be visible in normal usage. Use load testing tools like Apache JMeter or Gatling to simulate different levels of traffic and usage patterns. This can help identify bottlenecks and scalability issues that may not be visible during normal usage.</p>","tags":["Java"]},{"location":"java/#configuration-review","title":"Configuration review","text":"<p>Review the application's configuration to ensure that it is optimized for performance. This includes reviewing settings such as JVM heap size, GC settings, thread pool sizes, and connection pool sizes.</p>","tags":["Java"]},{"location":"java/#data-analysis","title":"Data Analysis","text":"<p>Look for patterns in your data that could be causing performance issues. Use SQL profiler to identify slow queries and indexes that could be improved. Analyze the data to identify any data issues that could be impacting performance.</p>","tags":["Java"]},{"location":"java/#network","title":"Network","text":"<p>Network issues can also cause performance problems. Check for network bottlenecks, dropped packets, and other network-related problems.</p> <p>It's important to note that performance troubleshooting can be a complex process, and it may be necessary to use multiple techniques to fully identify and resolve a performance issue. It's also important to have a clear understanding of the requirements of the application, as well as the expected usage patterns, to effectively troubleshoot performance issues.</p>","tags":["Java"]},{"location":"java/#exceptions","title":"Exceptions","text":"<p>Exception is an error event that can happen during the execution of a program and disrupts its normal flow.</p> <p>Types of Java Exceptions</p>","tags":["Java"]},{"location":"java/#checked-exception","title":"Checked Exception","text":"<p>The classes which directly inherit Throwable class except RuntimeException and Error are known as checked exceptions e.g. IOException, SQLException etc. Checked exceptions are checked at compile-time.</p>","tags":["Java"]},{"location":"java/#unchecked-exception","title":"Unchecked Exception","text":"<p>The classes which inherit RuntimeException are known as unchecked exceptions e.g. ArithmeticException, NullPointerException, ArrayIndexOutOfBoundsException etc. Unchecked exceptions are not checked at compile-time, but they are checked at runtime.</p>","tags":["Java"]},{"location":"java/#error","title":"Error","text":"<p>Error is irrecoverable e.g. OutOfMemoryError, VirtualMachineError, AssertionError etc.</p>","tags":["Java"]},{"location":"java/#hierarchy-of-java-exception-classes","title":"Hierarchy of Java Exception classes","text":"","tags":["Java"]},{"location":"java/#error-vs-exception","title":"Error vs Exception","text":"BASIS FOR COMPARISON ERROR EXCEPTION Basic An error is caused due to lack of system resources. An exception is caused because of the code. Recovery An error is irrecoverable. An exception is recoverable. Keywords There is no means to handle an error by the program code. Exceptions are handled using three keywords \"try\", \"catch\", and \"throw\". Consequences As the error is detected the program will terminated abnormally. As an exception is detected, it is thrown and caught by the \"throw\" and \"catch\" keywords correspondingly. Types Errors are classified as unchecked type. Exceptions are classified as checked or unchecked type. Package In Java, errors are defined \"java.lang.Error\" package. In Java, an exceptions are defined in\"java.lang.Exception\". Example OutOfMemory, StackOverFlow. Checked Exceptions: NoSuchMethod, ClassNotFound.Unchecked Exceptions: NullPointer, IndexOutOfBounds.","tags":["Java"]},{"location":"java/#custom-exception","title":"Custom exception","text":"<p>we can create our own exceptions that are derived classes of the Exception class. Creating our own Exception is known as custom exception or user-defined exception.</p> <p>Why we need for custom exceptions?</p> <ul> <li>To catch and provide specific treatment to a subset of existing Java exceptions.</li> <li><code>Business logic exceptions</code>: These are the exceptions related to business logic and workflow. It is useful for the application users or the developers to understand the exact problem.</li> </ul>","tags":["Java"]},{"location":"java/#exception-propagation","title":"Exception Propagation","text":"<p>An exception is first thrown from the top of the stack and if it is not caught, it drops down the call stack to the previous method, If not caught there, the exception again drops down to the previous method, and so on until they are caught or until they reach the very bottom of the call stack. This is called exception propagation.</p> <pre><code>class TestExceptionPropagation {\n\n  void m() {  \n    int data = 50/0;  \n  }  \n  void n() {  \n    m();  \n  }  \n  void p() {  \n      try {  \n         n();  \n      } catch(Exception e) { \n         System.out.println(\"exception handled\");\n      }  \n  }  \n  public static void main(String args[]) {  \n   TestExceptionPropagation obj = new TestExceptionPropagation();  \n   obj.p();  \n   System.out.println(\"Normal Flow...\");  \n  }  \n}  \n</code></pre>","tags":["Java"]},{"location":"java/#classloader","title":"Classloader","text":"<p>The Java ClassLoader is a part of the Java Runtime Environment that dynamically loads Java classes into the Java Virtual Machine. Java code is compiled into class file by javac compiler and JVM executes Java program, by executing byte codes written in class file. ClassLoader is responsible for loading class files from file system, network or any other source.</p> <p>Types of ClassLoader</p>","tags":["Java"]},{"location":"java/#bootstrap-class-loader","title":"Bootstrap Class Loader","text":"<p>It loads standard JDK class files from rt.jar and other core classes. It loads class files from jre/lib/rt.jar. For example, java.lang package class.</p>","tags":["Java"]},{"location":"java/#extensions-class-loader","title":"Extensions Class Loader","text":"<p>It loads classes from the JDK extensions directly usually JAVA_HOME/lib/ext directory or any other directory as java.ext.dirs.</p>","tags":["Java"]},{"location":"java/#system-class-loader","title":"System Class Loader","text":"<p>It loads application specific classes from the CLASSPATH environment variable. It can be set while invoking program using -cp or classpath command line options.</p>","tags":["Java"]},{"location":"java/#types-of-memory-areas-are-allocated-by-jvm","title":"Types of memory areas are allocated by JVM","text":"<p>JVM is a program which takes Java bytecode and converts the byte code (line by line) into machine understandable code. JVM perform some particular types of operations:</p> <p>Loading of code Verification of code Executing the code It provide run-time environment to the users Types of Memory areas allocated by the JVM:</p> <ol> <li>Classloader: Classloader is a subsystem of JVM that is used to load class files.</li> <li>Class(Method) Area: Class(Method) Area stores per-class structures such as the runtime constant pool, field and method data, the code for methods.</li> <li>Heap: It is the runtime data area in which objects are allocated.</li> <li>Stack: Java Stack stores frames.It holds local variables and partial results, and plays a part in method invocation and return. Each thread has a private JVM stack, created at the same time as thread.</li> <li>Program Counter Register: PC (program counter) register. It contains the address of the Java virtual machine instruction currently being executed.</li> <li>Native Method Stack: It contains all the native methods used in the application.</li> </ol>","tags":["Java"]},{"location":"java/#java-reflection-api","title":"Java Reflection API","text":"<p>Java Reflection is the process of analyzing and modifying all the capabilities of a class at runtime. Reflection API in Java is used to manipulate class and its members which include fields, methods, constructor, etc. at runtime. The java.lang.Class class provides many methods that can be used to get metadata, examine and change the run time behavior of a class.</p> <p>There are 3 ways to get the instance of Class class. They are as follows:</p> <ul> <li>forName() method of Class class</li> <li>getClass() method of Object class</li> <li>the .class syntax</li> </ul> <p>1. forName() method of Class class</p> <ul> <li>is used to load the class dynamically.</li> <li>returns the instance of Class class.</li> <li>It should be used if you know the fully qualified name of class.This cannot be used for primitive types.</li> </ul> <pre><code>class Simple{}  \n\nclass Test {  \n   public static void main(String args[]) {  \n      Class c = Class.forName(\"Simple\");  \n      System.out.println(c.getName());  \n   }  \n}  \n</code></pre> <p>Output</p> <pre><code>Simple\n</code></pre> <p>2. getClass() method of Object class</p> <p>It returns the instance of Class class. It should be used if you know the type. Moreover, it can be used with primitives.</p> <pre><code>class Simple{}  \n\nclass Test {  \n  void printName(Object obj) {  \n    Class c=obj.getClass();    \n    System.out.println(c.getName());  \n  }  \n  public static void main(String args[]) {  \n    Simple s=new Simple();  \n    Test t=new Test();  \n    t.printName(s);  \n  }  \n}  \n</code></pre> <p>Output <pre><code>Simple\n</code></pre> 3. The .class syntax</p> <p>If a type is available but there is no instance then it is possible to obtain a Class by appending \".class\" to the name of the type.It can be used for primitive data type also.</p> <pre><code>class Test {  \n  public static void main(String args[]) {  \n   Class c = boolean.class;   \n   System.out.println(c.getName());  \n\n   Class c2 = Test.class;   \n   System.out.println(c2.getName());  \n }  \n}  \n</code></pre> <p>Output</p> <pre><code>boolean\nTest\n</code></pre>","tags":["Java"]},{"location":"java/#misc-questions","title":"Misc Questions","text":"","tags":["Java"]},{"location":"java/#can-you-declare-the-main-method-as-final","title":"Can you declare the main method as final?","text":"<p>Yes. We can declare main method as final. But, In inheritance concept we cannot declare main method as final in parent class. It give compile time error. The main method has to be public because it has to be called by JVM which is outside the scope of the package and hence would need the access specifier-public.</p> <pre><code>public class Test {\n    public final static void main(String[] args) throws Exception {\n        System.out.println(\"This is Test Class\");\n    }\n}\n\nclass Child extends Test {\n    public static void main(String[] args) throws Exception {\n        System.out.println(\"This is Child Class\");\n    }\n}\n</code></pre> <p>Output <pre><code>Cannot override the final method from Test.\n</code></pre></p>","tags":["Java"]},{"location":"java/#what-is-the-difference-between-abstract-class-and-interface","title":"What is the difference between abstract class and interface?","text":"<p>Abstract class and interface both are used to achieve abstraction where we can declare the abstract methods. Abstract class and interface both can't be instantiated.</p> Sl.No Abstract Class Interface 01. Abstract class can have abstract and non-abstract methods. Interface can have only abstract methods. Since Java 8, it can have default and static methods also. 02. Abstract class doesn't support multiple inheritance. Interface supports multiple inheritance. 03. Abstract class can have final, non-final, static and non-static variables. Interface has only static and final variables. 04. Abstract class can provide the implementation of interface. Interface can't provide the implementation of abstract class. 05. The abstract keyword is used to declare abstract class. The interface keyword is used to declare interface. 06. An abstract class can extend another Java class and implement multiple Java interfaces. An interface can extend another Java interface only. 07. An abstract class can be extended using keyword \"extends\". An interface can be implemented using keyword \"implements\". 08. A Java abstract class can have class members like private, protected, etc. Members of a Java interface are public by default.","tags":["Java"]},{"location":"java/#what-are-wrapper-classes","title":"What are Wrapper classes?","text":"<p>The wrapper class in Java provides the mechanism to convert primitive into object and object into primitive.</p> <p>Use of Wrapper classes in Java</p> <ul> <li>Change the value in Method: Java supports only call by value. So, if we pass a primitive value, it will not change the original value. But, if we convert the primitive value in an object, it will change the original value.</li> <li>Serialization: We need to convert the objects into streams to perform the serialization. If we have a primitive value, we can convert it in objects through the wrapper classes.</li> <li>Synchronization: Java synchronization works with objects in Multithreading.</li> <li>java.util package: The java.util package provides the utility classes to deal with objects.</li> <li>Collection Framework: Java collection framework works with objects only. All classes of the collection framework (ArrayList, LinkedList, Vector, HashSet, LinkedHashSet, TreeSet, PriorityQueue, ArrayDeque, etc.) deal with objects only.</li> </ul> Sl.No Primitive Type Wrapper class 01. boolean Boolean 02. char Character 03. byte Byte 04. short Short 05. int Integer 06. long Long 07. float Float 08. double Double <p>Example: Primitive to Wrapper</p> <p><pre><code>//Java program to convert primitive into objects  \n//Autoboxing example of int to Integer  \nclass WrapperExample {  \n  public static void main(String args[]){  \n      //Converting int into Integer  \n      int a=20;  \n      Integer i = Integer.valueOf(a);//converting int into Integer explicitly  \n      Integer j = a; //autoboxing, now compiler will write Integer.valueOf(a) internally  \n\n   System.out.println(a+\" \"+i+\" \"+j);  \n  }\n}  \n</code></pre> Output <pre><code>20 20 20\n</code></pre></p>","tags":["Java"]},{"location":"java/#what-are-the-restrictions-that-are-applied-to-the-java-static-methods","title":"What are the restrictions that are applied to the Java static methods?","text":"<p>If a method is declared as static, it is a member of a class rather than belonging to the object of the class. It can be called without creating an object of the class. A static method also has the power to access static data members of the class.</p> <ul> <li>There are a few restrictions imposed on a static method</li> <li>The static method cannot use non-static data member or invoke non-static method directly.</li> <li>The <code>this</code> and <code>super</code> cannot be used in static context.</li> <li>The static method can access only static type data (static type instance variable).</li> <li>There is no need to create an object of the class to invoke the static method.</li> <li>A static method cannot be overridden in a subclass</li> </ul> <p><pre><code>class Parent {\n   static void display() {\n      System.out.println(\"Super class\");    \n   }\n}\npublic class Example extends Parent {\n   void display()  // trying to override display() {\n      System.out.println(\"Sub class\");  \n   }\n   public static void main(String[] args) {\n      Parent obj = new Example();\n      obj.display();\n   }\n}\n</code></pre> This generates a compile time error. The output is as follows \u2212</p> <pre><code>Example.java:10: error: display() in Example cannot override display() in Parent\nvoid display()  // trying to override display()\n     ^\noverridden method is static\n\n1 error\n</code></pre>","tags":["Java"]},{"location":"java/#what-is-the-difference-between-serializable-and-externalizable-interface","title":"What is the difference between Serializable and Externalizable interface?","text":"Sl.No SERIALIZABLE EXTERNALIZABLE 01. Serializable is a marker interface i.e. does not contain any method. Externalizable interface contains two methods writeExternal() and readExternal() which implementing classes MUST override. 02. Serializable interface pass the responsibility of serialization to JVM and it\u2019s default algorithm. Externalizable provides control of serialization logic to programmer \u2013 to write custom logic. 03. Mostly, default serialization is easy to implement, but has higher performance cost. Serialization done using Externalizable, add more responsibility to programmer but often result in better performance. 04. It\u2019s hard to analyze and modify class structure because any change may break the serialization. It\u2019s more easy to analyze and modify class structure because of complete control over serialization logic. 05. Default serialization does not call any class constructor. A public no-arg constructor is required while using Externalizable interface.","tags":["Java"]},{"location":"java/#what-are-the-ways-to-instantiate-the-class-class","title":"What are the ways to instantiate the Class class?","text":"","tags":["Java"]},{"location":"java/#1-using-new-keyword","title":"1. Using new keyword","text":"<pre><code>MyObject object = new MyObject();\n</code></pre>","tags":["Java"]},{"location":"java/#2-using-classforname","title":"2. Using Class.forName()","text":"<pre><code>MyObject object = (MyObject) Class.forName(\"subin.rnd.MyObject\").newInstance();\n</code></pre>","tags":["Java"]},{"location":"java/#3-using-clone","title":"3. Using clone()","text":"<pre><code>MyObject anotherObject = new MyObject();\nMyObject object = (MyObject) anotherObject.clone();\n</code></pre>","tags":["Java"]},{"location":"java/#4-using-object-deserialization","title":"4. Using object deserialization","text":"<pre><code>ObjectInputStream inStream = new ObjectInputStream(anInputStream );\nMyObject object = (MyObject) inStream.readObject();\n</code></pre>","tags":["Java"]},{"location":"java/#what-is-the-difference-between-creating-string-as-new-and-literal","title":"What is the difference between creating String as new() and literal?","text":"<p>When you create String object using <code>new()</code> operator, it always create a new object in heap memory. On the other hand, if you create object using String literal syntax e.g. \"Java\", it may return an existing object from String pool (a cache of String object in Perm gen space, which is now moved to heap space in recent Java release), if it's already exists. Otherwise it will create a new string object and put in string pool for future re-use.</p> <pre><code>String a = \"abc\"; \nString b = \"abc\";\nSystem.out.println(a == b);  // true\n\nString c = new String(\"abc\");\nString d = new String(\"abc\");\nSystem.out.println(c == d);  // false\n</code></pre>","tags":["Java"]},{"location":"java/#what-is-difference-between-string-stringbuffer-and-stringbuilder","title":"What is difference between String, StringBuffer and StringBuilder?","text":"","tags":["Java"]},{"location":"java/#mutability-difference","title":"Mutability Difference","text":"<p><code>String</code> is immutable, if you try to alter their values, another object gets created, whereas <code>StringBuffer</code> and <code>StringBuilder</code> are mutable so they can change their values.</p>","tags":["Java"]},{"location":"java/#thread-safety-difference","title":"Thread-Safety Difference","text":"<p>The difference between <code>StringBuffer</code> and <code>StringBuilder</code> is that StringBuffer is thread-safe. So when the application needs to be run only in a single thread then it is better to use StringBuilder. StringBuilder is more efficient than StringBuffer.</p> <p>Example: StringBuffer</p> <pre><code>public class BufferTest{  \n   public static void main(String[] args){  \n        StringBuffer buffer=new StringBuffer(\"Hello\");  \n        buffer.append(\" World\");  \n        System.out.println(buffer);  \n   }  \n}  \n</code></pre> <p>Example: StringBuilder</p> <pre><code>public class BuilderTest{  \n    public static void main(String[] args){  \n        StringBuilder builder=new StringBuilder(\"Hello\");  \n        builder.append(\" World\");  \n        System.out.println(builder);  \n    }  \n}  \n</code></pre>","tags":["Java"]},{"location":"java/#for-more-information","title":"For more information","text":"<ol> <li>Java, J2EE, JSP, Servlet, Hibernate Interview Questions</li> </ol>","tags":["Java"]},{"location":"java/collection-framework/","title":"Collection Framework","text":"<p>{: .no_toc }</p>      Table of contents    <p>{: .text-delta } 1. TOC</p> <p>Collection framework represents an architecture to store and manipulate a group of objects. All the classes and interfaces of this framework are present in java.util package.</p> <p>Some points: - Iterable interface is the root interface for all collection classes, it has one abstract method iterator() - Collection interface extends the Iterable interface</p>"},{"location":"java/collection-framework/#arraylist","title":"ArrayList","text":"<ul> <li>An ArrayList is a re-sizable array, also called a dynamic array. It grows its size to accommodate new elements and shrinks the size when the elements are removed.</li> <li>ArrayList internally uses an array to store the elements. Just like arrays, It allows you to retrieve the elements by their index.</li> <li>ArrayList allows duplicate and null values.</li> <li>ArrayList is an ordered collection. It maintains the insertion order of the elements.</li> <li>You cannot create an ArrayList of primitive types like int, char etc. You need to use boxed types like Integer, Character, Boolean etc.</li> <li>ArrayList is not synchronized. If multiple threads try to modify an ArrayList at the same time, then the final outcome will be non-deterministic. You must explicitly synchronize access to an ArrayList if multiple threads are gonna modify it.</li> </ul>"},{"location":"java/collection-framework/#accessing-elements","title":"Accessing elements","text":"<ul> <li>check if an ArrayList is empty using the <code>isEmpty()</code> method.</li> <li>find the size of an ArrayList using the <code>size()</code> method.</li> <li>access the element at a particular index in an ArrayList using the <code>get()</code> method.</li> <li>modify the element at a particular index in an ArrayList using the <code>set()</code> method.</li> </ul>"},{"location":"java/collection-framework/#removing-elements","title":"Removing elements","text":"<ul> <li>remove the element at a given index in an ArrayList using <code>remove(int index)</code></li> <li>remove an element from an ArrayList using <code>remove(Object o)</code></li> <li>remove all the elements from an ArrayList that exist in a given collection using <code>removeAll()</code></li> <li>remove all the elements matching a given predicate using <code>removeIf()</code></li> <li>clear an ArrayList using <code>clear()</code></li> </ul>"},{"location":"java/collection-framework/#iterating-over-an-arraylist","title":"Iterating over an ArrayList","text":"<ul> <li>Java 8 forEach and lambda expression.</li> <li>iterator().</li> <li>iterator() and Java 8 forEachRemaining() method.</li> <li>listIterator().</li> <li>Simple for-each loop.</li> <li>for loop with index.</li> </ul>"},{"location":"java/collection-framework/#searching-for-elements-in-an-arraylist","title":"Searching for elements in an ArrayList","text":"<ul> <li>Check if an ArrayList contains a given element | contains()</li> <li>Find the index of the first occurrence of an element in an ArrayList | indexOf()</li> <li>Find the index of the last occurrence of an element in an ArrayList | lastIndexOf()</li> </ul>"},{"location":"java/collection-framework/#sorting-an-arraylist","title":"Sorting an ArrayList","text":"<ul> <li>Sort an ArrayList using <code>Collections.sort()</code> method.</li> <li>Sort an ArrayList using <code>ArrayList.sort()</code> method.</li> <li>Sort an ArrayList of user defined objects with a custom comparator.</li> </ul>"},{"location":"java/collection-framework/#hashmap","title":"HashMap","text":"<p>HashMap class implements the Map interface and it stores data in key, value pairs. HashMap provides constant time performance for its get() and put() operations, assuming the equals and hashcode method has been implemented properly, so that elements can be distributed correctly among the buckets.</p> <p>Some points to remember: - Keys should be unique in HashMap, if you try to insert the duplicate key, then it will override the corresponding key\u2019s value - HashMap may have one null key and multiple null values - HashMap does not guarantee the insertion order (if you want to maintain the insertion order, use LinkedHashMap class) - HashMap is not synchronized - HashMap uses an inner class Node for storing map entries - Hashmap has a default initial capacity of 16, which means it has 16 buckets or bins to store map entries, each bucket is a singly linked list. The default load factor in HashMap is 0.75 - Load factor is that threshold value which when crossed will double the hashmap\u2019s capacity i.e. when you add 13<sup>th</sup> element in hashmap, the capacity will increase from 16 to 32"},{"location":"java/collection-framework/#hashmap-internal-working-1","title":"HashMap Internal working 1","text":"<p>HashMap is a data structure that uses a hash function to map keys to their values. The internal working of HashMap in Java involves the following steps:</p>"},{"location":"java/collection-framework/#hashcode-calculation","title":"Hashcode Calculation","text":"<p>When a key is added to the HashMap, its hashcode is calculated using the hashCode() method. This hashcode is then used to determine the index of the bucket where the key-value pair will be stored.</p>"},{"location":"java/collection-framework/#buckets","title":"Buckets","text":"<p>The HashMap is divided into an array of buckets, where each bucket is a linked list of elements. The number of buckets is determined by the initial capacity of the HashMap.</p>"},{"location":"java/collection-framework/#resizing","title":"Resizing","text":"<p>If the number of elements in the HashMap exceeds the capacity of the buckets, the HashMap is resized to accommodate more elements. This is done by creating a new array of buckets with a larger capacity and rehashing all the elements to their new locations.</p>"},{"location":"java/collection-framework/#collision-resolution","title":"Collision Resolution","text":"<p>When two or more keys have the same hashcode, they are stored in the same bucket. This is known as a collision. HashMap uses a technique called open addressing to resolve collisions. In open addressing, if a collision occurs, the next available bucket is checked for an empty slot to store the key-value pair.</p>"},{"location":"java/collection-framework/#rehashing","title":"Rehashing","text":"<p>When a key-value pair is added to the HashMap, the key's hashcode is used to determine the index of the bucket where it should be stored. If the bucket is already full, the HashMap checks the next available bucket, and so on, until an empty slot is found.</p>"},{"location":"java/collection-framework/#iteration","title":"Iteration","text":"<p>To iterate over the elements of a HashMap, the HashMap's entrySet() method is used to return a Set view of the mappings contained in this map. The set is backed by the map, so changes to the map are reflected in the set, and vice-versa.</p>"},{"location":"java/collection-framework/#load-factor","title":"Load Factor","text":"<p>HashMap uses a load factor to determine when to resize the map. The load factor is a measure of how full the map is allowed to get before its capacity is automatically increased. The default load factor of HashMap is 0.75, meaning that the map can be filled to 75% of its capacity before it is resized.</p>"},{"location":"java/collection-framework/#concurrency","title":"Concurrency","text":"<p>HashMap is not thread-safe and it is not intended for use in concurrent environments. If multiple threads access a HashMap concurrently and at least one of the threads modifies the map, it must be synchronized externally.</p>"},{"location":"java/collection-framework/#performance","title":"Performance","text":"<p>HashMap provides constant-time performance for basic operations like get and put, assuming that the hash function distributes the keys evenly across the buckets. However, if the hash function is not good, the performance of the HashMap can degrade to linear time. Also, if the number of collisions is high, the performance of HashMap can also degrade.</p>"},{"location":"java/collection-framework/#null-keys-and-values","title":"Null keys and values","text":"<p>HashMap allows null keys and values. However, it is important to note that only one null key is allowed in the map and if a null key is used, it will always be stored at index 0. Also, if multiple null values are added to the map, they will be stored in the same bucket.</p>"},{"location":"java/collection-framework/#hashmap-implementation-in-the-jdk","title":"HashMap implementation in the JDK","text":"<p>HashMap is implemented in the JDK using an array of Entry objects, where each Entry object represents a key-value pair. Each Entry object also contains a reference to the next Entry object in the same bucket, in case of collisions.</p> <p>In summary, It uses a hash function to map keys to their values, and it uses open addressing to resolve collisions. HashMap provides constant-time performance for basic operations, but its performance can degrade if the hash function is not good or if there are a large number of collisions. It is important to understand the internal working of HashMap to effectively use it in your code and to optimize its performance.</p>"},{"location":"java/collection-framework/#hashmap-internal-working-2","title":"HashMap Internal working 2","text":"<ul> <li>HashMap works on the principal of hashing.</li> <li>HashMap in Java uses the <code>hashCode()</code> method to calculate a hash value. Hash value is calculated using the key object. This hash value is used to find the correct bucket where Entry object will be stored.</li> <li>HashMap uses the <code>equals()</code> method to find the correct key whose value is to be retrieved in case of get() and to find if that key already exists or not in case of put().</li> <li>With in the internal implementation of HashMap hashing collision means more than one key having the same hash value, in that case Entry objects are stored as a linked-list with in a same bucket.</li> <li>With in a bucket values are stored as Entry objects which contain both key and value.</li> <li>In Java 8 hash elements use balanced trees instead of linked lists after a certain threshold is reached while storing values. This improves the worst case performance from O(n) to O(log n).</li> </ul> <p>HashMap class in Java internally uses an array called table of type Node to store the elements which is defined in the HashMap class as- <pre><code>    /**\n * The table, initialized on first use, and resized as\n * necessary. When allocated, length is always a power of two.\n * (We also tolerate length zero in some operations to allow\n * bootstrapping mechanics that are currently not needed.)\n */\ntransient Node&lt;K,V&gt;[] table;\n</code></pre></p> <p>Node is defined as a static class with in a Hashmap.</p> <pre><code> static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {\n  final int hash;\n  final K key;\n  V value;\n  Node&lt;K,V&gt; next;\n\n  Node(int hash, K key, V value, Node&lt;K,V&gt; next) {\n    this.hash = hash;\n    this.key = key;\n    this.value = value;\n    this.next = next;\n  }\n\n  public final K getKey()        { return key; }\n  public final V getValue()      { return value; }\n  public final String toString() { return key + \"=\" + value; }\n\n  public final int hashCode() {\n    return Objects.hashCode(key) ^ Objects.hashCode(value);\n  }\n\n  public final V setValue(V newValue) {\n    V oldValue = value;\n    value = newValue;\n    return oldValue;\n  }\n\n  public final boolean equals(Object o) {\n    if (o == this)\n      return true;\n    if (o instanceof Map.Entry) {\n      Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;\n      if (Objects.equals(key, e.getKey()) &amp;&amp;\n              Objects.equals(value, e.getValue()))\n        return true;\n    }\n    return false;\n  }\n}\n</code></pre> <p>For each element 4 things are stored in the  fields-</p> <ol> <li>hash- For storing Hashcode calculated using the key.</li> <li>key- For holding key of the element.</li> <li>value- For storing value of the element.</li> <li>next- To store reference to the next node when a bucket has more than one element and a linkedlist is formed with in a bucket to store elements.</li> </ol> <p>Objects are stored internally in <code>table</code> array of the HashMap class.</p> <p></p>"},{"location":"java/collection-framework/#how-put-method-of-hashmap-works-internally","title":"How put() method of HashMap works internally","text":"<p>There are 3 steps in the internal implementation of HashMap put() method-</p> <ul> <li>Using <code>hashCode()</code> method, hash value will be calculated. In which bucket particular entry will be stored is ascertained using that hash.</li> <li><code>equals()</code> method is used to find if such a key already exists in that bucket, if not found then a new node is created with the map entry and stored within the same bucket. A linked-list is used to store those nodes.</li> <li>If <code>equals()</code> method returns true, it means that the key already exists in the bucket. In that case, the new value will overwrite the old value for the matched key.</li> </ul>"},{"location":"java/collection-framework/#how-hashmap-get-method-works-internally","title":"How  HashMap get() method works internally","text":"<p>Using the key (passed in the get() method) hash value will be calculated to determine the bucket where that Entry object is stored, in case there are more than one Entry object with in the same bucket (stored as a linked-list) equals() method will be used to find out the correct key. As soon as the matching key is found get() method will return the value object stored in the Entry object.</p>"},{"location":"java/collection-framework/#when-null-key-is-inserted-in-a-hashmap","title":"When null Key is inserted in a HashMap","text":"<p>HashMap in Java also allows null as key, though there can only be one null key in HashMap. While storing the Entry object HashMap implementation checks if the key is null, in case key is null, it is always mapped to bucket 0, as hash is not calculated for null keys.</p>"},{"location":"java/collection-framework/#hashmap-implementation-changes-in-java-8","title":"HashMap implementation changes in Java 8","text":"<p>HashMap implementation in Java provides constant time performance O(1) for get() and put() methods but that is in the ideal case when the Hash function distributes the objects evenly among the buckets.</p> <p>But the performance may worsen in the case hashCode() used is not proper and there are lots of hash collisions. As we know now that in case of hash collision entry objects are stored as a node in a linked-list and equals() method is used to compare keys. That comparison to find the correct key with in a linked-list is a linear operation so in a worst case scenario the complexity becomes O(n).</p> <p>To fix this issue in Java 8 hash elements use balanced trees instead of linked lists after a certain threshold is reached. Which means HashMap starts with storing Entry objects in linked list but after the number of items in a hash becomes larger than a certain threshold, the hash changes from using a linked list to a balanced tree, this improves the worst case performance from O(n) to O(log n).</p>"},{"location":"java/collection-framework/#interal-working-of-put-and-get-methods-of-hashmap","title":"Interal working of put() and get() methods of HashMap","text":"<ul> <li> <p>put() method internal working: When you call map.put(key,value), the below things happens:</p> </li> <li> <p>Key\u2019s hashCode() method is called</p> </li> <li>Hashmap has an internal hash function which takes the key\u2019s hashCode and it calculates the bucket index</li> <li>If there is no element present at that bucket index, our  pair along with hash is stored at that bucket <li>But if there is an element present at the bucket index, then key\u2019s hashCode is used to check whether this key is already present with the same hashCode or not.</li> <p>If there is key with same hashCode, then equals method is used on the key. If equals method returns true, then the key\u2019s previous value is replaced with the new value otherwise a new entry is appended to the linked list.</p> <ul> <li> <p>get() method internal working:   When you call map.get(key), the below things happen:</p> </li> <li> <p>Key\u2019s hashCode() method is called</p> </li> <li>Hash function uses this hashCode to calculate the index, just like in put method</li> <li>Now the key of element stored in bucket is compared with the passed key using equals() method, if both are equals, value is returned otherwise the next element is checked if it exists.</li> </ul> <p>See HashMap\u2019s Javadoc: Default capacity: <pre><code>/**\n* The default initial capacity - MUST be a power of two.\n*/\nstatic final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16\n</code></pre></p> <p>Load factor: <pre><code>/**\n* The load factor used when none specified in constructor.\n*/\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f;\n</code></pre></p> <p>Node class: <pre><code>static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {\nfinal int hash ;\n\"final K key ;\n    V value ;\n    Node&lt;K,V&gt; next ;\n    Node(int hash , K key , V value , Node&lt;K,V&gt; next ) {\n        this .hash = hash ;\n        this .key = key ;\n        this .value = value ;\n        this .next = next ;\n    }\n</code></pre></p> <p>Internal Hash function:</p> <pre><code>static final int hash(Object key ) {\nint h ;\nreturn (key == null ) ? 0 : (h = key .hashCode()) ^ (h &gt;&gt;&gt; 16);\n}\n</code></pre> <p>Internal Data structure used by HashMap to hold buckets: <pre><code>transient Node&lt;K,V&gt;[] table ;\n</code></pre></p> <p>HashMap\u2019s default constructor:</p> <p><pre><code>/**\n* Constructs an empty &lt;tt&gt; HashMap &lt;/tt&gt; with the default initial capacity\n* (16) and the default load factor (0.75).\n  */\npublic HashMap() {\nthis .loadFactor = DEFAULT_LOAD_FACTOR ; // all other fields defaulted\n}\n</code></pre> So, to conclude, Hashmap internally uses an array of Nodes named as table where each Node contains the calculated hash value, the key-value pair and the address to the next node.</p>"},{"location":"java/collection-framework/#hashmap-collisions","title":"HashMap collisions","text":"<p>It is possible that multiple keys will make the hash function generate the same index, this is called a collision. It happens because of poor hashcode method implementation.</p> <p>One collision handling technique is called Chaining. Since every element in the array is a linked list, the keys which have the same hash function will be appended to the linked list.</p> <ul> <li>Performance improvement in Java 8 :    It is possible that due to multiple collisions, the linked list size has become very large, and as we know, searching in a linked list is O(n), it will impact the constant time performance of hashmap\u2019s get() method. So, in Java 8, if the linked list size becomes more than 8, the linked list is converted to a binary search tree which will give a better time complexity of O(log n). <pre><code>/**\n* The bin count threshold for using a tree rather than list for a\n* bin. Bins are converted to trees when adding an element to a\"\n \"* bin with at least this many nodes. The value must be greater\n * than 2 and should be at least 8 to mesh with assumptions in\n * tree removal about conversion back to plain bins upon\n * shrinkage.\n */\nstatic final int TREEIFY_THRESHOLD = 8;\n</code></pre> Program showing the default capacity: <pre><code>import java.lang.reflect.Field;\nimport java.util.HashMap;\n\npublic class TestHashMap {\n    public static void main(String[] args) throws Exception {\n        HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();\n        map.put(\"name\", \"Mike\");\n\n        Field tableField = HashMap.class.getDeclaredField(\"table\");\n        tableField.setAccessible(true);\n        Object[] table = (Object[]) tableField.get(map);\n        System.out.print(\"hashmap capacity: \");\n        System.out.print(table == null ? 0 : table.length);\n        System.out.println(\"\\nhashmap size:\" + map.size());\n    }\n}\n</code></pre></li> </ul> <p>Output: <pre><code>hashmap capacity: 16\nhashmap size: 1\n</code></pre> Program showing that hashmap\u2019s capacity gets doubled after load factor\u2019s threshold value breaches :</p> <pre><code>import java.lang.reflect.Field;\nimport java.util.HashMap;\n\nclass Employee {\n    private int age;\n\n    public Employee(int age) {\n        this.age = age;\n    }\n}\n\npublic class TestHashMap {\n    public static void main(String[] args) throws Exception {\n        HashMap&lt;Employee, String&gt; map = new HashMap&lt;&gt;();\n\n        for(int i=1;i&lt;13;i++) {\n            map.put(new Employee(i), \"Hello \" + i);\n        }\n\n        Field tableField = HashMap.class.getDeclaredField(\"table\");\n        tableField.setAccessible(true);\n        Object[] table = (Object[]) tableField.get(map);\n        System.out.print(\"hashmap capacity: \");\n        System.out.print(table == null ? 0 : table.length);\n        System.out.println(\"\\nhashmap size:\" + map.size());\n    }\n}\n</code></pre> <p>Output: <pre><code>hashmap capacity: 16\nhashmap size: 12\n</code></pre></p> <p>Change the for loop condition from i&lt;13 to i&lt;=13, see below:</p> <pre><code>import java.lang.reflect.Field;\nimport java.util.HashMap;\n\nclass Employee {\n    private int age;\n\n    public Employee(int age) {\n        this.age = age;\n    }\n}\n\npublic class TestHashMap {\n    public static void main(String[] args) throws Exception {\n        HashMap&lt;Employee, String&gt; map = new HashMap&lt;&gt;();\n\n        for(int i=1;i&lt;13;i++) {\n            map.put(new Employee(i), \"Hello \" + i);\n        }\n\n        Field tableField = HashMap.class.getDeclaredField(\"table\");\n        tableField.setAccessible(true);\n        Object[] table = (Object[]) tableField.get(map);\n        System.out.print(\"hashmap capacity: \");\n        System.out.print(table == null ? 0 : table.length);\n        System.out.println(\"\\nhashmap size:\" + map.size());\n    }\n}\n</code></pre> <p>Output: <pre><code>hashmap capacity: 32\nhashmap size: 13\n</code></pre></p>"},{"location":"java/collection-framework/#equals-and-hashcode-method-in-hashmap-when-the-key-is-a-custom-class","title":"equals and hashCode method in HashMap when the key is a custom class","text":"<p><code>equals</code> and <code>hashCode</code> methods are called when we store and retrieve values from hashmap.</p> <p>if in your custom class, you are not implementing <code>equals()</code> and <code>hashCode()</code>, then the Object class <code>equals()</code> and <code>hashCode()</code> will be called, and the contract between these 2 methods.  It says when 2 objects are equal according to equals() method, then their hashCode must be same, reverse may not be true.</p> <ul> <li>Scenario 1: when custom class does not implement both equals and hashCode methods <pre><code>public class Employee {\n  private String name;\n  private int age;\n  public Employee(String name, int age) {\n    this.name = name;\n    this.age = age;\n  }\n}\n</code></pre> Here, <code>Employee</code> class has not given <code>equals()</code> and <code>hashCode()</code> method implementation, so Object\u2019s class <code>equals()</code> and <code>hashCode()</code> methods will be used when we use this <code>Employee</code> class as hashmap\u2019s key, and remember, equals() method of Object class compares the reference.</li> </ul> <p>TestHashMap.java: <pre><code>import java.util.HashMap;\nimport java.util.Map;\n\npublic class TestHashMap {\n  public static void main(String[] args) {\n\n    Map&lt;Employee, Integer&gt; map = new HashMap&lt;&gt;();\n\n    Employee e1 = new Employee(\"Mike\", 15);\n    Employee e2 = new Employee(\"Mike\", 15);\n    Employee e3 = new Employee(\"John\", 20);\n    Employee e4 = e3;\n\n    System.out.println(\"e1 hashcode: \" + e1.hashCode());\n    System.out.println(\"e2 hashcode: \" + e2.hashCode());\n    System.out.println(\"e3 hashcode: \" + e3.hashCode());\n    System.out.println(\"e4 hashcode: \" + e4.hashCode());\n\n    System.out.println(\"e1 equals e2: \" + e1.equals(e2));\n    System.out.println(\"e3 equals e4: \" + e3.equals(e4));\n\n    map.put(e1, 100);\n    map.put(e2, 200);\n    map.put(e3, 300);\n    map.put(e4, 400);\n\n    System.out.println(map.get(e1));\n    System.out.println(map.get(e2));\n    System.out.println(map.get(e3));\n    System.out.println(map.get(e4));\n    System.out.println(\"hashmap size: \" + map.size());\n  }\n}\n</code></pre></p> <p>Output: <pre><code>e1 hashcode: 1324119927\ne2 hashcode: 999966131\ne3 hashcode: 1989780873\ne4 hashcode: 1989780873\ne1 equals e2: false\ne3 equals e4: true\n100\n200\n400\n400\nhashmap size: 3\n</code></pre> Here, <code>Employee</code> objects e1 and e2 are same but they are both inserted in the <code>HashMap</code> because both are created using new keyword and holding a different reference, and as the Object\u2019s <code>equals()</code> method checks reference, they both are unique. And as for objects e3 and e4, they both are pointing to same reference (e4 = e3), so they are equal according to Object\u2019s <code>equals()</code> method hence the value of e3 which was 300 gets replaced with the value 400 of the same key e4, and finally size of HashMap is 3.</p> <ul> <li>Scenario 2:  when only equals() method is implemented by Employee class</li> </ul> <pre><code>public class Employee {\n\n  private String name;\n  private int age;\n\n  public Employee(String name, int age) {\n    this.name = name;\n    this.age = age;\n  }\n\n  @Override\n  public boolean equals(Object obj) {\n    if (this == obj)\n      return true;\n    if (obj == null)\n      return false;\n    if (getClass() != obj.getClass())\n      return false;\n    Employee other = (Employee) obj;\n    if (age != other.age)\n      return false;\n    if (name == null) {\n      if (other.name != null)\n        return false;\n    } else if (!name.equals(other.name))\n      return false;\n    return true;\n  }\n\n}\n</code></pre> <pre><code>import java.util.HashMap;\nimport java.util.Map;\n\npublic class TestHashMap {\n  public static void main(String[] args) {\n\n    Map&lt;Employee, Integer&gt; map = new HashMap&lt;&gt;();\n\n    Employee e1 = new Employee(\"Mike\", 15);\n    Employee e2 = new Employee(\"Mike\", 15);\n    Employee e3 = new Employee(\"John\", 20);\n    Employee e4 = e3;\n\n    System.out.println(\"e1 hashcode: \" + e1.hashCode());\n    System.out.println(\"e2 hashcode: \" + e2.hashCode());\n    System.out.println(\"e3 hashcode: \" + e3.hashCode());\n    System.out.println(\"e4 hashcode: \" + e4.hashCode());\n\n    System.out.println(\"e1 equals e2: \" + e1.equals(e2));\n    System.out.println(\"e3 equals e4: \" + e3.equals(e4));\n\n    map.put(e1, 100);\n    map.put(e2, 200);\n    map.put(e3, 300);\n    map.put(e4, 400);\n\n    System.out.println(map.get(e1));\n    System.out.println(map.get(e2));\n    System.out.println(map.get(e3));\n    System.out.println(map.get(e4));\n    System.out.println(\"hashmap size: \" + map.size());\n  }\n}\n</code></pre> <p>Let\u2019s see the output: <pre><code>e1 hashcode: 1324119927\ne2 hashcode: 999966131\ne3 hashcode: 1989780873\ne4 hashcode: 1989780873\ne1 equals e2: true\ne3 equals e4: true\n100\n200\n400\n400\nhashmap size: 3\n</code></pre></p> <p>Well, nothing\u2019s changed here. Because even though e1 and e2 are equal according to our newly implemented <code>equals()</code> method, they still have different hashCode as the Object\u2019s class <code>hashCode()</code> is used. So the equals and hashCode contract is not followed and both e1, e2 got inserted in <code>HashMap</code>.</p> <ul> <li>Scenario 3:  when only hashCode() method is implemented:</li> </ul> <pre><code>public class Employee {\n  private String name;\n  private int age;\n\n  public Employee(String name, int age) {\n    this.name = name;\n    this.age = age;\n  }\n\n  @Override\n  public int hashCode() {\n    final int prime = 31;\n    int result = 1;\n    result = prime * result + age;\n    result = prime * result + ((name == null) ? 0 : name.hashCode());\n    return result;\n  }\n\n}\n</code></pre> <p>Let\u2019s run our <code>TestHashMap</code> class again and see the output:  <pre><code>e1 hashcode: 2399656\ne2 hashcode: 2399656\ne3 hashcode: 2316120\ne4 hashcode: 2316120\ne1 equals e2: false\ne3 equals e4: true\n100\n200\n400\n400\nhashmap size: 3\n</code></pre></p> <p>Well, now we have same hashCode for e1 and e2, but Object\u2019s equals method still checks the references and as references are different, both are not equal and are inserted in the hashmap.</p> <ul> <li>Scenario 4: When both equals and hashCode are implemented properly:</li> </ul> <pre><code>public class Employee {\n    private String name;\n    private int age;\n\n    public Employee(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    @Override\n    public int hashCode() {\n        final int prime = 31;\n        int result = 1;\n        result = prime * result + age;\n        result = prime * result + ((name == null) ? 0 : name.hashCode());\n        return result;\n    }\n\n    @Override\n    public boolean equals(Object obj) {\n        if (this == obj)\n            return true;\n        if (obj == null)\n            return false;\n        if (getClass() != obj.getClass())\n            return false;\n        Employee other = (Employee) obj;\n        if (age != other.age)\n            return false;\n        if (name == null) {\n            if (other.name != null)\n                return false;\n        } else if (!name.equals(other.name))\n            return false;\n        return true;\n    }\n}\n</code></pre> <p>Output:</p> <p><pre><code>e1 hashcode: 2399656\ne2 hashcode: 2399656\ne3 hashcode: 2316120\ne4 hashcode: 2316120\ne1 equals e2: true\ne3 equals e4: true\n200\n200\n400\n400\nhashmap size: 2\n</code></pre> Here, both e1 and e2 are equals as we are comparing the contents of them in our <code>equals()</code> method, so their hashCodes must be same, which they are. So value of e1 which was 100 got replaced by 200, and size of hashmap is 2.</p> <p>How to make a HashMap synchronized?</p> <p>Collections.synchronizedMap(map);</p>"},{"location":"java/collection-framework/#does-hashmap-allow-duplicate-keys","title":"Does Hashmap allow duplicate keys ?","text":"<p>No. If we attempt to add duplicate keys, it will replace the element of the corresponding keys</p> <p>example - <pre><code>    public static void main(String[] args)\n    {\n\n        // This is how to declare HashMap\n        HashMap&lt;Integer, String&gt; hm = new HashMap&lt;Integer, String&gt;();\n\n        // Adding elements to HashMap*/\n        hm.put(12, \"geeks\");\n        hm.put(2, \"practice\");\n        hm.put(7, \"contribute\");\n\n        System.out.println(\"\\nHashMap object output :\\n\\n\" + hm);\n\n        // store data with duplicate key\n        hm.put(7, \"geeks\");\n        hm.put(12, \"contribute\");\n\n        System.out.println(\"\\nAfter inserting duplicate key :\\n\\n\" + hm);\n    }\n</code></pre></p> <p>Output :</p> <pre><code>{2=practice, 7=contribute, 12=geeks}\nAfter inserting duplicate key :\n{2=practice, 7=geeks, 12=contribute}\n</code></pre>"},{"location":"java/collection-framework/#concurrenthashmap","title":"ConcurrentHashMap","text":"<p><code>ConcurrentHashMap</code> class provides concurrent access to the map, this class is very similar to <code>HashTable</code>, except that <code>ConcurrentHashMap</code> provides better concurrency than <code>HashTable</code> or even <code>synchronizedMap</code>.</p> <p>Some points to remember: - <code>ConcurrentHashMap</code> is internally divided into segments, by default size is 16 that means, at max 16 threads can work at a time - Unlike <code>HashTable</code>, the entire map is not locked while reading/writing from the map - In <code>ConcurrentHashMap</code>, concurrent threads can read the value without locking - For adding or updating the map, the lock is obtained on segment level, that means each thread can work on each segment during high concurrency - Concurrency level defines a number, which is an estimated number of threads concurrently accessing the map - <code>ConcurrentHashMap</code> does not allow null keys or null values - put() method acquires lock on the segment - get() method returns the most recently updated value - iterators returned by <code>ConcurrentHashMap</code> are fail-safe and never throw <code>ConcurrentModificationException</code></p>"},{"location":"java/collection-framework/#concurrenthashmap-internal-working","title":"ConcurrentHashMap Internal Working","text":"<p>As opposed to the HashTables where every read/write operation needs to acquire the lock, there is no locking at the object level in CHM and locking is much granular at a hashmap bucket level. CHM(ConcurrentHashMap) never locks the whole Map, instead, it divides the map into segments and locking is done on these segments. CHM is separated into different regions(default-16) and locks are applied to them. When setting data in a particular segment, the lock for that segment is obtained. This means that two updates can still simultaneously execute safely if they each affect separate buckets, thus minimizing lock contention and so maximizing performance.</p>"},{"location":"java/collection-framework/#concurrenthashmap-vs-synchronized-hashmap","title":"ConcurrentHashMap vs Synchronized HashMap","text":"<p>Synchronized HashMap\uff1a - Each method is synchronized using an object level lock. So the get and put methods on synchMap acquire a lock. - Locking the entire collection is a performance overhead. While one thread holds on to the lock, no other thread can use the collection.</p> <p>ConcurrentHashMap was introduced in JDK 5. - There is no locking at the object level,The locking is at a much finer granularity. For a ConcurrentHashMap, the locks may be at a hashmap bucket level. - The effect of lower level locking is that you can have concurrent readers and writers which is not possible for synchronized collections. This leads to much more scalability. - ConcurrentHashMap does not throw a ConcurrentModificationException if one thread tries to modify it while another is iterating over it.</p>"},{"location":"java/collection-framework/#hashset-class","title":"HashSet class","text":"<p>HashSet is a class in Java that implements the Set Interface and it allows us to have the unique elements only. HashSet class does not maintain the insertion order of elements, if you want to maintain the insertion order, then you can use LinkedHashSet.</p> <ul> <li>Internal implementation of HashSet:</li> </ul> <p>HashSet internally uses HashMap and as we know the keys are unique in hashmap, the value passed in the add() method of HashSet is stored as the key of hashmap, that is how Set maintains the unique elements.</p> <p><pre><code>/**\n* Constructs a new, empty set; the backing &lt;tt&gt; HashMap &lt;/tt&gt; instance has\n* default initial capacity (16) and load factor (0.75).\n*/\npublic HashSet() {\n        map = new HashMap&lt;&gt;();\n}\nprivate transient HashMap&lt;E,Object&gt; map ;\n</code></pre> Let\u2019s see add() method\u2019s Javadoc: <pre><code>public boolean add(E e ) {\n        return map .put(e , PRESENT )==null ;\n}\n// Dummy value to associate with an Object in the backing Map\nprivate static final Object PRESENT = new Object();\n</code></pre></p> <p>So, when we call hashSet.add(element) method then - map.put() is called where key is the element and value is the dummy value (the map.put() method internal working has already been discussed above) - if value is added in the map then put method will return null which will be compared with null, hence returning true from hashSet.add() method indicating the element is added - however if the element is already present in the map, then the value associated with the element will be returned which in turn will be compared with null, returning false from hashSet.add() method</p> <p>set.contains() method:</p> <p><pre><code>public boolean contains(Object o ) {\n    return map .containsKey(o );\n}\n</code></pre> The passed object is given to map.containsKey() method, as the HashSet\u2019s values are stored as the keys of internal map.</p> <p>NOTE: If you are adding a custom class object inside the HashSet, do follow equals and hashCode contract.</p>"},{"location":"java/collection-framework/#treemap","title":"TreeMap","text":"<p>TreeMap class is one of the implementation of Map interface.</p> <p>Some points to remember: - TreeMap entries are sorted based on the natural ordering of its keys. This means if we are using a custom class as the key, we have to make sure that the custom class is implementing Comparable interface - TreeMap class also provides a constructor which takes a Comparator object, this should be used when we want to do a custom sorting - TreeMap provides guaranteed log(n) time complexity for the methods such as containsKey(), get(), put() and remove() - TreeMap iterator is fail-fast in nature, so any concurrent modification will result in ConcurrentModificationException - TreeMap does not allow null keys but it allows multiple null values - TreeMap is not synchronized, so it is not thread-safe. We can make it thread-safe by using utility method, Collections.synchronizedSortedMap(treeMap) - TreeMap internally uses Red-Black tree based NavigableMap implementation.</p> <p>Red-Black tree algorithm has the  properties:</p> <ul> <li>Color of every node in the tree is either red or black.</li> <li>Root node must be Black in color.</li> <li>Red node cannot have a red color neighbor node.</li> <li> <p>All paths from root node to the null should consist the same number of black nodes</p> </li> <li> <p>Program 1: Using Wrapper class as key</p> </li> </ul> <p><pre><code>import java.util.TreeMap;\n\npublic class TestTreeMap {\n  public static void main(String[] args) {\n    TreeMap&lt;Integer, String&gt; map = new TreeMap&lt;&gt;();\n    map.put(4, \"Mike\");\n    map.put(1, \"John\");\n    map.put(3, \"Jack\");\n    map.put(2, \"Lisa\");\n\n    map.forEach((k,v) -&gt; System.out.println(k + \":\" + v));\n  }\n}\n</code></pre> Output:</p> <p><pre><code>1:John\n2:Lisa\n3:Jack\n4:Mike\n</code></pre> Here, Integer class already implements Comparable interface, so the keys are sorted based on the Integer\u2019s natural sorting order (ascending order).</p> <p>Let\u2019s see, when key is a custom class:</p> <ul> <li>Program 2:</li> </ul> <pre><code>import java.util.TreeMap;\n\nclass Employee {\n    String name;\n    int age;\n    Employee(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n}\n\npublic class TestTreeMap {\n    public static void main(String[] args) {\n\n        TreeMap&lt;Employee, Integer&gt; map = new TreeMap&lt;&gt;();\n\n        map.put(new Employee(\"Mike\", 20), 100);\n        map.put(new Employee(\"John\", 10), 500);\n        map.put(new Employee(\"Ryan\", 15), 200);\n        map.put(new Employee(\"Lisa\", 20), 400);\n\n        map.forEach((k,v) -&gt; System.out.println(k + \":\" + v));      \n    }\n}\n</code></pre> <pre><code>Exception in thread \"main\" java.lang.ClassCastException: class GrokkingInterview.Grokking.Question109.Program2.Employee cannot be cast to class java.lang.Comparable (GrokkingInterview.Grokking.Question109.Program2.Employee is in unnamed module of loader 'app'; java.lang.Comparable is in module java.base of loader 'bootstrap')\n    at java.base/java.util.TreeMap.compare(TreeMap.java:1563)\n    at java.base/java.util.TreeMap.addEntryToEmptyMap(TreeMap.java:768)\n    at java.base/java.util.TreeMap.put(TreeMap.java:777)\n    at java.base/java.util.TreeMap.put(TreeMap.java:534)\n    at GrokkingInterview.Grokking.Question109.Program2.TestTreeMap.main(TestTreeMap.java:19)\n</code></pre> <p>We get <code>ClassCastException</code> at runtime. Now, let\u2019s implement <code>Comparable</code> interface in <code>Employee</code> class and provide implementation of its <code>compareTo()</code> method:</p> <ul> <li>Program 3: <pre><code>import java.util.TreeMap;\n\nclass Employee implements Comparable&lt;Employee&gt; {\n  String name;\n  int age;\n  Employee(String name, int age) {\n    this.name = name;\n    this.age = age;\n  }\n  @Override\n  public int compareTo(Employee emp) {\n    return this.name.compareTo(emp.name);\n  }\n  @Override\n  public String toString() {\n    return \"Employee [name=\" + name + \", age=\" + age + \"]\";\n  }\n}\n\npublic class TestTreeMap {\n  public static void main(String[] args) {\n\n    TreeMap&lt;Employee, Integer&gt; map = new TreeMap&lt;&gt;();\n\n    map.put(new Employee(\"Mike\", 20), 100);\n    map.put(new Employee(\"John\", 10), 500);\n    map.put(new Employee(\"Ryan\", 15), 200);\n    map.put(new Employee(\"Lisa\", 20), 400);\n\n    map.forEach((k,v) -&gt; System.out.println(k + \":\" + v));\n  }\n}\n</code></pre> Here, we are sorting based on <code>Employee</code> name,</li> </ul> <p>Output:</p> <p><pre><code>Employee [name=John, age=10]:500\nEmployee [name=Lisa, age=20]:400\nEmployee [name=Mike, age=20]:100\nEmployee [name=Ryan, age=15]:200\n</code></pre> Let\u2019s look at a program where we pass a <code>Comparator</code> in the <code>TreeMap</code> constructor, and sort the <code>Employee</code> object\u2019s based on age in descending order:</p> <ul> <li>Program 4:</li> </ul> <pre><code>import java.util.Comparator;\nimport java.util.TreeMap;\nimport java.util.TreeSet;\n\nclass Employee {\n    String name;\n    int age;\n    Employee(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n    @Override\n    public String toString() {\n        return \"Employee [name=\" + name + \", age=\" + age + \"]\";\n    }\n}\n\npublic class TestTreeMap {\n    public static void main(String[] args) {\n        TreeMap&lt;Employee, Integer&gt; map = new TreeMap&lt;&gt;(\n                new Comparator&lt;Employee&gt;() {\n                    @Override\n                    public int compare(Employee e1, Employee e2) {                  \n                        if(e1.age &lt; e2.age){\n                            return 1;\n                        } else if(e1.age &gt; e2.age) {\n                            return -1;\n                        }\n                        return 0;\n                    }       \n                }\n            );\n\n        map.put(new Employee(\"Mike\", 20), 100);\n        map.put(new Employee(\"John\", 10), 500);\n        map.put(new Employee(\"Ryan\", 15), 200);\n        map.put(new Employee(\"Lisa\", 40), 400);\n\n        map.forEach((k,v) -&gt; System.out.println(k + \":\" + v));      \n    }\n}\n</code></pre> <p>Output:</p> <pre><code>Employee [name=Lisa, age=40]:400\nEmployee [name=Mike, age=20]:100\nEmployee [name=Ryan, age=15]:200\nEmployee [name=John, age=10]:500\n</code></pre> <p>Here, in Employee class, I have not implemented equals() and hashCode()</p> <p>TreeMap\u2019s Javadoc:</p> <pre><code>public class TreeMap&lt;K,V&gt;\n        extends AbstractMap&lt;K,V&gt;\n        implements NavigableMap&lt;K,V&gt;, Cloneable, java.io.Serializable\n{\n  /**\n   * The comparator used to maintain order in this tree map, or\n   * null if it uses the natural ordering of its keys.\n   *\n   * @serial\n   */\n  private final Comparator&lt;? super K&gt; comparator ;\n  private transient Entry&lt;K,V&gt; root ;\n  //No-arg TreeMap constructor:\n  public TreeMap() {\n    comparator = null ;\n  }\n}\n</code></pre> <p>TreeMap constructor which takes comparator object:</p> <pre><code>public TreeMap(Comparator&lt;? super K&gt; comparator ) {\n            this .comparator = comparator ;\n        }\n\n       // TreeMap.put() method excerpt:\npublic V put(K key , V value ) {\n        Entry&lt;K,V&gt; t = root ;\n        if (t == null ) {\n          compare(key , key ); // type (and possibly null) check\n          root = new Entry&lt;&gt;(key , value , null );\n          size = 1;\n          modCount ++;\n          return null ;\n        }\n\n        int cmp ;\n        Entry&lt;K,V&gt; parent ;\n// split comparator and comparable paths\n        Comparator&lt;? super K&gt; cpr = comparator ;\n        if (cpr != null ) {\n          do {\n            parent = t ;\n            cmp = cpr .compare(key , t .key );\n            if (cmp &lt; 0)\n                t = t .left ;\n            else if (cmp &gt; 0)\n              t = t .right ;\n            else\n                return t .setValue(value );\n          } while (t != null );\n        }\n</code></pre>"},{"location":"java/collection-framework/#treeset","title":"TreeSet","text":"<p>TreeSet class is one of the implementation of Set interface</p> <p>Some points to remember: - TreeSet class contains unique elements just like HashSet - TreeSet class does not allow null elements - TreeSet class is not synchronized - TreeSet class internally uses TreeMap, i.e. the value added in TreeSet is internally stored in the key of TreeMap - TreeSet elements are ordered using their natural ordering or by a Comparator which can be provided at the set creation time - TreeSet provides guaranteed log(n) time cost for the basic operations (add, remove and contains) - TreeSet iterator is fail-fast in nature</p> <p>TreeSet Javadoc:</p> <pre><code>public class TreeSet&lt;E&gt; extends AbstractSet&lt;E&gt;\n        implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable\n        public TreeSet() {\n          this (new TreeMap&lt;E,Object&gt;());\n        }\n        public TreeSet(Comparator&lt;? super E&gt; comparator ) {\n          this (new TreeMap&lt;&gt;(comparator ));\n        }\n</code></pre>"},{"location":"java/collection-framework/#fail-safe-and-fail-fast-iterators","title":"fail-safe and fail-fast iterators","text":"<p>Iterators in Java are used to iterate over the Collection objects.</p>"},{"location":"java/collection-framework/#fail-fast-iterators","title":"Fail-fast iterators","text":"<p>immediately throw <code>ConcurrentModificationException</code>, if the collection is modified while iterating over it. <code>Iterator</code> of <code>ArrayList</code> and <code>HashMap</code> are fail-fast iterators. All the collections internally maintain some sort of array to store the elements, Fail-fast iterators fetch the elements from this array. Whenever, we modify the collection, an internal field called modCount is updated. This modCount is used by Fail-safe iterators to know whether the collection is structurally modified or not. Every time when the Iterator\u2019s next() method is called, it checks the modCount. If it finds that modCount has been </p> <p>updated after the Iterator has been created, it throws <code>ConcurrentModificationException</code>.</p> <p>Program 1: <pre><code>import java.util.ArrayList;\nimport java.util.Iterator;\n\npublic class FailFastIteratorTest {\n    public static void main(String[] args) {\n\n        ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;();\n        list.add(1);\n        list.add(2);\n        list.add(3);\n\n        Iterator&lt;Integer&gt; itr = list.iterator();\n        while(itr.hasNext()) {\n            System.out.println(itr.next());\n            list.add(4);\n        }\n    }\n}\n</code></pre></p> <p>Output: <pre><code>1\nException in thread \"main\" java.util.ConcurrentModificationException\nat java.base/java.util.ArrayList$Itr.checkForComodification(ArrayList.java:1013)\nat java.base/java.util.ArrayList$Itr.next(ArrayList.java:967)\nat GrokkingInterview.Grokking.Question111.Failfastiterator.Program1.FailFastIteratorTest.main(FailFastIteratorTest.java:16)\n</code></pre></p> <p>But they don\u2019t throw the exception, if the collection is modified by Iterator\u2019s <code>remove()</code> method.</p> <p>Program 2:</p> <pre><code>import java.util.ArrayList;\nimport java.util.Iterator;\n\npublic class FailFastIteratorTest {\n    public static void main(String[] args) {\n\n        ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;();\n        list.add(1);\n        list.add(2);\n        list.add(3);\n        System.out.println(\"List: \" + list);\n        Iterator&lt;Integer&gt; itr = list.iterator();\n        while(itr.hasNext()) {\n            System.out.println(itr.next());\n            itr.remove();\n        }\n        System.out.println(\"List: \" + list);\n    }\n}\n</code></pre> <p>Output: <pre><code>List: [1, 2, 3]\n1\n2\n3\nList: []\n</code></pre></p> <p>Javadoc:</p> <p>arrayList.iterator() method:</p> <pre><code>public Iterator&lt;E&gt; iterator(){\n        return new Itr();\n}\n</code></pre> <p>Itr is a private nested class in ArrayList:</p> <pre><code>private class Itr implements Iterator&lt;E&gt; {\n  int cursor ;\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// index of next element to return\n  int lastRet = -1; // index of last element returned; -1 if no such\n  int expectedModCount = modCount ;\n  Itr() {}\n  public boolean hasNext() {\n    return cursor != size ; \n  }\n</code></pre> <p>Itr.next() method:</p> <pre><code>@SuppressWarnings (\"unchecked\" )\npublic E next() {\n        checkForComodification();\n        int i = cursor ;\n        if (i &gt;= size )\n            throw new NoSuchElementException();\n        Object[] elementData = ArrayList.this .elementData ;\n        if (i &gt;= elementData .length )\n            throw new ConcurrentModificationException();\n        cursor = i + 1;\n        return (E) elementData [lastRet = i ];\n        }\n</code></pre> <p>See the first statement is a call to checkForComodification():</p> <pre><code>final void checkForComodification() {\n    if (modCount != expectedModCount )\n        throw new ConcurrentModificationException();\n}\n</code></pre> <p>On the other hand, </p>"},{"location":"java/collection-framework/#fail-safe-iterators","title":"Fail-safe iterators","text":"<p>does not throw <code>ConcurrentModificationException</code> , because they operate on the clone of the collection, not the actual collection. This also means that any modification done on the actual collection goes unnoticed by these iterators. The last statement is not always true though, sometimes it can happen that the iterator may reflect modifications to the collection after the iterator is created. But there is no guarantee of it. CopyOnWriteArrayList, ConcurrentHashMap are the examples of fail-safe iterators.</p> <p>Program 1: ConcurrentHashMap example</p> <pre><code>import java.util.Iterator;\nimport java.util.TreeMap;\nimport java.util.concurrent.CopyOnWriteArrayList;\n\npublic class FailSafeIteratorTest {\n    public static void main(String[] args) {\n        CopyOnWriteArrayList&lt;Integer&gt; list = new CopyOnWriteArrayList&lt;&gt;();\n        list.add(1);\n        list.add(2);\n        list.add(3);\n\n        Iterator&lt;Integer&gt; itr = list.iterator();\n        while(itr.hasNext()) {\n            System.out.println(itr.next());\n            list.add(4);\n        }\n        System.out.println(\"List: \" + list);\n    }\n}\n</code></pre> <p>Output:</p> <pre><code>1 : Mike\n2 : John\n3 : Lisa\n4 : Ryan\nMap: {1=Mike, 2=John, 3=Lisa, 4=Ryan}\n</code></pre> <p>Here, iterator is reflecting the element which was added during the iteration operation.</p> <p>Program 2: CopyOnWriteArrayList example <pre><code>import java.util.Iterator;\nimport java.util.TreeMap;\nimport java.util.concurrent.CopyOnWriteArrayList;\n\npublic class FailSafeIteratorTest {\n    public static void main(String[] args) {\n        CopyOnWriteArrayList&lt;Integer&gt; list = new CopyOnWriteArrayList&lt;&gt;();\n        list.add(1);\n        list.add(2);\n        list.add(3);\n\n        Iterator&lt;Integer&gt; itr = list.iterator();\n        while(itr.hasNext()) {\n            System.out.println(itr.next());\n            list.add(4);\n        }\n        System.out.println(\"List: \" + list);\n    }\n}\n</code></pre></p> <p>Output:  <pre><code>1\n2\n3\nList: [1, 2, 3, 4, 4, 4]\n</code></pre></p>"},{"location":"java/collection-framework/#for-more-information","title":"For more information","text":"<ol> <li>Java ArrayList Tutorial with Examples</li> <li>Guide to the Java ArrayList</li> <li>How HashMap Works Internally in Java</li> <li>Java 8 Collectors toMap with Examples</li> </ol>"},{"location":"java/java-basics/","title":"Java Basics","text":""},{"location":"java/java-basics/#java-8-features","title":"Java 8 Features","text":"<ul> <li>Lambda Expressions : They enable you to treat functionality as a method argument, or code as data. Lambda expressions let you express instances of single-method interfaces (referred to as functional interfaces) more compactly.</li> <li>Method references : Method references provide easy-to-read lambda expressions for methods that already have a name.</li> <li>Pipelines and Streams New stream API to facilitate pipeline processing.</li> <li>Functional interfaces : An Interface that contains only one abstract method is known as functional interface. It can have any number of default and static methods. It can also declare methods of object class.</li> <li>Date and Time API: Date and Time API give us a  new package java.time package.</li> <li>Default Methods: Default methods enable new functionality to be added to the interfaces of libraries and ensure binary compatibility with code written for older versions of those interfaces.</li> <li>Type Annotations: Before Java 8 Java annotations can be applied to type declarations. From this Java 8 release onwards, annotations can be applied to type use. Annotations can be applied wherever a type is used like in new instance creates, exception throws clause etc. This will help to enforce stronger type checks and using this feature we can come up with a type checking framework itself.</li> <li>Nashorn JavaScript Engine: Using this we can develop standalone JavaScript applications in Java. Pre Java 8, we got JDK with a JavaScript engine based on Rhino. It is a developed from scratch. It will provide better compatibility with ECMA normalized JavaScript specification and better performance than Rhino.</li> <li>Concurrent Accumulators: java.util.concurrent.atomic package is getting additional classes as part of Java 8 release. These will help to sum values from across multiple threads.</li> <li>Parallel operations: Iterating over a collection can be done in parallel using the aggregate operations easily. Pre Java 8 Iterators are used to parse the elements of a collection one by on explicitly. Now that can be done in parallel internally with the use of streams and aggregate operations. We can create multiple substreams and those substreams can be processed internally in parallel and then the results be combined. For this to be effective, we need to have multiple cores and data volume.</li> <li>PermGen Space Removed: The PermGen space is removed from Java 8 and instead we have MetaSpace introduced. One of the most dreaded error, \"java.lang.OutOfMemoryError: PermGen error will no longer be seen from Java 8. Nice thing is that the MetaSpace default is unlimited and that the system memory itself becomes the memory.</li> <li>TLS SNI : Server Name Indentification (SNI) is an extension of the TLS protocol used for identifying the certificate to serve based on the hostname specified by the client. This enables a server to have virtual host over HTTPS. The same IP address can be used for multiple hosts and their respective different security certificates.</li> <li>Optional  : Emphasis on best practices to handle null values properly.</li> <li>Collection API improvements: Some new methods added in Collection API Iterator default method forEachRemaining(Consumer action),Collection default method removeIf(Predicate filter)</li> <li>Concurrency API improvements: ConcurrentHashMap compute(), forEach(), forEachEntry(), forEachKey(), forEachValue(), merge(), reduce() and search() methods.</li> </ul>"},{"location":"java/java-basics/#why-string-is-immutable","title":"Why String is Immutable?","text":"<p>String is immutable for below reasons:</p> <ul> <li>String Pool : String Pool is possible only because String is Immutable in Java. String pool is a special storage area in Java heap. If the string is already present in the pool, then instead of creating a new object, old object\u2019s reference is returned. This way different String variables can refer to the same reference in the pool, thus saving a lot of heap space also. If String is not immutable then changing the string with one reference will lead to the wrong values to other string variables having the same reference.</li> <li>Security : String parameters are used in network connections, database URL\u2019s, username and passwords etc. Because String is immutable, these values can\u2019t be changed. Otherwise any hacker could change the referenced values which will cause severe security issues in the application.</li> <li>Multi-threading : Since String is immutable, it is safe for multithreading. A single String instance can be shared across different threads. This avoids the use of synchronization for thread safety. Strings are implicitly thread-safe.</li> <li>Caching : The hashcode of string is frequently used in Java. Since string is immutable, the hashcode will remain the same, so it can be cached without worrying about the changes. This makes it a great candidate for using it as a Key in Map.</li> <li>Class Loaders : Strings are used in Java ClassLoaders and since String is made immutable, it provides security that correct class is being loaded.</li> </ul>"},{"location":"java/java-basics/#stringbuffer-and-stringbuilder","title":"StringBuffer and StringBuilder","text":"<ul> <li> <p>Both StringBuffer and StringBuilder classes are used for String manipulation. These are mutable objects. But StringBuffer provides thread-safety as all its methods are synchronized, this makes performance of StringBuffer slower as compared to StringBuilder.</p> </li> <li> <p>StringBuffer class is present from Java 1.0, but due to its slower performance, StringBuilder class was introduced in Java 1.5</p> </li> <li> <p>If you are in a single-threaded environment or don\u2019t care about thread safety, you should use StringBuilder. Otherwise, use StringBuffer for thread-safe operations.</p> </li> <li> <p>You should use String class if you require immutability, use StringBuffer if you require mutability + Thread safety and use StringBuilder if you require mutability and no thread safety.</p> </li> </ul>"},{"location":"java/java-basics/#equals-and-hashcode-contract","title":"equals and hashcode contract","text":"<p>The hashCode() and equals() methods are two important methods that you can override in your Java classes. These methods are used to determine the equality of objects, and they are used in various APIs and libraries throughout the Java ecosystem, such as hash-based collections like HashMap, HashSet, and Hashtable.</p> <p>Here is an in-depth explanation of these methods:</p>"},{"location":"java/java-basics/#hashcode","title":"hashCode():","text":"<p>The hashCode() method is used to generate a unique integer that represents an object. It is typically used by hash-based collections to index objects and quickly determine if two objects are equal. The basic contract of the hashCode() method is as follows:</p> <ul> <li>If two objects are equal according to the equals(Object) method, then calling hashCode() on each of the two objects must produce the same integer result.</li> <li>If two objects are unequal according to the equals(Object) method, it is not required that calling hashCode() on each of the two objects produces distinct integer results.</li> </ul> <p>To implement the hashCode() method, you should use a formula that combines the hash codes of all the fields of the object that are used in the equals() method. A common approach is to use the Objects.hash() utility method to generate the hash code:</p> <pre><code>@Override\npublic int hashCode() {\n  return Objects.hash(field1, field2, ...);\n}\n</code></pre>"},{"location":"java/java-basics/#equals","title":"equals():","text":"<p>The equals() method is used to determine if two objects are equal. It compares the objects based on the values of their fields. The basic contract of the equals() method is as follows:</p> <p>It is reflexive: for any non-null reference value x, x.equals(x) should return true. It is symmetric: for any non-null reference values x and y, x.equals(y) should return true if and only if y.equals(x) returns true. It is transitive: for any non-null reference values x, y, and z, if x.equals(y) returns true and y.equals(z) returns true, then x.equals(z) should return true. It is consistent: for any non-null reference values x and y, multiple invocations of x.equals(y) consistently return true or consistently return false, provided no information used in equals comparisons on the objects is modified.</p> <p>For any non-null reference value x, x.equals(null) should return false.</p> <p>To implement the equals() method, you should compare the fields of the object to the fields of the argument, and return true if they are all equal:</p> <pre><code>@Override\npublic boolean equals(Object o) {\n  if (this == o) return true;\n  if (o == null || getClass() != o.getClass()) return false;\n  MyClass that = (MyClass) o;\n  return Objects.equals(field1, that.field1) &amp;&amp;\n         Objects.equals(field2, that.field2) &amp;&amp;\n         ...;\n}\n</code></pre> <p>It is important to note that the hashCode() and equals() methods are closely related and should be overridden together. If you override one, you should override the other. In most cases, if you override the equals() method, you should also override the hashCode() method to ensure that objects that are equal according to the equals() method have the same hash code.</p> <p>Additionally, it is recommended to follow the conventions outlined in the Java API documentation and in the book \"Effective Java\" by Joshua Bloch when implementing these methods. This will ensure that your code works well with the standard Java libraries and APIs.</p> <p>In summary, the hashCode() and equals() methods are important tools for determining the equality of objects in Java. They are used by many libraries and APIs, and should be implemented with care to ensure that they work as expected and follow established conventions.</p>"},{"location":"java/java-basics/#comparable-and-comparator-interfaces","title":"Comparable and Comparator interfaces","text":"<p>Both Comparable and Comparator interfaces are used to sort the collection of objects. These interfaces should be implemented by your custom classes, if you want to use Arrays/Collections class sorting methods. Comparable interface has compareTo(Obj) method, you can override this method in your class, and you can write your own logic to sort the collection.</p> <p>General rule to sort a collection of objects is: - If \u2018this\u2019 object is less than passed object, return negative integer. - If \u2018this\u2019 object is greater than passed object, return positive integer. - If \u2018this\u2019 object is equal to the passed object, return zero.</p> <ul> <li>Comparable Example :</li> </ul> <p>Employee.java <pre><code>public class Employee implements Comparable&lt;Employee&gt;{\n    private int id;\n    private String name;\n    private int age;\n    private long salary;\n\n    public Employee(int id, String name, int age, long salary) {\n        this.id = id;\n        this.name = name;\n        this.age = age;\n        this.salary = salary;\n    }\n\n    public int getId() { return id; }\n    public String getName() { return name; }\n    public int getAge() { return age; }\n    public long getSalary() { return salary; }\n\n    public void setId(int id) { this.id = id; }\n    public void setName(String name) { this.name = name; }\n    public void setAge(int age) { this.age = age; }\n    public void setSalary(long salary) { this.salary = salary; }\n\n    @Override\n    public int compareTo(Employee obj) {\n        return this.id - obj.id;\n    }\n\n    @Override\n    public String toString() {\n        return \"Employee [id=\" + id + \", name=\" + name + \", age=\" + age + \", \"\n                + \"salary=\" + salary + \"]\" + \"\\n\";\n    }\n\n}\n</code></pre> ComparableDemo.java : <pre><code>import java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.List;\n\npublic class ComparableDemo {\n\n    public static void main(String[] args) {\n        List&lt;Employee&gt; empList = new ArrayList&lt;&gt;();\n\n        empList.add(new Employee(4, \"Dave\", 25, 28000));\n        empList.add(new Employee(20, \"Mike\", 20, 10000));\n        empList.add(new Employee(9, \"Abhi\", 32, 5000));\n        empList.add(new Employee(1, \"Lisa\", 40, 19000));\n\n        Collections.sort(empList);\n        System.out.println(empList);\n    }\n\n}\n</code></pre></p> <p>Output: <pre><code>[Employee [id=1, name=Lisa, age=40, salary=19000]\n, Employee [id=4, name=Dave, age=25, salary=28000]\n, Employee [id=9, name=Abhi, age=32, salary=5000]\n, Employee [id=20, name=Mike, age=20, salary=10000]\n]\n</code></pre></p> <p>Here, we have sorted the Employee list based on \u2018id\u2019 attribute.</p> <ul> <li>Comparator Example : Now, if we want to sort the employee list based on any other attribute, say name, we will have to change our compareTo() method implementation for this. So, Comparable allows only single sorting mechanism. But Comparator allows sorting based on multiple parameters. We can define another class which will implement Comparator interface and then we can override it\u2019s compare(Obj, Obj) method. Suppose we want to sort the Employee list based on name and salary.</li> </ul> <p>NameComparator.java : <pre><code>import java.util.Comparator;\npublic class NameComparator implements Comparator&lt;Employee&gt; {\n\n    @Override\n    public int compare(Employee emp1, Employee emp2) {\n        return emp1.getName().compareTo(emp2.getName());\n    }\n}\n</code></pre></p> <p>String class already implements Comparable interface and provides a lexicographic implementation for compareTo() method which compares 2 strings based on contents of characters or you can say in lexical order. Here, Java will determine whether passed String object is less than, equal to or greater than the current object.</p> <p>ComparatorDemo.java :</p> <pre><code>import java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.List;\n\npublic class ComparatorDemo {\n    public static void main(String[] args) {\n        List&lt;Employee&gt; empList = new ArrayList&lt;&gt;();\n\n        empList.add(new Employee(4, \"Dave\", 25, 28000));\n        empList.add(new Employee(20, \"Mike\", 20, 10000));\n        empList.add(new Employee(9, \"Abhi\", 32, 5000));\n        empList.add(new Employee(1, \"Lisa\", 40, 19000));\n\n        Collections.sort(empList, new NameComparator());\n        System.out.println(empList);\n    }\n}\n</code></pre> <p>Output:</p> <pre><code>[Employee [id=9, name=Abhi, age=32, salary=5000]\n, Employee [id=4, name=Dave, age=25, salary=28000]\n, Employee [id=1, name=Lisa, age=40, salary=19000]\n, Employee [id=20, name=Mike, age=20, salary=10000]\n]\n</code></pre> <p>The output list is sorted based on employee\u2019s names.</p> <p>SalaryComparator.java : <pre><code>import java.util.Comparator;\npublic class SalaryComparator implements Comparator&lt;Employee&gt; {\n    @Override\n    public int compare(Employee emp1, Employee emp2) {\n        return (int) (emp1.getSalary() - emp2.getSalary());\n    }\n}\n</code></pre> ComparatorDemo.java : <pre><code>import java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.List;\npublic class ComparatorDemo {\n    public static void main(String[] args) {\n        List&lt;Employee&gt; empList = new ArrayList&lt;&gt;();\n\n        empList.add(new Employee(4, \"Dave\", 25, 28000));\n        empList.add(new Employee(20, \"Mike\", 20, 10000));\n        empList.add(new Employee(9, \"Abhi\", 32, 5000));\n        empList.add(new Employee(1, \"Lisa\", 40, 19000));\n\n        Collections.sort(empList, new SalaryComparator());\n        System.out.println(empList);\n    }\n}\n</code></pre></p> <p>Output: <pre><code>[Employee [id=9, name=Abhi, age=32, salary=5000]\n, Employee [id=20, name=Mike, age=20, salary=10000]\n, Employee [id=1, name=Lisa, age=40, salary=19000]\n, Employee [id=4, name=Dave, age=25, salary=28000]\n]\n</code></pre></p>"},{"location":"java/java-basics/#comparable-and-comparator","title":"Comparable and Comparator","text":"<ul> <li><code>Comparable</code> interface can be used to provide single way of sorting whereas <code>Comparator</code> interface is used to provide multiple ways of sorting</li> <li><code>Comparable</code> interface is present in \u2018java.lang\u2019 package whereas <code>Comparator</code> interface is present in <code>java.util</code> package</li> <li>For using <code>Comparable</code>, the class needs to implement <code>Comparable</code> interface whereas for using <code>Comparator</code>, there is no need to make changes in the class</li> <li><code>Comparable</code> provides <code>compareTo()</code> method to sort elements, whereas <code>Comparator</code> provides <code>compare()</code> method to sort elements</li> <li>We can sort the list elements of <code>Comparable</code> type by using <code>Collections.sort(listObj)</code> method, whereas to sort the list elements of <code>Comparator</code> type, we have to provide a <code>Comparator</code> object like, <code>Collections.sort(listObj, Comparator)</code></li> </ul> <p>At times, when you are using any third-party classes or the classes where you are not the author of the class, then in that case <code>Comparator</code> is the only choice to sort those objects</p>"},{"location":"java/java-basics/#static-keyword","title":"static keyword","text":"<p>In Java, a static member is a member of a class that isn\u2019t associated with an instance of a class. Instead, the member belongs to the class itself.</p> <p>In Java, Static is applicable for the: 1.  Variable 2.  Method 3.  Block 4.  Nested class</p>"},{"location":"java/java-basics/#static-variable","title":"Static Variable","text":"<p>if any variable is declared as static, then it is known as \u2018static variable\u2019. Only single copy of the variable gets created and all instances of the class share same static variable. The static variable gets memory only once in the class area at the time of class loading. When to use static variable : static variables should be used to declare common property of all objects as only single copy is created and shared among all class objects, for example, the company name of employees etc.</p>"},{"location":"java/java-basics/#static-method","title":"Static Method","text":"<p>When a method is declared with static keyword then it is known as static method. These methods belong to the class rather than the object of the class. As a result, a static method can be directly accessed using class name without the need of creating an object. One of the basic rules of working with static methods is that you can\u2019t access a non-static method or field from a static method because the static method doesn\u2019t have an instance of the class to use to reference instance methods or fields. Another restriction is, \u2018this\u2019 and \u2018super\u2019 cannot be used in static context. For example: main() method is static, Java Runtime uses this method to start an application without creating an object.</p>"},{"location":"java/java-basics/#static-block","title":"Static Block","text":"<p>Static block gets executed exactly once when the class is first loaded, use static block to initialize the static variables.</p>"},{"location":"java/java-basics/#static-nested-classes","title":"Static nested classes","text":"<p>Static nested classes are a type of inner class in java where the inner class is static. Static nested classes can access only the static members of the outer class. The advantage of using static nested classes is that it makes the code more readable and maintainable. In the case of normal inner class, you cannot create inner class object without first creating the outer class object, but in the case of static inner class, there can be a static inner class object without the outer class object.</p> <p>How to create object of static inner class: <pre><code>    OuterClass.StaticNestedClass nestedClassObject = new OuterClass.StaticNestedClass();\n</code></pre></p> <p>Compile Time Error comes when we try to access non-static member inside static nested class:</p> <p><pre><code>class OuterClass {\n    int a = 10;\n    static int b = 20;\n    private static int c = 30;\n\n    static class InnerClass {\n        void print() {\n            System.out.println(\"Outer class variable a : \" + a);\n            System.out.println(\"Outer class variable b : \" + b);\n            System.out.println(\"Outer class variable c : \" + c);\n        }\n    }\n}\n</code></pre> Compile Time Error <pre><code>Non-static field 'a' cannot be referenced from a static context\n</code></pre></p> <pre><code>class OuterClass {\n    int a = 10;\n    static int b = 20;\n    private static int c = 30;\n\n    static class InnerClass {\n        void print() {\n            //System.out.println(\"Outer class variable a : \" + a);\n            System.out.println(\"Outer class variable b : \" + b);\n            System.out.println(\"Outer class variable c : \" + c);\n        }\n    }\n}\n\npublic class StaticNestedTestClass {\n    public static void main(String[] args) {\n        OuterClass.InnerClass innerClassObject = new OuterClass.InnerClass();\n        innerClassObject.print();\n    }\n}\n</code></pre> <p>Output: <pre><code>Outer class variable b : 20\nOuter class variable c : 30\n</code></pre></p> <p>If you have static members in your Static Inner class then there is no need to create the inner class object: <pre><code>class OuterClass {\n    static int x = 20;\n\n    static class InnerClass {\n        static int y = 30;\n\n        static void display() {\n            System.out.println(\"Outer x : \" + x);\n        }\n    }\n}\n\npublic class StaticNestedTestClass {\n    public static void main(String[] args) {\n        OuterClass.InnerClass.display();\n        System.out.println(OuterClass.InnerClass.y);\n    }   \n}\n</code></pre></p> <p>Output:  <pre><code>Outer x : 20\n30\n</code></pre></p>"},{"location":"java/java-basics/#shallow-copy-and-deep-copy","title":"Shallow Copy and Deep Copy","text":""},{"location":"java/java-basics/#shallow-copy","title":"Shallow Copy","text":"<p>When we use the default implementation of clone() method, a shallow copy of object is returned, meaning if the object that we are trying to clone contains both primitive variables and non-primitive or reference type variable, then only the object\u2019s reference is copied not the entire object itself.</p> <p>Consider this with the example: Employee object is having Company object as a reference, now when we perform cloning on Employee object, then for primitive type variables, cloning will be done i.e. new instances will be created and copied to the cloned object but for non-primitive i.e. Company object, only the object\u2019s reference will be copied to the cloned object. It simply means Company object will be same in both original and cloned object, changing the value in one will change the value in other and vice-versa. Now, if you want to clone the Company object also, so that your original and cloned Employee object will be independent of each other, then you have to perform Deep Copy.</p>"},{"location":"java/java-basics/#deep-copy","title":"Deep Copy","text":"<p>In Deep copy, the non-primitive types are also cloned to make the original and cloned object fully independent of each other.</p> <p>Program 1:</p> <pre><code>class Company implements Cloneable {\n    private String name;\n    public Company(String name) {\n        this.name = name;\n    }\n    public String getName() {   return name;    }\n    public void setName(String name) {  this.name = name;   }\n\n    @Override\n    protected Object clone() throws CloneNotSupportedException {\n        return super.clone();\n    }\n}\n\npublic class Employee implements Cloneable {\n    private String name;\n    private int age;\n    private Company company;\n\n    public Employee(String name, int age, Company company) {\n        this.name = name;\n        this.age = age;\n        this.company = company;\n    }\n\n    public String getName() {   return name;    }\n    public int getAge() {   return age;     }\n    public void setName(String name) {  this.name = name;   }\n    public void setAge(int age) {   this.age = age;     }\n    public Company getCompany() {   return company;     }\n    public void setCompany(Company company) {   this.company = company;     }\n\n    @Override\n    protected Object clone() throws CloneNotSupportedException {\n        Employee employee = (Employee) super.clone();\n        employee.company = (Company) company.clone();\n        return employee;\n    }\n    public static void main(String[] args) throws CloneNotSupportedException {\n        Company c1 = new Company(\"Company_ABC\");\n        Employee e1 = new Employee(\"Mike\", 10, c1);\n        System.out.println(\"Employee 1, company name : \" + e1.getCompany().getName());\n\n        Employee e2 = (Employee) e1.clone();\n        System.out.println(\"Employee 2, company name : \" + e2.getCompany().getName());\n        e2.getCompany().setName(\"XYZ\");\n        System.out.println(\"----------------------------\");\n        System.out.println(\"Employee 1, company name : \" + e1.getCompany().getName());\n        System.out.println(\"Employee 2, company name : \" + e2.getCompany().getName());\n    }\n}\n</code></pre> <p>Output: <pre><code>Employee 1, company name : Company_ABC\nEmployee 2, company name : Company_ABC\n----------------------------\nEmployee 1, company name : Company_ABC\nEmployee 2, company name : XYZ\n</code></pre></p> <p>In above example, we have overridden the clone method in our employee class and we called the clone method on mutable company object.</p> <p>We can also use Copy constructor to perform deep copy:</p> <p>Program 2: <pre><code>class Company {\n    private String name;\n    public Company(String name) {\n        this.name = name;\n    }\n    public String getName() {   return name;    }\n    public void setName(String name) {  this.name = name;   }\n\n}\n\npublic class Employee {\n    private String name;\n    private int age;\n    private Company company;\n\n    public Employee(String name, int age, Company company) {\n        this.name = name;\n        this.age = age;\n        this.company = company;\n    }\n\n    //Copy constructor\n    public Employee(Employee emp) {\n        this.name = emp.getName();\n        this.age = emp.getAge();\n        Company company = new Company(emp.getCompany().getName());\n        this.company = company;\n    }\n\n    public String getName() {   return name;    }\n    public int getAge() {   return age;     }\n    public void setName(String name) {  this.name = name;   }\n    public void setAge(int age) {   this.age = age;     }\n    public Company getCompany() {   return company;     }\n    public void setCompany(Company company) {   this.company = company;     }\n\n    public static void main(String[] args) {\n        Company c1 = new Company(\"Company_ABC\");\n        Employee e1 = new Employee(\"Mike\", 10, c1);\n        System.out.println(\"Employee 1, company name : \" + e1.getCompany().getName());\n\n        //Invoking copy constructor\n        Employee e2 = new Employee(e1);\n        System.out.println(\"Employee 2, company name : \" + e2.getCompany().getName());\n        e2.getCompany().setName(\"XYZ\");\n        System.out.println(\"----------------------------\");\n        System.out.println(\"Employee 1, company name : \" + e1.getCompany().getName());\n        System.out.println(\"Employee 2, company name : \" + e2.getCompany().getName());\n    }\n}\n</code></pre></p> <p>Output: <pre><code>Employee 1, company name : Company_ABC\nEmployee 2, company name : Company_ABC\n----------------------------\nEmployee 1, company name : Company_ABC\nEmployee 2, company name : XYZ\n</code></pre></p> <p>There are 2 other methods by which you can perform deep copy: - By using Serialization, where you serialize the original object and returns the deserialized object as a clone - By using external library of Apache Commons Lang. Apache Common Lang comes with SerializationUtils.clone() method for performing deep copy on an object. It expects all classes in the hierarchy to implement Serializable interfaces else SerializableException is thrown by the system</p>"},{"location":"java/java-basics/#serialization-and-de-serialization","title":"Serialization and De-serialization","text":"<p>Serialization is a process of reading or writing an object. It is a process of saving an object\u2019s state to a sequence of bytes, as well as a process of rebuilding those bytes back into a live object at some future time. An object is marked serializable by implementing the java.io.Serializable interface, which is only a marker interface -- it simply allows the serialization mechanism to verify that the class can be persisted, typically to a file.</p> <p>Transient variables cannot be serialized. The fields marked transient in a serializable object will not be transmitted in the byte stream. An example would be a file handle, a database connection, a system thread etc. Such objects are only meaningful locally. So they should be marked as transient in a serializable class.</p> <p>Serialization is a mechanism to convert the state of an object into a byte stream while De-serialization is the reverse process where the byte stream is used to recreate the actual object in memory. The byte stream created is platform independent that means objects serialized on one platform can be deserialized on another platform. To make a Java <code>Object</code> serializable, the class must implement Serializable interface. <code>Serializable</code> is a Marker interface. Object</p> <p><code>OutputStream</code> and <code>ObjectInputStream</code> classes are used for Serialization and Deserialization in java. We will serialize the below Employee class:</p> <pre><code>import java.io.Serializable;\n\npublic class Employee implements Serializable{\n    private String name;\n    private int age;\n    private transient int salary;\n\n    public Employee(String name, int age, int salary) {\n        this.name = name;\n        this.age = age;\n        this.salary = salary;\n    }\n\n    @Override\n    public String toString() {\n        return \"Employee [name=\" + name + \", age=\" + age + \", salary=\" + salary + \"]\";\n    }\n\n}\n</code></pre> <p>SerializationDemo.java: <pre><code>import java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\n\npublic class SerializationDemo {\n    public static void main(String[] args) {\n        Employee emp = new Employee(\"Mike\", 15, 20000);\n        String file = \"byteStream.txt1\";\n        try {\n            FileOutputStream fos = new FileOutputStream(file);\n            ObjectOutputStream oos = new ObjectOutputStream(fos);           \n            oos.writeObject(emp);\n\n            fos.close();\n            oos.close();            \n            System.out.println(\"Employee object is serialized : \" + emp);\n        } catch (IOException e1) {\n            System.out.println(\"IOException is caught\");\n        }   \n        try {\n            FileInputStream fis = new FileInputStream(file);\n            ObjectInputStream ois = new ObjectInputStream(fis);\n            Employee emp1 = (Employee) ois.readObject();\n\n            fis.close();\n            ois.close();\n            System.out.println(\"Employee object is de-serialized : \" + emp1);\n        } catch (IOException e) {\n            System.out.println(\"IOException is caught\");\n        } catch (ClassNotFoundException e) {\n            System.out.println(\"ClassNotFoundException is caught\"); \n        }\n    }\n}\n</code></pre></p> <p>Output: <pre><code>Employee object is serialized : Employee [name=Mike, age=15, salary=20000]\nEmployee object is de-serialized : Employee [name=Mike, age=15, salary=0]\n</code></pre></p> <p>Here, while de-serializing the employee object, salary is 0, that is because we have made salary variable to be <code>transient</code>. <code>static</code> and <code>transient</code> variables do not take part in Serialization process. During de-serialization, transient variables will be initialized with their default values i.e. if objects, it will be null and if <code>int</code>, it will be 0 and static variables will be having the current value. And if you look at the file present in current directory bytestream.txt, you can see how the object is serialized into this file,</p> <p>See file bytestream.txt</p>"},{"location":"java/java-basics/#serialization-scenarios-with-inheritance","title":"Serialization scenarios with Inheritance","text":"<ul> <li>Case 1: If super class is Serializable then by default, its sub-classes are also Serializable</li> </ul> <pre><code>import java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\nimport java.io.Serializable;\n\nclass Parent implements Serializable {\n    int x;\n    public Parent(int x) {\n        this.x = x;\n    }\n}\n\nclass Child extends Parent {\n    int y;\n    public Child(int x, int y) {\n        super(x);\n        this.y = y;\n    }\n}\n\npublic class TestSerialization {\n    public static void main(String[] args) {\n        Child child = new Child(10,50);\n        System.out.println(\"x : \" + child.x);\n        System.out.println(\"y : \" + child.y);\n        String file = \"temp/child.ser\";\n\n        serializeObject(file, child);\n        deserializeObject(file);            \n    }\n\n    private static void serializeObject(String file, Child child) {\n        try {\n            FileOutputStream fos = new FileOutputStream(file);\n            ObjectOutputStream oos = new ObjectOutputStream(fos);           \n            oos.writeObject(child);\n\n            fos.close();\n            oos.close();        \n            System.out.println(\"The object has been serialized\");\n        } catch (IOException e) {\n            e.printStackTrace();\n        }   \n    }\n\n    private static void deserializeObject(String file) {\n        try {\n            FileInputStream fis = new FileInputStream(file);\n            ObjectInputStream ois = new ObjectInputStream(fis);\n            Child child1 = (Child) ois.readObject();\n\n            fis.close();\n            ois.close();\n            System.out.println(\"The object has been deserialized\");\n            System.out.println(\"x : \" + child1.x);\n            System.out.println(\"y : \" + child1.y);\n        } catch (IOException e) {\n            e.printStackTrace();\n        } catch (ClassNotFoundException e) {\n            e.printStackTrace(); \n        }\n    }\n}\n</code></pre> <p>See file child.ser</p> <p>Output: <pre><code>x : 10\ny : 50\nThe object has been serialized\nThe object has been deserialized\nx : 10\ny : 50\n</code></pre></p> <ul> <li>Case 2: When super class does not implement the Serializable Interface, then also we can serialize the subclass provided that it implements Serializable interface.</li> </ul> <p>In this case, when we de-serialize the subclass object, then no-arg constructor of its parent class gets called. So, the serializable sub-class must have access to the default no-arg constructor of its parent class (general rule is that the Serializable sub-class must have access to the no-arg constructor of first non-Serializable super class).</p> <pre><code>import java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\nimport java.io.Serializable;\n\nclass Parent {\n    int x;\n    public Parent(int x) {\n        this.x = x;\n    }\n}\n\nclass Child extends Parent implements Serializable {\n    int y;\n    public Child(int x, int y) {\n        super(x);\n        this.y = y;\n    }\n}\n\npublic class TestSerialization {\n    public static void main(String[] args) {\n        Child child = new Child(20,40);\n        System.out.println(\"x : \" + child.x);\n        System.out.println(\"y : \" + child.y);\n        String file = \"child1.ser\";\n\n        serializeObject(file, child);\n        deserializeObject(file);\n    }\n\n    private static void serializeObject(String file, Child child) {\n        try {\n            FileOutputStream fos = new FileOutputStream(file);\n            ObjectOutputStream oos = new ObjectOutputStream(fos);\n            oos.writeObject(child);\n\n            fos.close();\n            oos.close();\n            System.out.println(\"The object has been serialized\");\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    private static void deserializeObject(String file) {\n        try {\n            FileInputStream fis = new FileInputStream(file);\n            ObjectInputStream ois = new ObjectInputStream(fis);\n            Child child1 = (Child) ois.readObject();\n\n            fis.close();\n            ois.close();\n            System.out.println(\"The object has been deserialized\");\n            System.out.println(\"x : \" + child1.x);\n            System.out.println(\"y : \" + child1.y);\n        } catch (IOException e) {\n            e.printStackTrace();\n        } catch (ClassNotFoundException e) {\n            e.printStackTrace();\n        }\n    }\n}\n</code></pre> <p>(Note: serializeObject() and deserializeObject() remains same as the Case 1 program)</p> <p>Output: <pre><code>x : 20\ny : 40\nThe object has been serialized\njava.io.InvalidClassException: Case2.Child; no valid constructor\n    at java.base/java.io.ObjectStreamClass$ExceptionInfo.newInvalidClassException(ObjectStreamClass.java:170)\n    at java.base/java.io.ObjectStreamClass.checkDeserialize(ObjectStreamClass.java:917)\n    at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2203)\n    at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1712)\n    at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:519)\n    at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:477)\n    at Case2.TestSerialization.deserializeObject(TestSerialization.java:54)\n    at Case2.TestSerialization.main(TestSerialization.java:33)\n</code></pre></p> <p>When no-arg constructor is present in Super class:</p> <pre><code>import java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.IOException;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\nimport java.io.Serializable;\n\nclass Parent {\n    int x;\n    public Parent(int x) {\n        this.x = x;\n        System.out.println(\"Parent class one-arg constructor\");\n    }\n    public Parent() {\n        x = 100;\n        System.out.println(\"Parent class no-arg constructor\");\n    }\n}\n\nclass Child extends Parent implements Serializable {\n    int y;\n    public Child(int x, int y) {\n        super(x);\n        this.y = y;\n        System.out.println(\"Child class two-arg constructor\");\n    }\n    public Child() {\n        System.out.println(\"Child class no-arg constructor\");\n    }\n}\n\npublic class TestSerialization {\n    public static void main(String[] args) {\n        Child child = new Child(20,40);\n        System.out.println(\"x : \" + child.x);\n        System.out.println(\"y : \" + child.y);\n        String file = \"child2.ser\";\n\n        serializeObject(file, child);\n        deserializeObject(file);            \n    }\n\n    private static void serializeObject(String file, Child child) {\n        try {\n            FileOutputStream fos = new FileOutputStream(file);\n            ObjectOutputStream oos = new ObjectOutputStream(fos);           \n            oos.writeObject(child);\n\n            fos.close();\n            oos.close();        \n            System.out.println(\"The object has been serialized\");\n        } catch (IOException e) {\n            e.printStackTrace();\n        }   \n    }\n\n    private static void deserializeObject(String file) {\n        try {\n            FileInputStream fis = new FileInputStream(file);\n            ObjectInputStream ois = new ObjectInputStream(fis);\n            Child child1 = (Child) ois.readObject();\n\n            fis.close();\n            ois.close();\n            System.out.println(\"The object has been deserialized\");\n            System.out.println(\"x : \" + child1.x);\n            System.out.println(\"y : \" + child1.y);\n        } catch (IOException e) {\n            e.printStackTrace();\n        } catch (ClassNotFoundException e) {\n            e.printStackTrace(); \n        }\n    }\n}\n</code></pre> <p>(Note: serializeObject() and deserializeObject() remains same as the Case 1 program) </p> <p>Output: <pre><code>Parent class one-arg constructor\nChild class two-arg constructor\nx : 20\ny : 40\nThe object has been serialized\nParent class no-arg constructor\nThe object has been deserialized\nx : 100\ny : 40\n</code></pre></p>"},{"location":"java/java-basics/#how-to-make-a-class-immutable","title":"How to make a class Immutable?","text":"<p>As we know, String is an Immutable class in Java, i.e. once initialized its value never change. We can also make our own custom Immutable class, where the class object\u2019s state will not change once it is initialized.</p> <p>1 Benefits of Immutable class: - Thread-safe: With immutable classes, we don\u2019t have to worry about the thread-safety in case of multi-threaded environment as these classes are inherently thread-safe - Cacheable: An immutable class is good for Caching because while we don\u2019t have to worry about the value changes</p> <p>2 How to create an Immutable class: - Declare the class as final so that it cannot be extended - Make all fields as private so that direct access to them is not allowed - Make all fields as final so that its value can be assigned only once - Don\u2019t provide \u2018setter\u2019 methods for variables - When the class contains a mutable object reference,     1. While initializing the field in constructor, perform a deep copy     2. While returning the object from its getter method, make sure to return a copy rather than the actual object reference</p> <p>Example: We will make Employee class as immutable, but Employee class contains a reference of Address class</p> <p>Address.java: <pre><code>public class Address {\n\n    private String city;\n    private String state;\n\n    public Address(String city, String state) {\n        this.city = city;\n        this.state = state;\n    }\n\n    public String getCity() { return city; }\n    public String getState() { return state; }\n\n    public void setCity(String city) { this.city = city; }\n    public void setState(String state) { this.state = state; }\n\n    @Override\n    public String toString() {\n        return \"Address [city=\" + city + \", state=\" + state + \"]\";\n    }\n\n}\n</code></pre></p> <p>Employee.java: <pre><code>public final class Employee {\n\n    private final String name;\n    private final int age;\n    private final Address address;\n\n    public Employee(String name, int age, Address address) {\n        this.name = name;\n        this.age = age;\n        Address cloneAddress = new Address(address.getCity(), address.getState());\n        this.address = cloneAddress;\n    }\n\n    public String getName() { return name; }\n\n    public int getAge() { return age; }\n\n    public Address getAddress() {\n        return new Address(address.getCity(), address.getState());\n    }\n\n    @Override\n    public String toString() {\n        return \"Employee [name=\" + name + \", age=\" + age + \", address=\" + address + \"]\";\n    }\n\n}\n</code></pre></p> <p>TestImmutable.java: <pre><code>public class TestImmutable {\n    public static void main(String[] args) {\n        Address address = new Address(\"Chennai\", \"Tamil Nadu\");\n        Employee employee = new Employee(\"Mike\", 15, address);\n\n        System.out.println(\"Original Employee object : \\n\" + employee);\n\n        address.setCity(\"Mumbai\");\n        address.setState(\"Maharashtra\");\n\n        System.out.println(\"Employee object after local variable address change :\\n\" + employee);\n\n        Address empAddress = employee.getAddress();\n        empAddress.setCity(\"Jaipur\");\n        empAddress.setState(\"Rajasthan\");\n\n        System.out.println(\"Employee object after employee address change:\\n\" + employee);\n    }\n}\n</code></pre></p> <p>Here, after creating Employee object, the first change is done in local address object and then we used the employee\u2019s getter method to access the address object and tried to change the value in it.</p> <p>Output: <pre><code>Original Employee object : \nEmployee [name=Mike, age=15, address=Address [city=Chennai, state=Tamil Nadu]]\nEmployee object after local variable address change :\nEmployee [name=Mike, age=15, address=Address [city=Chennai, state=Tamil Nadu]]\nEmployee object after employee address change:\nEmployee [name=Mike, age=15, address=Address [city=Chennai, state=Tamil Nadu]]\n</code></pre></p> <p>As, you can see that the value remained the same. If we don\u2019t follow the rule about mutable object reference present in the class, let\u2019s see what will happen in that case. Let\u2019s change the Employee class constructor and getter method:</p> <p>Employee.java:</p> <p><pre><code>public final class Employee {\n\n    private final String name;\n    private final int age;\n    private final Address address;\n\n    public Employee(String name, int age, Address address) {\n        this.name = name;\n        this.age = age;\n        this.address = address;\n    }\n\n    public String getName() { return name; }\n\n    public int getAge() { return age; }\n\n    public Address getAddress() {\n        return address;\n    }\n\n    @Override\n    public String toString() {\n        return \"Employee [name=\" + name + \", age=\" + age + \", address=\" + address + \"]\";\n    }\n\n}\n</code></pre> Now, if we run our TestImmutable.java class, below is the output:</p> <p>Output: <pre><code>Original Employee object :\nEmployee [name=Mike, age=15, address=Address [city=Chennai, state=Tamil Nadu]]\nEmployee object after local variable address change :\nEmployee [name=Mike, age=15, address=Address [city=Mumbai, state=Maharashtra]]\nEmployee object after employee address change:\nEmployee [name=Mike, age=15, address=Address [city=Jaipur, state=Rajasthan]]\n</code></pre></p> <p>Why we perform deep copy in constructor: - When you assign the actual address object in the constructor, then remember it is storing the reference of address object, so if you change the value in this address object, it will reflect in the employee object</p> <p>Why we don\u2019t return original reference from the getter: - When you return the original address object from the getter method then you can use the returned object reference to change the values in employee object</p>"},{"location":"java/java-basics/#class-loaders-in-java","title":"Class loaders in Java","text":"<p>ClassLoader is a java class which is used to load .class files in memory. When we compile a java class, JVM creates a bytecode which is platform independent. The bytecode is present in .class file. When we try to use a class, then classloader loads it into memory.</p> <p>There are 3 types of built-in class loaders in java:</p>"},{"location":"java/java-basics/#bootstrap-class-loader","title":"Bootstrap class loader","text":"<p>it loads JDK class files from <code>jre/lib/rt.jar</code> and other core classes. It is the parent of all class loaders, it is also called Primordial classloader. </p>"},{"location":"java/java-basics/#extensions-class-loader","title":"Extensions class loader","text":"<p>it loads classes from <code>JDK extensions</code> directory, it delegates class loading request to its parent, Bootstrap and if the loading of class is unsuccessful, it loads classes from <code>jre/lib/ext</code> directory or any other directory pointed by <code>java.ext.dirs</code> system property.</p>"},{"location":"java/java-basics/#system-class-loader","title":"System class loader","text":"<p>It loads application specific classes from the <code>CLASSPATH</code>. We can set classpath while invoking the program using -cp or classpath command line options. It is a child of Extension ClassLoader.</p> <p>Java class loader is based on three principles:</p> <ol> <li>Delegation principle: It forwards the request for class loading to its parent class loader. It only loads the class if the parent does not find or load the class.</li> <li>Visibility principle: According to Visibility principle, the child ClassLoader can see all the classes loaded by parent ClassLoader. But the parent class loader cannot see classes loaded by the child class loader.</li> <li>Uniqueness principle: According to this principle, a class loaded by Parent should not be loaded by Child ClassLoader again. It is achieved by delegation principle.</li> </ol> <p>Suppose, you have created a class <code>Employee.java</code> and compiled this class and <code>Emloyee.class</code> file is created. Now, you want to use this class, the first request to load this class will come to System/Application ClassLoader, which will delegate the request to its parent, Extension ClassLoader which further delegates to Primordial or Bootstrap class loader Now, Bootstrap ClassLoader will look for this class in rt.jar, since this class is not there, the request will come to Extension ClassLoader which looks in <code>jre/lib/ext</code> directory and tries to locate this class there, if this class is found there then Extension ClassLoader will load this class and Application ClassLoader will not load this class, this has been done to maintain the Uniqueness principle. But if the class is not loaded by Extension ClassLoader, then this <code>Employee.class</code> will be loaded by Application ClassLoader from the CLASSPATH.</p> <p><pre><code>public class Employee {\n\n    public static void main(String[] args) {\n        System.out.println(Employee.class.getClassLoader());\n        System.out.println(System.class.getClassLoader());\n    }\n\n}\n</code></pre> Output: <pre><code>jdk.internal.loader.ClassLoaders$AppClassLoader@73d16e93\nnull\n</code></pre></p> <p>If you are thinking why null is printed when we tried to know which classloader is loading the java.lang.System class then take a look at the Javadoc : <pre><code>    /**\n     * Returns the class loader for the class.  Some implementations may use\n     * null to represent the bootstrap class loader. This method will return\n     * null in such implementations if this class was loaded by the bootstrap\n     * class loader.\n     *\n     * &lt;p&gt;If this {@code Class} object\n     * represents a primitive type or void, null is returned.\n     *\n     * @return  the class loader that loaded the class or interface\n     *          represented by this {@code Class} object.\n     * @throws  SecurityException\n     *          if a security manager is present, and the caller's class loader\n     *          is not {@code null} and is not the same as or an ancestor of the\n     *          class loader for the class whose class loader is requested,\n     *          and the caller does not have the\n     *          {@link RuntimePermission}{@code (\"getClassLoader\")}\n     * @see java.lang.ClassLoader\n     * @see SecurityManager#checkPermission\n     * @see java.lang.RuntimePermission\n     */\n    @CallerSensitive\n    @ForceInline // to ensure Reflection.getCallerClass optimization\n    public ClassLoader getClassLoader() {\n        ClassLoader cl = getClassLoader0();\n        if (cl == null)\n            return null;\n        SecurityManager sm = System.getSecurityManager();\n        if (sm != null) {\n            ClassLoader.checkClassLoaderPermission(cl, Reflection.getCallerClass());\n        }\n        return cl;\n    }\n</code></pre></p> <p>We can also create our own custom class loader by extending the ClassLoader class.</p>"},{"location":"java/java-basics/#garbage-collector","title":"Garbage Collector","text":"<p>In Java, garbage collection is the process by which the Java Virtual Machine (JVM) automatically frees up memory that is no longer needed by the program. The goal of garbage collection is to reclaim memory occupied by objects that are no longer accessible by the program and make that memory available for reuse.</p> <p>The Java garbage collector works by maintaining a record of all objects that are currently accessible by the program. These objects are referred to as \"live\" objects. The garbage collector periodically scans the heap, which is the portion of memory where objects are stored, to identify objects that are no longer accessible by the program. These objects are referred to as \"dead\" objects.</p> <p>Once dead objects are identified, the garbage collector reclaims the memory occupied by these objects and makes it available for reuse. This process is called \"garbage collection.\" The garbage collector runs as a low-priority thread, so it doesn't interfere with the normal execution of the program.</p> <p>The Java garbage collector uses several algorithms to optimize the process of garbage collection. One common algorithm is called \"mark and sweep.\" In this algorithm, the garbage collector starts by marking all of the objects that are accessible by the program. It then sweeps the heap, freeing up memory occupied by all objects that are not marked.</p> <p>Another common algorithm is called \"generational garbage collection.\" In this algorithm, the heap is divided into two or more generations, with each generation being a different age group of objects. The garbage collector is more likely to reclaim the memory occupied by objects in the older generations because they are more likely to be dead objects.</p> <p>The exact algorithms used by the Java garbage collector and the way they are implemented can vary depending on the specific JVM implementation. However, the general principles of garbage collection in Java remain the same across all implementations.</p>"},{"location":"java/java-basics/#types-of-garbage-collection","title":"Types of Garbage Collection","text":"<p>In Java, there are several types of garbage collection that are commonly used:</p>"},{"location":"java/java-basics/#serial-garbage-collector","title":"Serial Garbage Collector:","text":"<p>This is the simplest form of garbage collection and is suitable for small to medium-sized applications. It uses a single thread to reclaim memory and is optimized for single-threaded environments.</p>"},{"location":"java/java-basics/#parallel-garbage-collector","title":"Parallel Garbage Collector:","text":"<p>This is a multi-threaded garbage collector that runs multiple threads in parallel to reclaim memory. It is more efficient than the serial garbage collector and is used in multi-threaded environments.</p>"},{"location":"java/java-basics/#cms-concurrent-mark-sweep-garbage-collector","title":"CMS (Concurrent Mark Sweep) Garbage Collector:","text":"<p>This is a low-pause, concurrent garbage collector that runs concurrently with the application threads. It is designed to minimize the amount of time that the application is paused for garbage collection.</p>"},{"location":"java/java-basics/#g1-garbage-first-garbage-collector","title":"G1 (Garbage First) Garbage Collector:","text":"<p>This is a low-pause, concurrent garbage collector that is designed for large-scale applications. It divides the heap into smaller regions and reclaims memory from one region at a time, which helps to reduce the amount of time that the application is paused for garbage collection.</p>"},{"location":"java/java-basics/#zgc-z-garbage-collector","title":"ZGC (Z Garbage Collector):","text":"<p>This is a new, low-latency garbage collector that is designed for very large-scale applications. It is designed to reclaim memory with minimal pauses and is optimized for large heaps.</p> <p>These are some of the most commonly used garbage collection algorithms in Java. The specific algorithm used by the JVM can be configured by setting command line options when starting the JVM. The appropriate garbage collector to use depends on the specific requirements of the application and the environment in which it runs.</p> <p>The Garbage Collector has only two things to do:</p> <ul> <li>Find garbage - unused objects. (An object is considered unused if none of the entities in the code currently executing contains references to it, or the chain of links that could connect the object with some application entity is broken);</li> <li>Free memory from garbage.</li> </ul> <p>There are two approaches to detecting garbage: - Reference counting ; - Tracing</p> <p>Counting the Reference (reference counting). The essence of this approach is that each object has a counter. A counter stores information about how many references are pointing to an object. When the link is destroyed, the counter is decremented. If the counter value is zero, the object can be considered garbage. The main disadvantage of this approach is the difficulty of ensuring the accuracy of the meter. Also, with this approach, it is difficult to detect circular dependencies (when two objects point to each other, but no living object refers to them), which leads to memory leaks.</p> <p>The main idea of the Tracing approach (tracing) is the assertion that only those objects that we can reach from the root points ( GC Root ) and those objects that are accessible from the living object can be considered alive. Everything else is rubbish.</p> <p>There are 4 types of root points: - Local variables and method parameters; - Streams; - Static variables; - Links from JNI.</p> <p>The simplest java application will have root points:</p> <ul> <li>Local variables inside the main()method and main()method parameters ;</li> <li>The thread that executes main();</li> <li>Static variables of the class inside which the main() method is located .</li> </ul> <p>Thus, if we represent all objects and links between them as a tree, then we will need to go from root nodes (points) along all edges. At the same time, the nodes that we can get to are not garbage, all the rest are garbage. With this approach, cyclical dependencies are easily identified. HotSpot VM takes exactly this approach.</p> <p>There are two main methods for cleaning up memory from garbage:</p> <ul> <li>Copying collectors</li> <li>Mark-and-sweep</li> </ul> <p>With the copying collectors approach, memory is divided into two parts \"from-space\" and \"to-space\", while the principle of operation is as follows: - Objects are created in \"from-space\"; - When the \"from-space\" is full, the application is suspended; - The garbage collector starts. Live objects are found in \"from-space\" and copied to \"to-space\"; - When all objects are copied, \"from-space\" is completely cleared; - \"To-space\" and \"from-space\" are swapped.</p> <p>The main advantage of this approach is that objects densely clog up memory. Cons of the approach:</p> <ol> <li>The application must be stopped for the time it takes to complete the garbage collection cycle;</li> <li>In the worst case (when all objects are alive) \"form-space\" and \"to-space\" will have to be the same size.</li> </ol> <p>The mark-and-sweep algorithm can be described as: - Objects are created in memory; - At the moment when the garbage collector needs to be started, the application is suspended; - The collector walks through the object tree, marking live objects; - The collector loops through the entire memory, finding all unmarked chunks of memory and storing them in the \"free list\"; - When new objects start to be created they are created in memory available in the \"free list\"</p> <p>Cons of this method: The application does not run while garbage collection is in progress; The stopping time directly depends on the size of the memory and the number of objects; If you do not use \"compacting\" the memory will not be used efficiently. The HotSpot VM garbage collectors use a combined Generational Garbage Collection approach that allows different algorithms to be used for different stages of garbage collection. This approach relies on the fact that:</p> <p>most objects created quickly become garbage; there are few links between objects that were created in the past and newly created objects.</p>"},{"location":"java/java-basics/#how-does-the-garbage-collector-work","title":"How does the garbage collector work?","text":"<p>Garbage collection is the process of freeing space on the heap so that new objects can be added.</p> <p>Objects are created through the operator new, thereby assigning a reference to the object. To finish working with an object, you just need to stop referring to it, for example, by assigning a reference to another object or value to a variable null; terminate the execution of the method so that its local variables expire naturally. Objects, links to which are not usually called garbage ( garbage ), which will be removed.</p> <p>The Java virtual machine, using the garbage collection mechanism, ensures that any object that has references remains in memory - all objects that are unreachable from the executable code, due to the lack of references to them, are deleted, freeing the memory allocated for them. More precisely, an object is outside the scope of the garbage collection process if it is reachable through a chain of links starting at the GC Root , i.e. a link that directly exists in the executable code.</p> <p>Memory is freed by the garbage collector at its own discretion. The program can successfully complete its work without exhausting the resources of free memory or not even approaching this limit, and therefore it will not need the \"services\" of the garbage collector.</p> <p>Garbage is collected by the system automatically, without user or programmer intervention, but this does not mean that this process does not require attention at all. The need to create and delete a large number of objects has a significant impact on the performance of applications and, if program performance is an important factor, you should carefully consider decisions related to the creation of objects - this, in turn, will reduce the amount of garbage to be disposed of.</p>"},{"location":"java/java-basics/#types-of-garbage-collectors","title":"Types of garbage collectors","text":"<p>The Java HotSpot VM provides four different garbage collectors to choose from:</p> <ul> <li>Serial is the easiest option for applications with low data volume and low latency requirements. At the moment, it is used relatively rarely, but on weak computers it can be selected by the virtual machine as the default collector. The use of Serial GC is enabled by option <code>-XX:+UseSerialGC</code>.</li> <li>Parallel - inherits assembly approaches from the sequential collector, but adds parallelism to some operations, as well as the ability to automatically adjust to the required performance parameters. Parallel collector is enabled by option <code>-XX:+UseParallelGC</code>.</li> <li>Concurrent Mark Sweep (CMS) - aims to reduce maximum latency by performing some of the garbage collection work in parallel with the main threads of the application. Suitable for dealing with relatively large amounts of data in memory. The use of CMS GC is enabled by option <code>-XX:+UseConcMarkSweepGC</code>.</li> <li>Garbage-First (G1) - designed to replace CMS, especially in server applications running on multiprocessor servers and handling large amounts of data. G1 is enabled by Java option <code>-XX:+UseG1GC</code>.</li> </ul>"},{"location":"java/java-basics/#garbage-collection-and-types-of-garbage-collectors","title":"Garbage Collection and types of Garbage Collectors","text":"<p>Garbage collection in java is the process of looking at heap memory, identifying which objects are in use and which are not and deleting the unused objects. An unused object or unreferenced object, is no longer referenced by any part of your program.</p> <p>Garbage collector is a daemon thread that keeps running in the background, freeing up heap memory by destroying the unreachable objects.</p> <p>There was an analysis done on several applications which showed that most objects are short lived, so this behavior was used to improve the performance of JVM. In this method, the heap space is divided into smaller parts or generations. These are, Young Generation , Old or Tenured Generation and Permanent Generation .</p> <p>The Young Generation is where all new objects are allocated and aged. The young generation is further divided into 3 parts: Eden Space, Survivor space S0 and Survivor space S1. When the young generation fills up, this causes a minor garbage collection . Some surviving objects are aged and eventually move to the old generation. All minor garbage collections are \"Stop the World\" events. This means that all application threads are stopped until the operation completes. Minor garbage collections are always Stop the World events.</p> <p>The Old Generation is used to store long surviving objects. Typically, a threshold is set for young generation object and when that age is met, the object gets moved to the old generation. Eventually the old generation needs to be collected. This event is called a major garbage collection . Major garbage collection are also Stop the World events. Often a major collection is much slower because it involves all live objects. So, for Responsive applications, major garbage collections should be minimized. Also note that the length of the Stop the World event for a major garbage collection is affected by the kind of garbage collector that is used for the old generation space.</p> <p>The Permanent generation contains metadata required by the JVM to describe the classes and methods used in the application. The permanent generation is populated by the JVM at runtime based on classes in use by the application. In addition, Java SE library classes and methods may be stored here.</p> <p>Classes may get collected (unloaded) if the JVM finds they are no longer needed and space may be needed for other classes. </p> <p>The Permanent generation contains metadata required by the JVM to describe the classes and methods used in the application. The permanent generation is populated by the JVM at runtime based on classes in use by the application. In addition, Java SE library classes and methods may be stored here.</p> <p>Classes may get collected (unloaded) if the JVM finds they are no longer needed and space may be needed for other classes. The permanent generation is included in a full garbage collection. And Perm Gen was available till Java 7, it is removed from Java 8 onwards and JVM uses native memory for the representation of class metadata which is called MetaSpace.</p> <p>There is a flag MaxMetaspaceSize, to limit the amount of memory used for class metadata. If we do not specify the value for this, the Metaspace re-sizes at runtime as per the demand of the running application.</p> <p>How Garbage collection works:</p> <p>When new objects are first created, they are stored in the eden space of Young Generation and at that time both Survivor spaces are empty. When the eden space is filled, then a minor garbage collection is triggered. All the unused or un-referenced objects are cleared from the eden space and the used objects are moved to first Survivor space S0.</p> <p>At the next minor garbage collection, same process happens, un-referenced objects are cleared from the eden space but this time, the surviving objects are moved to Survivor space S1. In addition, the objects that were in S0 will also be matured and they also get moved to S1. Once all surviving objects are moved to S1, both eden and S0 are cleared.</p> <p>At the next minor GC, the same process repeats. When surviving objects reached a certain threshold, they get promoted from Young generation to Old generation. These minor GC will continue to occur and objects will continue to be promoted to the Old generation.</p> <p>Eventually, a major GC will be performed on the Old generation which cleans up and compacts the space.</p> <p>Types of Garbage collector</p> <p>Serial GC: Serial GC is designed for smaller applications that have small heap sizes of up to a few hundred MBs. It only uses single virtual CPU for its garbage collection and the collection is done serially. It takes around couple of second for Full garbage collections.</p> <p>It can be turned on by using <code>-XX:+UseSerialGC</code></p> <p>java -Xmx12m -Xms3m -Xmn1m -XX:PermSize=20m -XX:MaxPermSize=20m -XX:+UseSerialGC -jar C:\\temp\\test.jar</p> <p>Parallel/Throughput GC:</p> <p>Parallel garbage collector uses multiple threads to perform the garbage collection. By default, on a host with N CPUs, this collector uses N garbage collector threads for collection. </p> <p>The number of collector threads can be controlled with the command line option: <code>-XX:ParallelGCThreads=&lt;N&gt;</code></p> <p>It is called Throughput collector as it uses multiple CPUs to speed up the application throughput. A drawback of this collector is that it pauses the application threads while performing minor or full GC, so it is best suited for applications where long pauses are acceptable. It is the default collector in JDK 8.</p> <p>It can be turned on by using below 2 options:</p> <p>-XX:+UseParallelGC</p> <p>With this command line option, you get a multi-thread young generation collector with a single-threaded old generation collector. The option also does single-threaded compaction of old generation.</p> <p>java -Xmx12m -Xms3m -Xmn1m -XX:PermSize=20m -XX:Max-PermSize=20m -XX:+UseParallelGC -jar C:\\temp\\test.jar</p> <p><code>-XX:+UseParallelOldGC</code></p> <p>With this option, the GC is both a multithreaded young generation collector and multithreaded old generation collector. It is also a multithreaded compacting collector.</p> <p>Compacting describes the act of moving objects in a way that there are no holes between objects. After a garbage collection sweep, there may be holes left between live objects. Compacting moves objects so that there are no remaining holes. This compacting of memory makes it faster to allocate new chunks of memory to the heap.</p> <p>java -Xmx12m -Xms3m -Xmn1m -XX:PermSize=20m -XX:MaxPermSize=20m -XX:+UseParallelOldGC -jar C:\\temp\\test.jar</p> <p>Concurrent Mark Sweep (CMS) Collector:</p> <p>The CMS collector, also called as the concurrent low pause collector, collects the tenured generation. It attempts to minimize the pauses due to garbage collection, by doing most of the garbage collection work concurrently with the application threads.</p> <p>It can be turned on by passing -XX:+UseConcMarkSweepGC in the command line option.</p> <p>If you want to set number of threads with this collector, pass -XX:ParallelCMSThreads= <p>java -Xmx12m -Xms3m -Xmn1m -XX:PermSize=20m -XX:Max-PermSize=20m -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads=2 -jar C:\\temp\\test.jar</p> <p>G1 Garbage Collector:</p> <p>The Garbage First or G1 collector is a parallel, concurrent and incrementally compacting low-pause garbage collector</p> <p>G1 collector partitions the heap into a set of equal-sized heap regions. When G1 performs garbage collection then a concurrent global marking phase is performed to determine the liveliness of objects throughout the heap. After this mark phase is complete, G1 knows which regions are mostly empty. It collects unreachable objects from these regions first, which usually yields a large amount of free space, also called Sweeping. So G1 collects these regions (containing garbage) first, and hence the name Garbage-First.</p> <p>It can be turned on by passing <code>-XX:+UseG1GC</code> in the command line options</p> <p>java \u2013Xmx25g \u2013Xms5g -XX:+UseG1GC -jar C:\\temp\\test.jar</p> <p>Java 8 has introduced one JVM parameter for reducing the unnecessary use of memory by creating too many instances of the same String. This optimizes the heap memory by removing duplicate String values to a global single char[] array. We can use the <code>-XX:+UseStringDeduplication</code> JVM argument to enable this optimization.</p> <p>G1 is the default garbage collector in JDK 9.</p> <p>Also Check: https://java2blog.com/garbage-collection-java/</p>"},{"location":"java/java-basics/#final-finally-and-finalize","title":"final, finally and finalize()","text":"BASIS FOR COMPARISON FINAL Keyword FINALLY Block FINALIZE Method Basic Final is a <code>Keyword</code> and <code>access modifier</code> in Java. Finally is a <code>block</code> in Java Finalize is a <code>method</code> in Java. Applicable to Final keyword is used with the classes, methods and variables. Finally block is always related to the try and catch block in exception handling. finalize() method is used with the objects. Functionality Once declared, final variable becomes constant and cannot be modified.final method cannot be overridden by sub class.final class cannot be inherited. finally block runs the important code even if exception occurs or not.final class cannot be inherited. finalize method performs the cleaning activities with respect to the object before its destruction. Execution Final method is executed only when we call it. Finally block is executed as soon as the try-catch block is executed.Finally block is executed as soon as the try-catch block is executed. finalize method is executed just before the object is destroyed. <p>Modifier <code>final</code>:</p> <ul> <li>The class cannot have descendants;</li> <li>The method cannot be overridden in inherited classes;</li> <li>The field cannot change its value after initialization;</li> <li>Local variables cannot be changed once a value has been assigned to them;</li> <li>Method parameters cannot change their value inside a method.</li> </ul> <p>The operator <code>finally</code> guarantees that a section of code defined in it will be executed regardless of what exceptions were raised and caught in the block try-catch.</p> <p>The method <code>finalize()</code> is called before the garbage collector performs object disposal.</p> <p>Example:</p> <pre><code>public class MainClass {\n\n    public static void main(String args[]) {\n        TestClass a = new TestClass();\n        System.out.println(\"result of a.a() is \" + a.a());\n        a = null;\n        System . gc (); // Forced to call the garbage collector \n        a = new TestClass();\n        System.out.println(\"result of a.a() is \" + a.a());\n        System.out.println(\"!!! done\");\n    }\n\n}\n</code></pre> <pre><code>public class TestClass {\n\n    public int a() {\n        try {\n            System.out.println(\"!!! a() called\");\n            throw new Exception(\"\");\n        } catch (Exception e) {\n            System.out.println(\"!!! Exception in a()\");\n            return 2;\n        } finally {\n            System.out.println(\"!!! finally in a() \");\n        }\n    }\n\n    @Override\n    protected void finalize() throws Throwable {\n        System.out.println(\"!!! finalize() called\");\n        super.finalize();\n    }\n}\n</code></pre> <p>Execution result: <pre><code>!!! a() called\n!!! Exception in a()\n!!! finally in a()\nresult of a.a() is 2\n!!! a() called\n!!! Exception in a()\n!!! finally in a()\n!!! finalize() called\nresult of a.a() is 2\n!!! done\n</code></pre></p>"},{"location":"java/java-basics/#finally-keyword","title":"finally keyword","text":"<ul> <li>finally is a reserved keyword in java so it cannot be used as an identifier name.</li> <li>finally is a block of code that is generally used with a try-catch block.</li> <li>finally block is always executed no matter whether an exception occurs or not and whether the exception is caught in catch block or not.</li> <li>finally block generally contains a piece of code which is closing the file or sockets or any other connection like DB, network so that resource should not be wasted.</li> </ul>"},{"location":"java/java-basics/#finalize-method","title":"finalize() method","text":"<ul> <li>It is a method written in Object class and called by Garbage Collector before destroying the objects which are in no use to perform clean up activity.</li> <li>The cleanup activity involves closing the connections or resource de-allocations e.g. Database, Sockets, Files, etc.</li> <li>All classes can override the finalize method as the Object class is the parent class for all java classes to perform their own cleanup activity.</li> <li>The overridden finalize method can also be called using the class object method in which the method is overridden.</li> <li>The resource de-allocation and clean up activity are done once all the methods of a class are executed.</li> </ul>"},{"location":"java/java-basics/#javadoc","title":"JavaDoc","text":"<pre><code>public class Object {\n    @Deprecated(since=\"9\")\n    protected void finalize() throws Throwable { }\n}\n</code></pre>"},{"location":"java/java-basics/#string-stringbuffer-stringbuilder","title":"String, StringBuffer, StringBuilder","text":"<p>The class <code>String</code> is immutable ( the immutable ) - modify an object of this class can not, we can only replace it with a new instance.</p> <p>The class is <code>StringBuffer</code> mutable - StringBuffer should be used when it is necessary to frequently modify the content.</p> <p>The class <code>StringBuilder</code> was added in Java 5 and is identical to the class in every StringBuffer way, except that it is not synchronized and therefore its methods are much faster.</p>"},{"location":"java/java-basics/#reflection","title":"Reflection","text":"<p>Reflection is a mechanism for obtaining data about a program at runtime. In Java, Reflection is implemented using the Java Reflection API , which consists of the package classes java.langand java.lang.reflect.</p> <p>Java Reflection API features: - Object class definition; - Getting information about class modifiers, fields, methods, constructors and superclasses; - Defining the interfaces implemented by the class; - Creating an instance of the class; - Getting and setting the values of the object's fields; - Calling object methods; - Creation of a new array.</p>"},{"location":"java/java-basics/#exceptions","title":"Exceptions","text":"<p>Exceptions are divided into several classes, but they all have a common ancestor - a class <code>Throwable</code> whose descendants are classes <code>Exception</code> and <code>Error</code>.</p> <ul> <li> <p>Errors are more serious problems that, according to the Java specification, should not be handled in a native program, as they are related to JVM-level problems. For example, exceptions of this kind are thrown if the memory available to the virtual machine runs out.</p> </li> <li> <p>Exceptions are the result of problems in the program that are, in principle, solvable, predictable, and the consequences of which can be eliminated within the program. For example, an integer was dividing by zero.</p> </li> </ul>"},{"location":"java/java-basics/#checked-and-unchecked-exception","title":"Checked and Unchecked Exception","text":"<p>In Java, all exceptions are of two types:</p> <ul> <li> <p>checked (checked / checked exceptions) must be handled by the block catch or described in the method header (for example throws IOException). The presence of such a handler / modifier in the method header is checked at compile time;   Examples: ArithmeticException, ClassCastException, ConcurrentModificationException, IllegalArgumentException, IllegalStateException, IndexOutOfBoundsException, NoSuchElementException, NullPointerException, UnsupportedOperationException.</p> </li> <li> <p>unchecked (unchecked / unchecked exceptions) , which include errors Error(for example OutOfMemoryError), which are not recommended to be handled, and runtime exceptions presented by the class RuntimeExceptionand its descendants (for example NullPointerException), which may not be handled by the block catchand not described in the method header.   Class errors <code>Error</code> are the most serious problems at the JVM level. For example, exceptions of this kind are thrown if the memory available to the virtual machine runs out. It is not prohibited to handle such errors, but it is not recommended to do so.</p> </li> </ul>"},{"location":"java/java-basics/#custom-exception","title":"Custom exception","text":"<p>You must inherit from the base class of the required type of exception (for example, from <code>Exception</code> or <code>RuntimeException</code>).</p> <pre><code>class CustomException extends Exception {\n    public CustomException() {\n        super();\n    }\n\n    public CustomException(final String string) {\n        super(string + \" is invalid\");\n    }\n\n    public CustomException(final Throwable cause) {\n        super(cause);\n    }\n}\n</code></pre>"},{"location":"java/java-basics/#outofmemoryerror","title":"OutOfMemoryError","text":"<p>OutOfMemoryError thrown when the Java virtual machine cannot create (allocate) an object due to insufficient memory, and the garbage collector cannot reclaim enough memory.</p> <p>The memory area occupied by a java process consists of several parts. The type OutOfMemoryErrordepends on which one is running out of space:</p> <ul> <li><code>java.lang.OutOfMemoryError</code>: Java heap space: There is not enough space in the heap, namely, in the area of memory in which objects created in the application programmatically are placed. Usually the problem lies in a memory leak. The size is set by the parameters -Xmsand -Xmx.</li> <li><code>java.lang.OutOfMemoryError</code>: PermGen space: (up to Java 8) This error occurs when there is not enough space in the Permanent area, the size of which is set by the -XX:PermSizeand parameters -XX:MaxPermSize.</li> <li><code>java.lang.OutOfMemoryError</code>: GC overhead limit exceeded: This error can occur both when the first and second areas are overflowed. It is connected with the fact that there is little memory left and the garbage collector is constantly working, trying to free up some space. This error can be disabled using the parameter -XX:-UseGCOverheadLimit.</li> <li><code>java.lang.OutOfMemoryError</code>: unable to create new native thread: Thrown out when it is not possible to create new streams.</li> </ul>"},{"location":"java/java-basics/#generics-in-java","title":"Generics in Java","text":"<p>Java Generics provides a way to reuse the same code with different inputs. The difference is that the inputs to formal parameters are values, while the inputs to type parameters are types.</p> <p>Advantages: - Generics provide compile-time type safety that allows programmers to catch invalid types at compile time. - When using Generics, there is no need of type-casting. - By using generics, programmers can implement generic algorithms that work on collections of different types, can be customized and are type safe and easier to read.</p>"},{"location":"java/java-basics/#benefits-of-generics","title":"Benefits of Generics","text":"<p>1. Stronger type checks at compile time</p> <p>A Java compiler applies strong type checking to generic code and issues errors if the code violates type safety. Fixing compile-time errors is easier than fixing runtime errors, which can be difficult to find. Example: In this example, List holds only a String type of objects in generics. It doesn\u2019t allow to store other objects</p> <pre><code>List&lt;String&gt; list = new ArrayList&lt;String&gt;(); \nlist.add(\"abc\");\n</code></pre> <p>2. Elimination of casts</p> <p>Code snippet without generics requires casting:</p> <pre><code>List list = new ArrayList();\nlist.add(\"hello\");\nString s = (String) list.get(0);\n</code></pre> <p>When re-written to use generics, the code does not require casting:</p> <pre><code>List&lt;String&gt; list = new ArrayList&lt;String&gt;();\nlist.add(\"hello\");\nString s = list.get(0);   // no cast\n</code></pre>"},{"location":"java/java-basics/#collection-framework-examples-for-generics","title":"Collection Framework examples for Generics","text":"<p>For Example: <code>ArrayList</code> class declaration from java.util package.</p> <pre><code>public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;\n        implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable\n{\n   .......\n}\n</code></pre> <p>For Example,  <code>HashSet</code> class declaration from java.util package.</p> <p><pre><code>public class HashSet&lt;E&gt;\n    extends AbstractSet&lt;E&gt;\n    implements Set&lt;E&gt;, Cloneable, java.io.Serializable\n{\n .....\n}\n</code></pre> For Example,  <code>HashMap</code> class declaration from java.util package.</p> <pre><code>public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt;\n    implements Map&lt;K,V&gt;, Cloneable, Serializable {\n....\n}\n</code></pre> <p>An <code>Iterable</code> interface from JDK 8 - java.lang package is an example for a Generic interface.</p> <pre><code>public interface Iterable&lt;T&gt; {\n\n    Iterator&lt;T&gt; iterator();\n\n    default void forEach(Consumer&lt;? super T&gt; action) {\n        Objects.requireNonNull(action);\n        for (T t : this) {\n            action.accept(t);\n        }\n    }\n\n    default Spliterator&lt;T&gt; spliterator() {\n        return Spliterators.spliteratorUnknownSize(iterator(), 0);\n    }\n}\n</code></pre> <p>One more example for Generic interface is <code>Comparable</code> interface.</p> <pre><code>public interface Comparable&lt;T&gt; {\n    public int compareTo(T o);\n}\n</code></pre>"},{"location":"java/java-basics/#type-parameter-naming-conventions","title":"Type Parameter Naming Conventions","text":"<p>By convention, type parameter names are single, uppercase letters. The type parameters naming conventions are important to learn generics thoroughly.</p> <p>The most commonly used type parameter names are: - E - Element (used extensively by the Java Collections Framework) - K - Key - N - Number - T - Type - V - Value - S, U, V etc. - 2<sup>nd</sup>, 3<sup>rd</sup>, 4<sup>th</sup> types</p>"},{"location":"java/java-basics/#multiple-type-parameters","title":"Multiple Type Parameters","text":"<p>A generic class can have multiple type parameters. Example: The generic OrderedPair class, which implements the generic Pair interface:</p> <pre><code>public interface Pair&lt;K, V&gt; {\n  public K getKey();\n  public V getValue();\n}\n\npublic class OrderedPair&lt;K, V&gt; implements Pair&lt;K, V&gt; {\n\n  private K key;\n  private V value;\n\n  public OrderedPair(K key, V value) {\n    this.key = key;\n    this.value = value;\n  }\n\n  public K getKey() { return key; }\n  public V getValue() { return value; }\n}\n</code></pre> <p>create two instantiations of the OrderedPair class <pre><code>Pair&lt;String, Integer&gt; p1 = new OrderedPair&lt;String, Integer&gt;(\"Even\", 8);\nPair&lt;String, String&gt;  p2 = new OrderedPair&lt;String, String&gt;(\"hello\", \"world\");\n</code></pre></p> <p>HashMap class is a good example of Multiple Type Parameters.</p> <pre><code>public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt;\n    implements Map&lt;K,V&gt;, Cloneable, Serializable {\n...\n}\npublic interface Map&lt;K,V&gt; {\n...\n}\n</code></pre>"},{"location":"java/java-basics/#immutable-object","title":"Immutable object","text":"<p>Immutable objects whose state (i.e. the object\u2019s data) does not change once it is instantiated (i.e. it becomes a read-only object after instantiation). Immutable classes are ideal for representing numbers (e.g. java.lang.Integer, java.lang.Float, java.lang.BigDecimal etc are immutable objects), enumerated types, colors (e.g. java.awt.Color is an immutable object), short lived objects like events, messages etc.</p>"},{"location":"java/java-basics/#benefits-of-immutable-objects","title":"Benefits of immutable objects","text":"<ul> <li>\u2022 Immutable classes can greatly simplify programming by freely allowing you to cache and share the references to the immutable objects without having to defensively copy them or without having to worry about their values becoming stale or corrupted.</li> <li>\u2022 Immutable classes are inherently thread-safe and you do not have to synchronize access to them to be used in a multi-threaded environment. So there is no chance of negative performance consequences.</li> <li>\u2022 Eliminates the possibility of data becoming inaccessible when used as keys in HashMaps or as elements in Sets. These types of errors are hard to debug and fix. </li> </ul>"},{"location":"java/java-basics/#immutable-class","title":"Immutable Class","text":"<p>Writing an immutable class is generally easy but there can be some tricky situations. Follow the following guidelines:</p> <ol> <li>A class is declared <code>final</code> (i.e. final classes cannot be extended). <pre><code>   public final class MyImmutable { ... }\n```\n2. All its fields are final (final fields cannot be mutated once assigned).\n```java\n   private final int[] myArray; //do not declare as -&gt;  private final int[] myArray = null;\n</code></pre></li> <li>Do not provide any methods that can change the state of the immutable object in any way \u2013 not just setXXX methods, but any methods which can change the state.</li> <li>The <code>this</code> reference is not allowed to escape during construction from the immutable class and the immutable class should have exclusive access to fields that contain references to mutable objects like arrays, collections and mutable classes like Date etc by:</li> <li>Declaring the mutable references as private.</li> <li>Not returning or exposing the mutable references to the caller (this can be done by defensive copying)</li> </ol>"},{"location":"java/java-basics/#wrong-way-to-write-an-immutable-class","title":"Wrong way to write an immutable class","text":"<ul> <li>Wrong way to write a constructor:</li> </ul> <p><pre><code>public final class MyImmutable {\n    private final int[] myArray;\n    public MyImmutable(int[] anArray) { this.myArray = anArray; // wrong\n    }\n    public String toString() {\n        StringBuffer sb = new StringBuffer(\"Numbers are: \"); \n        for (int i = 0; i &lt; myArray.length; i++) {\n            sb.append(myArray[i] + \" \");\n        }\n        return sb.toString(); }\n}   \n</code></pre> The caller could change the array after calling the constructor.</p> <pre><code> int[] array = {1,2};\nMyImmutable myImmutableRef = new MyImmutable(array) ; \nSystem.out.println(\"Before constructing \" + myImmutableRef); array[1] = 5; // change (i.e. mutate) the element \nSystem.out.println(\"After constructing \" + myImmutableRef);\n</code></pre> <p>Out put: <pre><code> Before constructing Numbers are: 1 2\n After constructing Numbers are: 1 5\n</code></pre></p> <p>As you can see in the output that the <code>MyImmutable</code> object has been mutated. This is because the object reference gets copied</p> <ul> <li>Wrong way to write an accessor.  A caller could get the array reference and then change the contents:</li> </ul> <pre><code>public  int[] getArray() {\n        return myArray;\n} \n</code></pre>"},{"location":"java/java-basics/#right-way-to-write-an-immutable-class","title":"Right way to write an immutable class","text":"<p>Right way is to copy the array before assigning in the constructor: <pre><code>public final class MyImmutable {\n    private final int[] myArray;\n    public MyImmutable(int[] anArray) {\n        this.myArray = anArray.clone(); // defensive copy\n    }\n    public String toString() {\n        StringBuffer sb = new StringBuffer(\"Numbers are: \"); for (int i = 0; i &lt; myArray.length; i++) {\n            sb.append(myArray[i] + \" \"); }\n        return sb.toString(); }\n}   \n</code></pre></p> <p>The caller cannot change the array after calling the constructor.</p> <pre><code>int[] array = {1,2};\n        MyImmutable myImmutableRef = new MyImmutable(array) ; \n        System.out.println(\"Before constructing \" + myImmutableRef); \n        array[1] = 5; // change (i.e. mutate) the element \n System.out.println(\"After constructing \" + myImmutableRef); \n</code></pre> <p>Out put: <pre><code>Before constructing Numbers are: 1 2\nAfter constructing Numbers are: 1 2\n</code></pre> As you can see in the output that the <code>MyImmutable</code> object has not been mutated.</p> <ul> <li>Right way to write an accessor by cloning. <pre><code> public int[] getAray() {\n        return (int[]) myArray.clone();\n}\n</code></pre></li> </ul>"},{"location":"java/java-basics/#pass-by-reference-and-pass-by-value","title":"Pass by reference and Pass by value","text":"<p>Other languages use <code>pass-by-reference</code> or <code>pass-by-pointer</code>. But in Java no matter what type of argument you pass the corresponding parameter (primitive variable or object reference) will get a copy of that data, which is exactly how pass-by-value (i.e. copy-by-value) works.</p> <p>In Java, if a calling method passes a reference of an object as an argument to the called method then the passed- in reference gets copied first and then passed to the called method. Both the original reference that was passed-in and the copied reference will be pointing to the same object. So no matter which reference you use, you will be always modifying the same original object, which is how the pass-by-reference works as well.</p> <p>If  method call involves inter-process (e.g. between two JVMs) communication, then the reference of the calling method has a different address space to the called method sitting in a separate process (i.e. separate JVM). Hence inter-process communication involves calling method passing objects as arguments to called method by-value in a serialized form, which can have negative affect performance due to marshaling and unmarshaling cost.</p>"},{"location":"java/java-basics/#shallow-cloning-and-deep-cloning","title":"Shallow cloning and Deep cloning","text":"<p>The default behavior of an object\u2019s clone() method automatically yields a shallow copy. So to achieve a deep copy the classes must be edited or adjusted.</p> <ul> <li> <p>Shallow copy: If a shallow copy is performed on object-1  then it is copied but its contained objects are not. The contained objects object-1 and object-2 are affected by changes to cloned Object-2. Java supports shallow cloning of objects by default when a class implements the java.lang.Cloneable interface.</p> </li> <li> <p>Deep copy: If a deep copy is performed on object-1 then not only object-1 has been copied but the objects contained within it have been copied as well. Serialization can be used to achieve deep cloning. Deep cloning through serialization is faster to develop and easier to maintain but carries a performance overhead.</p> </li> </ul> <p></p> <p><code>For example:</code> invoking clone() method on a collection like HashMap, List etc returns a shallow copy of HashMap, List, instances. This means if you clone a HashMap, the map instance is cloned but the keys and values themselves are not cloned. If you want a deep copy then a simple method is to serialize the HashMap to a ByteArrayOutputSream and then deserialize it. This creates a deep copy but does require that all keys and values in the HashMap are Serializable. Main advantage of this approach is that it will deep copy any arbitrary object graph. Alternatively you can provide a static factory method to deep copy. </p> <p>Example: to deep copy a list of Car objects.</p> <pre><code>public static List deepCopy(List listCars) {\n    List copiedList = new ArrayList(10);\n    for (Object object : listCars) { \n        Car original = (Car)object;\n        Car carCopied = new Car(); //instantiate a new Car object \n        carCopied.setColor((original.getColor())); \n        copiedList.add(carCopied);\n    }\n        return copiedList;\n}\n</code></pre>"},{"location":"java/java-basics/#instance-variable-and-a-static-variable","title":"Instance variable and a Static variable","text":"Static variables Instance variables Class variables are called static variables. There is only one occurrence of a class variable per JVM per class loader. When a class is loaded the class variables (aka static variables) are initialized. Instance variables are non-static and there is one occurrence of an instance variable in each class instance (i.e. each object). Also known as a member variable or a field. A static variable is used in the singleton pattern Instance variables we can not use A static variable is used with a final modifier to define constants. Instance variables we can not use"},{"location":"java/java-basics/#local-variables-vs-instance-and-static-variables","title":"Local variables vs Instance and static variables","text":"Local variables Instance and static variables Local variables have a narrower scope than instance variables. Instance variables have a narrower scope than static variables. The lifetime of a local variable is determined by execution path and local variables are also known as stack variables because they live on the stack. Instance and static variables are associated with objects and therefore live in the heap. For a local variable, it is illegal for code to fail to assign it a value. It is the best practice to declare local variables only where required as opposed to declaring them upfront and cluttering up your code with some local variables that never get used. Both the static and instance variables always have a value. If your code does not assign them a value then the run-time system will implicitly assign a default value (e.g. null/0/0.0/false)."},{"location":"java/java-basics/#access-modifiers","title":"Access modifiers","text":"Modifier Used with Description public Outer classes, interfaces, constructors, Inner classes, methods and field variables A class or interface may be accessed from outside the package. Constructors, inner classes, methods and field variables may be accessed wherever their class is accessed. protected Constructors, inner classes, methods, and field variables. Accessed by other classes in the same package or any subclasses of the class in which they are referred (i.e. same package or different package). private Constructors, inner classes,methods and field variables, Accessed only within the class in which they are declared No modifier: (Package by default). Outer classes, inner classes, interfaces, constructors, methods, and field variables Accessed only from within the package in which they are declared."},{"location":"java/java-basics/#volatile-keyword","title":"Volatile keyword","text":"<ol> <li>The volatile keyword is only applicable to a variable and using a volatile keyword with class and method is illegal.</li> <li>volatile keyword in Java guarantees that the value of the volatile variable will always be read from main memory and not from Thread's local cache.</li> <li>In Java reads and writes are atomic for all variables declared using Java volatile keyword (including long and double variables).</li> <li>Using the volatile keyword in Java on variables reduces the risk of memory consistency errors because any write to a volatile variable in Java establishes a happens-before relationship with subsequent reads of that same variable.</li> <li>From Java 5 changes to a volatile variable are always visible to other threads. What's more, it also means that when a thread reads a volatile variable in Java, it sees not just the latest change to the volatile variable but also the side effects of the code that led up the change.</li> <li>Reads and writes are atomic for reference variables are for most primitive variables (all types except long and double) even without the use of volatile keyword in Java.</li> <li>Access to a volatile variable in Java never has a chance to block, since we are only doing a simple read or write, so unlike a synchronized block we will never hold on to any lock or wait for any lock.</li> <li>Java volatile variable that is an object reference may be null.</li> <li>Java volatile keyword doesn't mean atomic, its common misconception that after declaring volatile ++ will be atomic, to make the operation atomic you still need to ensure exclusive access using synchronized method or block in Java.</li> <li>If a variable is not shared between multiple threads, you don't need to use volatile keyword with that variable.</li> </ol>"},{"location":"java/java-basics/#synchronized-vs-volatile","title":"synchronized vs volatile","text":"<ol> <li>The volatile keyword in Java is a field modifier while synchronized modifies code blocks and methods.</li> <li>Synchronized obtains and releases the lock on monitor\u2019s Java volatile keyword doesn't require that.</li> <li>Threads in Java can be blocked for waiting for any monitor in case of synchronized, that is not the case with the volatile keyword in Java.</li> <li>Synchronized method affects performance more than a volatile keyword in Java.</li> <li>Since volatile keyword in Java only synchronizes the value of one variable between Thread memory and \"main\" memory while synchronized synchronizes the value of all variable between thread memory and \"main\" memory and locks and releases a monitor to boot. Due to this reason synchronized keyword in Java is likely to have more overhead than volatile.</li> <li>You can not synchronize on the null object but your volatile variable in Java could be null.</li> </ol>"},{"location":"java/java-basics/#volatile-vs-transient-keyword","title":"Volatile vs transient keyword","text":"<p>A <code>volatile keyword</code> is used in a multithreading environment where two threads reading and writing the same variable simultaneously. The volatile keyword flushes the changes directly to the main memory instead of the CPU cache.</p> <p>On the other hand, the <code>transient keyword</code> is used during serialization. Fields that are marked as transient can not be part of the serialization and deserialization. We don't want to save the value of any variable then we use transient keyword with that variable.</p> S.No. key Volatile Transient 1 Basic Volatile keyword is used to flush changes directly to the main memory The transient keyword is used to exclude variable during serialization 2 Default value Volatile are not initialized with a default value During deserialization, transient  variables are initialized with a default value 3 Static Volatile can be used with a static variable. Transient can not be used with the static keyword 4 Final Volatile can be used with the final keyword Transient can not be used with the final keyword <p>Example of Volatile</p> <pre><code>class VolatileExmaple extends Thread{\n   booleanvolatile isRunning = true;\n   public void run() {\n      long count=0;\n      while (isRunning) {\n         count++;\n      }\n      System.out.println(\"Thread terminated.\" + count);\n   }\n   public static void main(String[] args) throws InterruptedException {\n      VolatileExmaple t = new VolatileExmaple();\n      t.start();\n      Thread.sleep(2000);\n      t.isRunning = false;\n      t.join();\n      System.out.println(\"isRunning set to \" + t.isRunning);\n   }\n}\n</code></pre> <p>Example of Transient</p> <p>A sample class that uses transient keyword to skip their serialization.</p> <pre><code>class TransientExample implements Serializable {\n   transient int age;\n   // serialize other fields\n   private String name;\n   private String address;\n   // other code\n}\n</code></pre>"},{"location":"java/java-basics/#java-for-each-loop-enhanced-for-loop","title":"Java For-each Loop | Enhanced For Loop","text":"<p>The Java for-each loop or enhanced for loop is introduced since J2SE 5.0. It provides an alternative approach to traverse the array or collection in Java. It is mainly used to traverse the array or collection elements.</p> <p>Advantages : it eliminates the possibility of bugs and makes the code more readable. It is known as the for-each loop because it traverses each element one by one.</p> <ul> <li>It makes the code more readable.</li> <li>It eliminates the possibility of programming errors.</li> </ul> <p>Disadvantages : it cannot traverse the elements in reverse order. Here, you do not have the option to skip any element because it does not work on an index basis. Moreover, you cannot traverse the odd or even elements only.</p> <p>Syntax : The syntax of Java for-each loop consists of data_type with the variable followed by a colon (:), then array or collection.</p> <p><code>java for(data_type variable : array | collection){   //body of for-each loop   }</code></p>"},{"location":"java/java-basics/#constructors-and-methods","title":"Constructors and Methods","text":"S.No. key Constructors Methods 1 Purpose Constructor is used to create and initialize an Object . Method is used to execute certain statements. 2 Invocation A constructor is invoked implicitly by the System. A method is to be invoked during program code. 3 Invocation A constructor is invoked when new keyword is used to create an object. A method is invoked when it is called. 4 Return type A constructor can not have any return type. A method can have a return type. 5 Object A constructor initializes an object which is not existent. A method can be invoked only on existing object. 6 Name A constructor must have same name as that of the class. A method name can not be same as class name. 7 Inheritance A constructor cannot be inherited by a subclass. A method is inherited by a subclass."},{"location":"java/java-basics/#for-more-information","title":"For more information","text":"<ol> <li>Java 8 Features</li> <li>java-interview</li> <li>Java Generics Tutorial with Examples</li> <li>Difference Between Final, Finally and Finalize in Java</li> <li>Know the Differences Between final, finally, and finalize in Java.</li> </ol>"},{"location":"java/java17/","title":"Java 17","text":""},{"location":"java/java17/#java-17-new-features-and-improvements","title":"Java 17 New Features and Improvements","text":"<p>Java 17, the latest release in the Java Development Kit (JDK) series, brings several exciting new features and improvements. These enhancements enhance the developer experience, performance, and functionality of the Java programming language. Let's dive into the details:</p>"},{"location":"java/java17/#sealed-classes-and-interfaces","title":"Sealed Classes and Interfaces:","text":"<p>One significant addition in Java 17 is the ability to declare classes and interfaces as \"sealed.\" Sealed classes and interfaces restrict which other classes or interfaces can extend or implement them. This helps in creating more robust and maintainable code by explicitly specifying the allowed subclasses. Here's a simple example:</p> <pre><code>sealed interface Shape permits Circle, Rectangle {\n    double area();\n}\n\nfinal class Circle implements Shape {\n    // Implementation for Circle\n    // ...\n}\n\nfinal class Rectangle implements Shape {\n    // Implementation for Rectangle\n    // ...\n}\n</code></pre>"},{"location":"java/java17/#pattern-matching-for-switch","title":"Pattern Matching for Switch:","text":"<p>Java 17 introduces enhanced pattern matching for the <code>switch</code> statement. You can now use patterns to perform more concise and expressive conditional branching. For instance:</p> <pre><code>int day = 3;\nString dayName = switch (day) {\n    case 1 -&gt; \"Monday\";\n    case 2 -&gt; \"Tuesday\";\n    case 3 -&gt; \"Wednesday\";\n    default -&gt; \"Other\";\n};\n</code></pre>"},{"location":"java/java17/#strong-encapsulation-of-jdk-internals","title":"Strong Encapsulation of JDK Internals:","text":"<p>Java 17 further strengthens encapsulation by removing internal APIs that were previously accessible but not intended for external use. This enhances security and encourages developers to rely only on the public APIs.</p>"},{"location":"java/java17/#foreign-function-memory-api-incubator","title":"Foreign Function &amp; Memory API (Incubator):","text":"<p>The Foreign Function &amp; Memory API, an incubator feature, provides better interoperation with native code and memory. This can improve performance and make it easier to work with native libraries. The Foreign Function &amp; Memory API allows you to work with native code and memory more efficiently. You can define data structures in Java that mirror native structures, making it easier to pass data between Java and native libraries. Here's a basic example:</p> <pre><code>import jdk.incubator.foreign.CLinker;\nimport jdk.incubator.foreign.MemoryAddress;\nimport jdk.incubator.foreign.MemorySegment;\n\nMemorySegment segment = MemorySegment.allocateNative(4); // Allocate 4 bytes\nMemoryAddress address = segment.baseAddress();\nCLinker.CLinkerTo&lt;?&gt; linkerTo = CLinker.toNativeFunction(Void.class, \"(int)printf\");\nlinkerTo.invokeExact(\"Hello from Java %d\\n\", 17);\nsegment.close();\n</code></pre>"},{"location":"java/java17/#new-macos-rendering-pipeline","title":"New macOS Rendering Pipeline:","text":"<p>On macOS, Java 17 introduces a new rendering pipeline that utilizes Apple's Metal framework for improved graphics performance and compatibility.</p> <p>The new rendering pipeline on macOS not only improves performance but also provides better support for high-resolution displays and retina screens, resulting in crisper and more visually appealing graphics in Java applications.</p>"},{"location":"java/java17/#unix-domain-socket-channel","title":"Unix-Domain Socket Channel:","text":"<p>For network programming on Unix-based systems, Java 17 introduces the Unix-Domain Socket Channel, allowing direct communication between processes on the same machine using Unix domain sockets.</p> <p>The Unix-Domain Socket Channel is particularly useful for developing server applications on Unix-based systems where processes need to communicate efficiently via sockets without the overhead of network communication.</p>"},{"location":"java/java17/#deprecation-and-removals","title":"Deprecation and Removals:","text":"<p>Java 17 also marks several APIs as deprecated or removed, including the Applet API, RMI Activation System, and various security-related components. Be aware of deprecated and removed APIs to ensure your codebase remains up-to-date and avoids using obsolete features. Review the release notes for comprehensive details on deprecated and removed APIs.</p>"},{"location":"java/java17/#pattern-matching-for-instanceof","title":"Pattern Matching for <code>instanceof</code>:","text":"<p>In addition to the enhanced <code>switch</code> statement, Java 17 introduces pattern matching for the <code>instanceof</code> operator. This simplifies type checking and casting. Here's an example:</p> <pre><code>if (obj instanceof String str) {\n    // Now 'str' is of type String within this block\n    System.out.println(\"Length of string: \" + str.length());\n} else {\n    System.out.println(\"Not a String\");\n}\n</code></pre>"},{"location":"java/java17/#project-loom-incubator","title":"Project Loom (Incubator):","text":"<p>While not a part of the standard Java SE Platform yet, Project Loom is an exciting incubator project in Java 17 that aims to simplify concurrency by introducing lightweight, user-mode threads called \"fibers.\" These fibers can be created and scheduled more efficiently than traditional threads, making it easier to write scalable and responsive applications.</p> <pre><code>import java.util.concurrent.Executors;\nimport java.util.concurrent.ExecutorService;\n\npublic class FiberExample {\n    public static void main(String[] args) {\n        ExecutorService executor = Executors.newVirtualThreadPerTaskExecutor();\n        executor.submit(() -&gt; {\n            System.out.println(\"Running in a fiber!\");\n        });\n        executor.shutdown();\n    }\n}\n</code></pre>"},{"location":"java/java17/#new-garbage-collectors","title":"New Garbage Collectors:","text":"<p>Java 17 introduces two new garbage collectors - <code>Epsilon</code> and <code>ZGC</code> (Z Garbage Collector). <code>Epsilon</code> is a \"no-op\" garbage collector useful for performance testing and debugging. <code>ZGC</code> is designed for low-latency applications, making it an excellent choice for applications that require minimal pause times.</p>"},{"location":"java/java17/#vector-api-incubator","title":"Vector API (Incubator):","text":"<p>The Vector API, also in incubator status, provides a way to express vector computations explicitly in Java. This feature is valuable for applications that require high-performance number crunching, such as scientific simulations and data analytics.</p> <pre><code>import jdk.incubator.vector.FloatVector;\nimport jdk.incubator.vector.VectorSpecies;\n\nVectorSpecies&lt;Float&gt; species = FloatVector.SPECIES_256;\nFloatVector vec1 = FloatVector.broadcast(species, 2.0f);\nFloatVector vec2 = FloatVector.broadcast(species, 3.0f);\nFloatVector result = vec1.mul(vec2);\n</code></pre>"},{"location":"java/java17/#enhanced-security","title":"Enhanced Security:","text":"<p>Java 17 includes updates to its security libraries and algorithms to provide stronger protection against security threats. Keeping your Java runtime up-to-date helps ensure the security of your applications.</p>"},{"location":"java/java17/#api-enhancements","title":"API Enhancements:","text":"<p>Java 17 includes various API enhancements and additions. One notable example is the introduction of new methods and classes in the standard libraries to simplify common tasks. For instance, the new <code>List.copyOf()</code> method allows you to create immutable lists easily:</p> <pre><code>List&lt;String&gt; originalList = List.of(\"Java\", \"is\", \"awesome\");\nList&lt;String&gt; immutableList = List.copyOf(originalList);\n</code></pre>"},{"location":"java/java17/#enhanced-performance","title":"Enhanced Performance:","text":"<p>With each new Java release, there are optimizations and performance improvements under the hood. Java 17 is no exception, as it continues to refine the runtime and compiler for better performance across various workloads.</p>"},{"location":"java/java17/#language-improvements","title":"Language Improvements:","text":"<p>While we've discussed several language-level improvements, Java 17 also includes other enhancements such as better type inference, improved error messages, and refinements in existing language features, all aimed at making the language more developer-friendly.</p>"},{"location":"java/java17/#improved-memory-management","title":"Improved Memory Management:","text":"<p>Java 17 introduces enhancements to memory management, garbage collection, and resource handling. These improvements contribute to more efficient memory utilization and reduced overhead.</p>"},{"location":"java/java17/#enhanced-documentation","title":"Enhanced Documentation:","text":"<p>With the release of Java 17, there is typically an updated JavaDocs and improved documentation, making it easier for developers to find information and understand the APIs better.</p>"},{"location":"java/java17/#sealed-classes-and-interfaces_1","title":"Sealed Classes and Interfaces","text":"<p>Sealed classes and interfaces are a new feature introduced in Java 17 to control the inheritance hierarchy more precisely. They allow you to specify which classes or interfaces can extend or implement them. This concept enhances code maintainability, security, and ensures that the code adheres to the intended design. In this explanation, we'll delve into the details of sealed classes and interfaces with clear examples.</p>"},{"location":"java/java17/#sealed-classes","title":"Sealed Classes:","text":"<p>A sealed class is one that explicitly specifies which other classes can extend it. This restriction is defined using the <code>sealed</code> modifier and the <code>permits</code> clause to list the allowed subclasses. Here's a simple example:</p> <pre><code>sealed class Shape permits Circle, Rectangle {\n    // Common methods and properties for shapes\n}\n\nfinal class Circle extends Shape {\n    // Implementation for Circle\n}\n\nfinal class Rectangle extends Shape {\n    // Implementation for Rectangle\n}\n\nclass Triangle extends Shape {\n    // Error! Triangle is not permitted to extend Shape\n}\n</code></pre> <p>In this example, the <code>Shape</code> class is sealed, and it permits only <code>Circle</code> and <code>Rectangle</code> to extend it. Attempting to create a <code>Triangle</code> class that extends <code>Shape</code> will result in a compilation error because it is not listed in the <code>permits</code> clause.</p>"},{"location":"java/java17/#sealed-interfaces","title":"Sealed Interfaces:","text":"<p>Similarly, you can create sealed interfaces to control which classes can implement them. Here's an example of sealed interfaces:</p> <pre><code>public sealed interface PaymentMethod permits CreditCard, PayPal {\n    void processPayment();\n}\n\nfinal class CreditCard implements PaymentMethod {\n    // Implementation for CreditCard payment\n    public void processPayment() {\n        // Payment processing logic\n    }\n}\n\nfinal class PayPal implements PaymentMethod {\n    // Implementation for PayPal payment\n    public void processPayment() {\n        // Payment processing logic\n    }\n}\n\nclass Bitcoin implements PaymentMethod {\n    // Error! Bitcoin is not permitted to implement PaymentMethod\n}\n</code></pre> <p>In this case, the <code>PaymentMethod</code> interface is sealed and permits only <code>CreditCard</code> and <code>PayPal</code> to implement it. Any attempt to have a class like <code>Bitcoin</code> implement the <code>PaymentMethod</code> interface will result in a compilation error.</p>"},{"location":"java/java17/#benefits-of-sealed-classes-and-interfaces","title":"Benefits of Sealed Classes and Interfaces:","text":"<ol> <li> <p>Enhanced Design Control: Sealed classes and interfaces allow developers to clearly define and restrict the hierarchy of subclasses or implementers, ensuring that the codebase adheres to the intended design.</p> </li> <li> <p>Improved Readability: By explicitly specifying which classes or interfaces can extend or implement, it becomes easier for developers to understand the design and intent of the code.</p> </li> <li> <p>Security: Sealed classes and interfaces can enhance security by preventing unexpected or unauthorized extensions or implementations.</p> </li> <li> <p>Maintenance: These features make code maintenance more straightforward, as developers can be confident that the hierarchy remains controlled and well-defined.</p> </li> </ol> <p>Incorporate sealed classes and interfaces into your Java development to create more robust and maintainable code. Whether you are a student learning Java or a developer looking to improve your code structure, sealed classes and interfaces are a valuable addition to your toolbox.</p>"},{"location":"java/java17/#guidelines-for-uses","title":"Guidelines for Uses","text":"<p>When working with sealed classes and interfaces in Java 17, here are some essential guidelines to keep in mind:</p> <ol> <li> <p>Choose Sealing Wisely: Not every class or interface needs to be sealed. Reserve sealed classes and interfaces for situations where you want to control the inheritance or implementation hierarchy explicitly.</p> </li> <li> <p>Use <code>permits</code> Sparingly: Be selective when listing permitted subclasses or implementers. Too many entries in the <code>permits</code> clause can make your code complex and harder to maintain.</p> </li> <li> <p>Default \"Unsealed\" Behavior: If you omit the <code>permits</code> clause, the class or interface is implicitly considered \"unsealed.\" This means that any class can extend or implement it without restrictions.</p> </li> <li> <p>Final Classes and Sealed: You can combine the <code>final</code> modifier with sealed classes to disallow any further subclassing. This can be useful when you want to create classes that are not meant to be extended.</p> </li> </ol> <pre><code>sealed final class FinalShape permits Circle, Rectangle {\n    // Common methods and properties for final shapes\n}\n</code></pre> <ol> <li> <p>Revisiting Sealing: You can change the permitted subclasses or implementers in subclasses. For example, if you have a sealed class, you can specify different permitted subclasses in its subclasses.</p> </li> <li> <p><code>non-sealed</code> Modifier: In some cases, you may want to allow unrestricted extension or implementation for a specific class or interface. You can use the <code>non-sealed</code> modifier to achieve this:</p> </li> </ol> <pre><code>public non-sealed interface UnrestrictedInterface {\n    // Interface members\n}\n</code></pre> <ol> <li> <p>Compatibility with Older Code: When using sealed classes and interfaces in newer versions of Java, consider the compatibility of your code with older Java versions. Older Java versions may not recognize these modifiers and may require adjustments.</p> </li> <li> <p>Documentation: Clearly document your design decisions when using sealed classes and interfaces. Explain why certain classes are sealed and what the permitted subclasses or implementers are.</p> </li> </ol> <p>Incorporating sealed classes and interfaces into your Java development workflow can greatly improve the structure and maintainability of your code. By following these guidelines, you can harness the power of this feature to create more secure and controlled class hierarchies and interfaces while ensuring your code remains readable and maintainable for all developers.</p>"},{"location":"java/java17/#pattern-matching-for-the-instanceof-operator","title":"Pattern Matching for the <code>instanceof</code> Operator","text":"<p>Pattern matching for the <code>instanceof</code> operator is a new feature introduced in Java 17, enhancing the readability and simplicity of type checking and casting. It allows you to combine the <code>instanceof</code> check with an automatic type casting, reducing boilerplate code. In this explanation, we'll explore how pattern matching for <code>instanceof</code> works in Java 17, with clear examples to illustrate its usage.</p>"},{"location":"java/java17/#traditional-instanceof-operator","title":"Traditional <code>instanceof</code> Operator:","text":"<p>Before we dive into pattern matching, let's review the traditional use of the <code>instanceof</code> operator in Java:</p> <pre><code>if (obj instanceof String) {\n    String str = (String) obj; // Explicit type casting\n    // Perform operations on 'str'\n}\n</code></pre> <p>In the above code, we check if <code>obj</code> is an instance of <code>String</code> and then perform a type casting to access its methods and properties. This approach requires both an <code>instanceof</code> check and explicit type casting, which can be verbose and error-prone.</p>"},{"location":"java/java17/#pattern-matching-for-instanceof-in-java-17","title":"Pattern Matching for <code>instanceof</code> in Java 17:","text":"<p>With pattern matching, you can combine the <code>instanceof</code> check and type casting into a single operation, making the code more concise and readable. Here's how it works:</p> <pre><code>if (obj instanceof String str) {\n    // 'str' is automatically cast to type 'String'\n    // Perform operations on 'str'\n} else {\n    // 'obj' is not an instance of 'String'\n}\n</code></pre> <p>In this updated code, we use the <code>instanceof</code> operator with a pattern variable <code>str</code>. If <code>obj</code> is an instance of <code>String</code>, it is automatically cast to <code>str</code>, and we can directly access and work with it. If the condition is not met, we can handle the alternative case in the <code>else</code> block.</p>"},{"location":"java/java17/#benefits-of-pattern-matching-for-instanceof","title":"Benefits of Pattern Matching for <code>instanceof</code>:","text":"<ol> <li> <p>Simpler and More Readable Code: Pattern matching reduces the verbosity and complexity of type checking and casting code, making it easier to understand at a glance.</p> </li> <li> <p>Eliminates Explicit Casting: You no longer need to explicitly cast the object after the <code>instanceof</code> check, reducing the potential for casting errors.</p> </li> <li> <p>Scope Control: The pattern variable (<code>str</code> in our example) is only accessible within the scope of the <code>if</code> block, enhancing code safety.</p> </li> <li> <p>Reduced Boilerplate: Pattern matching reduces the boilerplate code associated with traditional <code>instanceof</code> checks and casting, resulting in more concise code.</p> </li> </ol>"},{"location":"java/java17/#use-cases-for-pattern-matching-for-instanceof","title":"Use Cases for Pattern Matching for <code>instanceof</code>:","text":"<p>Pattern matching for <code>instanceof</code> is particularly useful in scenarios where you need to determine the type of an object and perform operations accordingly. Common use cases include:</p> <ul> <li>Handling different types of data in a collection.</li> <li>Parsing and processing data from external sources.</li> <li>Implementing polymorphic behavior in object-oriented code.</li> </ul> <p>By incorporating pattern matching for the <code>instanceof</code> operator into your Java code, you can simplify type checking and casting, leading to cleaner and more maintainable code. It's a valuable addition to Java 17 that benefits both beginners and experienced developers.</p>"},{"location":"java/java17/#benefits-of-the-foreign-function-and-memory-api","title":"Benefits of the Foreign Function and Memory API","text":"<p>The Foreign Function and Memory API, introduced as an incubator feature in Java 17, brings significant advantages to Java developers. This API enhances interoperability with native code and memory, opening up new possibilities for performance optimization and integration with external libraries. In this explanation, we'll explore the benefits of the Foreign Function and Memory API with clear examples to illustrate its advantages.</p>"},{"location":"java/java17/#enhanced-interoperability","title":"Enhanced Interoperability:","text":"<p>The Foreign Function and Memory API enable Java applications to communicate more efficiently with native code and libraries written in languages like C and C++. This enhanced interoperability brings several benefits:</p>"},{"location":"java/java17/#1-performance-optimization","title":"1. Performance Optimization:","text":"<ul> <li> <p>By leveraging native code for performance-critical tasks, you can achieve significant speed improvements. This is especially valuable in applications where milliseconds matter, such as real-time simulations or high-frequency trading systems.</p> </li> <li> <p>The API allows you to use native libraries or system calls directly, reducing the overhead associated with Java's abstraction layers.</p> </li> </ul>"},{"location":"java/java17/#2-access-to-platform-specific-features","title":"2. Access to Platform-Specific Features:","text":"<ul> <li>You can access platform-specific features and system libraries that might not have Java equivalents, unlocking the full potential of the underlying hardware and operating system.</li> </ul>"},{"location":"java/java17/#3-integration-with-existing-codebases","title":"3. Integration with Existing Codebases:","text":"<ul> <li>For projects with existing native codebases, the Foreign Function and Memory API simplify the integration of Java components, making it easier to modernize and extend legacy systems.</li> </ul>"},{"location":"java/java17/#memory-management-and-resource-efficiency","title":"Memory Management and Resource Efficiency:","text":"<p>The API introduces features for more efficient memory management and resource handling:</p>"},{"location":"java/java17/#1-direct-memory-access","title":"1. Direct Memory Access:","text":"<ul> <li> <p>The API allows direct memory access, which is essential for working with native libraries that expect data in specific memory layouts or require pointer-level operations.</p> </li> <li> <p>This capability is valuable for tasks like reading and writing data to files, network sockets, or low-level hardware interfaces.</p> </li> </ul>"},{"location":"java/java17/#2-resource-management","title":"2. Resource Management:","text":"<ul> <li>The API offers a resource management mechanism, allowing you to allocate and release native resources efficiently. This helps prevent resource leaks and ensures that resources are released when they are no longer needed.</li> </ul>"},{"location":"java/java17/#example-using-foreign-function-and-memory-api","title":"Example - Using Foreign Function and Memory API:","text":"<p>Here's a simplified example of using the Foreign Function and Memory API to call a native function from a shared library (DLL on Windows, SO on Linux/Unix):</p> <pre><code>import jdk.incubator.foreign.CLinker;\nimport jdk.incubator.foreign.MemoryAddress;\n\npublic class NativeLibraryExample {\n    public static void main(String[] args) {\n        MemoryAddress libraryHandle = CLinker.SystemLoad.INSTANCE.dlopen(\"example.so\", CLinker.SystemLoad.FLAGS);\n        if (libraryHandle == null) {\n            throw new UnsatisfiedLinkError(\"Failed to load native library\");\n        }\n\n        // Define a native function signature\n        CLinker.CLinkerTo&lt;Void&gt; function = CLinker.CLinkerTo.name(\"example_function\", CLinker.CLinkerTo.address(CLinker.CLinkerTo.void_()));\n\n        // Call the native function\n        function.invoke();\n\n        // Close the library handle when done\n        CLinker.SystemLoad.INSTANCE.dlclose(libraryHandle);\n    }\n}\n</code></pre> <p>The Foreign Function and Memory API in Java 17 provide Java developers with enhanced interoperability, improved performance, and efficient memory management. Whether you're optimizing critical sections of your code, integrating with existing native libraries, or accessing platform-specific features, this API empowers you to take full advantage of the native environment. Incorporate it into your Java projects to unlock new possibilities and elevate the performance of your applications.</p>"},{"location":"java/java17/#strong-encapsulation-of-jdk-internals_1","title":"Strong Encapsulation of JDK Internals","text":"<p>The goal of strong encapsulation of JDK (Java Development Kit) internals in Java 17 is to enhance the security, stability, and maintainability of Java applications by restricting access to internal APIs (Application Programming Interfaces). This initiative seeks to ensure that developers rely only on the officially documented and supported APIs, reducing the risk of compatibility issues and vulnerabilities. In this explanation, we'll explore the purpose and impact of strong encapsulation on developers with practical insights.</p>"},{"location":"java/java17/#the-purpose-of-strong-encapsulation","title":"The Purpose of Strong Encapsulation:","text":""},{"location":"java/java17/#1-security-enhancement","title":"1. Security Enhancement:","text":"<ul> <li> <p>By limiting access to internal APIs, Java strengthens the security of applications. It prevents developers from using undocumented or unapproved APIs that may pose security risks.</p> </li> <li> <p>It reduces the attack surface and minimizes the chances of malicious code exploiting hidden, internal functions.</p> </li> </ul>"},{"location":"java/java17/#2-stability-and-compatibility","title":"2. Stability and Compatibility:","text":"<ul> <li> <p>Strong encapsulation helps maintain the stability of Java applications across different versions and implementations.</p> </li> <li> <p>Previously, relying on internal APIs could lead to unexpected issues when Java updates or vendor-specific implementations were introduced.</p> </li> <li> <p>Encouraging the use of official APIs ensures that applications are more likely to work consistently across different Java environments.</p> </li> </ul>"},{"location":"java/java17/#3-code-quality-and-maintainability","title":"3. Code Quality and Maintainability:","text":"<ul> <li> <p>Developers are encouraged to write code that adheres to official APIs and standards, resulting in higher-quality and more maintainable codebases.</p> </li> <li> <p>This practice helps future-proof applications, making them easier to maintain, update, and extend.</p> </li> </ul>"},{"location":"java/java17/#impact-on-developers","title":"Impact on Developers:","text":""},{"location":"java/java17/#1-deprecated-and-removed-apis","title":"1. Deprecated and Removed APIs:","text":"<ul> <li> <p>With strong encapsulation, developers may encounter warnings or errors when using deprecated or removed internal APIs.</p> </li> <li> <p>It is essential to review and update code to use recommended alternatives to avoid issues during migration to newer Java versions.</p> </li> </ul>"},{"location":"java/java17/#2-restricted-access","title":"2. Restricted Access:","text":"<ul> <li> <p>Developers may find that certain previously accessible internal classes, methods, or fields are no longer accessible.</p> </li> <li> <p>This might require adjustments in code to use official APIs or seek alternative solutions.</p> </li> </ul>"},{"location":"java/java17/#3-improved-documentation","title":"3. Improved Documentation:","text":"<ul> <li> <p>As internal APIs become inaccessible, developers will increasingly rely on official documentation and public APIs.</p> </li> <li> <p>This encourages better understanding of the available features and promotes good programming practices.</p> </li> </ul>"},{"location":"java/java17/#example-impact-on-deprecated-methods","title":"Example - Impact on Deprecated Methods:","text":"<p>In earlier Java versions, it was possible to use certain deprecated methods from internal classes. In Java 17, strong encapsulation restricts access to these methods. Here's a simplified example:</p> <pre><code>public class DeprecatedMethodExample {\n    public static void main(String[] args) {\n        // Deprecated method in an internal class (not recommended)\n        sun.misc.BASE64Encoder encoder = new sun.misc.BASE64Encoder();\n        String encoded = encoder.encode(\"Hello, World!\".getBytes());\n        System.out.println(encoded);\n    }\n}\n</code></pre> <p>In Java 17, attempting to use such deprecated methods will result in compilation errors, encouraging developers to use recommended alternatives provided by the standard libraries.</p> <p>The strong encapsulation of JDK internals in Java 17 is a significant step toward enhancing security, stability, and maintainability. While it may require developers to update existing code, the long-term benefits of stronger security, improved compatibility, and better code quality make it a worthwhile endeavor. Embracing official APIs and adhering to coding best practices ensures that Java applications remain secure and robust in an ever-evolving software landscape.</p>"},{"location":"java/java17/#the-vector-api-in-java-17-accelerating-parallel-computing","title":"The Vector API in Java 17: Accelerating Parallel Computing","text":"<p>The Vector API, introduced as an incubator feature in Java 17, empowers Java developers to harness the power of vectorization and parallel computing for performance-intensive tasks. This API enables efficient and simultaneous processing of multiple data elements, offering substantial speed improvements in various domains. In this explanation, we'll delve into the Vector API, its use cases, and how it can benefit developers with practical examples.</p> <p>The Vector API in Java 17 introduces the concept of \"vectors,\" which are data structures capable of holding multiple data elements of the same type. This API enables developers to express vector computations explicitly, taking advantage of modern hardware's ability to perform operations on multiple data elements in parallel.</p>"},{"location":"java/java17/#key-features-and-use-cases","title":"Key Features and Use Cases:","text":""},{"location":"java/java17/#1-data-parallel-operations","title":"1. Data-Parallel Operations:","text":"<ul> <li> <p>The Vector API facilitates data-parallelism, where the same operation is applied to multiple data elements simultaneously.</p> </li> <li> <p>This is particularly useful in scenarios involving large datasets, such as scientific simulations, data processing, and image manipulation.</p> </li> </ul>"},{"location":"java/java17/#2-enhanced-numerical-computations","title":"2. Enhanced Numerical Computations:","text":"<ul> <li> <p>The Vector API shines in numerical and scientific computing. It allows developers to perform complex mathematical operations efficiently on arrays of data.</p> </li> <li> <p>Use cases include matrix multiplication, signal processing, and simulations requiring rapid computations.</p> </li> </ul>"},{"location":"java/java17/#3-performance-optimization","title":"3. Performance Optimization:","text":"<ul> <li> <p>Developers can utilize the Vector API to optimize performance-critical code segments by parallelizing operations. This can lead to substantial speed improvements.</p> </li> <li> <p>Performance gains are most noticeable in CPU-bound applications, where computational tasks dominate execution time.</p> </li> </ul>"},{"location":"java/java17/#example-computing-element-wise-sum","title":"Example - Computing Element-Wise Sum:","text":"<p>Here's a simplified example demonstrating how the Vector API can be used to perform an element-wise sum of two arrays:</p> <pre><code>import jdk.incubator.vector.*;\n\npublic class VectorExample {\n    public static void main(String[] args) {\n        VectorSpecies&lt;Float&gt; species = FloatVector.SPECIES_128; // Choose the vector size\n\n        float[] data1 = {1.0f, 2.0f, 3.0f, 4.0f};\n        float[] data2 = {0.5f, 1.5f, 2.5f, 3.5f};\n        float[] result = new float[data1.length];\n\n        for (int i = 0; i &lt; data1.length; i += species.length()) {\n            FloatVector vec1 = FloatVector.fromArray(species, data1, i);\n            FloatVector vec2 = FloatVector.fromArray(species, data2, i);\n            FloatVector sum = vec1.add(vec2);\n            sum.intoArray(result, i);\n        }\n\n        for (float num : result) {\n            System.out.println(num);\n        }\n    }\n}\n</code></pre> <p>In this example, we create two arrays (<code>data1</code> and <code>data2</code>) and use the Vector API to perform an element-wise sum, utilizing vectorization for parallel computation.</p> <p>The Vector API in Java 17 empowers developers to unlock the full potential of modern hardware for parallel computing. It is a valuable addition for applications that require high-performance numerical computations and data processing. By harnessing the power of vectors, developers can optimize their code and significantly improve execution speed, making Java a more compelling choice for performance-intensive tasks in various domains.</p>"},{"location":"java/java17/#low-latency-garbage-collection-enhancements","title":"Low-Latency Garbage Collection Enhancements","text":"<p>Java 17 introduces several enhancements related to low-latency garbage collection, aimed at reducing pause times and improving the overall responsiveness of Java applications. These improvements address the critical need for real-time and low-latency applications, making Java a more attractive choice for a wider range of use cases. In this explanation, we'll explore the enhancements and their significance for developers.</p>"},{"location":"java/java17/#enhancements-for-low-latency-garbage-collection","title":"Enhancements for Low-Latency Garbage Collection:","text":""},{"location":"java/java17/#1-z-garbage-collector-zgc-enhancements","title":"1. Z Garbage Collector (ZGC) Enhancements:","text":"<ul> <li> <p>Java 17 continues to enhance the Z Garbage Collector (ZGC), which is known for its low-latency characteristics.</p> </li> <li> <p>Improved Concurrent Class Unloading: ZGC now allows for the concurrent unloading of classes, reducing pause times associated with class unloading.</p> </li> <li> <p>Smoother Garbage Collection Pauses: ZGC aims to provide consistently low-latency performance by minimizing pause times, making it suitable for real-time applications.</p> </li> </ul>"},{"location":"java/java17/#2-epsilon-garbage-collector","title":"2. Epsilon Garbage Collector:","text":"<ul> <li> <p>While not a collector for production use, Java 17 introduces the Epsilon Garbage Collector, which is essentially a \"no-op\" collector.</p> </li> <li> <p>Epsilon GC is useful for performance testing and debugging, as it doesn't perform any garbage collection. This can help identify memory allocation hotspots in applications.</p> </li> </ul>"},{"location":"java/java17/#3-predictable-and-consistent-behavior","title":"3. Predictable and Consistent Behavior:","text":"<ul> <li> <p>The enhancements in low-latency garbage collection contribute to more predictable and consistent garbage collection behavior.</p> </li> <li> <p>Applications with stringent latency requirements can benefit from these improvements by reducing the risk of unexpected pause times.</p> </li> </ul>"},{"location":"java/java17/#why-low-latency-garbage-collection-matters","title":"Why Low-Latency Garbage Collection Matters:","text":""},{"location":"java/java17/#1-real-time-and-interactive-applications","title":"1. Real-Time and Interactive Applications:","text":"<ul> <li> <p>Applications requiring real-time or interactive responses, such as online gaming, financial trading platforms, and multimedia streaming, demand low-latency garbage collection.</p> </li> <li> <p>Low-latency collectors like ZGC ensure that application responsiveness is maintained even under heavy load.</p> </li> </ul>"},{"location":"java/java17/#2-smooth-user-experience","title":"2. Smooth User Experience:","text":"<ul> <li> <p>Low-latency garbage collection is crucial for providing a smooth user experience in applications where interruptions or delays are highly noticeable and undesirable.</p> </li> <li> <p>Users of web applications, mobile apps, and virtual reality experiences benefit from reduced pauses and improved performance.</p> </li> </ul>"},{"location":"java/java17/#3-improved-resource-utilization","title":"3. Improved Resource Utilization:","text":"<ul> <li>By minimizing pause times, low-latency garbage collection allows applications to make better use of available system resources, resulting in more efficient resource utilization.</li> </ul>"},{"location":"java/java17/#4-compliance-with-service-level-agreements-slas","title":"4. Compliance with Service Level Agreements (SLAs):","text":"<ul> <li>Businesses and services that rely on meeting specific SLAs can achieve more predictable performance with low-latency garbage collection, reducing the risk of SLA violations.</li> </ul>"},{"location":"java/java17/#example-z-garbage-collector-configuration","title":"Example - Z Garbage Collector Configuration:","text":"<p>Here's an example of configuring the Z Garbage Collector in Java 17:</p> <pre><code>java -XX:+UseZGC -Xmx2g -Xms2g -jar YourApplication.jar\n</code></pre> <p>This command specifies the use of the Z Garbage Collector (<code>-XX:+UseZGC</code>) with a maximum heap size (<code>-Xmx2g</code>) and an initial heap size (<code>-Xms2g</code>) of 2 gigabytes.</p> <p>The enhancements related to low-latency garbage collection in Java 17 cater to the growing demand for real-time and low-latency applications. By reducing pause times and providing predictable performance, these improvements enable developers to build more responsive and efficient software. Whether you're creating interactive games, financial platforms, or any application where latency matters, the low-latency garbage collection features in Java 17 make it a compelling choice for a wide range of use cases.</p>"},{"location":"java/java17/#foreign-function-and-memory-api","title":"Foreign Function and Memory API","text":"<p>Java 17 introduces the Foreign Function and Memory API, which significantly enhances the way Java handles native libraries and dependencies. This API simplifies the interaction between Java and native code, making it easier for developers to work with external libraries and improving the overall integration of Java applications with the native ecosystem. In this explanation, we'll explore how Java 17 improves native library handling through the Foreign Function and Memory API, with practical examples and insights.</p>"},{"location":"java/java17/#simplified-native-library-integration","title":"Simplified Native Library Integration:","text":""},{"location":"java/java17/#1-native-function-calls","title":"1. Native Function Calls:","text":"<ul> <li> <p>The Foreign Function and Memory API allow Java applications to call functions in shared libraries (DLLs on Windows, SOs on Linux/Unix) directly, without the need for complex and error-prone JNI (Java Native Interface) code.</p> </li> <li> <p>This simplifies the integration of native functionality, enabling Java developers to access native libraries seamlessly.</p> </li> </ul>"},{"location":"java/java17/#2-memory-management","title":"2. Memory Management:","text":"<ul> <li> <p>The API offers a more efficient and controlled way to manage native memory. Developers can allocate, read, write, and release native memory segments with ease.</p> </li> <li> <p>This feature is particularly valuable when working with external libraries that expect data in specific memory layouts or require low-level memory operations.</p> </li> </ul>"},{"location":"java/java17/#enhanced-interoperability_1","title":"Enhanced Interoperability:","text":""},{"location":"java/java17/#1-data-structure-definitions","title":"1. Data Structure Definitions:","text":"<ul> <li> <p>Developers can define data structures in Java that mirror native structures. This allows for precise data mapping between Java and native code, ensuring compatibility.</p> </li> <li> <p>This is crucial for scenarios where data needs to be passed back and forth between Java and native functions.</p> </li> </ul>"},{"location":"java/java17/#2-bridging-the-gap","title":"2. Bridging the Gap:","text":"<ul> <li> <p>The Foreign Function and Memory API acts as a bridge between the managed Java environment and the unmanaged world of native code.</p> </li> <li> <p>This seamless integration simplifies the development of applications that rely on both Java and native functionality, such as multimedia processing or hardware interfacing.</p> </li> </ul>"},{"location":"java/java17/#example-calling-a-native-function","title":"Example - Calling a Native Function:","text":"<p>Here's a simplified example of calling a native function using the Foreign Function and Memory API:</p> <pre><code>import jdk.incubator.foreign.*;\n\npublic class NativeFunctionExample {\n    public static void main(String[] args) {\n        try (LibraryLoader&lt;CLibrary&gt; loader = LibraryLoader.of(CLibrary.class)) {\n            CLibrary cLibrary = loader.load(\"my_native_library\");\n\n            int result = cLibrary.myNativeFunction(42);\n            System.out.println(\"Result from native function: \" + result);\n        }\n    }\n}\n</code></pre> <p>In this example, we load a native library (<code>my_native_library</code>) and call a native function (<code>myNativeFunction</code>) directly from Java, simplifying the process of working with external native code.</p> <p>Java 17's Foreign Function and Memory API provide a significant improvement in handling native libraries and dependencies. By simplifying native function calls, offering efficient memory management, and enhancing interoperability, Java developers can seamlessly integrate native functionality into their applications. Whether you're working on multimedia applications, system-level utilities, or projects that require interfacing with hardware, the Foreign Function and Memory API in Java 17 makes it easier to leverage the power of native code while benefiting from Java's robust ecosystem.</p>"},{"location":"java/java17/#project-panama-and-its-relation-to-java-17","title":"Project Panama and Its Relation to Java 17","text":"<p>Project Panama is an open-source project initiated by Oracle to improve the connections between Java and native code, making it easier for Java developers to interact with native libraries and platforms. While Project Panama is a long-term effort spanning multiple Java releases, Java 17 introduces some features and enhancements that align with its goals. In this explanation, we'll delve into what Project Panama is and how it relates to Java 17's new features, with practical insights.</p>"},{"location":"java/java17/#understanding-project-panama","title":"Understanding Project Panama:","text":"<p>Project Panama aims to enhance Java's interoperability with native code by addressing several key areas:</p>"},{"location":"java/java17/#1-foreign-function-interface-ffi","title":"1. Foreign Function Interface (FFI):","text":"<ul> <li>Project Panama introduces an FFI that simplifies the process of calling native functions and working with native libraries from Java.</li> </ul>"},{"location":"java/java17/#2-memory-access-and-management","title":"2. Memory Access and Management:","text":"<ul> <li>It provides better support for handling native memory, allowing for efficient memory allocation, access, and management.</li> </ul>"},{"location":"java/java17/#3-data-structure-definitions","title":"3. Data Structure Definitions:","text":"<ul> <li>Project Panama enables Java to define data structures that map directly to native structures, ensuring seamless data exchange between Java and native code.</li> </ul>"},{"location":"java/java17/#4-platform-and-abi-application-binary-interface-support","title":"4. Platform and ABI (Application Binary Interface) Support:","text":"<ul> <li>It focuses on improving platform-specific and ABI support, making it easier to interact with native code on various platforms.</li> </ul>"},{"location":"java/java17/#relation-to-java-17s-new-features","title":"Relation to Java 17's New Features:","text":"<p>While Project Panama is an ongoing project, Java 17 introduces features related to native code handling and low-level memory management that align with Project Panama's goals:</p>"},{"location":"java/java17/#1-foreign-function-and-memory-api","title":"1. Foreign Function and Memory API:","text":"<ul> <li> <p>Java 17 introduces the Foreign Function and Memory API as an incubator feature, simplifying native function calls and providing efficient memory management.</p> </li> <li> <p>These features directly contribute to Project Panama's aim of improving the FFI and memory access in Java.</p> </li> </ul>"},{"location":"java/java17/#2-low-latency-garbage-collection-enhancements","title":"2. Low-Latency Garbage Collection Enhancements:","text":"<ul> <li>Java 17's improvements in low-latency garbage collection indirectly benefit Project Panama, as reduced garbage collection pauses are essential for applications that heavily interact with native code.</li> </ul>"},{"location":"java/java17/#example-calling-a-native-function-project-panama","title":"Example - Calling a Native Function (Project Panama):","text":"<p>Here's an example of calling a native function using the Foreign Function and Memory API introduced in Java 17 (aligned with Project Panama's goals):</p> <pre><code>import jdk.incubator.foreign.*;\n\npublic class NativeFunctionExample {\n    public static void main(String[] args) {\n        try (LibraryLoader&lt;CLibrary&gt; loader = LibraryLoader.of(CLibrary.class)) {\n            CLibrary cLibrary = loader.load(\"my_native_library\");\n\n            int result = cLibrary.myNativeFunction(42);\n            System.out.println(\"Result from native function: \" + result);\n        }\n    }\n}\n</code></pre> <p>This code demonstrates how Java can seamlessly call a native function from a shared library.</p> <p>Project Panama is an ongoing effort to enhance Java's interoperability with native code. While it spans multiple Java releases, Java 17 introduces features like the Foreign Function and Memory API and low-latency garbage collection enhancements that directly align with Project Panama's goals. These features make it easier for Java developers to work with native libraries and platforms, opening up new possibilities for Java applications that need to interact with native code efficiently. As Project Panama continues to evolve, it promises to further simplify and enhance the Java-native code interaction.</p>"},{"location":"java/java17/#best-practices","title":"Best Practices","text":"<p>Java 17 introduces several new features and enhancements that can empower developers to write more efficient and robust code. To make the most of these features, it's essential to follow best practices that ensure code readability, maintainability, and performance. In this explanation, we'll explore some best practices for using Java 17's new features, with practical insights and examples.</p>"},{"location":"java/java17/#1-keep-your-jdk-up-to-date","title":"1. Keep Your JDK Up to Date:","text":"<ul> <li>Ensure you are using the latest version of the Java Development Kit (JDK). Java 17 introduced these features, and later updates may include bug fixes and improvements.</li> </ul>"},{"location":"java/java17/#2-embrace-pattern-matching","title":"2. Embrace Pattern Matching:","text":"<ul> <li> <p>When using pattern matching, leverage the power of the <code>instanceof</code> operator to simplify code and enhance readability. Replace verbose type casting with pattern variables.</p> </li> <li> <p>Use pattern matching for <code>switch</code> statements to make code more concise and maintainable.</p> </li> </ul> <pre><code>// Before Java 17\nif (obj instanceof String) {\n    String str = (String) obj;\n    // Perform operations on 'str'\n}\n\n// With Java 17\nif (obj instanceof String str) {\n    // 'str' is automatically cast to type 'String'\n    // Perform operations on 'str'\n}\n</code></pre>"},{"location":"java/java17/#3-optimize-with-vector-api","title":"3. Optimize with Vector API:","text":"<ul> <li> <p>When working with the Vector API, identify performance-critical sections of your code and apply vectorization to parallelize operations. Use the API for numerical and data-parallel computations.</p> </li> <li> <p>Understand the hardware's SIMD (Single Instruction, Multiple Data) capabilities to make the most of vectorized operations.</p> </li> </ul> <pre><code>// Example of vectorized addition\nFloatVector vec1 = FloatVector.of(1.0f, 2.0f, 3.0f, 4.0f);\nFloatVector vec2 = FloatVector.of(0.5f, 1.5f, 2.5f, 3.5f);\nFloatVector sum = vec1.add(vec2);\n</code></pre>"},{"location":"java/java17/#4-low-latency-garbage-collection","title":"4. Low-Latency Garbage Collection:","text":"<ul> <li> <p>Take advantage of the low-latency garbage collection enhancements in Java 17 for applications requiring real-time or low-latency responses.</p> </li> <li> <p>Profile and tune your code to minimize object creation and reduce the impact of garbage collection pauses.</p> </li> </ul>"},{"location":"java/java17/#5-use-foreign-function-and-memory-api-wisely","title":"5. Use Foreign Function and Memory API Wisely:","text":"<ul> <li> <p>When working with the Foreign Function and Memory API, carefully manage native resources and memory. Ensure that you release resources explicitly to avoid leaks.</p> </li> <li> <p>Document your code and explain the usage of native functions and libraries, as this can be critical for maintenance.</p> </li> </ul>"},{"location":"java/java17/#6-stay-informed","title":"6. Stay Informed:","text":"<ul> <li> <p>Keep yourself updated with Java's evolving ecosystem. Follow official documentation, blogs, and community resources to learn about the latest best practices and recommendations.</p> </li> <li> <p>Engage with the Java community to share experiences and gain insights into using new features effectively.</p> </li> </ul>"},{"location":"java/java17/#7-test-and-profile","title":"7. Test and Profile:","text":"<ul> <li> <p>Thoroughly test your code to ensure it functions as expected with the new features.</p> </li> <li> <p>Use profiling tools to identify performance bottlenecks and areas where new features can be applied for optimization.</p> </li> </ul>"},{"location":"java/java17/#8-code-reviews","title":"8. Code Reviews:","text":"<ul> <li> <p>Engage in code reviews with peers to ensure that best practices are followed consistently throughout your codebase.</p> </li> <li> <p>Discuss the usage of new features to identify potential improvements or issues.</p> </li> </ul>"},{"location":"java/java17/#9-gradual-adoption","title":"9. Gradual Adoption:","text":"<ul> <li>If you have existing codebases, consider gradual adoption of new features. Migrating an entire codebase at once may be challenging, so start with small, manageable changes.</li> </ul>"},{"location":"java/java17/#10-documentation","title":"10. Documentation:","text":"<ul> <li>Document the usage of new features in your codebase. This helps other developers understand how to work with these features and their role in your project.</li> </ul> <p>By following these best practices, you can harness the power of Java 17's new features to write more efficient, maintainable, and reliable code. Whether you're a student, a developer, or a seasoned professional, these guidelines will help you make the most of Java's evolving capabilities.</p>"},{"location":"java/java17/#migrating-to-java-17","title":"Migrating to Java 17","text":"<p>Migrating code from older Java versions to Java 17 to take advantage of its new features is a rewarding endeavor that can lead to enhanced performance, improved code quality, and better developer productivity. To achieve a successful migration, developers should follow a structured approach that includes assessing compatibility, making code adjustments, and embracing new language features. In this guide, we'll explore how developers can migrate their code to Java 17 effectively, with practical insights and examples.</p>"},{"location":"java/java17/#steps","title":"Steps:","text":""},{"location":"java/java17/#1-assess-compatibility","title":"1. Assess Compatibility:","text":"<ul> <li> <p>Begin by assessing the compatibility of your existing codebase with Java 17. Identify any dependencies, libraries, or third-party tools that might not be compatible with the new version.</p> </li> <li> <p>Use Java's backward compatibility to your advantage, as most code written for older Java versions should work in Java 17 without major issues.</p> </li> </ul>"},{"location":"java/java17/#2-update-jdk","title":"2. Update JDK:","text":"<ul> <li>Ensure you have Java 17 (or a later version) installed on your development environment. You can download and install the latest JDK from the official Oracle or OpenJDK websites.</li> </ul>"},{"location":"java/java17/#3-code-analysis","title":"3. Code Analysis:","text":"<ul> <li>Analyze your codebase to identify areas where new features in Java 17 can be beneficial. Consider using code analysis tools and IDE plugins to assist in this process.</li> </ul>"},{"location":"java/java17/#4-compile-and-test","title":"4. Compile and Test:","text":"<ul> <li> <p>Compile your code using Java 17 and perform thorough testing. Pay close attention to any warnings or errors during compilation, as they may indicate deprecated or removed features that need to be addressed.</p> </li> <li> <p>Run your test suite to verify that the application behaves as expected in the new environment.</p> </li> </ul>"},{"location":"java/java17/#5-address-deprecated-features","title":"5. Address Deprecated Features:","text":"<ul> <li> <p>Java evolves with each version, and some features may be deprecated or removed. Review the Java release notes to identify deprecated features in your code.</p> </li> <li> <p>Replace deprecated features with recommended alternatives to ensure your code remains maintainable and compatible with future Java versions.</p> </li> </ul>"},{"location":"java/java17/#6-adopt-new-features-gradually","title":"6. Adopt New Features Gradually:","text":"<ul> <li> <p>Java 17 introduces several new features and enhancements. Instead of rewriting your entire codebase, consider adopting new features gradually.</p> </li> <li> <p>Start with smaller, manageable changes, and progressively refactor and optimize your codebase.</p> </li> </ul>"},{"location":"java/java17/#7-refactor-for-performance","title":"7. Refactor for Performance:","text":"<ul> <li> <p>Utilize Java 17's new features like the Vector API and low-latency garbage collection to optimize performance-critical sections of your code.</p> </li> <li> <p>Profile and benchmark your code to identify areas where these features can lead to performance improvements.</p> </li> </ul>"},{"location":"java/java17/#8-documentation","title":"8. Documentation:","text":"<ul> <li>Update your code's documentation to reflect the changes made during migration. Clearly document the usage of new Java 17 features to help other developers understand their purpose and usage.</li> </ul>"},{"location":"java/java17/#9-continuous-integration-and-testing","title":"9. Continuous Integration and Testing:","text":"<ul> <li>Implement continuous integration (CI) and automated testing to ensure that your codebase remains compatible with Java 17 as you make updates and enhancements.</li> </ul>"},{"location":"java/java17/#10-collaborate-and-seek-assistance","title":"10. Collaborate and Seek Assistance:","text":"<ul> <li> <p>Engage with the Java community and colleagues to share experiences and seek assistance when facing migration challenges.</p> </li> <li> <p>Online forums, mailing lists, and developer communities can provide valuable insights and solutions.</p> </li> </ul>"},{"location":"java/java17/#example-migrating-a-for-loop-to-foreach-java-5-to-java-17","title":"Example - Migrating a <code>for</code> Loop to <code>foreach</code> (Java 5 to Java 17):","text":"<p>Old Code (Java 5): <pre><code>List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\nfor (String name : names) {\n    System.out.println(name);\n}\n</code></pre></p> <p>Updated Code (Java 17): <pre><code>List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\nnames.forEach(name -&gt; System.out.println(name));\n</code></pre></p> <p>In this example, we migrate from a traditional <code>for</code> loop to the more concise <code>foreach</code> construct introduced in Java 5 and continue to use it in Java 17.</p> <p>Migrating your codebase from older Java versions to Java 17 is a valuable investment that can lead to improved code quality and enhanced performance. By following a systematic migration approach, addressing compatibility issues, and gradually adopting new features, you can unlock the full potential of Java 17 and stay current in the ever-evolving Java ecosystem.</p>"},{"location":"java/java8/","title":"Java 8","text":"","tags":["Java 8"]},{"location":"java/java8/#java-8-key-features","title":"Java 8 Key Features","text":"<p>Java 8 introduced several key features that have had a profound impact on the language and its ecosystem. These features include lambda expressions, the Stream API, default and static methods in interfaces, functional interfaces, method references, the new Date and Time API, the Optional class, and enhancements for parallel and concurrent programming. Let's dive into each of these features with easy-to-understand explanations and examples.</p>","tags":["Java 8"]},{"location":"java/java8/#lambda-expressions","title":"Lambda Expressions:","text":"<p>Lambda expressions provide a concise way to represent anonymous functions. They allow you to define and pass around blocks of code, making your code more readable and expressive. Here's a simple example:</p> <pre><code>   // Traditional approach\n   Runnable runnable = new Runnable() {\n       @Override\n       public void run() {\n           System.out.println(\"Hello from a traditional anonymous class!\");\n       }\n   };\n\n   // Using Lambda expression\n   Runnable lambdaRunnable = () -&gt; {\n       System.out.println(\"Hello from a lambda expression!\");\n   };\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#stream-api","title":"Stream API:","text":"<p>The Stream API allows you to process collections in a functional and more readable way. You can perform operations like filtering, mapping, and reducing on collections with ease. For example:</p> <pre><code>   List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\n   int sum = numbers.stream()\n                   .filter(n -&gt; n % 2 == 0)\n                   .mapToInt(Integer::intValue)\n                   .sum();\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#default-and-static-methods-in-interfaces","title":"Default and Static Methods in Interfaces:","text":"<p>Java 8 introduced the ability to define default and static methods in interfaces, enabling you to add new methods to existing interfaces without breaking implementations.</p> <pre><code>   interface MyInterface {\n       void regularMethod();\n\n       default void defaultMethod() {\n           System.out.println(\"This is a default method.\");\n       }\n\n       static void staticMethod() {\n           System.out.println(\"This is a static method.\");\n       }\n   }\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#functional-interfaces","title":"Functional Interfaces:","text":"<p>Functional interfaces have a single abstract method and are essential for working with lambda expressions. Examples include <code>java.util.function.Predicate</code>, <code>Consumer</code>, and <code>Supplier</code>.</p>","tags":["Java 8"]},{"location":"java/java8/#method-references","title":"Method References:","text":"<p>Method references provide a shorthand notation for invoking methods. They come in four forms, including references to static methods and instance methods.</p> <pre><code>   // Reference to a static method\n   Function&lt;String, Integer&gt; parseInt = Integer::parseInt;\n\n   // Reference to an instance method of a particular object\n   String str = \"Hello\";\n   Consumer&lt;String&gt; printer = str::println;\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#new-date-and-time-api","title":"New Date and Time API:","text":"<p>Java 8 introduced a modern Date and Time API (java.time package) that addresses the shortcomings of the old java.util.Date and java.util.Calendar classes. It provides better support for date and time calculations, formatting, and parsing.</p> <pre><code>   LocalDate today = LocalDate.now();\n   LocalTime now = LocalTime.now();\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#optional-class","title":"Optional Class:","text":"<p>The <code>Optional</code> class is used to represent an optional value that may or may not be present. It helps prevent <code>NullPointerExceptions</code> by explicitly handling absence of values.</p> <pre><code>   Optional&lt;String&gt; optionalName = Optional.ofNullable(getName());\n   String name = optionalName.orElse(\"DefaultName\");\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#parallel-and-concurrent-programming-enhancements","title":"Parallel and Concurrent Programming Enhancements:","text":"<p>Java 8 introduced parallel streams that allow you to leverage multi-core processors for improved performance when processing large datasets in parallel. However, it's essential to use them judiciously.</p>","tags":["Java 8"]},{"location":"java/java8/#nashorn-javascript-engine","title":"Nashorn JavaScript Engine:","text":"<p>Java 8 includes the Nashorn JavaScript engine, which provides a modern JavaScript runtime environment for Java applications. It allows you to execute JavaScript code within your Java applications, making it easier to work with both languages together.</p> <pre><code>   ScriptEngineManager manager = new ScriptEngineManager();\n   ScriptEngine engine = manager.getEngineByName(\"javascript\");\n   engine.eval(\"print('Hello, Nashorn!')\");\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#enhanced-collections","title":"Enhanced Collections:","text":"<p>Java 8 introduced several enhancements to the Collections framework, including the <code>forEach</code> method for iterating over collections and the <code>removeIf</code> method for removing elements based on a condition.</p> <pre><code>    List&lt;String&gt; names = new ArrayList&lt;&gt;();\n    names.add(\"Alice\");\n    names.add(\"Bob\");\n    names.add(\"Charlie\");\n\n    // Using forEach\n    names.forEach(name -&gt; System.out.println(\"Hello, \" + name));\n\n    // Using removeIf\n    names.removeIf(name -&gt; name.length() &gt; 5);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#improved-type-inference","title":"Improved Type Inference:","text":"<p>Java 8 improved type inference, making it easier to work with generic classes and methods. You can now omit explicit type declarations in many cases.</p> <pre><code>    List&lt;String&gt; names = new ArrayList&lt;&gt;();\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#repeatable-annotations","title":"Repeatable Annotations:","text":"<p>Java 8 introduced the ability to apply multiple annotations of the same type to a single element, making it more flexible and expressive for defining metadata.</p> <pre><code>    @Author(\"Alice\")\n    @Author(\"Bob\")\n    public class Book {\n        // ...\n    }\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#improved-concurrency-with-completablefuture","title":"Improved Concurrency with CompletableFuture:","text":"<p>Java 8 introduced the <code>CompletableFuture</code> class, which simplifies asynchronous programming and enhances concurrency. It allows you to perform asynchronous tasks, handle exceptions, and compose multiple asynchronous operations.</p> <pre><code>    CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; 42);\n    future.thenApply(result -&gt; result * 2)\n          .thenAccept(finalResult -&gt; System.out.println(\"Final result: \" + finalResult));\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#default-methods-for-extending-interfaces","title":"Default Methods for Extending Interfaces:","text":"<p>Default methods in interfaces allow you to add new methods to existing interfaces without breaking the implementing classes. This feature promotes backward compatibility while evolving APIs.</p> <pre><code>    interface MyInterface {\n        default void myDefaultMethod() {\n            System.out.println(\"Default method in interface.\");\n        }\n    }\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#functional-programming-paradigm","title":"Functional Programming Paradigm:","text":"<p>Java 8 encourages functional programming by providing lambda expressions and streams. This paradigm shift allows developers to write more concise and expressive code, which is especially valuable for complex operations on collections and data processing.</p> <pre><code>    List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\n    long count = names.stream()\n                     .filter(name -&gt; name.length() &gt; 4)\n                     .count();\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#simplified-exception-handling-with-try-with-resources","title":"Simplified Exception Handling with <code>try-with-resources</code>:","text":"<p>Java 8 introduced the <code>try-with-resources</code> statement for automatic resource management. It simplifies the handling of resources like files and streams by automatically closing them when they are no longer needed.</p> <pre><code>    try (BufferedReader reader = new BufferedReader(new FileReader(\"file.txt\"))) {\n        // Read from the file\n    } catch (IOException e) {\n        // Handle the exception\n    }\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#improved-garbage-collection","title":"Improved Garbage Collection:","text":"<p>Java 8 introduced the G1 (Garbage First) garbage collector, which aims to provide better performance and predictability by minimizing pause times and maximizing throughput. This can be especially valuable for applications with large heaps.</p>","tags":["Java 8"]},{"location":"java/java8/#new-and-enhanced-apis","title":"New and Enhanced APIs:","text":"<p>Java 8 introduced various new and enhanced APIs, including the <code>CompletableFuture</code> API for asynchronous programming, the <code>Spliterator</code> interface for improved iteration over collections, and enhancements to the <code>java.util.concurrent</code> package for better concurrency control.</p>","tags":["Java 8"]},{"location":"java/java8/#improved-security-with-tls-12","title":"Improved Security with TLS 1.2:","text":"<p>Java 8 introduced support for Transport Layer Security (TLS) 1.2, which is crucial for secure communication over the internet. It enhances the security of Java applications, ensuring that they can establish secure connections with external services and servers.</p>","tags":["Java 8"]},{"location":"java/java8/#method-parameter-reflection","title":"Method Parameter Reflection:","text":"<p>Java 8 introduced the ability to reflectively access method parameter names, which is particularly useful for libraries and frameworks that require runtime access to parameter names for tasks such as validation and documentation generation.</p> <pre><code>    public void myMethod(@MyAnnotation String name, @MyAnnotation int age) {\n        // Access parameter names and annotations reflectively\n    }\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#enhanced-collections-factory-methods","title":"Enhanced Collections Factory Methods:","text":"<p>Java 8 added factory methods to create immutable or unmodifiable collections easily. These methods simplify the process of creating collections and help avoid accidental modifications.</p> <pre><code>    List&lt;String&gt; immutableList = List.of(\"Alice\", \"Bob\", \"Charlie\");\n    Set&lt;Integer&gt; unmodifiableSet = Set.copyOf(mySet);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#compact-profiles","title":"Compact Profiles:","text":"<p>Java 8 introduced compact profiles, which are smaller subsets of the Java SE platform. They allow developers to create more compact and optimized runtime environments tailored to the specific needs of their applications, reducing the footprint of Java applications.</p>","tags":["Java 8"]},{"location":"java/java8/#performance-enhancements","title":"Performance Enhancements:","text":"<p>Java 8 brought various performance enhancements, including improvements in the JVM (Java Virtual Machine) that resulted in faster execution of Java applications. These enhancements contribute to better overall application performance.</p>","tags":["Java 8"]},{"location":"java/java8/#integration-with-javafx","title":"Integration with JavaFX:","text":"<p>Java 8 integrated JavaFX as part of the standard library, making it easier to develop modern and interactive user interfaces for desktop applications.</p> <pre><code>    import javafx.application.Application;\n    import javafx.scene.Scene;\n    import javafx.scene.control.Button;\n    import javafx.stage.Stage;\n\n    public class JavaFXExample extends Application {\n        // JavaFX application code\n    }\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#easier-migration-to-later-versions","title":"Easier Migration to Later Versions:","text":"<p>With the introduction of new features and improved APIs in Java 8, developers are better equipped to migrate their code to later versions of Java, taking advantage of additional enhancements and features introduced in subsequent releases.</p>","tags":["Java 8"]},{"location":"java/java8/#lambda-expressions_1","title":"Lambda Expressions","text":"<p>Lambda expressions in Java 8 are a powerful feature that allows you to represent anonymous functions concisely. They are primarily used to define and pass around blocks of code, making your code more readable and expressive. Lambda expressions enable you to write more compact code when working with functional interfaces. Let's dive into the concept of lambda expressions and provide clear examples to facilitate understanding.</p> <p>In Java 8, lambda expressions provide a way to define small, reusable blocks of code in a more concise and readable manner. These expressions are particularly useful when working with functional interfaces, which are interfaces that have a single abstract method.</p> <p>Here's the basic syntax of a lambda expression:</p> <pre><code>(parameters) -&gt; expression or block of code\n</code></pre> <p>Let's break down the components:</p> <ul> <li> <p>Parameters: These are the input parameters (if any) that your lambda expression takes. You can have zero or more parameters. If there's only one parameter and its type is inferred, you can omit the parentheses. For multiple parameters, parentheses are required.</p> </li> <li> <p>Arrow (-&gt;): The arrow separates the parameter list from the expression or block of code. It's the central symbol in a lambda expression.</p> </li> <li> <p>Expression or Block of Code: This is the code that the lambda expression encapsulates. It can be a single expression or a block of code enclosed in curly braces. If it's a block of code, you must use curly braces, and you may need to include a <code>return</code> statement if the block returns a value.</p> </li> </ul> <p>Let's see some practical examples:</p> <ol> <li>Lambda Expression with No Parameters:</li> </ol> <pre><code>   Runnable runnable = () -&gt; {\n       System.out.println(\"Hello from a lambda expression!\");\n   };\n</code></pre> <ol> <li>Lambda Expression with One Parameter:</li> </ol> <pre><code>   (x) -&gt; x * x\n</code></pre> <p>In this example, the lambda expression takes one parameter (<code>x</code>) and returns its square.</p> <ol> <li>Lambda Expression with Multiple Parameters:</li> </ol> <pre><code>   (a, b) -&gt; a + b\n</code></pre> <p>This lambda expression takes two parameters (<code>a</code> and <code>b</code>) and returns their sum.</p> <ol> <li>Lambda Expression as an Argument:</li> </ol> <p>Lambda expressions are often used as arguments to methods that accept functional interfaces. For example, the <code>forEach</code> method of a <code>List</code> accepts a <code>Consumer</code> functional interface:</p> <pre><code>   List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\n   names.forEach(name -&gt; System.out.println(\"Hello, \" + name));\n</code></pre> <p>Here, the lambda expression is used to define what should happen for each element in the list.</p> <p>Lambda expressions shine when you work with functional interfaces, such as <code>Runnable</code>, <code>Consumer</code>, <code>Predicate</code>, and others from the <code>java.util.function</code> package. They allow you to pass behavior as a parameter, making your code more modular and easier to maintain.</p> <p>In summary, lambda expressions in Java 8 are a concise way to define and use anonymous functions. They provide a clearer and more expressive way to work with functional interfaces, making your code more readable and flexible.</p>","tags":["Java 8"]},{"location":"java/java8/#capturing-variables-in-lambda-expressions","title":"Capturing Variables in Lambda Expressions","text":"<p>Lambda expressions can also capture variables from their enclosing scope, making them extremely flexible. These variables can be either effectively final or final. An effectively final variable is one whose value doesn't change after it's assigned.</p> <p>Here's an example of capturing variables:</p> <pre><code>public void calculate(int a, int b) {\n    int result = 0; // Local variable\n    Operation operation = (x, y) -&gt; {\n        result = x + y; // Capturing 'result' from the outer scope\n        return result; // Using 'result' in the lambda expression\n    };\n\n    int sum = operation.perform(a, b);\n    System.out.println(\"Sum: \" + sum);\n}\n</code></pre> <p>In this example, the lambda expression captures the <code>result</code> variable from the enclosing method's scope. However, you can only capture variables that are effectively final or final.</p>","tags":["Java 8"]},{"location":"java/java8/#method-references-and-lambda-expressions","title":"Method References and Lambda Expressions","text":"<p>In addition to lambda expressions, Java 8 introduced method references, which provide a concise way to refer to methods or constructors. Method references are often used in conjunction with lambda expressions.</p> <p>There are four types of method references:</p> <ol> <li>Reference to a Static Method:</li> </ol> <pre><code>   Function&lt;String, Integer&gt; parseInt = Integer::parseInt;\n</code></pre> <p>This example references the <code>parseInt</code> method of the <code>Integer</code> class.</p> <ol> <li>Reference to an Instance Method of a Particular Object:</li> </ol> <pre><code>   String str = \"Hello\";\n   Consumer&lt;String&gt; printer = str::println;\n</code></pre> <p>Here, <code>str::println</code> is a reference to the <code>println</code> method of the <code>str</code> object.</p> <ol> <li>Reference to an Instance Method of an Arbitrary Object of a Particular Type:</li> </ol> <pre><code>   List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\n   names.forEach(System.out::println);\n</code></pre> <p><code>System.out::println</code> is a reference to the <code>println</code> method of any <code>System.out</code> object.</p> <ol> <li>Reference to a Constructor:</li> </ol> <pre><code>   Supplier&lt;List&lt;String&gt;&gt; listSupplier = ArrayList::new;\n</code></pre> <p>This example references the constructor of the <code>ArrayList</code> class.</p> <p>Method references provide a more concise way to express lambda expressions when you're simply calling a method or constructor, making your code even more readable.</p> <p>In conclusion, lambda expressions in Java 8 are a game-changer for writing concise and expressive code, especially when working with functional interfaces. They allow you to pass behavior as parameters and capture variables from their enclosing scope. When combined with method references, they offer a powerful toolset for writing clean and efficient code. Understanding and using lambda expressions is a crucial skill for Java developers in the modern programming landscape.</p>","tags":["Java 8"]},{"location":"java/java8/#best-practices","title":"Best Practices","text":"<p>While lambda expressions in Java 8 provide a powerful way to write concise and expressive code, it's important to follow best practices to ensure readability and maintainability of your code. Here are some tips:</p> <ol> <li>Use Descriptive Variable Names: When defining lambda parameters, use meaningful and descriptive variable names. This makes it easier for others (and your future self) to understand the code.</li> </ol> <pre><code>   names.forEach(name -&gt; System.out.println(\"Hello, \" + name));\n</code></pre> <p>In this example, <code>name</code> is a clear and descriptive variable name.</p> <ol> <li>Keep Lambda Expressions Short: Lambda expressions should be concise and focused on a specific task. If a lambda expression becomes too long or complex, consider refactoring it into a separate method.</li> </ol> <pre><code>   // Avoid long and complex lambda expressions\n   names.forEach(name -&gt; {\n       if (name.length() &gt; 5) {\n           System.out.println(\"Long name: \" + name);\n       }\n   });\n\n   // Better: Extract the logic into a separate method\n   names.stream()\n        .filter(name -&gt; isLongName(name))\n        .forEach(name -&gt; System.out.println(\"Long name: \" + name));\n\n   // Define a method\n   private static boolean isLongName(String name) {\n       return name.length() &gt; 5;\n   }\n</code></pre> <ol> <li>Consider Using Method References: When a lambda expression simply calls an existing method or constructor, consider using method references for clarity and brevity.</li> </ol> <pre><code>   // Lambda expression\n   Function&lt;String, Integer&gt; parseInt = s -&gt; Integer.parseInt(s);\n\n   // Method reference\n   Function&lt;String, Integer&gt; parseInt = Integer::parseInt;\n</code></pre> <ol> <li>Avoid Capturing Mutable Variables: Be cautious when capturing variables from an outer scope in lambda expressions, especially if those variables are mutable. Changes to mutable captured variables can lead to unexpected behavior.</li> </ol> <pre><code>   int counter = 0;\n   Runnable runnable = () -&gt; {\n       counter++; // Avoid capturing mutable variables\n   };\n</code></pre> <ol> <li>Use Lambda Expressions with Streams: Lambda expressions work seamlessly with Java streams, allowing you to write functional and declarative code for operations on collections.</li> </ol> <pre><code>   List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\n\n   // Using lambda expressions with streams\n   int sum = numbers.stream()\n                   .filter(n -&gt; n % 2 == 0)\n                   .mapToInt(Integer::intValue)\n                   .sum();\n</code></pre> <ol> <li> <p>Know Your Functional Interfaces: Familiarize yourself with common functional interfaces from the <code>java.util.function</code> package, such as <code>Consumer</code>, <code>Predicate</code>, <code>Function</code>, etc. Understanding these interfaces will help you choose the appropriate one for your lambda expressions.</p> </li> <li> <p>Test and Debug: Lambda expressions, like any other code, should be thoroughly tested and debugged. Use unit tests and debugging tools to ensure their correctness.</p> </li> <li> <p>Document When Necessary: While lambda expressions can make your code more concise, avoid making it cryptic. When a lambda expression's purpose is not immediately obvious, consider adding comments or documentation to clarify its intent.</p> </li> </ol> <p>By following these best practices, you can make the most of lambda expressions in Java 8 while maintaining code readability and reliability. Lambda expressions are a valuable addition to Java's toolbox, enabling more expressive and functional programming styles.</p>","tags":["Java 8"]},{"location":"java/java8/#stream-api_1","title":"Stream API","text":"<p>Java 8 introduced the Stream API, which provides a powerful way to process collections of data. Streams allow you to perform complex data manipulations and transformations in a concise and functional style. In this explanation, we'll dive into what the Stream API is and provide easy-to-understand examples and code snippets.</p> <p>The Stream API is a significant enhancement in Java 8 for processing collections of data. It's designed to make working with data in collections more efficient and expressive. Streams allow you to perform operations like filtering, mapping, and reducing on collections with ease. Let's explore some key concepts and examples.</p>","tags":["Java 8"]},{"location":"java/java8/#creating-a-stream","title":"Creating a Stream:","text":"<p>You can create a Stream from various data sources, including collections, arrays, and even I/O channels. Here's how you can create a Stream from a list of integers:</p> <pre><code>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\nStream&lt;Integer&gt; numberStream = numbers.stream();\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#stream-operations","title":"Stream Operations:","text":"<p>Once you have a Stream, you can perform operations on it. There are two types of operations: intermediate and terminal.</p>","tags":["Java 8"]},{"location":"java/java8/#intermediate-operations","title":"Intermediate Operations:","text":"<p>Intermediate operations are operations that transform a Stream into another Stream. Common intermediate operations include <code>filter</code>, <code>map</code>, <code>flatMap</code>, and <code>distinct</code>. For example, let's filter even numbers from our <code>numberStream</code>:</p> <pre><code>Stream&lt;Integer&gt; evenNumbers = numberStream.filter(n -&gt; n % 2 == 0);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#terminal-operations","title":"Terminal Operations:","text":"<p>Terminal operations produce a result or a side-effect and close the Stream. Common terminal operations include <code>forEach</code>, <code>collect</code>, <code>reduce</code>, and <code>count</code>. For example, let's find the sum of even numbers:</p> <pre><code>int sum = evenNumbers.reduce(0, (a, b) -&gt; a + b);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#example-filtering-and-collecting","title":"Example: Filtering and Collecting:","text":"<p>Here's a more complete example. Suppose we have a list of strings representing names and we want to filter out names that start with the letter \"A\" and collect the result into a new list:</p> <pre><code>List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Amy\", \"David\");\nList&lt;String&gt; filteredNames = names.stream()\n    .filter(name -&gt; !name.startsWith(\"A\"))\n    .collect(Collectors.toList());\n\n// filteredNames will contain [\"Bob\", \"David\"]\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#benefits-of-streams","title":"Benefits of Streams:","text":"<ul> <li>Streams promote a more functional and declarative style of coding, making code more readable.</li> <li>They enable parallel processing, which can significantly improve performance when working with large datasets.</li> </ul> <p>The Stream API in Java 8 provides a powerful and expressive way to process collections of data. It simplifies complex data manipulations and encourages a more functional programming approach. By understanding how to create and use streams, developers can write cleaner and more efficient code for data processing tasks.</p>","tags":["Java 8"]},{"location":"java/java8/#working-with-parallel-streams","title":"Working with Parallel Streams:","text":"<p>One of the standout features of the Stream API is its ability to easily switch between sequential and parallel processing. Parallel streams allow you to leverage multi-core processors for potentially significant performance improvements when dealing with large datasets. You can convert a sequential stream to a parallel stream using the <code>parallel()</code> method:</p> <pre><code>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\nStream&lt;Integer&gt; parallelStream = numbers.parallelStream();\n</code></pre> <p>Once you have a parallel stream, the operations you perform on it are automatically parallelized, distributing the work across available processor cores. Be cautious when using parallel streams, though, as parallelism introduces the overhead of thread management, and not all operations benefit from parallel processing.</p>","tags":["Java 8"]},{"location":"java/java8/#stream-example-mapping-and-collecting","title":"Stream Example: Mapping and Collecting:","text":"<p>Let's take another example where we have a list of employee objects, and we want to extract their names and collect them into a comma-separated string:</p> <pre><code>class Employee {\n    private String name;\n\n    public Employee(String name) {\n        this.name = name;\n    }\n\n    public String getName() {\n        return name;\n    }\n}\n\nList&lt;Employee&gt; employees = Arrays.asList(\n    new Employee(\"Alice\"),\n    new Employee(\"Bob\"),\n    new Employee(\"Carol\")\n);\n\nString employeeNames = employees.stream()\n    .map(Employee::getName)\n    .collect(Collectors.joining(\", \"));\n\n// employeeNames will be \"Alice, Bob, Carol\"\n</code></pre> <p>In this example, the <code>map</code> operation transforms each employee object into their name, and the <code>collect</code> operation joins the names into a single string.</p>","tags":["Java 8"]},{"location":"java/java8/#exception-handling","title":"Exception Handling:","text":"<p>Streams provide a convenient way to handle exceptions during processing. You can use the <code>forEach</code> method with a lambda that includes exception handling:</p> <pre><code>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\nnumbers.stream()\n    .forEach(number -&gt; {\n        try {\n            int result = 10 / number;\n            System.out.println(\"Result: \" + result);\n        } catch (ArithmeticException e) {\n            System.err.println(\"Error: Division by zero\");\n        }\n    });\n</code></pre> <p>This code safely handles division by zero errors within the stream.</p> <p>The Stream API in Java 8 is a versatile tool for processing collections of data. It offers a functional and expressive way to work with data, allowing you to perform various operations seamlessly. Whether you're filtering, mapping, reducing, or working with parallel streams, Java 8's Stream API empowers developers to write cleaner and more efficient code for a wide range of data processing tasks.</p>","tags":["Java 8"]},{"location":"java/java8/#working-with-parallel-streams_1","title":"Working with Parallel Streams:","text":"<p>One of the standout features of the Stream API is its ability to easily switch between sequential and parallel processing. Parallel streams allow you to leverage multi-core processors for potentially significant performance improvements when dealing with large datasets. You can convert a sequential stream to a parallel stream using the <code>parallel()</code> method:</p> <pre><code>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\nStream&lt;Integer&gt; parallelStream = numbers.parallelStream();\n</code></pre> <p>Once you have a parallel stream, the operations you perform on it are automatically parallelized, distributing the work across available processor cores. Be cautious when using parallel streams, though, as parallelism introduces the overhead of thread management, and not all operations benefit from parallel processing.</p>","tags":["Java 8"]},{"location":"java/java8/#best-practices_1","title":"Best Practices:","text":"<p>To make the most of the Stream API, consider the following best practices:</p> <ol> <li> <p>Use Method References: Method references, like <code>Employee::getName</code> in the previous example, make your code more concise and readable.</p> </li> <li> <p>Avoid Stateful Operations: Some stream operations, like <code>sorted()</code>, are stateful and can be inefficient for parallel streams. Be mindful of their use and prefer stateless operations when possible.</p> </li> <li> <p>Keep Streams Short and Simple: Long chains of operations can become hard to read and debug. Break down complex operations into smaller, more manageable steps.</p> </li> <li> <p>Parallelize with Caution: Parallel streams can improve performance, but they also introduce complexity and potential thread-safety issues. Use them judiciously and be aware of synchronization requirements.</p> </li> <li> <p>Immutable Data: It's a good practice to work with immutable data structures when using streams. It simplifies parallelism and reduces the risk of unintended side effects.</p> </li> <li> <p>Avoid Blocking Operations: If you need to perform blocking operations within a stream, consider using <code>CompletableFuture</code> or other asynchronous mechanisms to prevent blocking the entire stream.</p> </li> <li> <p>Collectors: Explore the various collectors available in the <code>Collectors</code> class, as they can simplify common collection tasks like grouping, partitioning, and summarizing.</p> </li> <li> <p>Exception Handling: Handle exceptions appropriately within stream operations to ensure robust error handling, as shown in the previous exception handling example.</p> </li> </ol>","tags":["Java 8"]},{"location":"java/java8/#intermediate-terminal-operations","title":"Intermediate &amp; Terminal Operations","text":"<p>Intermediate Operations are used to perform transformations and filters on the elements of a Stream. They are called intermediate because they can be chained together to form a pipeline of operations. Here are some common Intermediate Operations:</p> <ol> <li>map(Function mapper): This operation applies the provided function to each element of the Stream and returns a new Stream with the results. For example: <pre><code>   List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\n   List&lt;Integer&gt; squares = numbers.stream()\n                                   .map(n -&gt; n * n)\n                                   .collect(Collectors.toList());\n</code></pre> <p>In this example, <code>map</code> transforms each element by squaring it.</p> <ol> <li>filter(Predicate predicate): This operation filters the elements of the Stream based on the provided predicate and returns a new Stream containing only the elements that satisfy the condition. For example: <pre><code>   List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\", \"David\");\n   List&lt;String&gt; filteredNames = names.stream()\n                                     .filter(name -&gt; name.length() &gt; 4)\n                                     .collect(Collectors.toList());\n</code></pre> <p>Here, <code>filter</code> retains only names with more than four characters.</p> <ol> <li>sorted() or sorted(Comparator comparator): These operations are used to sort the elements of the Stream. The first one sorts the elements in their natural order, while the second allows you to specify a custom comparator. Example: <pre><code>   List&lt;Integer&gt; numbers = Arrays.asList(5, 3, 1, 4, 2);\n   List&lt;Integer&gt; sortedNumbers = numbers.stream()\n                                         .sorted()\n                                         .collect(Collectors.toList());\n</code></pre> <p>This sorts the numbers in ascending order.</p> <ol> <li>distinct(): This operation removes duplicates from the Stream, ensuring that each element is unique. Example:</li> </ol> <pre><code>   List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 2, 3, 3, 4, 5);\n   List&lt;Integer&gt; distinctNumbers = numbers.stream()\n                                           .distinct()\n                                           .collect(Collectors.toList());\n</code></pre> <p>Here, <code>distinct</code> eliminates the duplicate values.</p>","tags":["Java 8"]},{"location":"java/java8/#terminal-operations_1","title":"Terminal Operations","text":"<p>Terminal Operations are the final step in a Stream pipeline, and they produce a result or a side-effect. They trigger the execution of the entire Stream pipeline. Here are some common Terminal Operations:</p> <ol> <li>collect(Collector collector): This operation collects the elements of the Stream into a collection or another data structure. Example: <pre><code>   List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\", \"David\");\n   String concatenatedNames = names.stream()\n                                   .collect(Collectors.joining(\", \"));\n</code></pre> <p>This collects the names into a single, comma-separated string.</p> <ol> <li>forEach(Consumer action): This operation performs a specified action for each element in the Stream. Example: <pre><code>   List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\n   numbers.stream().forEach(n -&gt; System.out.println(n));\n</code></pre> <p>It prints each number in the Stream.</p> <ol> <li>count(): This operation returns the number of elements in the Stream. Example:</li> </ol> <pre><code>   List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\n   long count = numbers.stream().count();\n</code></pre> <p><code>count</code> in this case would be 5.</p> <ol> <li>reduce(BinaryOperator accumulator): This operation combines the elements of the Stream using the provided binary operator and returns the result. Example: <pre><code>   List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\n   int sum = numbers.stream()\n                   .reduce((x, y) -&gt; x + y)\n                   .orElse(0);\n</code></pre> <p>Here, <code>reduce</code> computes the sum of the numbers.</p> <p>These are the main types of operations in the Stream API in Java 8. Intermediate Operations allow you to transform and filter data in a stream, while Terminal Operations produce a final result or perform side-effects on the data. Understanding these operations is key to effectively using Java 8 Streams for data processing.</p>","tags":["Java 8"]},{"location":"java/java8/#example-demonstrations","title":"Example Demonstrations","text":"<p>To make it even clearer, let's dive into more detailed examples of how Intermediate and Terminal Operations work:</p>","tags":["Java 8"]},{"location":"java/java8/#intermediate-operations-examples","title":"Intermediate Operations Examples:","text":"","tags":["Java 8"]},{"location":"java/java8/#example-1-using-map-and-filter","title":"Example 1: Using <code>map</code> and <code>filter</code>","text":"<p>Suppose you have a list of words, and you want to create a new list containing the lengths of words that start with the letter 'A':</p> <pre><code>List&lt;String&gt; words = Arrays.asList(\"Apple\", \"Banana\", \"Avocado\", \"Cherry\", \"Apricot\");\nList&lt;Integer&gt; lengthsOfAWords = words.stream()\n                                      .filter(word -&gt; word.startsWith(\"A\"))\n                                      .map(String::length)\n                                      .collect(Collectors.toList());\n</code></pre> <p>In this example, <code>filter</code> is used to select words that start with 'A', and <code>map</code> transforms those words into their lengths. The result is <code>[5, 7, 7]</code>.</p>","tags":["Java 8"]},{"location":"java/java8/#example-2-using-sorted","title":"Example 2: Using <code>sorted</code>","text":"<p>Let's say you have a list of integers, and you want to sort them in descending order:</p> <pre><code>List&lt;Integer&gt; numbers = Arrays.asList(5, 3, 1, 4, 2);\nList&lt;Integer&gt; sortedDescending = numbers.stream()\n                                         .sorted((a, b) -&gt; b.compareTo(a))\n                                         .collect(Collectors.toList());\n</code></pre> <p>Here, the <code>sorted</code> operation with a custom comparator sorts the numbers in descending order. The result is <code>[5, 4, 3, 2, 1]</code>.</p>","tags":["Java 8"]},{"location":"java/java8/#terminal-operations-examples","title":"Terminal Operations Examples:","text":"","tags":["Java 8"]},{"location":"java/java8/#example-1-using-collect","title":"Example 1: Using <code>collect</code>","text":"<p>Suppose you have a list of names, and you want to concatenate them into a single comma-separated string:</p> <pre><code>List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\", \"David\");\nString concatenatedNames = names.stream()\n                               .collect(Collectors.joining(\", \"));\n</code></pre> <p>After applying the <code>collect</code> operation, <code>concatenatedNames</code> will contain <code>\"Alice, Bob, Charlie, David\"</code>.</p>","tags":["Java 8"]},{"location":"java/java8/#example-2-using-foreach","title":"Example 2: Using <code>forEach</code>","text":"<p>If you have a list of numbers and you want to print each number squared:</p> <pre><code>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\nnumbers.stream().forEach(n -&gt; System.out.println(n * n));\n</code></pre> <p>This code will print the squares of the numbers, one per line:</p> <pre><code>1\n4\n9\n16\n25\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#example-3-using-count","title":"Example 3: Using <code>count</code>","text":"<p>If you have a list of integers and you want to count how many of them are even:</p> <pre><code>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\nlong countOfEvens = numbers.stream()\n                           .filter(n -&gt; n % 2 == 0)\n                           .count();\n</code></pre> <p>After applying the <code>count</code> operation, <code>countOfEvens</code> will be <code>2</code>, as there are two even numbers in the list.</p>","tags":["Java 8"]},{"location":"java/java8/#example-4-using-reduce","title":"Example 4: Using <code>reduce</code>","text":"<p>Suppose you have a list of numbers and you want to find their product:</p> <pre><code>List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5);\nint product = numbers.stream()\n                     .reduce((x, y) -&gt; x * y)\n                     .orElse(1);\n</code></pre> <p>Here, the <code>reduce</code> operation multiplies all the numbers together, and the <code>orElse(1)</code> provides a default value of <code>1</code> in case the stream is empty. The result will be <code>120</code>, which is the product of all the numbers.</p> <p>These examples should help you understand how to use Intermediate and Terminal Operations in Java 8 Stream API effectively for various data processing tasks.</p>","tags":["Java 8"]},{"location":"java/java8/#functional-interfaces_1","title":"Functional Interfaces","text":"<p>In Java 8, a functional interface is an interface that has exactly one abstract method. These interfaces can be used with lambda expressions and method references, making it easier to work with functions as first-class citizens in Java.</p> <p>Functional interfaces are interfaces that define a single abstract method. They act as blueprints for functions, allowing you to create instances of these interfaces using lambda expressions and method references. Functional interfaces are not a new concept in Java, but Java 8 formalized them and introduced the <code>@FunctionalInterface</code> annotation to mark such interfaces explicitly.</p> <p>The key characteristic of a functional interface is that it can be used wherever a functional interface is expected, making it easy to work with functions in a more concise and expressive way.</p>","tags":["Java 8"]},{"location":"java/java8/#example-of-a-functional-interface","title":"Example of a Functional Interface","text":"<p>Let's create a simple example to illustrate the concept of functional interfaces. We'll start by defining a functional interface called <code>Calculator</code>, which has a single abstract method <code>calculate</code>:</p> <pre><code>@FunctionalInterface\ninterface Calculator {\n    int calculate(int a, int b);\n}\n</code></pre> <p>In this example:</p> <ul> <li><code>@FunctionalInterface</code> annotation is used to indicate that <code>Calculator</code> is a functional interface. While this annotation is not strictly required, it helps convey the intent of the interface.</li> </ul> <p>Now, we can use this <code>Calculator</code> functional interface to create instances of it using lambda expressions. For instance, we can define two different implementations for addition and subtraction:</p> <pre><code>public class Main {\n    public static void main(String[] args) {\n        // Lambda expression for addition\n        Calculator addition = (a, b) -&gt; a + b;\n\n        // Lambda expression for subtraction\n        Calculator subtraction = (a, b) -&gt; a - b;\n\n        int result1 = addition.calculate(5, 3);\n        int result2 = subtraction.calculate(8, 2);\n\n        System.out.println(\"Result of addition: \" + result1);\n        System.out.println(\"Result of subtraction: \" + result2);\n    }\n}\n</code></pre> <p>In this code:</p> <ul> <li>We create instances of the <code>Calculator</code> functional interface using lambda expressions, providing implementations for the <code>calculate</code> method.</li> <li>We then use these instances to perform addition and subtraction operations.</li> </ul> <p>Functional interfaces simplify the creation of small, reusable functions in Java, allowing you to write more concise and expressive code.</p>","tags":["Java 8"]},{"location":"java/java8/#benefits-of-functional-interfaces","title":"Benefits of Functional Interfaces","text":"<p>Functional interfaces provide several benefits in Java:</p> <ol> <li> <p>Conciseness: They allow you to define and use functions with less boilerplate code.</p> </li> <li> <p>Readability: Lambda expressions make code more readable and closer to natural language.</p> </li> <li> <p>Expressiveness: Functional interfaces promote functional programming paradigms, enabling you to work with functions as first-class citizens in Java.</p> </li> <li> <p>Compatibility: Functional interfaces are compatible with legacy code, making it easier to integrate functional programming concepts into existing Java applications.</p> </li> </ol> <p>In summary, functional interfaces in Java 8 are a powerful feature that enhances the expressiveness and readability of your code by enabling the use of lambda expressions and method references to work with functions effectively. They are a fundamental building block for functional programming in Java.</p>","tags":["Java 8"]},{"location":"java/java8/#javautilfunction-package","title":"<code>java.util.function</code> Package","text":"<p>While you can create your own functional interfaces as demonstrated earlier, Java 8 introduced a standard set of functional interfaces in the <code>java.util.function</code> package. These predefined functional interfaces cover common use cases and make it easier to work with functions in a consistent way.</p> <p>Here are some of the most commonly used functional interfaces from the <code>java.util.function</code> package:</p> <ol> <li><code>Function&lt;T, R&gt;</code>: Represents a function that takes an argument of type <code>T</code> and returns a result of type <code>R</code>. For example, it can be used for mapping operations.</li> </ol> <pre><code>    Function&lt;Integer, String&gt; intToString = (num) -&gt; Integer.toString(num);\n</code></pre> <ol> <li><code>Predicate&lt;T&gt;</code>: Represents a function that takes an argument of type <code>T</code> and returns a boolean. It is often used for filtering operations.</li> </ol> <pre><code>    Predicate&lt;String&gt; isLong = (str) -&gt; str.length() &gt; 5;\n</code></pre> <ol> <li><code>Consumer&lt;T&gt;</code>: Represents a function that takes an argument of type <code>T</code> and performs an action, typically with a side-effect.</li> </ol> <pre><code>    Consumer&lt;String&gt; printUpperCase = (str) -&gt; System.out.println(str.toUpperCase());\n</code></pre> <ol> <li><code>Supplier&lt;T&gt;</code>: Represents a function that supplies a value of type <code>T</code>. It is typically used when you need to generate or provide data.</li> </ol> <pre><code>    Supplier&lt;Double&gt; randomDouble = () -&gt; Math.random();\n</code></pre> <p>Using these predefined functional interfaces, you can write more expressive and concise code for various functional programming tasks.</p>","tags":["Java 8"]},{"location":"java/java8/#lambda-expressions-and-method-references","title":"Lambda Expressions and Method References","text":"<p>Lambda expressions are a natural fit for working with functional interfaces. They allow you to define inline implementations of the functional interface's abstract method.</p> <p>Method references provide another way to use functional interfaces when you want to reference an existing method. There are different types of method references, including:</p> <ul> <li>Static Method Reference: Reference to a static method.</li> </ul> <pre><code>    Function&lt;String, Integer&gt; stringToLength = String::length;\n</code></pre> <ul> <li>Instance Method Reference: Reference to an instance method of a particular object.</li> </ul> <pre><code>    List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\n    names.forEach(System.out::println);\n</code></pre> <ul> <li>Constructor Reference: Reference to a constructor.</li> </ul> <pre><code>    Supplier&lt;List&lt;String&gt;&gt; listSupplier = ArrayList::new;\n</code></pre> <p>Functional interfaces in Java 8 and the associated lambda expressions and method references have revolutionized the way Java developers write code. They bring functional programming concepts into the language, making it more expressive and concise.</p>","tags":["Java 8"]},{"location":"java/java8/#real-world-use-cases","title":"Real-World Use Cases","text":"<p>To further illustrate the significance of functional interfaces and how they are used in real-world scenarios, let's explore a couple of practical examples:</p>","tags":["Java 8"]},{"location":"java/java8/#example-1-list-filtering","title":"Example 1: List Filtering","text":"<p>Imagine you have a list of employees, and you want to filter out those who earn more than a certain salary threshold. You can use the <code>Predicate</code> functional interface for this task:</p> <pre><code>List&lt;Employee&gt; employees = // your list of employees\ndouble salaryThreshold = 50000.0;\n\nPredicate&lt;Employee&gt; highEarners = (employee) -&gt; employee.getSalary() &gt; salaryThreshold;\nList&lt;Employee&gt; filteredEmployees = employees.stream()\n                                           .filter(highEarners)\n                                           .collect(Collectors.toList());\n</code></pre> <p>Here, the <code>Predicate</code> functional interface is used to define the condition for filtering. The <code>filter</code> method then applies this condition to create a new list of high earners.</p>","tags":["Java 8"]},{"location":"java/java8/#example-2-data-transformation","title":"Example 2: Data Transformation","text":"<p>Suppose you have a list of student objects, and you want to transform it into a list of their names. You can use the <code>Function</code> functional interface:</p> <pre><code>List&lt;Student&gt; students = // your list of students\n\nFunction&lt;Student, String&gt; nameExtractor = (student) -&gt; student.getName();\nList&lt;String&gt; studentNames = students.stream()\n                                    .map(nameExtractor)\n                                    .collect(Collectors.toList());\n</code></pre> <p>In this case, the <code>Function</code> functional interface is employed to extract the name from each student object and create a list of names.</p>","tags":["Java 8"]},{"location":"java/java8/#benefit-of-functional-interfaces","title":"Benefit of Functional Interfaces","text":"<p>Functional interfaces provide a level of abstraction that allows you to focus on the \"what\" (the behavior you want) rather than the \"how\" (how to implement that behavior). They promote clean, readable, and modular code by encapsulating behavior within functions.</p> <p>Moreover, functional interfaces, in combination with lambda expressions and method references, enable concise and expressive code. They are particularly useful when working with collections, streams, and various functional programming paradigms.</p> <p>In your journey as a developer, understanding and using functional interfaces effectively will empower you to write more elegant and maintainable code in Java, harnessing the power of functional programming principles.</p>","tags":["Java 8"]},{"location":"java/java8/#method-reference","title":"Method reference","text":"<p>Method references in Java 8 provide a concise way to refer to methods or constructors of classes, making your code more readable and maintainable. There are four types of method references:</p> <ol> <li>Reference to a Static Method</li> <li>Reference to an Instance Method of a Particular Object</li> <li>Reference to an Instance Method of an Arbitrary Object of a Particular Type</li> <li>Reference to a Constructor</li> </ol> <p>Let's delve deeper into each type with examples:</p>","tags":["Java 8"]},{"location":"java/java8/#reference-to-a-static-method","title":"Reference to a Static Method:","text":"<p>You can reference a static method using the <code>ClassName::staticMethodName</code> syntax. It's similar to lambda expressions and is particularly useful when the lambda expression just calls a single static method.</p> <pre><code>// Lambda expression\nFunction&lt;Integer, Double&gt; squareRoot = (x) -&gt; Math.sqrt(x);\n\n// Method reference\nFunction&lt;Integer, Double&gt; squareRootRef = Math::sqrt;\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#reference-to-an-instance-method-of-a-particular-object","title":"Reference to an Instance Method of a Particular Object:","text":"<p>This type of method reference allows you to invoke an instance method on a specific object. Use the <code>object::instanceMethodName</code> syntax.</p> <pre><code>String name = \"John\";\nSupplier&lt;Integer&gt; nameLength = name::length;\nSystem.out.println(nameLength.get()); // Outputs: 4\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#reference-to-an-instance-method-of-an-arbitrary-object-of-a-particular-type","title":"Reference to an Instance Method of an Arbitrary Object of a Particular Type:","text":"<p>In this case, you reference an instance method for an object of a particular type. It's useful for scenarios like sorting a list of objects.</p> <pre><code>List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\nnames.sort(String::compareToIgnoreCase);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#reference-to-a-constructor","title":"Reference to a Constructor:","text":"<p>You can use method references to create instances of classes by referencing constructors using the <code>ClassName::new</code> syntax.</p> <pre><code>Supplier&lt;List&lt;String&gt;&gt; listSupplier = ArrayList::new;\nList&lt;String&gt; myList = listSupplier.get();\n</code></pre> <p>Method references help make your code more concise and readable, especially in situations where lambda expressions would otherwise be used. They are a powerful feature introduced in Java 8, enhancing the expressiveness of the language.</p>","tags":["Java 8"]},{"location":"java/java8/#understanding-in-detail","title":"Understanding in Detail:","text":"<p>Let's break down each type of method reference with more detailed explanations and examples.</p>","tags":["Java 8"]},{"location":"java/java8/#1-reference-to-a-static-method","title":"1. Reference to a Static Method:","text":"<p>Static methods belong to a class rather than an instance. You can reference them using the <code>ClassName::staticMethodName</code> syntax. For example:</p> <pre><code>Function&lt;Integer, Double&gt; squareRootRef = Math::sqrt;\n</code></pre> <p>Here, <code>Math::sqrt</code> refers to the <code>sqrt</code> method of the <code>Math</code> class, which takes an integer as an argument and returns a double. This reference is concise and easy to understand.</p>","tags":["Java 8"]},{"location":"java/java8/#2-reference-to-an-instance-method-of-a-particular-object","title":"2. Reference to an Instance Method of a Particular Object:","text":"<p>When you want to invoke an instance method on a specific object, you can use the <code>object::instanceMethodName</code> syntax. For instance:</p> <pre><code>String name = \"John\";\nSupplier&lt;Integer&gt; nameLength = name::length;\n</code></pre> <p>Here, <code>name::length</code> references the <code>length</code> method of the <code>name</code> string, and <code>nameLength.get()</code> will return the length of the string, which is 4.</p>","tags":["Java 8"]},{"location":"java/java8/#3-reference-to-an-instance-method-of-an-arbitrary-object-of-a-particular-type","title":"3. Reference to an Instance Method of an Arbitrary Object of a Particular Type:","text":"<p>This type of method reference is often used in situations like sorting lists. You reference an instance method for objects of a particular type. For example:</p> <pre><code>List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\");\nnames.sort(String::compareToIgnoreCase);\n</code></pre> <p>Here, <code>String::compareToIgnoreCase</code> refers to the <code>compareToIgnoreCase</code> method of the <code>String</code> class. It allows you to sort the list of names without explicitly specifying a lambda function.</p>","tags":["Java 8"]},{"location":"java/java8/#4-reference-to-a-constructor","title":"4. Reference to a Constructor:","text":"<p>To create instances of classes using method references, you can reference constructors with the <code>ClassName::new</code> syntax. For instance:</p> <pre><code>Supplier&lt;List&lt;String&gt;&gt; listSupplier = ArrayList::new;\nList&lt;String&gt; myList = listSupplier.get();\n</code></pre> <p>In this example, <code>ArrayList::new</code> refers to the constructor of the <code>ArrayList</code> class, and <code>listSupplier.get()</code> creates a new ArrayList instance.</p> <p>Method references simplify your code and make it more readable, as you can express your intent more clearly. They are particularly helpful when working with functional interfaces and lambda expressions in Java 8 and later versions, providing a more concise way to reference methods and constructors.</p>","tags":["Java 8"]},{"location":"java/java8/#practical-examples-of-method-references","title":"Practical Examples of Method References:","text":"<p>Let's explore practical examples to illustrate the usage of method references in various scenarios:</p>","tags":["Java 8"]},{"location":"java/java8/#example-1-using-static-method-references-in-functional-interfaces","title":"Example 1: Using Static Method References in Functional Interfaces","text":"<p>Suppose you have a list of numbers, and you want to calculate the sum of their squares. You can use a static method reference to <code>Math.pow</code> for this:</p> <pre><code>List&lt;Double&gt; numbers = Arrays.asList(2.0, 3.0, 4.0);\ndouble sumOfSquares = numbers.stream()\n                            .mapToDouble(Math::pow)\n                            .sum();\nSystem.out.println(\"Sum of squares: \" + sumOfSquares);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#example-2-instance-method-reference-in-predicate","title":"Example 2: Instance Method Reference in Predicate","text":"<p>Imagine you have a list of strings, and you want to filter out the ones with a length greater than a certain value. You can use an instance method reference with a Predicate:</p> <pre><code>List&lt;String&gt; words = Arrays.asList(\"apple\", \"banana\", \"cherry\", \"date\");\nint minLength = 5;\nList&lt;String&gt; filteredWords = words.stream()\n                                  .filter(s -&gt; s.length() &gt;= minLength)\n                                  .collect(Collectors.toList());\nSystem.out.println(\"Filtered words: \" + filteredWords);\n</code></pre> <p>Here's how you can achieve the same result using an instance method reference:</p> <pre><code>List&lt;String&gt; filteredWords = words.stream()\n                                  .filter(s -&gt; s.length() &gt;= minLength)\n                                  .collect(Collectors.toList());\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#example-3-constructor-reference-in-stream","title":"Example 3: Constructor Reference in Stream","text":"<p>Suppose you have a list of integers, and you want to create a list of corresponding objects with those integers as values. You can use a constructor reference in a stream:</p> <pre><code>List&lt;Integer&gt; values = Arrays.asList(1, 2, 3, 4, 5);\nList&lt;MyObject&gt; objects = values.stream()\n                               .map(MyObject::new)\n                               .collect(Collectors.toList());\n</code></pre> <p>Here, <code>MyObject::new</code> refers to the constructor of the <code>MyObject</code> class.</p> <p>These examples demonstrate how method references can simplify your code and make it more readable by replacing lambda expressions with concise references to methods and constructors. By using method references, you can write cleaner and more expressive Java code, making it easier for students, developers, and others to understand and learn from.</p>","tags":["Java 8"]},{"location":"java/java8/#optional-class_1","title":"Optional Class","text":"<p>The <code>Optional</code> class in Java 8 was introduced to tackle the problem of <code>NullPointerExceptions</code> by providing a more expressive and safer way to handle nullable values. It encourages developers to be explicit about the presence or absence of a value, reducing the chances of unexpected null references in their code.</p>","tags":["Java 8"]},{"location":"java/java8/#understanding-the-need","title":"Understanding the Need","text":"<p>Before Java 8, dealing with potentially null values in code was often error-prone. Developers would frequently forget to check for null, leading to <code>NullPointerExceptions</code> at runtime. The <code>Optional</code> class aims to address this issue by promoting a clear and structured approach to handling nullable values.</p>","tags":["Java 8"]},{"location":"java/java8/#creating-an-optional","title":"Creating an Optional","text":"<p>You can create an <code>Optional</code> instance using various factory methods:</p> <pre><code>Optional&lt;String&gt; name = Optional.of(\"John\"); // Creates an Optional with a non-null value\nOptional&lt;String&gt; emptyName = Optional.empty(); // Creates an empty Optional\nOptional&lt;String&gt; nullableName = Optional.ofNullable(getName()); // Creates an Optional from a potentially null value\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#avoiding-null-checks","title":"Avoiding Null Checks","text":"<p>One of the primary benefits of <code>Optional</code> is that it encourages you to avoid explicit null checks. Instead, you can use methods like <code>ifPresent</code>, which only executes a block of code if a value is present:</p> <pre><code>Optional&lt;String&gt; name = Optional.ofNullable(getName());\nname.ifPresent(n -&gt; System.out.println(\"Name is present: \" + n));\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#handling-absence","title":"Handling Absence","text":"<p>To perform an action when a value is absent, you can use the <code>orElse</code> method:</p> <pre><code>Optional&lt;String&gt; name = Optional.empty();\nString result = name.orElse(\"Default Name\");\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#chaining-operations","title":"Chaining Operations","text":"<p><code>Optional</code> also supports method chaining, allowing you to perform a series of operations on the value:</p> <pre><code>Optional&lt;String&gt; name = Optional.of(\"John\");\nString upperCaseName = name.map(String::toUpperCase).orElse(\"No Name\");\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#filtering-values","title":"Filtering Values","text":"<p>You can filter values within an <code>Optional</code> using the <code>filter</code> method:</p> <pre><code>Optional&lt;String&gt; name = Optional.of(\"Alice\");\nOptional&lt;String&gt; filteredName = name.filter(n -&gt; n.startsWith(\"A\"));\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#dealing-with-null-values","title":"Dealing with Null Values","text":"<p>When working with legacy code that may return null values, you can convert them to <code>Optional</code> to maintain consistency:</p> <pre><code>String legacyValue = getLegacyValue(); // May return null\nOptional&lt;String&gt; optionalValue = Optional.ofNullable(legacyValue);\n</code></pre> <p>The <code>Optional</code> class in Java 8 provides a structured and safer approach to handle nullable values, reducing the risk of <code>NullPointerExceptions</code>. By using <code>Optional</code>, developers can write cleaner and more expressive code while making it clear when a value might be absent. This helps improve code quality, readability, and maintainability.</p>","tags":["Java 8"]},{"location":"java/java8/#pitfalls-to-avoid","title":"Pitfalls to Avoid","text":"<p>While <code>Optional</code> is a powerful tool for handling nullable values, it's essential to use it judiciously and understand its limitations:</p> <ol> <li>Avoid Nesting: Don't nest <code>Optional</code> instances excessively. Use methods like <code>flatMap</code> to handle nested <code>Optional</code> values more elegantly.</li> </ol> <pre><code>   Optional&lt;Optional&lt;String&gt;&gt; nestedName = Optional.of(Optional.of(\"Nested Name\"));\n   Optional&lt;String&gt; flattenedName = nestedName.flatMap(Function.identity());\n</code></pre> <ol> <li> <p>Don't Overuse: Not every variable should be an <code>Optional</code>. Reserve it for cases where the absence of a value has a particular meaning in your domain logic.</p> </li> <li> <p>Performance: Creating and using <code>Optional</code> instances comes with a minor performance overhead. For most cases, it won't be noticeable, but be mindful in performance-critical scenarios.</p> </li> <li> <p>Avoid Throwing Exceptions: Avoid calling methods like <code>get()</code> directly on an <code>Optional</code> since it can throw a <code>NoSuchElementException</code>. Use <code>orElse</code> or <code>orElseThrow</code> to provide fallback values or handle exceptional cases.</p> </li> </ol> <pre><code>Optional&lt;String&gt; name = Optional.empty();\nString result = name.orElse(\"Default Name\"); // Preferred\nString value = name.get(); // Avoid\n</code></pre> <ol> <li>Null Values in Optional: Although you can put null values into an <code>Optional</code>, it's generally discouraged. The primary purpose of <code>Optional</code> is to eliminate null references, so using it with null values defeats that purpose.</li> </ol>","tags":["Java 8"]},{"location":"java/java8/#best-practices_2","title":"Best Practices","text":"<p>To get the most out of <code>Optional</code>, follow these best practices:</p> <ol> <li> <p>Use <code>ifPresent</code> for Side Effects: Use <code>ifPresent</code> when you want to perform an action if a value is present without returning a new value.</p> </li> <li> <p>Use <code>map</code> and <code>filter</code> for Value Transformation: Use <code>map</code> to transform the value inside an <code>Optional</code>. Use <code>filter</code> to conditionally modify an <code>Optional</code> based on a predicate.</p> </li> <li> <p>Prefer <code>orElse</code> over <code>orElseGet</code>: <code>orElse</code> is suitable for providing default values, while <code>orElseGet</code> is more efficient when generating the default value involves significant computation.</p> </li> <li> <p>Embrace Functional Programming: <code>Optional</code> works well with Java's functional programming features like lambdas and streams. Combining them can lead to concise and expressive code.</p> </li> <li> <p>Think About Domain Semantics: Consider the meaning of absent values in your domain when deciding to use <code>Optional</code>. Make it clear in your code's comments and documentation.</p> </li> </ol> <p>By following these best practices and understanding the purpose and limitations of the <code>Optional</code> class, you can leverage it effectively to prevent <code>NullPointerExceptions</code> and write cleaner, safer, and more maintainable Java code.</p>","tags":["Java 8"]},{"location":"java/java8/#parallel-streams","title":"Parallel streams","text":"<p>Parallel streams in Java 8 offer significant benefits when it comes to processing large data sets concurrently, improving performance, and taking full advantage of multi-core processors. They allow developers to write cleaner, more efficient code for tasks that can be parallelized, making Java applications faster and more scalable.</p> <p>Java 8 introduced the concept of streams, which provide a functional approach to working with collections of data. Parallel streams take this concept a step further by allowing you to harness the power of multiple cores in modern processors for improved performance. Here are the key benefits of using parallel streams in Java 8:</p> <ol> <li> <p>Improved Performance: Parallel streams enable you to perform operations on a collection of data in parallel, dividing the workload among multiple threads. This can lead to significant performance improvements, especially when dealing with large datasets. For tasks that can be parallelized, you can expect faster execution times compared to sequential processing.</p> </li> <li> <p>Utilizing Multi-Core Processors: In today's computing environment, most machines come with multi-core processors. Parallel streams allow you to fully utilize these cores, making your Java applications more efficient. Each core can work on a portion of the data simultaneously, maximizing CPU resources.</p> </li> <li> <p>Cleaner and More Readable Code: Parallel streams promote cleaner and more readable code compared to traditional multithreading approaches. They abstract away the complexity of managing threads manually and allow you to express your intentions more clearly. This leads to code that is easier to maintain and understand.</p> </li> <li> <p>Conciseness: Parallel stream operations are concise and can often be written in a single line of code. This simplicity reduces the chances of introducing bugs and makes your codebase more concise and elegant.</p> </li> <li> <p>Automatic Load Balancing: Parallel streams handle the distribution of tasks and load balancing automatically. Java's ForkJoinPool is used under the hood to split the work efficiently among available threads, ensuring that each thread gets a fair share of the work.</p> </li> <li> <p>Immutable Data: Parallel streams work seamlessly with immutable data structures. This encourages functional programming practices, reducing the risk of data inconsistencies caused by mutable data.</p> </li> <li> <p>Example - Calculating Sum of Numbers: Here's a simple example to illustrate the benefits of parallel streams. Suppose you have a large list of numbers and want to calculate their sum.</p> </li> </ol> <pre><code>   List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\n\n   // Sequential Stream\n   int sumSequential = numbers.stream()\n       .reduce(0, (a, b) -&gt; a + b);\n\n   // Parallel Stream\n   int sumParallel = numbers.parallelStream()\n       .reduce(0, (a, b) -&gt; a + b);\n</code></pre> <p>In this example, the parallel stream version can take advantage of multiple cores and perform the addition concurrently, potentially resulting in faster execution for large lists.</p> <p>In conclusion, parallel streams in Java 8 provide a powerful tool for improving the performance of your applications when dealing with data processing tasks that can be parallelized. They simplify concurrent programming, make the code more readable, and take advantage of modern hardware capabilities. However, it's essential to use them judiciously, as not all tasks are suitable for parallelization, and improper usage can lead to performance degradation or even bugs related to thread safety.</p>","tags":["Java 8"]},{"location":"java/java8/#monitoring-and-debugging","title":"Monitoring and Debugging:","text":"<p>While parallel streams offer significant advantages, they also come with some considerations, such as monitoring and debugging:</p> <ol> <li> <p>Resource Consumption: Parallel streams consume more system resources due to the creation of multiple threads. Be mindful of this resource usage, especially in a production environment with limited resources.</p> </li> <li> <p>Thread Safety: Ensure that the operations performed within parallel streams are thread-safe. Data races and concurrency issues can occur if you modify shared data without proper synchronization.</p> </li> <li> <p>Ordering: In some cases, parallel streams may not preserve the order of elements in the output. If maintaining order is crucial, consider using sequential streams or applying additional sorting operations.</p> </li> <li> <p>Debugging Complexity: Debugging parallel code can be more challenging than debugging sequential code. When issues arise, identifying the cause of a problem across multiple threads may require specialized debugging tools and techniques.</p> </li> <li> <p>Choosing the Right Candidates: Not all tasks benefit from parallelization. Some operations, such as simple filtering or mapping on small data sets, may perform better in a sequential stream. It's essential to profile your application and identify the parts that can benefit the most from parallelization.</p> </li> <li> <p>Example - Parallelism with <code>forEach</code>: Here's an example that demonstrates how to use parallel streams to perform a parallelized operation with <code>forEach</code>.</p> </li> </ol> <pre><code>   List&lt;String&gt; names = Arrays.asList(\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\");\n\n   // Sequential forEach\n   names.forEach(name -&gt; System.out.println(\"Hello, \" + name));\n\n   // Parallel forEach\n   names.parallelStream()\n       .forEach(name -&gt; System.out.println(\"Hello, \" + name));\n</code></pre> <p>When using parallel streams with <code>forEach</code>, keep in mind that the order of output may not be the same as the input list due to concurrent processing.</p> <p>In conclusion, while parallel streams offer substantial benefits for parallelizing data processing tasks in Java 8, it's essential to use them judiciously, considering the nature of the task, thread safety, and debugging challenges. When used appropriately, parallel streams can significantly boost the performance of your Java applications and provide a more responsive user experience.</p>","tags":["Java 8"]},{"location":"java/java8/#mitigating-common-pitfalls","title":"Mitigating Common Pitfalls:","text":"<p>To make the most of parallel streams and avoid common pitfalls, consider the following best practices:</p> <ol> <li> <p>Choose the Right Data Structures: Opt for data structures that are suitable for parallel processing. For example, <code>ArrayList</code> may be more efficient than <code>LinkedList</code> in parallel scenarios due to its better cache locality.</p> </li> <li> <p>Avoid Stateful Operations: Try to avoid stateful operations, which can lead to unexpected results in parallel streams. Stateful operations are those that rely on the order or state of elements, such as <code>sorted()</code> or <code>distinct()</code>. If needed, apply these operations after parallel processing.</p> </li> <li> <p>Consider Using Parallelism Safeguards: In some cases, you may want to restrict the degree of parallelism to prevent excessive thread creation. You can achieve this by configuring the underlying ForkJoinPool using <code>System.setProperty(\"java.util.concurrent.ForkJoinPool.common.parallelism\", \"n\")</code>, where 'n' is the desired parallelism level.</p> </li> <li> <p>Benchmark and Profile: Always benchmark your code and profile its performance to ensure that parallelization indeed improves the execution time. Profiling tools like VisualVM or Java Flight Recorder can help identify bottlenecks.</p> </li> <li> <p>Test for Thread Safety: Thoroughly test your code for thread safety. Ensure that shared data is properly synchronized or use thread-safe data structures to prevent data corruption and race conditions.</p> </li> <li> <p>Use Parallel Streams with Caution for I/O Operations: While parallel streams are excellent for CPU-bound tasks, they may not be suitable for I/O-bound operations, as creating excessive threads for I/O can lead to diminishing returns or even performance degradation. Consider asynchronous programming techniques for I/O-bound tasks.</p> </li> <li> <p>Graceful Degradation: Implement graceful degradation strategies, such as falling back to sequential processing for small data sets or in cases where parallelization doesn't provide a significant benefit.</p> </li> <li> <p>Test for Scalability: Assess how well your parallelized code scales with increasing workload. Sometimes, adding more threads may not result in a linear performance improvement due to contention or other factors.</p> </li> </ol> <p>Incorporating these practices into your development workflow will help you maximize the benefits of parallel streams in Java 8 while minimizing potential issues.</p> <p>In conclusion, parallel streams in Java 8 are a valuable tool for improving the performance of your applications, especially when dealing with large datasets and CPU-bound tasks. However, they should be used judiciously, with careful consideration of thread safety, debugging, and the nature of the task at hand. When applied correctly, parallel streams can significantly enhance the responsiveness and efficiency of your Java applications, benefiting both developers and end-users alike.</p>","tags":["Java 8"]},{"location":"java/java8/#date-and-time-api-javatime-package","title":"Date and Time API (java.time package)","text":"<p>Java 8 introduced a new Date and Time API in the <code>java.time</code> package to address the shortcomings of the old <code>java.util.Date</code> and <code>java.util.Calendar</code> classes. This new API provides a more comprehensive and flexible way to work with dates and times, making it easier for developers to handle date and time-related operations.</p> <p>The Java 8 Date and Time API is based on the ISO calendar system and provides a rich set of classes for representing dates, times, durations, and intervals. It introduces several new classes, including <code>LocalDate</code>, <code>LocalTime</code>, <code>LocalDateTime</code>, <code>ZonedDateTime</code>, <code>Instant</code>, <code>Duration</code>, and <code>Period</code>, among others.</p>","tags":["Java 8"]},{"location":"java/java8/#key-classes-and-concepts","title":"Key Classes and Concepts:","text":"","tags":["Java 8"]},{"location":"java/java8/#1-localdate","title":"1. LocalDate:","text":"<p><code>LocalDate</code> represents a date without a time component. It's suitable for tasks like handling birthdates or any date where time information is not required. Here's an example:</p> <pre><code>LocalDate today = LocalDate.now();\nSystem.out.println(\"Current date: \" + today);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#2-localtime","title":"2. LocalTime:","text":"<p><code>LocalTime</code> represents a time without a date. It's useful for tasks like tracking event timings. Here's an example:</p> <pre><code>LocalTime currentTime = LocalTime.now();\nSystem.out.println(\"Current time: \" + currentTime);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#3-localdatetime","title":"3. LocalDateTime:","text":"<p><code>LocalDateTime</code> represents a date and time. It's suitable for tasks that require both date and time information. Here's an example:</p> <pre><code>LocalDateTime dateTime = LocalDateTime.now();\nSystem.out.println(\"Current date and time: \" + dateTime);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#4-zoneddatetime","title":"4. ZonedDateTime:","text":"<p><code>ZonedDateTime</code> extends <code>LocalDateTime</code> to include time zone information. It's crucial for handling dates and times across different time zones.</p> <pre><code>ZonedDateTime zonedDateTime = ZonedDateTime.now(ZoneId.of(\"America/New_York\"));\nSystem.out.println(\"Current date and time in New York: \" + zonedDateTime);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#5-instant","title":"5. Instant:","text":"<p><code>Instant</code> represents a point in time on the timeline in Coordinated Universal Time (UTC). It's suitable for measuring time intervals and working with timestamps.</p> <pre><code>Instant instant = Instant.now();\nSystem.out.println(\"Current timestamp in UTC: \" + instant);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#6-duration-and-period","title":"6. Duration and Period:","text":"<p><code>Duration</code> represents a time-based amount, such as \"5 hours\" or \"30 minutes,\" while <code>Period</code> represents a date-based amount, such as \"3 years\" or \"2 months.\" These classes are useful for performing arithmetic operations with time and dates.</p> <pre><code>Duration duration = Duration.ofHours(5);\nSystem.out.println(\"5 hours duration: \" + duration);\n\nPeriod period = Period.ofMonths(2);\nSystem.out.println(\"2 months period: \" + period);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#benefits","title":"Benefits:","text":"<ol> <li>Improved API design for better readability and maintainability.</li> <li>Immutable classes ensure thread safety.</li> <li>Comprehensive support for date and time manipulation.</li> <li>Time zone support for global applications.</li> <li>Better handling of leap years and daylight saving time changes.</li> </ol> <p>The Java 8 Date and Time API provides a robust and modern solution for working with dates and times in Java applications. Its easy-to-use classes and methods simplify date and time manipulation tasks, making it a valuable addition to the Java ecosystem for developers, students, and anyone dealing with date and time-related challenges.</p>","tags":["Java 8"]},{"location":"java/java8/#working-with-date-and-time","title":"Working with Date and Time:","text":"","tags":["Java 8"]},{"location":"java/java8/#parsing-and-formatting-dates-and-times","title":"Parsing and Formatting Dates and Times:","text":"<p>You can parse strings into <code>LocalDate</code>, <code>LocalTime</code>, or <code>LocalDateTime</code> using the <code>DateTimeFormatter</code> class:</p> <pre><code>DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"dd-MM-yyyy\");\nLocalDate parsedDate = LocalDate.parse(\"31-01-2024\", formatter);\nSystem.out.println(\"Parsed date: \" + parsedDate);\n</code></pre> <p>Formatting works the other way around:</p> <pre><code>DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"dd-MM-yyyy\");\nString formattedDate = LocalDate.now().format(formatter);\nSystem.out.println(\"Formatted date: \" + formattedDate);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#date-and-time-arithmetic","title":"Date and Time Arithmetic:","text":"<p>Performing arithmetic operations with dates and times is straightforward:</p> <pre><code>LocalDate today = LocalDate.now();\nLocalDate futureDate = today.plusDays(7);\nSystem.out.println(\"Future date: \" + futureDate);\n\nLocalTime now = LocalTime.now();\nLocalTime later = now.plusHours(3);\nSystem.out.println(\"Later time: \" + later);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#comparing-dates-and-times","title":"Comparing Dates and Times:","text":"<p>You can easily compare dates and times using built-in methods:</p> <pre><code>LocalDate date1 = LocalDate.of(2024, 1, 31);\nLocalDate date2 = LocalDate.of(2023, 12, 31);\n\nif (date1.isAfter(date2)) {\n    System.out.println(\"date1 is after date2\");\n} else {\n    System.out.println(\"date1 is not after date2\");\n}\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#handling-time-zones","title":"Handling Time Zones:","text":"<p>Working with time zones is crucial when dealing with global applications. You can convert between time zones using <code>ZonedDateTime</code>:</p> <pre><code>ZonedDateTime newYorkTime = ZonedDateTime.now(ZoneId.of(\"America/New_York\"));\nZonedDateTime londonTime = newYorkTime.withZoneSameInstant(ZoneId.of(\"Europe/London\"));\nSystem.out.println(\"New York time: \" + newYorkTime);\nSystem.out.println(\"London time: \" + londonTime);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#daylight-saving-time-dst","title":"Daylight Saving Time (DST):","text":"<p>The Java 8 Date and Time API automatically adjusts for DST changes, ensuring accurate calculations.</p> <pre><code>ZonedDateTime beforeDST = ZonedDateTime.of(2023, 3, 12, 1, 30, 0, 0, ZoneId.of(\"Europe/London\"));\nZonedDateTime afterDST = beforeDST.plusHours(1);\nSystem.out.println(\"Before DST: \" + beforeDST);\nSystem.out.println(\"After DST: \" + afterDST);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#handling-time-intervals","title":"Handling Time Intervals:","text":"<p>The Java 8 Date and Time API also provides convenient methods for dealing with time intervals. You can calculate the difference between two <code>LocalDate</code>, <code>LocalTime</code>, or <code>LocalDateTime</code> objects using <code>Duration</code>:</p> <pre><code>LocalDateTime start = LocalDateTime.of(2024, 1, 31, 10, 0);\nLocalDateTime end = LocalDateTime.of(2024, 1, 31, 14, 30);\n\nDuration duration = Duration.between(start, end);\nSystem.out.println(\"Duration: \" + duration.toHours() + \" hours and \" + duration.toMinutesPart() + \" minutes\");\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#working-with-weekdays-and-months","title":"Working with Weekdays and Months:","text":"<p>You can easily retrieve information about weekdays and months using the API. For example, checking if a date falls on a weekend:</p> <pre><code>LocalDate someDate = LocalDate.of(2024, 1, 31);\n\nif (someDate.getDayOfWeek() == DayOfWeek.SATURDAY || someDate.getDayOfWeek() == DayOfWeek.SUNDAY) {\n    System.out.println(\"It's a weekend!\");\n} else {\n    System.out.println(\"It's a weekday.\");\n}\n</code></pre> <p>You can also get information about the current month:</p> <pre><code>LocalDate currentDate = LocalDate.now();\nMonth currentMonth = currentDate.getMonth();\nSystem.out.println(\"Current month: \" + currentMonth);\n</code></pre>","tags":["Java 8"]},{"location":"java/java8/#converting-legacy-date-time-types","title":"Converting Legacy Date-Time Types:","text":"<p>If you need to work with legacy <code>java.util.Date</code> objects, you can easily convert between the old and new date-time types:</p> <pre><code>Date legacyDate = new Date();\nInstant instant = legacyDate.toInstant();\nLocalDateTime localDateTime = instant.atZone(ZoneId.systemDefault()).toLocalDateTime();\nSystem.out.println(\"Legacy Date converted to LocalDateTime: \" + localDateTime);\n</code></pre> <p>The Java 8 Date and Time API in the <code>java.time</code> package provides a modern and comprehensive solution for handling dates, times, and intervals in Java applications. It simplifies common tasks, handles time zones and DST changes, and offers excellent readability. Whether you're a developer or a student, mastering this API will greatly enhance your ability to work with date and time data effectively in Java.</p>","tags":["Java 8"]},{"location":"java/multi-threading/","title":"Multi threading","text":"<p>Multithreading in java is a process of executing multiple threads simultaneously. Thread is basically a lightweight sub-process, a smallest unit of processing. Multiprocessing and multithreading, both are used to achieve multitasking.</p> <p>But we use multithreading than multiprocessing because threads share a common memory area. They don't allocate separate memory area so saves memory, and context-switching between the threads takes less time than process.</p> <p>Thread is executed inside the process. There is context-switching between the threads. There can be multiple processes inside the OS and one process can have multiple threads.</p>"},{"location":"java/multi-threading/#advantages-of-multithreading","title":"Advantages of Multithreading:","text":"<ol> <li>It doesn't block the user because threads are independent and you can perform multiple operations at same time.</li> <li>You can perform many operations simultaneously so it saves time.</li> <li>Threads are independent so it doesn't affect other threads if exception occur in a single thread.</li> </ol>"},{"location":"java/multi-threading/#life-cycle-of-a-thread","title":"Life Cycle of a Thread","text":"<p>A java thread can be in any of following thread states during it\u2019s life cycle i.e. New, Runnable, Blocked, Waiting, Timed Waiting or Terminated. These are also called life cycle events of a thread in java.</p> <ul> <li>New - The thread is in new state if you create an instance of Thread class but before the invocation of start() method.</li> <li>Runnable - The thread is in runnable state after invocation of start() method, but the thread scheduler has not selected it to be the running thread.</li> <li>Running - The thread is in running state if the thread scheduler has selected it.</li> <li>Non-Runnable (Blocked) - This is the state when the thread is still alive, but is currently not eligible to run.</li> <li>Terminated - A thread is in terminated or dead state when its run() method exits.</li> </ul> <p></p>"},{"location":"java/multi-threading/#creating-a-thread","title":"Creating a Thread","text":"<p>There are two ways to create a thread: 1. Extends Thread class 2. Implement Runnable interface</p>"},{"location":"java/multi-threading/#extends-thread-class","title":"Extends Thread class","text":"<p>Create a thread by a new class that extends Thread class and create an instance of that class. The extending class must override run() method which is the entry point of new thread.</p> <p><pre><code>public class MyThread extends Thread {\n\n    public void run() {\n      System.out.println(\"Thread started running..\");\n    }\n    public static void main( String args[] ) {\n       MyThread mt = new  MyThread();\n       mt.start();\n    }\n}\n</code></pre> Output <pre><code>Thread started running..\n</code></pre></p>"},{"location":"java/multi-threading/#implementing-the-runnable-interface","title":"Implementing the Runnable Interface","text":"<p>After implementing runnable interface, the class needs to implement the run() method, which is public void run().</p> <ul> <li>run() method introduces a concurrent thread into your program. This thread will end when run() returns.</li> <li>You must specify the code for your thread inside run() method.</li> <li>run() method can call other methods, can use other classes and declare variables just like any other normal method.</li> </ul> <pre><code>class MyThread implements Runnable {\n\n    public void run() {\n        System.out.println(\"Thread started running..\");\n    }\n    public static void main(String args[]) {\n        MyThread mt = new MyThread();\n        Thread t = new Thread(mt);\n        t.start();\n    }\n}\n</code></pre>"},{"location":"java/multi-threading/#difference-between-runnable-vs-thread","title":"Difference between Runnable vs Thread","text":"<ul> <li>Implementing Runnable is the preferred way to do it. Here, you\u2019re not really specializing or modifying the thread\u2019s behavior. You\u2019re just giving the thread something to run. That means composition is the better way to go.</li> <li>Java only supports single inheritance, so you can only extend one class.</li> <li>Instantiating an interface gives a cleaner separation between your code and the implementation of threads.</li> <li>Implementing Runnable makes your class more flexible. If you extend Thread then the action you\u2019re doing is always going to be in a thread. However, if you implement Runnable it doesn\u2019t have to be. You can run it in a thread, or pass it to some kind of executor service, or just pass it around as a task within a single threaded application.</li> </ul> <p>A thread can be defined in two ways. First, by extending a Thread class that has already implemented a Runnable interface. Second, by directly implementing a Runnable interface.</p> <p>Difference</p> THREAD CLASS RUNNABLE INTERFACE Each thread creates a unique object and gets associated with it. Multiple threads share the same objects. As each thread create a unique object, more memory required. As multiple threads share the same object less memory is used. In Java, multiple inheritance not allowed hence, after a class extends Thread class, it can not extend any other class. If a class define thread implementing the Runnable interface it has a chance of extending one class. A user must extend thread class only if it wants to override the other methods in Thread class. If you only want to specialize run method then implementing Runnable is a better option. Extending Thread class introduces tight coupling as the class contains code of Thread class and also the job assigned to the thread Implementing Runnable interface introduces loose coupling as the code of Thread is separate form the job of Threads."},{"location":"java/multi-threading/#synchronized-keyword","title":"synchronized keyword","text":"<p><code>synchronized</code> keyword in java is used to control the access of multiple threads to any shared resource, so that any consistency problem can be avoided. We can make the entire method as <code>synchronized</code> or just the part where the shared resource is getting used, to do this <code>synchronized</code> blocks are used.</p> <p>Synchronized method/block can only have one thread executing inside it, all the other threads trying to enter into the <code>synchronized</code> method/block will get blocked until the thread inside finishes its execution. When the thread exits the <code>synchronized</code> method/block then Java guarantees that changes to the state of the object is visible to all the threads. This eliminates the memory inconsistency errors.</p>"},{"location":"java/multi-threading/#static-synchronization","title":"static synchronization","text":"<p>When synchronized keyword is used with a static method, then that is called static synchronization. In this, lock will be on the class not the object. This means only one thread can access the class at a time.</p> <p>The purpose of static synchronization is to make the static data thread-safe.</p> <p>Let\u2019s look at some programs:</p> <p>Here, we have a Hello class which has a synchronized method: <pre><code>class Hello {\n\n    synchronized void sayHello() {\n        System.out.println(\"in sayHello() method \" + Thread.currentThread().getName());\n        for(int i=1; i&lt;=5; i++) {\n            System.out.println(Thread.currentThread().getName() + \" , i = \" + i);\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n</code></pre></p> <p>A Task class which implements Runnable and its run() method simply calls the synchronized method of Hello class: <pre><code>class Task implements Runnable {\n\n    Hello h;\n\n    Task(Hello h) {\n        this.h = h;\n    }\n\n    @Override\n    public void run() {\n        h.sayHello();\n    }\n\n}\n</code></pre> Our main class: <pre><code>public class SynchronizationDemo {\npublic static void main(String[] args) {\nHello obj1 = new Hello();\nHello obj2 = new Hello();\n\n        Thread task1 = new Thread(new Task(obj1));\n        task1.setName(\"First Thread\");\n        Thread task2 = new Thread(new Task(obj1));\n        task2.setName(\"Second Thread\");\n        Thread task3 = new Thread(new Task(obj2));\n        task3.setName(\"Third Thread\");\n        Thread task4 = new Thread(new Task(obj2));\n        task4.setName(\"Fourth Thread\");\n\n        task1.start();\n        task2.start();\n        task3.start();\n        task4.start();\n    }\n}\n</code></pre> We have 2 objects of our Hello class, one object is shared among First and Second thread, and one object is shared among Third and Fourth thread, and we are starting these threads.</p> <p>Output: <pre><code>in sayHello() method First Thread\nin sayHello() method Third Thread\nFirst Thread , i = 1\nThird Thread , i = 1\nFirst Thread , i = 2\nThird Thread , i = 2\nFirst Thread , i = 3\nThird Thread , i = 3\nFirst Thread , i = 4\nThird Thread , i = 4\nFirst Thread , i = 5\nThird Thread , i = 5\nin sayHello() method Second Thread\nSecond Thread , i = 1\nin sayHello() method Fourth Thread\nFourth Thread , i = 1\nSecond Thread , i = 2\nFourth Thread , i = 2\nSecond Thread , i = 3\nFourth Thread , i = 3\nSecond Thread , i = 4\nFourth Thread , i = 4\nSecond Thread , i = 5\nFourth Thread , i = 5\n</code></pre></p> <p>As you can see from the output, the First and Second thread are not having any thread interference. Same way, Third and Fourth thread does not have any thread interference but First and Third thread are entering the synchronized method at the same time with their own object locks (Hello obj1 and obj2).</p> <p>Lock which is hold by First thread will only stop the Second thread from entering the synchronized block, because they are working on the same instance i.e. obj1, but it cannot stop Third or Fourth thread as they are working on another instance i.e. obj2.</p> <p>If we want our synchronized method to be accessed by only one thread at a time then we have to use a static synchronized method/block to have the synchronization on the class level rather than on the instance level.</p> <pre><code>class Hello {\n\n    static synchronized void sayHello() {\n        System.out.println(\"in sayHello() method \" +\n                                    Thread.currentThread().getName());\n        for(int i=1; i&lt;=5; i++) {\n            System.out.println(Thread.currentThread().getName() + \" , i = \" + i);\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n</code></pre> <p>Let\u2019s see the output now:</p> <pre><code>in sayHello() method First Thread\nFirst Thread , i = 1\nFirst Thread , i = 2\nFirst Thread , i = 3\nFirst Thread , i = 4\nFirst Thread , i = 5\nin sayHello() method Fourth Thread\nFourth Thread , i = 1\nFourth Thread , i = 2\nFourth Thread , i = 3\nFourth Thread , i = 4\nFourth Thread , i = 5\nin sayHello() method Third Thread\nThird Thread , i = 1\nThird Thread , i = 2\nThird Thread , i = 3\nThird Thread , i = 4\nThird Thread , i = 5\nin sayHello() method Second Thread\nSecond Thread , i = 1\nSecond Thread , i = 2\nSecond Thread , i = 3\nSecond Thread , i = 4\nSecond Thread , i = 5\n</code></pre> <p>Here, only one thread is accessing the static synchronized method.</p> <p>Same can be done by synchronized block also: <pre><code>class Hello {\n\n    static void sayHello() {\n      synchronized (Hello.class) {\n        System.out.println(\"in sayHello() method \" + Thread.currentThread().getName());\n        for (int i = 1; i &lt;= 5; i++) {\n          System.out.println(Thread.currentThread().getName() + \" , i = \" + i);\n          try {\n            Thread.sleep(1000);\n          } catch (InterruptedException e) {\n            e.printStackTrace();\n          }\n        }\n      }\n    }\n}\n</code></pre></p>"},{"location":"java/multi-threading/#what-does-join-method","title":"What does join() method?","text":"<p><code>java.lang.Thread</code> class provides the <code>join()</code> method which allows one thread to wait until another thread completes its execution. <code>join()</code> method can be used to execute the threads sequentially or in some specific order. <pre><code>public class ThreadJoinExample {\n\n    public static void main(String[] args) {\n        Thread t1 = new Thread(new MyRunnable(), \"t1\");\n        Thread t2 = new Thread(new MyRunnable(), \"t2\");\n        Thread t3 = new Thread(new MyRunnable(), \"t3\");\n\n        t1.start();\n\n        //start second thread after waiting for 2 seconds or if it's dead\n        try {\n            t1.join(2000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        t2.start();\n\n        //start third thread only when first thread is dead\n        try {\n            t1.join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        t3.start();\n\n        //let all threads finish execution before finishing main thread\n        try {\n            t1.join();\n            t2.join();\n            t3.join();\n        } catch (InterruptedException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n\n        System.out.println(\"All threads are dead, exiting main thread\");\n    }\n\n}\n\nclass MyRunnable implements Runnable {\n\n    @Override\n    public void run() {\n        System.out.println(\"Thread started: \"+Thread.currentThread().getName());\n        try {\n            Thread.sleep(4000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"Thread ended: \"+Thread.currentThread().getName());\n    }\n}\n</code></pre> Output <pre><code>Thread started: t1\nThread started: t2\nThread ended: t1\nThread started: t3\nThread ended: t2\nThread ended: t3\nAll threads are dead, exiting main thread\n</code></pre></p> <p>In the code, if you don\u2019t write t2.join(), then current thread will not wait from the t2 thread to die.</p> <p>There are overloaded versions of join() method also, - join(long milliseconds) : when this method is called, then the current thread will wait at most for the specified milliseconds - join(long milliseconds, long nanoseconds) : when this method is called, then the current thread will wait at most for the specified milliseconds plus nanoseconds.</p> <p>These join methods are dependent on the underlying Operating system for timing. So, you should not assume that join() will wait exactly as long as you specify. You can execute threads in a sequence using CountDownLatch also.</p>"},{"location":"java/multi-threading/#deadlock","title":"Deadlock","text":"<p>Deadlock is a programming situation where two or more threads are blocked forever, this situation arises with at least two threads and two or more resources.</p> <pre><code>class HelloClass {\n    public synchronized void first(HiClass hi) {\n        try {\n            Thread.sleep(1000);\n        }\n        catch(InterruptedException ie) {}\n        System.out.println(\" HelloClass is calling  HiClass second() method\");\n        hi.second();\n    }\n\n    public synchronized void second() {\n        System.out.println(\"I am inside second method of HelloClass\");\n    }\n}\n\nclass HiClass {\n    public synchronized void first(HelloClass he) {\n        try {\n            Thread.sleep(1000);\n        }\n        catch(InterruptedException ie){}\n        System.out.println(\" HiClass is calling HelloClass second() method\");\n        he.second();\n    }\n\n    public synchronized void second() {\n        System.out.println(\"I am inside second method of HiClass\");\n    }\n}\n\nclass DeadlockClass extends Thread {\n    HelloClass he = new HelloClass();\n    HiClass hi = new HiClass();\n\n    public void demo() {\n        this.start();\n        he.first(hi);\n    } \n    public void run() {\n        hi.first(he);\n    }\n\n    public static void main(String[] args) {\n        DeadlockClass dc = new DeadlockClass();\n        dc.demo();\n    }\n}\n</code></pre> <pre><code>cmd&gt; java DeadlockClass\nHelloClass is calling HiClass second() method\nHiClass is calling HelloClass second() method\n</code></pre>"},{"location":"java/multi-threading/#how-to-avoid-deadlock","title":"How to avoid deadlock?","text":"<ul> <li>1. Avoid Nested Locks: This is the most common reason for deadlocks, avoid locking another resource if you already hold one. It\u2019s almost impossible to get deadlock situation if you are working with only one object lock. For example, here is the another implementation of run() method without nested lock and program runs successfully without deadlock situation.</li> </ul> <p><pre><code>public void run() {\n        String name = Thread.currentThread().getName();\n        System.out.println(name + ' acquiring lock on ' + obj1);\n        synchronized (obj1) {\n          System.out.println(name + ' acquired lock on ' + obj1);\n          work();\n        }\n        System.out.println(name + ' released lock on ' + obj1);\n        System.out.println(name + ' acquiring lock on ' + obj2);\n        synchronized (obj2) {\n          System.out.println(name + ' acquired lock on ' + obj2);\n          work();\n        }\n        System.out.println(name + ' released lock on ' + obj2);\n        System.out.println(name + ' finished execution.');\n        }\n}\n</code></pre> - 2. Lock Only What is Required:   You should acquire lock only on the resources you have to work on, for example in above program I am locking the complete Object resource but if we are only interested in one of it\u2019s fields, then we should lock only that specific field not complete object.</p> <ul> <li>3. Avoid waiting indefinitely:   You can get deadlock if two threads are waiting for each other to finish indefinitely using thread join. If your thread has to wait for another thread to finish, it\u2019s always best to use join with maximum time you want to wait for thread to finish.</li> </ul>"},{"location":"java/multi-threading/#what-will-happen-if-i-directly-call-the-run-method-and-not-the-start-method-to-execute-a-thread","title":"What will happen if I directly call the run() method and not the start() method to execute a thread?","text":"<p>if run() method is called directly, then a new thread will not be created instead the code will run on the current thread which is main thread. Calling run() method directly will make it behave as any other normal method call. Only a call to start() method creates separate thread.</p>"},{"location":"java/multi-threading/#once-a-thread-has-been-started-can-it-be-started-again","title":"Once a thread has been started can it be started again?","text":"<p>No. A thread can be started only once in its lifetime. If you try to start a thread which has already been started, an IllegalThreadStateException is thrown, which is a runtime exception. A thread in runnable state or a dead thread cannot be restarted</p>"},{"location":"java/multi-threading/#why-wait-notify-and-notifyall-methods-are-defined-in-the-object-class-instead-of-thread-class","title":"Why wait, notify and notifyAll methods are defined in the Object class instead of Thread class?","text":"<p>The methods wait, notify and notifyAll are present in the Object class, that means they are available to all class objects, as Object class is the parent of all classes. - wait() method \u2013 it tells the current thread to release the lock and go to sleep until some other thread enters the same monitor and calls notify() - notify() method \u2013 wakes up the single thread that is waiting on the same object\u2019s monitor - notifyAll() method \u2013 wakes up all the threads that called wait() on the same object</p> <p>if these methods were in Thread class, then thread T1 must know that another thread T2 is waiting for this particular resource, so T2 can be notified by something like T2.notify()</p> <p>But in java, the object itself is shared among all the threads, so one thread acquires the lock on this object\u2019s monitor, runs the code and while releasing the lock, it calls the notify or notifyAll method on the object itself, so that any other thread which was \"waiting on the same object\u2019s monitor will be notified that now the shared resource is available. That is why these methods are defined in the Object class.</p> <p>Threads have no specific knowledge of each other. They can run asynchronously and are independent. They do not need to know about the status of other threads. They just need to call notify method on an object, so whichever thread is waiting on that resource will be notified.</p> <p>Let\u2019s consider this with a real-life example:</p> <p>Suppose there is a petrol pump and it has a single washroom, the key of which is kept at the service desk. This washroom is a shared resource for all. To use this shared resource, the user must acquire the key to the washroom lock. So, the user goes to service desk, acquires the key, opens the door, locks it from the inside and use the facility.</p> <p>Meanwhile if another user arrives at the petrol pump and wants to use the washroom, he goes to the washroom and found that it is locked. He goes to the service desk and the key is not there because it is with the current user. When the current user finishes, he unlocks the door and returns the key to the service desk. He does not bother about the waiting users. The service desk gives the key to waiting user. If there are more than one user waiting to use the facility, then they must form a queue.</p> <p>Now, apply this analogy to Java, one user is one thread and the washroom is the shared resource which the threads wish to execute. The key will be synchronized keyword provided by Java through which thread acquires a lock for the code it wants to execute and making other threads wait until the current thread finishes. Java will not be as fair as the service station, because any of the waiting threads may get a chance to acquire the lock, regardless of the order in which the threads came. The only guarantee is that all the waiting threads will get to use the shared resource sooner or later.</p> <p>In this example, the lock can be acquired on the key object or the service desk and none of them is a thread. These are the objects that decide whether the washroom is locked or not.</p>"},{"location":"java/multi-threading/#why-wait-notify-notifyall-methods-must-be-called-from-synchronized-block","title":"Why wait(), notify(), notifyAll() methods must be called from synchronized block?","text":"<p>These methods are used for inter-thread communication. So, a wait() method only makes sense when there is a notify() method also. If these methods are not called from a synchronized block then</p> <ul> <li>IllegalMonitorStateException will be thrown</li> <li>Race condition can occur</li> </ul>"},{"location":"java/multi-threading/#wait-vs-sleep-methods","title":"wait() vs sleep() methods","text":"<p>The differences are: - <code>wait()</code> method can only be called from a synchronized context while <code>sleep()</code> method can be called without synchronized context - <code>wait()</code> method releases the lock on the object while waiting but <code>sleep()</code> method does not release the lock it holds while waiting, it means if the thread is currently in a synchronized block/method then no other thread can enter this block/method - <code>wait()</code> method is used for inter-thread communication while <code>sleep()</code> method is used to introduce a pause on execution -  waiting thread can be waked by calling <code>notify()</code> or <code>notifyAll()</code>, while sleeping thread will wake up when the specified sleep time is over or the sleeping thread gets interrupted - <code>wait()</code> method is non-static, it gets called on an object on which synchronization block is locked while <code>sleep()</code> is a static method, we call this method like Thread.sleep(), that means it always affects the currently executing thread - <code>wait()</code> is normally called when a condition is fulfilled like if the buffer size of queue is full then producer thread will wait, whereas <code>sleep()</code> method can be called without a condition</p>"},{"location":"java/multi-threading/#executor-framework","title":"Executor Framework","text":"<p>With an Executor framework, we only have to implement the Runnable objects and send them to the executor. The executor is responsible for their execution, instantiation, and running with necessary threads. But it goes beyond that and improves performance using a pool of threads. When you send a task to the executor, it tries to use a pooled thread for the execution of this task, to avoid continuous spawning of threads.</p> <p>Another important advantage of the Executor framework is the Callable interface. It's similar to the Runnable interface, but offers two improvements, which are: 1. The main method of this interface, named call(), may return a result. 2. When you send a Callable object to an executor, you get an object that implements the Future interface. You can use this object to control the status and the result of the Callable object.</p> <p>Summary - At a low level, we can create a thread in two ways, either by implementing Runnable or by subclassing Thread and overriding the run() method. - At a high-level, we use Executors, which use thread pools, which in turn use worker threads. - One type of thread pool is the fixed thread pool, which has a fixed number of threads running. We can also use single-thread pools. - ExecutorService has methods to execute thread pools that either take a Runnable or Callable task. A Callable returns a result and throws a checked exception. - The submit() method returns a Future object that represents the result of the task (if the task is a Runnable, null is returned). - An executor has to be shutdown to close the pool thread with either shutdown() (gracefully) or shutdownNow() (forcefully). - A deadlock situation occurs when two or more threads are blocked forever, waiting for each other to acquire/release some resource. - Starvation happens when a thread is constantly waiting for a lock, never able to take it because other threads with higher priority are continually acquiring it. - A livelock is like a deadlock in the sense that two (or more) threads are blocking each other, but in a livelock, each thread tries to resolve the problem on its own (live) instead of just waiting (dead). - A race condition is a situation where two threads compete to access or modify the same resource at the same time in a way that causes unexpected results.</p>"},{"location":"java/multi-threading/#high-level-concurrency-features-executor-framework","title":"High level concurrency features Executor framework","text":"<ul> <li>ExecutorService Interface</li> <li>ScheduledExecutorService Interface</li> <li>Future Interface</li> <li>Executors newSingleThreadExecutor Method </li> <li>Executors newFixedThreadPool Method </li> <li>Executors newCachedThreadPool Method </li> <li>Executors newScheduledThreadPool Method </li> </ul>"},{"location":"java/multi-threading/#executor-interface","title":"Executor Interface","text":"<p>An object that executes submitted Runnable tasks. This interface provides a way of decoupling task submission from the mechanics of how each task will be run, including details of thread use, scheduling, etc. An Executor is normally used instead of explicitly creating threads.</p> <p>For example, rather than invoking <code>new Thread(new(RunnableTask())).start()</code> for each of a set of tasks, you might use:</p> <pre><code>Executor executor = anExecutor;\n executor.execute(new RunnableTask1());\n executor.execute(new RunnableTask2());\n        ...\n</code></pre>"},{"location":"java/multi-threading/#executorservice-interface","title":"ExecutorService Interface","text":"<p>The <code>ExecutorService</code> interface supplements execute with a similar, but more versatile submit method. Like <code>execute</code>, <code>submit</code> accepts Runnable objects, but also accepts <code>Callable</code> objects, which allow the task to return a value. The submit method returns a <code>Future</code> object, which is used to retrieve the <code>Callable</code> return value and to manage the status of both <code>Callable</code> and <code>Runnable</code> tasks.</p> <p><code>ExecutorService</code> also provides methods for submitting large collections of <code>Callable</code> objects.  Finally, <code>ExecutorService</code> provides a number of methods for managing the shutdown of the executor. To support an immediate shutdown, tasks should handle interrupts correctly.</p> <p>Source Code from JDK Library <pre><code>public interface ExecutorService extends Executor {\n\n    void shutdown();\n\n    List&lt;Runnable&gt; shutdownNow();\n\n    boolean isShutdown();\n\n    boolean isTerminated();\n\n    boolean awaitTermination(long timeout, TimeUnit unit)\n        throws InterruptedException;\n\n    &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);\n\n    &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);\n\n    Future&lt;?&gt; submit(Runnable task);\n\n    &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)\n        throws InterruptedException;\n\n    &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,\n                                  long timeout, TimeUnit unit)\n        throws InterruptedException;\n    &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)\n        throws InterruptedException, ExecutionException;\n\n    &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,\n                    long timeout, TimeUnit unit)\n        throws InterruptedException, ExecutionException, TimeoutException;\n}\n</code></pre></p>"},{"location":"java/multi-threading/#executorservice-interface-examples","title":"ExecutorService Interface Examples","text":"<p>By  using Executors.newSingleThreadExecutor() method to create an ExecutorService that uses a single worker thread for executing tasks.</p> <pre><code>public class ExecutorServiceExample {\n    public static void main(String[] args) {\n\n        System.out.println(\"Thread main started\");\n\n       // Create a task\n        Runnable task = () -&gt; {\n             for (int i = 0; i &lt; 5; i++) {\n                 System.out.println(\"[\" + Thread.currentThread().getName() + \"] \" + \"Message \" + i);\n             }\n        };\n\n        ExecutorService executorService = Executors.newSingleThreadExecutor();\n\n        executorService.execute(task);\n\n        executorService.shutdown();\n\n        System.out.println(\"Thread main finished\");\n\n     }\n}\n</code></pre> <pre><code>Thread main started\nThread main finished\n[pool-1-thread-1] Message 0\n[pool-1-thread-1] Message 1\n[pool-1-thread-1] Message 2\n[pool-1-thread-1] Message 3\n[pool-1-thread-1] Message 4\n</code></pre>"},{"location":"java/multi-threading/#different-between-execute-and-submit-methods","title":"Different Between execute() and submit() Methods","text":"<ul> <li>The main difference is submit() method returns Future object for tracking the results but execute() method does't return anthing.</li> <li>Both submit() and execute() methods are used to submit a task to Executor framework for asynchronous execution.</li> <li>The submit() can accept both Runnable and Callable task but execute() can only accept the Runnable task.</li> <li>You can access submit() and execute() from the ExecutorService interface because it also extends the Executor interface which declares the execute() method.</li> </ul>"},{"location":"java/multi-threading/#scheduledexecutorservice-interface","title":"ScheduledExecutorService Interface","text":"<p>A ScheduledExecutorService can schedule commands to run after a given delay or to execute periodically.</p> <p>The schedule() methods create tasks with various delays and return a task object that can be used to cancel or check execution. The scheduleAtFixedRate() and scheduleWithFixedDelay() methods create and execute tasks that run periodically until cancelled.</p> <p>Commands submitted using the Executor.execute(Runnable) and ExecutorService submit methods are scheduled with a requested delay of zero. Zero and negative delays (but not periods) are also allowed in schedule methods and are treated as requests for immediate execution.</p> <pre><code>public class SchedulingTasksWithScheduledThreadPool {\n\n    public static void main(String[] args) throws InterruptedException {\n        System.out.println(\"Thread main started\");\n\n        // Create a task\n        Runnable task1 = () -&gt; {\n            System.out.println(\"Executing the task1 at: \" + new Date());\n        };\n\n        // Create a task\n        Runnable task2 = () -&gt; {\n            System.out.println(\"Executing the task2 at: \" + new Date());\n        };\n\n        ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(2);\n\n        System.out.println(\"Scheduling task to run after 5 seconds... \" + new Date());\n        scheduledExecutorService.schedule(task1, 5, TimeUnit.SECONDS);\n        scheduledExecutorService.schedule(task2, 5, TimeUnit.SECONDS);\n\n        scheduledExecutorService.shutdown();\n        System.out.println(\"Thread main finished\");\n    }\n}\n</code></pre> <p>Output <pre><code>Thread main started\nScheduling task to run after 5 seconds... Sat Sep 01 10:56:40 IST 2018\nThread main finished\nExecuting the task1 at: Sat Sep 01 10:56:45 IST 2018\nExecuting the task2 at: Sat Sep 01 10:56:45 IST 2018\n</code></pre></p>"},{"location":"java/multi-threading/#future-interface","title":"Future Interface","text":"<p>Future is a generic interface that represents the value that will be returned by a Callable object. Because this value is obtained at some future time, the name Future is appropriate.</p> <p>Future is defined like this:</p> <p><pre><code>public interface Future&lt;V&gt; {\n\n    boolean cancel(boolean mayInterruptIfRunning);\n\n    boolean isCancelled();\n\n    boolean isDone();\n\n    V get() throws InterruptedException, ExecutionException;\n\n    V get(long timeout, TimeUnit unit)\n        throws InterruptedException, ExecutionException, TimeoutException;\n}\n</code></pre> Here, V specifies the type of the result. To obtain the returned value, you will call Future\u2019s get( ) method, which has these two forms:</p> <pre><code>V get( ) throws InterruptedException, ExecutionException\nV get(long wait, TimeUnit tu) throws InterruptedException, ExecutionException, TimeoutException\n</code></pre> <p>The first form waits for the result indefinitely. The second form allows you to specify a timeout period in wait.</p> <pre><code>public class ReturnValuesUsingCallable {\n\n    public static void main(String[] args) throws InterruptedException, ExecutionException {\n\n        System.out.println(\"Thread main started\");\n\n        ExecutorService executorService = Executors.newSingleThreadExecutor();\n        Future&lt;Integer&gt; returnedValues = executorService.submit(() -&gt; {\n             int sum = 0;\n             for (int i = 1; i &lt;= 5; i++) {\n\n                sum += i;\n             try {\n                 Thread.sleep(200);\n             } catch (InterruptedException e) {\n                 e.printStackTrace();\n             }\n         }\n            System.out.println(\"[\" + Thread.currentThread().getName() + \"] of sum \" + sum);\n            return sum;\n       });\n\n        while(!returnedValues.isDone()) {\n             System.out.println(\"Task is still not done...\");\n             Thread.sleep(200);\n         }\n\n         System.out.println(\"Result of Future object:: \" + returnedValues.get());\n         executorService.shutdown();\n\n         System.out.println(\"Thread main finished\");\n    }\n}\n</code></pre> <p>Output: <pre><code>Thread main started\nTask is still not done...\nTask is still not done...\nTask is still not done...\nTask is still not done...\nTask is still not done...\nTask is still not done...\n[pool-1-thread-1] of sum 15\nResult of Future object:: 15\nThread main finished\n</code></pre></p>"},{"location":"java/multi-threading/#executor-framework-2","title":"Executor Framework-2","text":"<p>With an Executor framework, we only have to implement the Runnable objects and send them to the executor. The executor is responsible for their execution, instantiation, and running with necessary threads. But it goes beyond that and improves performance using a pool of threads. When you send a task to the executor, it tries to use a pooled thread for the execution of this task, to avoid continuous spawning of threads.</p> <p>Another important advantage of the Executor framework is the Callable interface. It's similar to the Runnable interface, but offers two improvements, which are as follows: - 1. The main method of this interface, named call(), may return a result. - 2. When you send a Callable object to an executor, you get an object that implements the Future interface. You can use this object to control the status and the result of the Callable object.</p> <p>Executor Framework is an abstraction to managing multiple threads by yourself. So, it decouples the execution of a task and the actual task itself. Now, we just have to focus on the task that means, only implement the Runnables and submit them to executor. Then these runnables will be managed by the executor framework. It is available from Java 1.5 onwards.</p> <p>Also, we don\u2019t have to create new threads every time. With executor framework, we use Thread pools. Think of Thread Pool as a user-defined number of threads which are called worker threads, these are kept alive and reused. The tasks that are submitted to the executor will be executed by these worker threads. If there are more tasks than the threads in the pool, they can be added in a Queue and as soon as one of thread is finished with a task, it can pick the next one from this Queue or else, it will be added back in the pool waiting for a task to be assigned.</p> <p>So, it saves the overhead of creating a new thread for each task. If you are thinking about what is the problem with creating a new thread every time we want to execute a task, then you should know that creating a thread is an expensive operation. Thread objects use a significant amount of memory, and in a large-scale application, allocating and deallocating many thread objects creates a significant memory management overhead and new threads without any throttling will lead to the creation of large number of threads. These threads will cause wastage of resources.</p> <p>There are 2 main interfaces that you must know, one is <code>Executor</code> and the other is <code>ExecutorService</code>.</p> <ul> <li> <p>Executor : interface contains <code>execute(Runnable task)</code> method through which you can execute only Runnables. Also, the return type of <code>execute()</code> method is void, since you are passing a <code>Runnable</code> to it and it does not return any result back.</p> </li> <li> <p>ExecutorService : interface contains the <code>submit()</code> method which can take both <code>Runnable</code> and <code>Callable</code>, and its return type is Future object. <code>ExecutorService</code> extends the <code>Executor</code> Interface, so it also has the <code>execute()</code> method.</p> </li> </ul> <p>Let\u2019s look at different types of Executors:</p> <ul> <li>SingleThreadExecutor :   This executor has only one thread and is used to execute tasks in a sequential manner. If the thread dies due to an exception while executing the task, a new thread is created to replace the old thread and the subsequent tasks are executed in the new thread.   How to create a SingleThreadExecutor:</li> </ul> <p><pre><code>  ExecutorService executor = Executors.newSingleThreadExecutor ();\n</code></pre>   Executors is a utility class which contains many factory methods to create different types of ExecutorService, like the one called SingleThreadExecutor, we just created.</p> <ul> <li>FixedThreadPoolExecutor :   As its name suggests, this is an executor with a fixed number of threads. The tasks submitted to this executor are executed by the specified number of threads and if there are more tasks than the number of threads, then those tasks will be added in a queue (e.g. LinkedBlockingQueue).   How to create a FixedThreadPoolExecutor: <pre><code>  ExecutorService executor = Executors.newFixedThreadPool (5);\n</code></pre></li> </ul> <p>Here, we have created a thread pool executor of 5 threads, that means at any given time, 5 tasks can be managed by this executor. If there are more active tasks, they will be added to a queue until one of the 5 threads becomes free.   An important advantage of the fixed thread pool is that applications using it degrade gracefully. </p> <p>To understand this, consider a web server application where each HTTP request is handled by a separate thread. If the application simply creates a new thread for every new HTTP request, and the system receives more requests than it can handle immediately, the application will suddenly stop responding to all requests when the overhead of all those threads exceed the capacity of the system. With a limit on the number of the threads that can be created, the application will not be servicing HTTP requests as quickly as they come in, but it will be servicing them as quickly as the system can sustain.</p> <ul> <li> <p>CachedThreadPoolExecutor :   This executor is mainly used when there are many short-lived tasks to be executed. If you compare this with the fixed thread pool, here the number of threads of this executor pool is not bounded. If all the threads are busy executing the assigned tasks and if there is a new task, then a new thread will be created and added to the pool. If a thread remains idle for close to sixty seconds, it is terminated and removed from the cache.   Use this one, if you are sure that the tasks will be short-lived, otherwise there will be a lot of threads in the pool which will lead to performance issues.   How to create a CachedThreadPoolExecutor: <pre><code>  ExecutorService executor = Executors.newCachedThreadPool ();\n</code></pre></p> </li> <li> <p>ScheduledExecutor :   Use this executor, when you want to schedule your tasks, like run them at regular intervals or run them after a given delay. There are 2 methods which are used for scheduling tasks: scheduleAtFixedRate and scheduleWithFixedDelay .   How to create ScheduledExecutor:</p> </li> </ul> <p><pre><code>  ExecutorService executor = Executors.newScheduledThreadPool (4);\n</code></pre>   ScheduledExecutorService interface extends the ExecutorService interface.   Now, apart from using Executors class to create executors, you can use ThreadPoolExecutor and ScheduledThreadPoolExecutor class also. Using these classes, you can manually configure and fine-tune various parameters of the executor according to your need. </p> <p>Let\u2019s see at some of those parameters:</p> <pre><code>  public ThreadPoolExecutor(int corePoolSize,\n        int maximumPoolSize,\n        long keepAliveTime,\n        TimeUnit unit,\n        BlockingQueue&lt;Runnable&gt; workQueue,\n        ThreadFactory threadFactory,\n        RejectedExecutionHandler handler)\n</code></pre> <p>Core and Max Pool sizes:</p> <p>A ThreadPoolExecutor will automatically adjust the pool size according to the bounds set by corePoolSize and maximumPoolSize</p> <p>When a new task is submitted to the executor then:</p> <ul> <li>If the number of threads running are less than the corePoolSize, a new thread is created to handle the request</li> <li>If the number of threads running are more than corePoolSize but less than maximumPoolSize then a new thread will be created only if the queue is full</li> </ul> <p>Let\u2019s understand this with an example:</p> <p>You have defined the core pool size as 5, maximum pool size as 10 and the queue capacity as 100. Now as tasks are coming in, new threads will be created up to 5, then other new tasks will be added to queue until it reaches 100. Now when the queue is full and if new tasks are coming in, threads will be created up to the maximumPoolSize i.e. 10. Once all the threads are in use and the queue is also full, the new tasks will be rejected. As the queue reduces, so does the number of active threads.</p> <p>Keep Alive Time and TimeUnit:</p> <p>When the number of threads are greater than the core size, this is the maximum time that excess idle threads will wait for new tasks before terminating. It is used to avoid the overhead of creating a new thread.</p> <p>Let\u2019s understand this with an example:</p> <p>You have defined the core pool size as 5 and maximum pool size as 15 and all the 15 threads are getting used at the moment. </p> <p>Now when the threads are getting finished with their work, the excess 10 threads (15-5) become idle and eventually die. To avoid these 10 threads being killed too quickly, we can specify the keep alive time for these by using the keepAliveTime parameter in the ThreadPoolExecutor constructor. If you have given its value as 1 and time unit as TimeUnit.MINUTE, each thread will wait for 1 min after it had finished executing a task. Basically, it is waiting for a new task to be assigned. If it is not given any task, it would let itself complete. And in the end, the executor will be left with the core threads (5).</p> <ul> <li>BlockingQueue :   The queue to use for holding tasks before they are executed. This queue will hold only the Runnable tasks submitted by the execute method, you can use a ArrayBlockingQueue or LinkedBlockingQueue like:</li> </ul> <pre><code>BlockingQueue&lt;Runnable&gt; queue = new ArrayBlockingQueue&lt;&gt;(100);\n</code></pre> <ul> <li> <p>ThreadFactory :   The factory to use when the executor creates a new thread. Using thread factories removes hardwiring of calls to new Thread , enabling applications to use special thread subclasses, priorities, etc.</p> </li> <li> <p>RejectedExecutionHandler : </p> </li> </ul> <p>This handler is used when a task is rejected by the executor because all the threads are busy and the queue is full.</p> <p>When this handler is not provided and the task submitted to execute() method is rejected, then an unchecked RejectedExecutionException is thrown. But adding a handler is a good practice to follow, there is a method:</p> <pre><code>void rejectedExecution(Runnable r , ThreadPoolExecutor executor );\n</code></pre> <p>This method will be invoked by ThreadPoolExecutor when execute() cannot accept a task. Putting it all together:</p> <pre><code>BlockingQueue&lt;Runnable&gt; blockingQueue = new ArrayBlockingQueue&lt;Runnable&gt;(50);\n        CustomThreadPoolExecutor executor = new CustomThreadPoolExecutor(5,15, 5000, TimeUnit.MILLISECONDS, blockingQueue);\n        executor.setRejectedExecutionHandler(new RejectedExecutionHandler() {\n            @Override\n            public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {\n                System.out.println(\"Waiting for a second !!\");\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                executor.execute(r);\n            }\n        });\n</code></pre>"},{"location":"java/multi-threading/#completablefuture","title":"CompletableFuture","text":"<p>CompletableFuture is used for asynchronous computation, where the code is executed as a non-blocking call in a separate thread and the result is made available when it is ready.</p> <p>Signature</p> <pre><code>public class CompletableFuture&lt;T&gt; extends Object implements Future&lt;T&gt;, CompletionStage&lt;T&gt;\n</code></pre> <p>CompletableFuture implements Future and CompletionStage interfaces and provides a huge set of convenience methods for creating, chaining and combining multiple Futures. It also has a very comprehensive exception handling support. CompletableFuture overcomes below limitations of Future:</p> <p>Future which was added in Java 5 also represents the result of an asynchronous computation. Problem with Future in Java is that the API is not that extensive you can just check whether the task is completed or cancelled using isDone() and isCancelled() method. For getting the result there is get() method which is blocking or you have an option for timed wait. There is also no provision for a callback method which can be called once the task completes.</p> <p>CompletableFuture class in Java which implements Future interface and CompletionStage interface tries to address these issues. This class provides methods like runAsync() and supplyAsync() that run a task asynchronously. But the biggest advantage of CompletableFuture class in Java is its ability to run a task as a series of stages (behavior this class gets from implementing CompletionStage) where each stage runs as a possible asynchronous computation, that performs an action or computes a value when another CompletionStage completes.</p> <p>Using CompletionStages you can create a single CompletableFuture as a chain of stages of CompletionStage where each stage runs when another CompletionStage completes.</p> <p>CompletableFuture overcomes below limitations of Future:</p> <ul> <li>Futures can not be explicitly completed even when it has encountered an exception scenario.</li> <li>Future provides a get() method which blocks until the result is available. further action can not be performed on a Future\u2019s result without blocking the primary application thread.</li> <li>Asynchronous workflows can not be created by chaining multiple Futures together.</li> <li>Futures which are running in parallel, can not be combined together.</li> <li>Future API does not have any exception handling construct.</li> </ul>"},{"location":"java/multi-threading/#java-completablefuture-api","title":"Java CompletableFuture API","text":"<p>In CompletableFuture API most of the methods have three variants where one of them is blocking and two are asynchronous (methods suffixed with Async). Choose the method as per your requirement.</p> <ol> <li>thenApply(Function&lt;? super T,? extends U&gt; fn)- Returns a new CompletionStage that, when this stage completes normally, is executed with this stage's result as the argument to the supplied function.</li> <li>thenApplyAsync(Function&lt;? super T,? extends U&gt; fn)- Returns a new CompletionStage that, when this stage completes normally, is executed using this stage's default asynchronous execution facility, with this stage's result as the argument to the supplied function. Default asynchronous execution generally is a task running in the ForkJoinPool.commonPool()</li> <li>thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor)- Returns a new CompletionStage that, when this stage completes normally, is executed using the supplied Executor, with this stage's result as the argument to the supplied function.</li> </ol>"},{"location":"java/multi-threading/#java-completablefuture-constructor","title":"Java CompletableFuture constructor","text":"<p>In CompletableFuture class there is one constructor.</p> <p>CompletableFuture()- Creates a new incomplete CompletableFuture.</p> <p>As you can see the description says incomplete CompletableFuture, so creating a CompletableFuture using this constructor and trying to get its value using get() method will block forever as the get() method waits for this future to complete and then returns its result.</p> <pre><code>CompletableFuture&lt;String&gt; cf = new CompletableFuture&lt;&gt;();\nString value = cf.get();\n</code></pre> <p>You will have to transition this CompletableFuture to a completed state using complete() method.</p> <pre><code>CompletableFuture&lt;String&gt; cf = new CompletableFuture&lt;&gt;();\ncf.complete(\"Hello\");\nString value = cf.get();\nSystem.out.println(\"Value- \" + value);\n</code></pre>"},{"location":"java/multi-threading/#completablefuture-examples","title":"CompletableFuture  examples","text":"<ol> <li>Let\u2019s start with a simple example where a new CompletableFuture is returned that is already completed with the given value.</li> </ol> <pre><code>String str = \"Hello\";\nCompletableFuture&lt;String&gt; cf = CompletableFuture.completedFuture(str);\nif(cf.isDone()) {\n  System.out.println(\"Value- \" + cf.get());\n}\n</code></pre> <p>Output</p> <p>Value- Hello</p> <ol> <li>Running an asynchronous task using runAsync(Runnable runnable) method. This method returns a CompletableFuture. <pre><code>CompletableFuture&lt;Void&gt; cf = CompletableFuture.runAsync(()-&gt;{\n  System.out.println(\"Task executing asynchronously\");\n});\n\nSystem.out.println(\"Value- \" + cf.get());\n</code></pre> <p>Output</p> <p>Task executing asynchronously Value- null</p> <ol> <li>runAsync() is fine for running asynchronous computations but it doesn't return value. If you want to return a new CompletableFuture with a value then you can use supplyAsync(Supplier supplier) method. Here U is the type of value obtained by calling the given Supplier. <p><pre><code>CompletableFuture cf = CompletableFuture.supplyAsync(()-&gt;{\n return \"Hello\";\n});\nSystem.out.println(\"Value- \" + cf.get());\n</code></pre> Output</p> <p>Value- Hello</p> <ol> <li>Let\u2019s add a new stage to create a chain.</li> </ol> <pre><code>CompletableFuture&lt;String&gt; cf = CompletableFuture.supplyAsync(()-&gt;{\n    return \"Hello\";\n}).thenApply(value-&gt; value.toUpperCase());\n\nSystem.out.println(\"Value- \" + cf.get());\n</code></pre> <p>Output</p> <p>Value- HELLO</p> <p>Here thenApply(Function&lt;? super T,? extends U&gt; fn) method is used. The current stage (thenApply() method) is executed with previous stage's result as the argument to the supplied function and it returns a new CompletionStage.</p> <ol> <li>Using the Async variant of the method where an Executor is passed. Note that with the Async variant, method is asynchronously executed in a separate thread obtained from the Executor or from the ForkJoinPool.commonPool() based on the Async variant used.</li> </ol> <pre><code>ExecutorService executor = Executors.newFixedThreadPool(2);\nCompletableFuture&lt;String&gt; cf = CompletableFuture.supplyAsync(()-&gt;{\n    return \"Hello\";\n}).thenApplyAsync(value-&gt; value.toUpperCase(), executor);\n\nSystem.out.println(\"Value- \" + cf.get());\nexecutor.shutdown();\n</code></pre> <ol> <li>Using thenAccept() method if there is no value to return from the stage. There is also thenRun() method which doesn\u2019t return value and takes Runnable as argument.</li> </ol> <pre><code>CompletableFuture.supplyAsync(()-&gt;{\n  return \"Hello\";\n}).thenAccept(value-&gt; {\n  System.out.println(\"Value- \" + value);\n});\n</code></pre>"},{"location":"java/multi-threading/#difference-between-thenapply-and-thencompose-methods","title":"Difference between thenApply() and thenCompose() methods","text":"<p>In the Java CompletableFuture class there are two methods thenApply() and thenCompose() with a very little difference and it often confuses people.</p> <p>thenApply()- Returns a new CompletionStage where the type of the result is based on the argument to the supplied function of thenApply() method.</p> <p>thenCompose()- Returns a new CompletionStage where the type of the result is same as the type of the previous stage.</p> <p>For getting the difference between thenApply() and thenCompose() methods consider the following code.</p> <pre><code>CompletableFuture&lt;CompletableFuture&lt;String&gt;&gt; cf = CompletableFuture.supplyAsync(()-&gt;{\n  return \"Hello\";\n}).thenApply(value-&gt; {\n  String str = value.toUpperCase();\n  return CompletableFuture.completedFuture(str);\n});\nSystem.out.println(\"Value- \" + cf.get().get());\n</code></pre> <p>If you see here value returned by the CompletableFuture.supplyAsync method is of type CompletableFuture and taking that as argument in thenApply there is another CompletableFuture returned which makes the return value as the nested layer of CompletableFuture (CompletableFuture&gt;). The structure is not flattened. <p>Now consider the same code with thenCompose() method.</p> <pre><code>CompletableFuture&lt;String&gt; cf = CompletableFuture.supplyAsync(()-&gt;{\n  return \"Hello\";\n}).thenCompose(value-&gt; {\n  String str = value.toUpperCase();\n  return CompletableFuture.completedFuture(str);\n});\nSystem.out.println(\"Value- \" + cf.get());\n</code></pre> <p>As you can see here the structure is flattened because thenCompose() returns a result having the type same as previous stage.</p>"},{"location":"java/multi-threading/#combining-two-independent-completablefutures","title":"Combining two independent CompletableFutures","text":"<p>There is a thenCombine() method that can be used if you want to combine two independent CompletableFutures in a way that when both of the CompletableFutures finish, you want to execute some logic with the results of both.</p> <p>thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)- Returns a new CompletionStage that, when this and the other given stage both complete normally, is executed with the two results as arguments to the supplied function.</p> <pre><code>CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(() -&gt; {\n  return \"Combining two CompletableFutures\";\n});\n\nCompletableFuture&lt;String&gt; future2 = CompletableFuture.supplyAsync(() -&gt; {\n  return \"and getting a new CompletableFuture\";\n});\n\nCompletableFuture&lt;String&gt; result = future1.thenCombine(future2, (str1, str2) -&gt; str1 + \" \" + str2);\nSystem.out.println(\"Value- \" + result.get());\n</code></pre> <p>Output</p> <p>Value- Combining two CompletableFutures and getting a new CompletableFuture</p>"},{"location":"java/multi-threading/#another-example","title":"Another example","text":"<p>In the example first method fetches the list of users, in the second method user names are changed to upper case. modified list is then returned.</p> <pre><code>public class CFDemo {\n  public static void main(String[] args) {    \n    CFDemo cfDemo = new CFDemo();    \n    try {\n      // blocking call\n      cfDemo.getUsers();\n    } catch (ExecutionException | InterruptedException e) {\n      // TODO Auto-generated catch block\n      e.printStackTrace();\n    }\n  }\n\n  public void getUsers() throws ExecutionException, InterruptedException{\n    CompletableFuture&lt;List&lt;User&gt;&gt; userList = CompletableFuture.supplyAsync(() -&gt; {\n      return getListOfUsers();\n    }).thenCompose(users-&gt; {            \n      List&lt;User&gt; upperCaseList = null;\n      try {\n        upperCaseList = users.get().stream().map(\n                      user-&gt;{\n                          user.setFirstName(user.getFirstName().toUpperCase());\n                          user.setLastName(user.getLastName().toUpperCase());\n                          return user;\n                      }).collect(Collectors.toList());\n      } catch (InterruptedException | ExecutionException e) {\n        // TODO Auto-generated catch block\n        e.printStackTrace();\n      }\n      return CompletableFuture.completedFuture(upperCaseList);\n    });\n\n    userList.get().forEach(System.out::println);\n  }\n\n  // Dummy method for adding List of Users\n  private CompletableFuture&lt;List&lt;User&gt;&gt; getListOfUsers() {\n    List&lt;User&gt; users = new ArrayList&lt;User&gt;();\n    users.add(new User(\"Jack\", \"Reacher\", \"abc@xyz.com\"));    \n    users.add(new User(\"Remington\", \"Steele\", \"rs@cbd.com\"));\n    users.add(new User(\"Laura\", \"Holt\", \"lh@cbd.com\"));\n    users.add(new User(\"Jonathan\", \"Raven\", \"jr@sn.com\"));\n    users.add(new User(\"Tom\", \"Hanson\", \"th@jd.com\"));\n    users.add(new User(\"Alexander\", \"Scott\", \"as@is.com\"));\n    users.add(new User(\"Jim\", \"Phelps\", \"jp@mi.com\"));\n    return CompletableFuture.completedFuture(users);\n  }\n}\n</code></pre> <p>Output</p> <p>JACK REACHER abc@xyz.com REMINGTON STEELE rs@cbd.com LAURA HOLT lh@cbd.com JONATHAN RAVEN jr@sn.com TOM HANSON th@jd.com ALEXANDER SCOTT as@is.com JIM PHELPS jp@mi.com</p>"},{"location":"java/multi-threading/#exception-handling-with-completablefuture","title":"Exception handling with CompletableFuture","text":"<p>If an exception is thrown at any of the stage with in the chain of CompletionStages the execution stops with in that stage and exception is thrown. For exception handling with CompletableFuture there are three methods handle, whenComplete and exceptionally.</p> <p>Out of these three, two methods handle and whenComplete are executed regardless of exception thrown or not. Exception is passed as an argument is these methods which will not be null in case exception is thrown. Using that null check you can write your exception handling code.</p> <p>Exceptionally supports computation only when the triggering stage throws an exception. This method also gives a chance to return a replacement result in case of exception.</p> <pre><code>String str = null;\nCompletableFuture&lt;String&gt; value = CompletableFuture.supplyAsync(() -&gt; {\n  if (str == null)\n    throw new IllegalArgumentException(\"Invalid String value passed \" + str);\n  return str;\n}).exceptionally(exp -&gt; {\n  System.out.println(\"Exception thrown with message - \" + exp.getMessage());\n  return \"\";\n});\n</code></pre> <p>Output</p> <p>Exception thrown with message - java.lang.IllegalArgumentException: Invalid String value passed null Value-</p> <p>When string is not null, exception is not thrown so exceptionally() won\u2019t be called.</p> <pre><code>String str = \"Hello\";\nCompletableFuture&lt;String&gt; value = CompletableFuture.supplyAsync(() -&gt; {\n  if (str == null)\n    throw new IllegalArgumentException(\"Invalid String value passed \" + str);\n  return str;\n}).exceptionally(exp -&gt; {\n  System.out.println(\"Exception thrown with message - \" + exp.getMessage());\n  return \"\";\n});\n</code></pre> <p>Output <pre><code>Value- Hello\n</code></pre></p>"},{"location":"java/multi-threading/#completablefuture-exception-handling-with-handle-example","title":"CompletableFuture exception handling with handle example","text":"<pre><code>String str = null;\nCompletableFuture&lt;String&gt; value = CompletableFuture.supplyAsync(() -&gt; {\n  if (str == null)\n    throw new IllegalArgumentException(\"Invalid String value passed \" + str);\n  return str;\n}).handle((s, exp) -&gt; {\n  if(exp != null) {\n    System.out.println(\"Exception thrown with message - \" + exp.getMessage());\n    s = \"\";\n  }\n  return s;\n});\n</code></pre> <p>Output</p> <pre><code>Exception thrown with message - java.lang.IllegalArgumentException: Invalid String value passed null\nValue-\n</code></pre> <p>When string is not null exception is not thrown but handle method still gets called.</p> <pre><code>String str = \"Hello\";\nCompletableFuture&lt;String&gt; value = CompletableFuture.supplyAsync(() -&gt; {\n  if (str == null)\n    throw new IllegalArgumentException(\"Invalid String value passed \" + str);\n  return str;\n}).handle((s, exp) -&gt; {\n  System.out.println(\"In handle method..\");\n  if(exp != null) {\n    System.out.println(\"Exception thrown with message - \" + exp.getMessage());\n    s = \"\";\n  }\n  return s;\n});\nSystem.out.println(\"Value- \" + value.get());\n</code></pre> <p>Output <pre><code>In handle method..\nValue- Hello\n</code></pre></p>"},{"location":"java/multi-threading/#completablefuture-exception-handling-with-whencomplete-example","title":"CompletableFuture exception handling with whenComplete example","text":"<p>Method whenComplete preserves the result of the triggering stage instead of computing a new one.</p> <p><pre><code>String str = null;\nCompletableFuture&lt;String&gt; value = CompletableFuture.supplyAsync(() -&gt; {\n  if (str == null)\n    throw new IllegalArgumentException(\"Invalid String value passed \" + str);\n  return str;\n}).whenComplete((s, exp) -&gt; {\n  System.out.println(\"in whenComplete method\");\n  if(exp != null) {\n    System.out.println(\"Exception thrown with message - \" + exp.getMessage());\n    //s = \"\";\n  }\n});\n</code></pre> Output</p> <pre><code>in whenComplete methodException in thread \"main\"\nException thrown with message - java.lang.IllegalArgumentException: Invalid String value passed null\njava.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Invalid String value passed null\nat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)\nat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)\nat org.nets.program.CFDemo.main(CFDemo.java:27)\nCaused by: java.lang.IllegalArgumentException: Invalid String value passed null\nat org.nets.program.CFDemo.lambda$0(CFDemo.java:18)\nat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)\nat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1692)\nat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\nat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1603)\nat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:177)\n</code></pre>"},{"location":"java/multi-threading/#for-more-information","title":"For more information","text":"<ol> <li>How to join two threads in Java? Thread.join()</li> <li>Multithreading Interview Questions and Answers</li> <li>ExecutorService Interface Overview</li> <li>Guide To CompletableFuture</li> <li>CompletableFuture in Java With Examples-netjstech.com</li> <li>Class CompletableFuture</li> </ol>"},{"location":"microservices/","title":"Microservices","text":""},{"location":"microservices/#microservices_1","title":"Microservices","text":"<p>Microservices are a software architectural style where an application is divided into small, independent services that can be developed, deployed, and scaled individually. In contrast, monolithic architectures consist of a single, tightly-coupled codebase where all functionality is part of a single application.</p> <p>Microservices is an architectural approach where a complex application is broken down into a set of smaller, independent services. Each service is responsible for a specific piece of functionality and operates as a standalone unit.</p>"},{"location":"microservices/#characteristics-of-microservices","title":"Characteristics of Microservices:","text":"<ul> <li> <p>Modularity: Services are divided based on specific business capabilities or functions, making them highly modular and focused.</p> </li> <li> <p>Independence: Each service can be developed, deployed, and maintained independently, allowing for faster development cycles.</p> </li> <li> <p>Scalability: Services can be scaled individually to handle varying levels of load, improving resource utilization.</p> </li> <li> <p>Technology Diversity: Different services can use different technologies and databases, allowing teams to choose the best tools for their tasks.</p> </li> <li> <p>Resilience: Failures in one service do not necessarily impact the entire system, as other services can continue to function.</p> </li> <li> <p>Flexibility: Easier to adopt DevOps practices, continuous deployment, and automated testing.</p> </li> </ul>"},{"location":"microservices/#monolithic-architectures","title":"Monolithic Architectures","text":"<p>In a monolithic architecture, the entire application is a single, tightly-coupled codebase. All components and functionalities are part of the same application, making it challenging to scale and maintain as it grows.</p>"},{"location":"microservices/#characteristics-of-monolithic-architectures","title":"Characteristics of Monolithic Architectures:","text":"<ul> <li> <p>Single Codebase: The entire application is developed within a single codebase, leading to increased complexity as the application grows.</p> </li> <li> <p>Tight Coupling: Components are tightly integrated, making it challenging to modify or update one part without affecting others.</p> </li> <li> <p>Limited Scalability: Scaling often involves replicating the entire application, even if only a specific component requires more resources.</p> </li> <li> <p>Homogeneous Technology: Typically uses a single technology stack and database system for the entire application.</p> </li> <li> <p>Development Bottlenecks: Slower development cycles, as changes to one part of the application can impact the entire codebase.</p> </li> <li> <p>Less Resilience: A failure in one part of the application can potentially bring down the entire system.</p> </li> </ul>"},{"location":"microservices/#choosing-between-microservices-and-monolithic-architectures","title":"Choosing Between Microservices and Monolithic Architectures","text":"<p>The choice between Microservices and monolithic architectures depends on various factors, including the complexity of the application, the team's expertise, scalability requirements, and development speed. Microservices offer flexibility, scalability, and modularity but come with additional complexity in terms of orchestration and communication between services. Monolithic architectures may be simpler for smaller projects but can become unwieldy as applications grow in size and complexity. The decision should be based on the specific needs and goals of the project.</p>"},{"location":"microservices/#introduction-to-microservices","title":"Introduction to Microservices","text":"<p>Microservices and monolithic architectures are two different approaches to software development. A monolithic architecture is a traditional model of a software program, which is built as a unified unit that is self-contained and independent from other applications. In contrast, a microservices architecture is a collection of smaller, independently deployable services.</p>"},{"location":"microservices/#monolithic-architecture","title":"Monolithic Architecture","text":"<p>In a monolithic architecture, the entire application is built as a single, self-contained unit. All the components of the application are tightly coupled and share the same codebase. This makes it difficult to scale individual components of the application independently. Monolithic architectures are typically easier to develop and deploy, but they can become difficult to maintain and scale as the application grows.</p>"},{"location":"microservices/#microservices-architecture","title":"Microservices Architecture","text":"<p>In a microservices architecture, the application is broken down into smaller, independent services. Each service is responsible for a specific task or set of tasks. These services communicate with each other through APIs. This makes it easier to scale individual components of the application independently. Microservices architectures are typically more complex to develop and deploy, but they are more flexible and scalable than monolithic architectures.</p> <p>Here are some of the key differences between microservices and monolithic architectures:</p> Monolithic Architecture Microservices Architecture Built as a single, self-contained unit Built as a collection of smaller, independent services All components are tightly coupled and share the same codebase Components are loosely coupled and communicate through APIs Difficult to scale individual components independently Easy to scale individual components independently Easier to develop and deploy More complex to develop and deploy Can become difficult to maintain and scale as the application grows More flexible and scalable than monolithic architectures"},{"location":"microservices/#key-benefits-of-using-microservices","title":"Key Benefits of Using Microservices","text":"<p>Microservices offer several key benefits for software development, including improved scalability, faster development cycles, enhanced flexibility, technology diversity, resilience, and easier maintenance. These advantages make Microservices a popular architectural choice for modern applications.</p> <p>Microservices architecture offers numerous advantages for software development and deployment, making it a preferred choice for building modern, scalable applications. Here are the key benefits of using Microservices:</p>"},{"location":"microservices/#1-scalability","title":"1. Scalability:","text":"<p>Microservices allow for individual components or services to be scaled independently. This flexibility ensures that resources can be allocated precisely where needed, optimizing performance and cost efficiency.</p>"},{"location":"microservices/#2-faster-development-cycles","title":"2. Faster Development Cycles:","text":"<p>Smaller, focused teams can develop and deploy Microservices independently. This parallelization of work accelerates development cycles, enabling quicker releases and updates.</p>"},{"location":"microservices/#3-enhanced-flexibility","title":"3. Enhanced Flexibility:","text":"<p>Microservices are highly modular, allowing developers to choose the best technology stack and database for each service. This flexibility enables the use of different programming languages, frameworks, and tools within the same application.</p>"},{"location":"microservices/#4-technology-diversity","title":"4. Technology Diversity:","text":"<p>Teams can select the most suitable technologies for specific Microservices, promoting innovation and adapting to evolving industry standards.</p>"},{"location":"microservices/#5-resilience","title":"5. Resilience:","text":"<p>Failures in one Microservice do not necessarily disrupt the entire application. Isolation of services ensures that the overall system remains operational even when some services experience issues.</p>"},{"location":"microservices/#6-easier-maintenance","title":"6. Easier Maintenance:","text":"<p>Smaller, self-contained Microservices are easier to maintain and update. Changes in one service have minimal impact on others, reducing the risk of unintended consequences.</p>"},{"location":"microservices/#7-scalable-teams","title":"7. Scalable Teams:","text":"<p>Microservices facilitate the division of larger development teams into smaller, autonomous groups. Each team can own and maintain a specific Microservice, leading to improved accountability and efficiency.</p>"},{"location":"microservices/#8-improved-fault-isolation","title":"8. Improved Fault Isolation:","text":"<p>Problems in one Microservice can be isolated and addressed without affecting the entire application, resulting in faster problem resolution.</p>"},{"location":"microservices/#9-elasticity","title":"9. Elasticity:","text":"<p>Microservices architecture aligns well with cloud-based deployment, allowing applications to take advantage of cloud resources and autoscaling capabilities.</p>"},{"location":"microservices/#10-devops-enablement","title":"10. DevOps Enablement:","text":"<p>Microservices encourage the adoption of DevOps practices, such as continuous integration, continuous deployment, and automated testing, enhancing collaboration between development and operations teams.</p>"},{"location":"microservices/#11-agility","title":"11. Agility:","text":"<p>Microservices enable organizations to respond quickly to changing market demands and customer requirements. New features can be developed, tested, and deployed independently.</p>"},{"location":"microservices/#12-cost-efficiency","title":"12. Cost Efficiency:","text":"<p>By optimizing resource usage through independent scaling, Microservices can lead to cost savings, particularly in cloud-based environments.</p>"},{"location":"microservices/#13-competitive-advantage","title":"13. Competitive Advantage:","text":"<p>Organizations that embrace Microservices can deliver innovative and responsive applications, gaining a competitive edge in the market.</p>"},{"location":"microservices/#14-polyglot-persistence","title":"14. Polyglot Persistence:","text":"<p>Microservices allow for the use of different databases, including NoSQL and relational databases, based on the specific requirements of each service.</p>"},{"location":"microservices/#15-micro-frontends-integration","title":"15. Micro Frontends Integration:","text":"<p>Micro Frontends, a complement to Microservices, enable the development of modular and independently deployable user interfaces, further enhancing application flexibility and maintainability.</p> <p>In summary, Microservices architecture offers a range of benefits that align with the demands of modern software development. These advantages include improved scalability, faster development cycles, enhanced flexibility, technology diversity, resilience, easier maintenance, and many others, making it a compelling choice for building scalable and agile applications.</p>"},{"location":"microservices/#challenges-and-drawbacks-of-microservices","title":"Challenges and Drawbacks of Microservices","text":"<p>While Microservices offer many advantages, they also come with challenges and drawbacks. Common issues include increased complexity in communication, potential data consistency problems, operational challenges, and the need for robust monitoring and testing strategies. It's essential to carefully consider these challenges when adopting Microservices.</p> <p>Microservices architecture offers numerous benefits, but it also presents several challenges and drawbacks that organizations must address:</p>"},{"location":"microservices/#1-increased-complexity-in-communication","title":"1. Increased Complexity in Communication:","text":"<ul> <li>Microservices rely on network communication for inter-service interactions, which can introduce latency and complexity. Developers must implement effective communication patterns, such as REST, gRPC, or message queues, and handle potential issues like network failures and service discovery.</li> </ul>"},{"location":"microservices/#2-data-consistency","title":"2. Data Consistency:","text":"<ul> <li>Maintaining data consistency across multiple Microservices can be challenging. Distributed transactions are complex to implement, and eventual consistency models may lead to data synchronization issues. Organizations must carefully design data management strategies.</li> </ul>"},{"location":"microservices/#3-operational-challenges","title":"3. Operational Challenges:","text":"<ul> <li>Microservices require robust operational practices. Organizations need to manage a larger number of services, potentially leading to increased operational overhead. Challenges include deployment automation, monitoring, and handling service failures.</li> </ul>"},{"location":"microservices/#4-service-discovery-and-load-balancing","title":"4. Service Discovery and Load Balancing:","text":"<ul> <li>Service discovery mechanisms are essential for locating and connecting to Microservices. Load balancing and routing traffic to healthy services can become complex, requiring the use of tools like service registries and API gateways.</li> </ul>"},{"location":"microservices/#5-testing-complexity","title":"5. Testing Complexity:","text":"<ul> <li>Testing Microservices poses challenges, as each service may have its own dependencies and dependencies on other services. Testing in isolation and ensuring end-to-end testing across services is critical for maintaining application reliability.</li> </ul>"},{"location":"microservices/#6-security-concerns","title":"6. Security Concerns:","text":"<ul> <li>Microservices introduce new security challenges, such as managing access control, authentication, and authorization across distributed services. Securing communication between services and protecting sensitive data are crucial considerations.</li> </ul>"},{"location":"microservices/#7-monitoring-and-debugging","title":"7. Monitoring and Debugging:","text":"<ul> <li>Microservices require robust monitoring and logging strategies. Debugging distributed systems can be challenging, as issues may span multiple services. Organizations must invest in tools and practices for effective monitoring and debugging.</li> </ul>"},{"location":"microservices/#8-resource-overhead","title":"8. Resource Overhead:","text":"<ul> <li>While Microservices offer resource scalability, they can also introduce overhead in terms of increased memory and CPU usage. Proper resource allocation and management are essential to optimize costs.</li> </ul>"},{"location":"microservices/#9-development-and-deployment-complexity","title":"9. Development and Deployment Complexity:","text":"<ul> <li>Coordinating the development, testing, and deployment of numerous Microservices can be complex. Continuous integration and continuous deployment (CI/CD) pipelines must be well-orchestrated.</li> </ul>"},{"location":"microservices/#10-team-coordination","title":"10. Team Coordination:","text":"<ul> <li>Microservices often lead to smaller, cross-functional teams owning individual services. Ensuring effective communication and coordination among these teams is essential to avoid service silos and maintain a cohesive architecture.</li> </ul>"},{"location":"microservices/#11-migration-challenges","title":"11. Migration Challenges:","text":"<ul> <li>Migrating from a monolithic architecture to Microservices can be a significant undertaking, involving code refactoring, data migration, and adapting existing processes. Organizations must plan migration strategies carefully.</li> </ul>"},{"location":"microservices/#12-costs-and-licensing","title":"12. Costs and Licensing:","text":"<ul> <li>Managing a larger number of services can incur additional costs for hosting, infrastructure, and licensing. Organizations should evaluate the financial implications of Microservices.</li> </ul>"},{"location":"microservices/#13-cultural-shift","title":"13. Cultural Shift:","text":"<ul> <li>Embracing Microservices often requires a cultural shift within an organization. Teams need to adopt new practices, including DevOps and agile methodologies, to fully realize the benefits of Microservices.</li> </ul>"},{"location":"microservices/#14-documentation-and-communication","title":"14. Documentation and Communication:","text":"<ul> <li>Maintaining up-to-date documentation for each Microservice and ensuring clear communication about service interfaces and contracts are critical to avoid misunderstandings and integration issues.</li> </ul> <p>In conclusion, while Microservices offer numerous advantages, they are not without challenges and drawbacks. Organizations must carefully plan and address these challenges to successfully adopt Microservices architecture and realize its benefits. Proper design, testing, monitoring, and a robust DevOps culture are key to mitigating these challenges.</p>"},{"location":"microservices/#microservices-communication-synchronous-vs-asynchronous","title":"Microservices Communication: Synchronous vs. Asynchronous","text":"<p>Microservices communicate with each other through various mechanisms, primarily synchronous and asynchronous communication. Synchronous communication involves direct, immediate requests and responses, while asynchronous communication relies on message-based systems, enabling decoupled interactions. The choice between these methods depends on factors like latency tolerance, scalability, and system complexity.</p> <p>Microservices architecture relies on effective communication between individual services to achieve complex functionality. Two primary communication paradigms are synchronous and asynchronous.</p>"},{"location":"microservices/#synchronous-communication","title":"Synchronous Communication:","text":"<ul> <li> <p>Definition: In synchronous communication, one Microservice makes a direct request to another Microservice and waits for an immediate response. This is often done via HTTP/HTTPS requests using RESTful APIs or gRPC.</p> </li> <li> <p>Pros:</p> <ul> <li>Simplicity: Synchronous communication is straightforward to implement and understand.</li> <li>Real-time: Well-suited for scenarios requiring real-time responses.</li> <li>Debugging: Easier to trace and debug as the request and response are correlated.</li> </ul> </li> <li> <p>Cons:</p> <ul> <li>Latency: The caller service must wait for the response, which can introduce latency, especially if the called service is slow.</li> <li>Tight Coupling: Synchronous calls can lead to tight coupling between services, making it harder to evolve and scale them independently.</li> <li>Blocking: Synchronous calls block the caller until the response is received, potentially impacting overall system responsiveness.</li> </ul> </li> <li> <p>Use Cases:</p> <ul> <li>Synchronous communication is suitable for simple, immediate interactions where low latency is acceptable. Examples include fetching reference data or simple data queries.</li> </ul> </li> </ul>"},{"location":"microservices/#asynchronous-communication","title":"Asynchronous Communication:","text":"<ul> <li> <p>Definition: In asynchronous communication, Microservices communicate via messages. One service sends a message to a message broker, and other services consume and act upon these messages at their own pace. Popular message brokers include Apache Kafka, RabbitMQ, and Amazon SQS.</p> </li> <li> <p>Pros:</p> <ul> <li>Decoupling: Asynchronous communication decouples services, allowing them to operate independently. Services do not need to know about each other.</li> <li>Scalability: Easier to scale services as they are not directly dependent on each other.</li> <li>Fault Tolerance: Messages can be retried or persisted, ensuring reliable communication even if a service is temporarily unavailable.</li> <li>Load Leveling: Helps distribute the load by allowing services to process messages at their own rate.</li> </ul> </li> <li> <p>Cons:</p> <ul> <li>Complexity: Implementing asynchronous communication can be more complex due to the need for message brokers and handling message processing errors.</li> <li>Eventual Consistency: Asynchronous systems may introduce eventual consistency, where data may not be immediately up-to-date across all services.</li> <li>Debugging: Debugging asynchronous systems can be challenging, as tracing the flow of messages may require additional tooling.</li> </ul> </li> <li> <p>Use Cases:</p> <ul> <li>Asynchronous communication is suitable for scenarios where low latency is not critical, and services can process messages at their own pace. Examples include event-driven architectures, distributed processing, and long-running tasks.</li> </ul> </li> </ul>"},{"location":"microservices/#choosing-the-right-communication-method","title":"Choosing the Right Communication Method:","text":"<p>The choice between synchronous and asynchronous communication depends on factors such as latency tolerance, system complexity, scalability requirements, and use case-specific needs. Many Microservices architectures combine both communication paradigms, leveraging the strengths of each to build flexible and responsive systems.</p>"},{"location":"microservices/#microservices-design-patterns","title":"Microservices Design Patterns","text":"<p>Microservices design patterns are architectural blueprints that provide solutions to common challenges faced when developing Microservices-based applications. These patterns help in achieving scalability, resilience, and maintainability. Here, we'll explore some essential Microservices design patterns with examples in Java.</p> <p>Microservices architecture introduces various challenges, such as service communication, data management, and fault tolerance. To address these challenges, developers can use Microservices design patterns. Let's explore some essential patterns with Java examples:</p>"},{"location":"microservices/#1-service-registry-and-discovery-eureka","title":"1. Service Registry and Discovery (Eureka)","text":"<ul> <li> <p>Pattern Overview: Microservices often need to locate and communicate with other services. The Service Registry and Discovery pattern, implemented using tools like Netflix Eureka, allows services to register themselves and discover others dynamically.</p> </li> <li> <p>Java Example: Using Spring Cloud Netflix Eureka for service registration and discovery:</p> </li> </ul> <pre><code>// Service registration in application.properties\nspring.application.name=my-service\neureka.client.serviceUrl.defaultZone=http://eureka-server:8761/eureka/\n</code></pre>"},{"location":"microservices/#2-api-gateway-spring-cloud-gateway","title":"2. API Gateway (Spring Cloud Gateway)","text":"<ul> <li> <p>Pattern Overview: An API Gateway acts as an entry point for clients and manages requests by routing them to the appropriate Microservices. It can handle authentication, load balancing, and caching.</p> </li> <li> <p>Java Example: Using Spring Cloud Gateway to create an API Gateway:</p> </li> </ul> <pre><code>@Bean\npublic RouteLocator customRouteLocator(RouteLocatorBuilder builder) {\n    return builder.routes()\n        .route(\"service-route\", r -&gt; r.path(\"/service/**\")\n            .uri(\"lb://service-instance\"))\n        .build();\n}\n</code></pre>"},{"location":"microservices/#3-circuit-breaker-hystrix","title":"3. Circuit Breaker (Hystrix)","text":"<ul> <li> <p>Pattern Overview: The Circuit Breaker pattern, implemented with libraries like Netflix Hystrix, prevents a service from repeatedly calling a failing service. It provides fallback mechanisms and helps maintain system stability.</p> </li> <li> <p>Java Example: Configuring a Hystrix command with fallback:</p> </li> </ul> <pre><code>@HystrixCommand(fallbackMethod = \"fallbackMethod\")\npublic String callService() {\n    // Call a remote service\n}\n\npublic String fallbackMethod() {\n    // Fallback logic when the service is unavailable\n}\n</code></pre>"},{"location":"microservices/#4-saga-pattern","title":"4. Saga Pattern","text":"<ul> <li> <p>Pattern Overview: The Saga pattern manages distributed transactions in Microservices by breaking them into smaller, independent steps. Each step is a separate service operation, allowing for compensation in case of failures.</p> </li> <li> <p>Java Example: Implementing a saga with Spring's @SagaEventHandler annotation:</p> </li> </ul> <pre><code>@Saga\n@Component\npublic class OrderSaga {\n\n    @Autowired\n    private OrderService orderService;\n\n    @StartSaga\n    @SagaEventHandler(associationProperty = \"orderId\")\n    public void handle(OrderCreatedEvent event) {\n        // Create order and other steps\n    }\n\n    @EndSaga\n    @SagaEventHandler(associationProperty = \"orderId\")\n    public void handle(OrderCompletedEvent event) {\n        // Handle order completion\n    }\n}\n</code></pre>"},{"location":"microservices/#5-event-sourcing-and-cqrs","title":"5. Event Sourcing and CQRS","text":"<ul> <li> <p>Pattern Overview: Event Sourcing involves storing all changes to an application's state as a sequence of immutable events. Command Query Responsibility Segregation (CQRS) separates the command (write) and query (read) sides of the application.</p> </li> <li> <p>Java Example: Using Axon Framework for Event Sourcing and CQRS:</p> </li> </ul> <pre><code>// Define an event\npublic class OrderCreatedEvent {\n    // Event details\n}\n\n// Create an Aggregate\n@Aggregate\npublic class OrderAggregate {\n\n    @AggregateIdentifier\n    private String orderId;\n\n    @CommandHandler\n    public OrderAggregate(CreateOrderCommand command) {\n        // Apply events\n    }\n\n    @EventSourcingHandler\n    public void on(OrderCreatedEvent event) {\n        // Handle the event\n    }\n}\n</code></pre>"},{"location":"microservices/#6-bulkhead-pattern","title":"6. Bulkhead Pattern","text":"<ul> <li> <p>Pattern Overview: The Bulkhead pattern prevents the failure of one component from causing the failure of other components. It isolates services into separate pools or threads, ensuring that issues in one component do not affect others.</p> </li> <li> <p>Java Example: Using Hystrix thread pools to implement bulkheads:</p> </li> </ul> <pre><code>@HystrixCommand(fallbackMethod = \"fallbackMethod\", threadPoolKey = \"exampleThreadPool\")\npublic String callService() {\n    // Execute in a separate thread pool\n}\n\npublic String fallbackMethod() {\n    // Fallback logic when the service is unavailable\n}\n</code></pre>"},{"location":"microservices/#7-database-per-service","title":"7. Database per Service","text":"<ul> <li> <p>Pattern Overview: In the Database per Service pattern, each Microservice has its own database, ensuring that services are loosely coupled from a data perspective. This pattern can improve data isolation and scalability.</p> </li> <li> <p>Java Example: Using Spring Data JPA to define service-specific data repositories:</p> </li> </ul> <pre><code>@Entity\npublic class Customer {\n    // Entity details\n}\n\n@Repository\npublic interface CustomerRepository extends JpaRepository&lt;Customer, Long&gt; {\n    // Custom queries for the customer service\n}\n</code></pre>"},{"location":"microservices/#8-aggregator-pattern","title":"8. Aggregator Pattern","text":"<ul> <li> <p>Pattern Overview: The Aggregator pattern combines data from multiple Microservices into a single response, reducing the number of client requests. It is useful when clients require data from various services in a single request.</p> </li> <li> <p>Java Example: Implementing an aggregation service using Spring:</p> </li> </ul> <pre><code>@RestController\npublic class AggregatorController {\n\n    @Autowired\n    private ServiceClient serviceClient;\n\n    @GetMapping(\"/aggregate\")\n    public AggregateResponse aggregateData() {\n        // Call multiple services and combine responses\n    }\n}\n</code></pre>"},{"location":"microservices/#9-saga-orchestrator","title":"9. Saga Orchestrator","text":"<ul> <li> <p>Pattern Overview: The Saga Orchestrator pattern coordinates the execution of a saga by controlling the order and timing of saga steps. It ensures that steps are executed in the correct sequence.</p> </li> <li> <p>Java Example: Implementing a saga orchestrator using a state machine framework like Spring State Machine:</p> </li> </ul> <pre><code>@Configuration\n@EnableStateMachineFactory\npublic class OrderSagaConfig extends StateMachineConfigurerAdapter&lt;String, String&gt; {\n\n    @Override\n    public void configure(StateMachineConfigurationConfigurer&lt;String, String&gt; config) throws Exception {\n        config.withConfiguration().autoStartup(true);\n    }\n\n    // Define states, transitions, and event handlers\n}\n</code></pre>"},{"location":"microservices/#10-retry-pattern","title":"10. Retry Pattern","text":"<ul> <li> <p>Pattern Overview: The Retry pattern is used to handle transient failures in Microservices communication. It involves automatically retrying an operation when it initially fails, helping to ensure that intermittent issues do not lead to service failures.</p> </li> <li> <p>Java Example: Using Spring Retry to implement a retry mechanism for service calls:</p> </li> </ul> <pre><code>@Retryable(maxAttempts = 3, backoff = @Backoff(delay = 1000))\npublic String callService() {\n    // Call a remote service with retry\n}\n</code></pre>"},{"location":"microservices/#11-back-pressure-pattern","title":"11. Back Pressure Pattern","text":"<ul> <li> <p>Pattern Overview: The Back Pressure pattern addresses scenarios where a fast producer of data overwhelms a slower consumer. It involves controlling the flow of data to prevent resource exhaustion in the consumer.</p> </li> <li> <p>Java Example: Using reactive programming with Project Reactor to implement back pressure:</p> </li> </ul> <pre><code>Flux&lt;Data&gt; dataStream = dataProducer.generateData();\ndataStream\n    .onBackpressureBuffer(100) // Buffer up to 100 elements\n    .subscribe(dataConsumer::consumeData);\n</code></pre>"},{"location":"microservices/#12-synchronous-communication-via-api","title":"12. Synchronous Communication via API","text":"<ul> <li> <p>Pattern Overview: While Microservices often use asynchronous communication, there are cases where synchronous communication via RESTful APIs is suitable, especially for simple, immediate interactions.</p> </li> <li> <p>Java Example: Implementing a synchronous RESTful API in Spring Boot:</p> </li> </ul> <pre><code>@RestController\npublic class UserController {\n\n    @Autowired\n    private UserService userService;\n\n    @GetMapping(\"/users/{id}\")\n    public ResponseEntity&lt;User&gt; getUserById(@PathVariable Long id) {\n        // Call UserService to fetch user data\n    }\n}\n</code></pre>"},{"location":"microservices/#13-polyglot-microservices","title":"13. Polyglot Microservices","text":"<ul> <li> <p>Pattern Overview: The Polyglot Microservices pattern allows each Microservice to use a programming language and technology stack best suited to its requirements. This flexibility enhances developer productivity and system performance.</p> </li> <li> <p>Java Example: Developing one Microservice in Java, another in Python, and another in Node.js, each using its preferred stack.</p> </li> </ul>"},{"location":"microservices/#14-externalized-configuration","title":"14. Externalized Configuration","text":"<ul> <li> <p>Pattern Overview: Externalized Configuration involves storing configuration settings outside the codebase, allowing Microservices to be configured independently without code changes. Spring Cloud Config is a popular tool for implementing this pattern.</p> </li> <li> <p>Java Example: Using Spring Cloud Config to externalize configuration:</p> </li> </ul> <pre><code>spring.application.name=my-service\nspring.cloud.config.uri=http://config-server:8888\n</code></pre>"},{"location":"microservices/#15-log-aggregation-and-monitoring","title":"15. Log Aggregation and Monitoring","text":"<ul> <li> <p>Pattern Overview: Log Aggregation and Monitoring patterns involve collecting logs and metrics from various Microservices to gain insights into the system's health and performance. Tools like ELK Stack (Elasticsearch, Logstash, Kibana) or Prometheus and Grafana are commonly used for this purpose.</p> </li> <li> <p>Java Example: Configuring logback.xml for centralized logging using Logstash:</p> </li> </ul> <pre><code>&lt;appender name=\"logstash\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\"&gt;\n    &lt;destination&gt;logstash-server:4560&lt;/destination&gt;\n    &lt;!-- Logstash encoder configuration --&gt;\n    &lt;encoder class=\"net.logstash.logback.encoder.LogstashEncoder\"&gt;\n        &lt;fieldNames&gt;\n            &lt;timestamp&gt;timestamp&lt;/timestamp&gt;\n            &lt;version&gt;version&lt;/version&gt;\n            &lt;!-- Add more field names as needed --&gt;\n        &lt;/fieldNames&gt;\n    &lt;/encoder&gt;\n&lt;/appender&gt;\n</code></pre>"},{"location":"microservices/#16-shared-database-with-schema-per-service","title":"16. Shared Database with Schema per Service","text":"<ul> <li> <p>Pattern Overview: In cases where a shared database is necessary, the Shared Database with Schema per Service pattern involves using a single database while isolating data by providing a separate schema for each Microservice. This separation minimizes data conflicts and provides service-level control.</p> </li> <li> <p>Java Example: Using Hibernate to define separate schemas for Microservices within a shared database:</p> </li> </ul> <pre><code>@Entity\n@Table(name = \"orders\", schema = \"order_service\")\npublic class Order {\n    // Entity details\n}\n</code></pre>"},{"location":"microservices/#17-service-mesh-istio","title":"17. Service Mesh (Istio)","text":"<ul> <li> <p>Pattern Overview: Service Mesh is a dedicated infrastructure layer for handling service-to-service communication. Tools like Istio provide features such as load balancing, security, and observability, enhancing Microservices communication and management.</p> </li> <li> <p>Java Example: Integrating Istio with Microservices for traffic management and security.</p> </li> </ul>"},{"location":"microservices/#18-event-driven-microservices-with-kafka","title":"18. Event-Driven Microservices with Kafka","text":"<ul> <li> <p>Pattern Overview: Event-Driven Microservices rely on event streaming platforms like Apache Kafka to facilitate real-time data exchange between services. This pattern enables loosely coupled, highly scalable, and responsive systems.</p> </li> <li> <p>Java Example: Using Spring Kafka to produce and consume events in Microservices:</p> </li> </ul> <pre><code>// Producer\n@Autowired\nprivate KafkaTemplate&lt;String, String&gt; kafkaTemplate;\n\npublic void sendMessage(String message) {\n    kafkaTemplate.send(\"topic-name\", message);\n}\n\n// Consumer\n@KafkaListener(topics = \"topic-name\", groupId = \"group-id\")\npublic void receiveMessage(String message) {\n    // Process the received message\n}\n</code></pre>"},{"location":"microservices/#19-distributed-tracing-with-zipkin","title":"19. Distributed Tracing with Zipkin","text":"<ul> <li> <p>Pattern Overview: Distributed tracing allows you to monitor and troubleshoot complex Microservices systems by tracking requests as they flow through different services. Zipkin is a popular tool for implementing distributed tracing.</p> </li> <li> <p>Java Example: Integrating Spring Cloud Sleuth with Zipkin for distributed tracing:</p> </li> </ul> <pre><code>// Add dependencies for Spring Cloud Sleuth and Zipkin\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n// Configure Zipkin server in application.properties\nspring.zipkin.base-url=http://zipkin-server:9411/\n</code></pre>"},{"location":"microservices/#20-api-versioning","title":"20. API Versioning","text":"<ul> <li> <p>Pattern Overview: As Microservices evolve, API changes can lead to compatibility issues with clients. The API Versioning pattern involves versioning your APIs to allow for backward compatibility while introducing new features.</p> </li> <li> <p>Java Example: Implementing API versioning using URL path or request headers:</p> </li> </ul> <pre><code>// Versioning using URL path\n@GetMapping(\"/v1/resource\")\npublic ResponseEntity&lt;String&gt; getResourceV1() {\n    // Version 1 logic\n}\n\n@GetMapping(\"/v2/resource\")\npublic ResponseEntity&lt;String&gt; getResourceV2() {\n    // Version 2 logic\n}\n</code></pre> <p>Conclusion</p> <p>Microservices design patterns are crucial for addressing various challenges that arise when developing and maintaining Microservices-based applications. The patterns discussed in this comprehensive guide, along with their Java examples, offer valuable insights into building robust, scalable, and maintainable Microservices systems.</p> <p>By selecting the appropriate patterns for your specific use cases and combining them effectively, you can create Microservices architectures that are adaptable, resilient, and efficient. These patterns provide solutions to common architectural and operational challenges, allowing you to build agile and responsive software solutions that align with your organization's goals and requirements.</p>"},{"location":"microservices/#api-gateway","title":"API Gateway","text":"<p>The API Gateway pattern is an architectural design pattern commonly used in Microservices-based applications. It involves the use of a dedicated component called the API Gateway to act as a single entry point for client requests and manage the communication between clients and the various Microservices within the system. The API Gateway pattern is important in Microservices for several reasons:</p> <ol> <li> <p>Request Routing: The API Gateway handles incoming client requests and routes them to the appropriate Microservices. It acts as a traffic cop, ensuring that each request reaches the correct service, eliminating the need for clients to know the specific endpoints of individual services. This simplifies the client's interaction with the system.</p> </li> <li> <p>Load Balancing: The API Gateway can distribute incoming requests evenly among multiple instances of a Microservice, providing load balancing and ensuring that no single service instance is overwhelmed with traffic. This enhances the system's scalability and fault tolerance.</p> </li> <li> <p>Authentication and Authorization: It can centralize authentication and authorization processes. The API Gateway can verify the identity of clients, validate their access rights, and enforce security policies, reducing the complexity of implementing security in each Microservice.</p> </li> <li> <p>Caching: An API Gateway can implement caching mechanisms to store frequently requested data or responses, reducing the load on Microservices and improving response times for clients. Caching can be particularly useful for read-heavy operations.</p> </li> <li> <p>Aggregation: In cases where a client's request involves data from multiple Microservices, the API Gateway can aggregate the data and provide a consolidated response to the client. This reduces the number of client-server interactions, improving efficiency.</p> </li> <li> <p>Protocol Translation: Microservices may use different communication protocols or data formats. The API Gateway can perform protocol translation, allowing clients to use a standardized protocol, such as HTTP, while translating requests and responses to match the specific protocols of the underlying Microservices.</p> </li> <li> <p>Logging and Monitoring: Centralized logging and monitoring can be implemented within the API Gateway to track incoming requests, monitor service health, and capture performance metrics. This helps in debugging, troubleshooting, and ensuring system reliability.</p> </li> <li> <p>Version Management: API versioning can be managed at the API Gateway level, allowing for backward compatibility with older clients while introducing new features or changes to Microservices. This ensures that clients are not disrupted by service updates.</p> </li> <li> <p>Rate Limiting and Throttling: To prevent abuse or overloading of Microservices, the API Gateway can enforce rate limiting and request throttling policies, ensuring fair resource allocation among clients and protecting the system from denial-of-service attacks.</p> </li> <li> <p>Reduction of Cross-Cutting Concerns: The API Gateway abstracts cross-cutting concerns, such as security, logging, and monitoring, away from individual Microservices. This simplifies the development and maintenance of Microservices, allowing teams to focus on their core functionality.</p> </li> <li> <p>Fault Tolerance: The API Gateway can help improve the overall fault tolerance of a Microservices system. It can implement retry mechanisms and circuit breakers to handle transient failures gracefully. For example, if a Microservice temporarily becomes unavailable, the API Gateway can retry the request or provide a fallback response, ensuring a better user experience.</p> </li> <li> <p>Consolidated Analytics: By centralizing request and response handling, the API Gateway can capture valuable analytics and metrics about client interactions. This data can be used for performance analysis, capacity planning, and making informed decisions about system optimizations.</p> </li> <li> <p>Simplified Client Development: Clients, whether web applications, mobile apps, or external services, benefit from a simplified and unified interface provided by the API Gateway. This simplification reduces the complexity of client-side development, as clients need to interact with a single entry point, rather than managing direct connections to numerous Microservices.</p> </li> <li> <p>Cross-Cutting Concerns Enforcement: The API Gateway can enforce cross-cutting concerns, such as access control, logging, and content compression, consistently across all services. This ensures that important policies and practices are uniformly applied, reducing the risk of security vulnerabilities and inconsistent behavior.</p> </li> <li> <p>Scalability and Elasticity: When the API Gateway is designed for scalability, it can be scaled independently of Microservices. This means that as the system's traffic increases, you can scale the API Gateway to handle the load without necessarily scaling each Microservice. This approach optimizes resource allocation and cost-effectiveness.</p> </li> <li> <p>Simplified Testing and Documentation: With a single entry point for client interactions, testing and documenting the API become more straightforward. Clients can refer to well-documented API endpoints provided by the API Gateway, streamlining the integration process and reducing ambiguity.</p> </li> <li> <p>Simplified Change Management: When Microservices evolve or new services are added, the API Gateway can act as a shield for clients from disruptive changes. It can manage versioning, handle requests that need to be routed to the old or new versions, and ensure a smooth transition.</p> </li> <li> <p>Simplified Cross-Origin Resource Sharing (CORS) Handling: When dealing with client applications hosted on different domains, CORS becomes a concern. The API Gateway can manage CORS policies in a centralized manner, allowing or restricting cross-origin requests according to configured rules, thus simplifying cross-domain communication.</p> </li> <li> <p>Unified Error Handling: The API Gateway can standardize error responses and codes, making it easier for clients to understand and handle errors consistently. It can also provide detailed error messages and logs, aiding in debugging and troubleshooting.</p> </li> <li> <p>Enhanced Security Controls: Implementing security features like rate limiting, IP whitelisting, and DDoS protection is more manageable within the API Gateway. It provides a single point where security policies can be enforced, helping protect the entire Microservices ecosystem from threats and attacks.</p> </li> <li> <p>Service Transformation: The API Gateway can perform data transformation, including data format conversion and data enrichment, to tailor responses to clients' needs. This can reduce the burden on Microservices, which can focus on providing raw data.</p> </li> <li> <p>Scalable and Centralized Middleware: Middleware components like caching, logging, and compression can be centrally managed within the API Gateway. This reduces the need to replicate these components across various Microservices and ensures consistent behavior.</p> </li> <li> <p>Reduced Network Overhead: By consolidating multiple requests into a single request or by caching responses, the API Gateway can reduce the overall network overhead and latency, resulting in improved system performance and responsiveness.</p> </li> <li> <p>Granular Access Control: The API Gateway can implement fine-grained access control policies, ensuring that only authorized clients can access specific services or endpoints. This adds an additional layer of security and control.</p> </li> <li> <p>Global Rate Limiting: In addition to per-service rate limiting, the API Gateway can apply global rate limits to prevent abuse of system resources. This helps maintain service quality and protects against misuse.</p> </li> <li> <p>Dynamic Configuration: API Gateway configurations can be dynamic and updated in real-time, allowing for on-the-fly changes to routing rules, security policies, and other settings without requiring Microservices redeployment.</p> </li> <li> <p>API Analytics and Insights: The API Gateway can collect detailed analytics and insights into how clients interact with the system. This information can be valuable for business intelligence, identifying trends, and making informed decisions.</p> </li> <li> <p>API Rate Limiting: API Gateway can enforce rate limiting on incoming requests to prevent abuse and ensure fair resource allocation. This helps maintain system stability and prevents a single client or service from overwhelming the backend Microservices.</p> </li> <li> <p>Authentication and Single Sign-On (SSO): API Gateway can handle authentication and SSO for clients, offloading the authentication process from individual Microservices. This centralization simplifies authentication management and improves security.</p> </li> <li> <p>Content Compression: The API Gateway can compress responses before sending them to clients, reducing bandwidth usage and improving overall performance, especially for clients with limited network resources.</p> </li> <li> <p>Distributed Tracing Integration: Integration with distributed tracing systems like Zipkin or Jaeger allows API Gateway to capture and trace requests across Microservices, providing insights into request flow and performance bottlenecks.</p> </li> <li> <p>A/B Testing and Canary Releases: API Gateway can facilitate A/B testing and canary releases by routing a subset of requests to specific Microservice versions. This enables controlled experimentation and gradual deployments.</p> </li> <li> <p>Request and Response Transformation: API Gateway can transform requests and responses, including data format conversion, filtering, and enrichment, ensuring that clients receive data in their preferred format or structure.</p> </li> <li> <p>Global Error Handling: Centralized error handling in the API Gateway ensures that error responses are consistent and can be customized for different clients. It simplifies error management and reporting.</p> </li> <li> <p>Consolidated Logging: Logging requests and responses at the API Gateway level provides a centralized view of system activities, simplifying troubleshooting and auditing.</p> </li> <li> <p>Service Composition: In cases where a client request requires data from multiple Microservices, API Gateway can orchestrate service composition, fetching data from multiple sources and aggregating responses.</p> </li> <li> <p>Resource Monitoring: API Gateway can monitor resource usage, performance, and health of Microservices, enabling proactive maintenance and scaling based on real-time data.</p> </li> <li> <p>WebSocket Handling: API Gateway can handle WebSocket connections and routing, allowing for real-time communication between clients and Microservices.</p> </li> <li> <p>Request Validation: API Gateway can validate incoming requests, ensuring that they adhere to predefined criteria and meet security standards before forwarding them to Microservices. This adds an additional layer of security and reduces the risk of malicious or malformed requests.</p> </li> <li> <p>Consolidated Metrics and Monitoring: API Gateway can collect and consolidate metrics and monitoring data from various Microservices. This aggregated information provides a comprehensive view of system performance and helps identify bottlenecks or issues.</p> </li> <li> <p>Centralized Access Logging: Logging access events and audit trails at the API Gateway level allows for centralized access control and auditing. This is crucial for compliance with security and regulatory requirements.</p> </li> <li> <p>Dynamic Routing and Load Balancing: API Gateway can dynamically adjust routing and load balancing strategies based on real-time traffic and Microservice health. It helps in optimizing resource allocation and ensuring high availability.</p> </li> <li> <p>API Documentation and Discovery: API Gateway can provide self-documentation of available services and endpoints, making it easier for developers to discover and understand the available APIs. This documentation can be generated automatically from Microservices metadata.</p> </li> <li> <p>Health Checking: API Gateway can perform health checks on Microservices, monitoring their availability and response times. It can automatically route requests away from unhealthy instances, improving system reliability.</p> </li> <li> <p>Geographical Routing: For global applications, API Gateway can route requests to geographically distributed Microservices instances, reducing latency and improving the user experience for clients in different regions.</p> </li> <li> <p>Request Transformation: API Gateway can transform client requests into a format that Microservices understand. This can include mapping incoming data to the appropriate data model or schema for processing.</p> </li> <li> <p>Security Token Exchange: API Gateway can handle security token exchange between different authentication providers or protocols, simplifying the integration of various security mechanisms within the Microservices ecosystem.</p> </li> <li> <p>Scalable Analytics: By processing request and response data, the API Gateway can generate valuable analytics and insights, helping organizations make data-driven decisions and optimize system performance.</p> </li> <li> <p>Service Version Management: The API Gateway can manage different versions of services, allowing clients to specify the desired version in their requests. This ensures backward compatibility while enabling service evolution.</p> </li> <li> <p>Real-Time Monitoring and Alerts: API Gateway can offer real-time monitoring and alerting capabilities, notifying administrators of critical issues or anomalies in system behavior as they occur.</p> </li> </ol> <p>In summary, the API Gateway pattern is a versatile and crucial component in Microservices architecture, providing a wide range of capabilities that streamline client interactions, enhance security, improve scalability, and simplify the management of complex Microservices ecosystems. Its role in optimizing communication and centralizing various functions makes it an essential element for building robust and efficient Microservices-based applications.</p>"},{"location":"microservices/solid/","title":"SOLID principles","text":""},{"location":"microservices/solid/#solid-principles_1","title":"SOLID principles","text":"<p>SOLID is an acronym that represents a set of five design principles for writing maintainable and scalable software. These principles are essential for any Java developer to understand and apply when designing and implementing software solutions. In this article, we will dive into each SOLID principle, explain them in detail, and provide examples to help you grasp their concepts.</p>"},{"location":"microservices/solid/#solid-principles-in-java","title":"SOLID Principles in Java","text":"<p>SOLID principles are a set of five object-oriented design principles that help developers create software that is modular, easy to maintain, and scalable. These principles were introduced by Robert C. Martin, also known as Uncle Bob, and have become a cornerstone of modern software development.</p> <p>Here are the five SOLID principles:</p> <ol> <li> <p>Single Responsibility Principle (SRP): Every Java class should have only one responsibility. This principle helps keep code modular and easy to maintain.</p> </li> <li> <p>Open-Closed Principle (OCP): Software entities should be open for extension but closed for modification. This principle helps ensure that changes to the codebase do not break existing functionality.</p> </li> <li> <p>Liskov Substitution Principle (LSP): Subtypes must be substitutable for their base types. This principle helps ensure that code is flexible and can be easily extended.</p> </li> <li> <p>Interface Segregation Principle (ISP): Clients should not be forced to depend on interfaces they do not use. This principle helps keep code modular and easy to maintain.</p> </li> <li> <p>Dependency Inversion Principle (DIP): High-level modules should not depend on low-level modules. Both should depend on abstractions. This principle helps ensure that code is flexible and can be easily extended.</p> </li> </ol> <p>Here's an example of how these principles can be applied in Java:</p> <pre><code>public interface Shape {\n    double area();\n}\n\npublic class Rectangle implements Shape {\n    private double width;\n    private double height;\n\n    public Rectangle(double width, double height) {\n        this.width = width;\n        this.height = height;\n    }\n\n    public double area() {\n        return width * height;\n    }\n}\n\npublic class Circle implements Shape {\n    private double radius;\n\n    public Circle(double radius) {\n        this.radius = radius;\n    }\n\n    public double area() {\n        return Math.PI * radius * radius;\n    }\n}\n</code></pre> <p>In this example, we have two classes that implement the Shape interface. The Rectangle class calculates the area of a rectangle, while the Circle class calculates the area of a circle. Both classes have a single responsibility and are open for extension but closed for modification. They also depend on abstractions rather than concrete implementations, which makes them flexible and easy to extend.</p>"},{"location":"microservices/solid/#single-responsibility-principle-srp","title":"Single Responsibility Principle (SRP)","text":"<p>The Single Responsibility Principle states that a class should have only one reason to change. In other words, a class should have a single responsibility, and it should encapsulate that responsibility entirely.</p> <p>Suppose you have a <code>User</code> class that handles user authentication and also manages user profile information. This violates SRP, as it has two distinct responsibilities. Instead, you should have separate classes for authentication and user profile management.</p> <pre><code>// Before SRP violation\nclass User {\n    public void authenticate() {\n        // Authentication logic\n    }\n\n    public void manageProfile() {\n        // Profile management logic\n    }\n}\n\n// After applying SRP\nclass UserAuthenticator {\n    public void authenticate() {\n        // Authentication logic\n    }\n}\n\nclass UserProfileManager {\n    public void manageProfile() {\n        // Profile management logic\n    }\n}\n</code></pre>"},{"location":"microservices/solid/#openclosed-principle-ocp","title":"Open/Closed Principle (OCP)","text":"<p>The Open/Closed Principle emphasizes that software entities (classes, modules, functions) should be open for extension but closed for modification. It means you should be able to add new functionality to your code without changing existing code.</p> <p>Consider a payment processing system that supports different payment methods (credit card, PayPal, etc.). Rather than modifying the existing code every time you introduce a new payment method, you can create new classes that implement a common interface, making it easy to extend the system without altering existing code.</p> <pre><code>// Before OCP violation\nclass PaymentProcessor {\n    public void processPayment(String paymentType) {\n        if (paymentType.equals(\"CreditCard\")) {\n            // Process credit card payment\n        } else if (paymentType.equals(\"PayPal\")) {\n            // Process PayPal payment\n        }\n        // More payment methods...\n    }\n}\n\n// After applying OCP\ninterface PaymentMethod {\n    void processPayment();\n}\n\nclass CreditCardPayment implements PaymentMethod {\n    public void processPayment() {\n        // Process credit card payment\n    }\n}\n\nclass PayPalPayment implements PaymentMethod {\n    public void processPayment() {\n        // Process PayPal payment\n    }\n}\n</code></pre>"},{"location":"microservices/solid/#liskov-substitution-principle-lsp","title":"Liskov Substitution Principle (LSP)","text":"<p>The Liskov Substitution Principle states that objects of a derived class should be able to replace objects of the base class without affecting the correctness of the program. In simpler terms, if you have a base class and a subclass, you should be able to use instances of the subclass wherever you use instances of the base class.</p> <p>Imagine a <code>Bird</code> class with a method <code>fly()</code>. If you have a subclass <code>Penguin</code> that cannot fly, but you try to call <code>fly()</code> on a <code>Penguin</code> object, it violates LSP. To adhere to this principle, you should either override the method in <code>Penguin</code> to provide a no-op implementation or reconsider the class hierarchy.</p> <pre><code>// Violating LSP\nclass Bird {\n    public void fly() {\n        // Flying logic\n    }\n}\n\nclass Penguin extends Bird {\n    // Penguins cannot fly, but this method still exists\n}\n\n// Adhering to LSP\ninterface Flyable {\n    void fly();\n}\n\nclass Sparrow implements Flyable {\n    public void fly() {\n        // Flying logic for sparrows\n    }\n}\n\nclass Penguin implements Flyable {\n    public void fly() {\n        // Penguins cannot fly, so this method does nothing\n    }\n}\n</code></pre>"},{"location":"microservices/solid/#interface-segregation-principle-isp","title":"Interface Segregation Principle (ISP)","text":"<p>The Interface Segregation Principle suggests that clients should not be forced to depend on interfaces they do not use. In other words, keep your interfaces small and specific to the needs of the clients.</p> <p>Suppose you have an interface <code>Worker</code> with methods for both manual labor and office work. If a class only performs manual labor, it shouldn't be forced to implement the office work methods. Instead, you can create separate interfaces like <code>ManualWorker</code> and <code>OfficeWorker</code> to segregate the responsibilities.</p> <pre><code>// Violating ISP\ninterface Worker {\n    void doManualWork();\n    void doOfficeWork();\n}\n\nclass ManualWorker implements Worker {\n    public void doManualWork() {\n        // Manual work logic\n    }\n\n    public void doOfficeWork() {\n        // Office work logic (not needed for ManualWorker)\n    }\n}\n\n// Adhering to ISP\ninterface ManualWorker {\n    void doManualWork();\n}\n\ninterface OfficeWorker {\n    void doOfficeWork();\n}\n\nclass ConcreteManualWorker implements ManualWorker {\n    public void doManualWork() {\n        // Manual work logic\n    }\n}\n\nclass ConcreteOfficeWorker implements OfficeWorker {\n    public void doOfficeWork() {\n        // Office work logic\n    }\n}\n</code></pre>"},{"location":"microservices/solid/#dependency-inversion-principle-dip","title":"Dependency Inversion Principle (DIP)","text":"<p>The Dependency Inversion Principle encourages high-level modules to depend on abstractions rather than concrete implementations. It promotes loose coupling between classes.</p> <p>Instead of directly depending on a specific database implementation, a service class can depend on an interface <code>DatabaseConnector</code>. This way, you can easily switch between different database implementations (MySQL, PostgreSQL) without changing the service class, as long as they implement the <code>DatabaseConnector</code> interface.</p> <pre><code>// Without DIP\nclass Database {\n    public void connect() {\n        // Database connection logic\n    }\n}\n\nclass Service {\n    private Database database;\n\n    public Service() {\n        this.database = new Database();\n    }\n\n    public void performOperation() {\n        database.connect();\n        // Perform operation using the database\n    }\n}\n\n// Applying DIP\ninterface DatabaseConnector {\n    void connect();\n}\n\nclass ConcreteDatabase implements DatabaseConnector {\n    public void connect() {\n        // Database connection logic\n    }\n}\n\nclass Service {\n    private DatabaseConnector databaseConnector;\n\n    public Service(DatabaseConnector databaseConnector) {\n        this.databaseConnector = databaseConnector;\n    }\n\n    public void performOperation() {\n        databaseConnector.connect();\n        // Perform operation using the database\n    }\n}\n</code></pre> <p>In conclusion, the SOLID principles provide valuable guidelines for writing clean, maintainable, and extensible Java code. By following these principles, you can improve the quality of your software, make it easier to maintain and scale, and reduce the risk of introducing bugs when making changes. Understanding and applying these principles is crucial for both novice and experienced Java developers.</p> <p>These examples illustrate how to apply each SOLID principle in Java code to improve maintainability, extensibility, and adherence to best practices in software design.</p>"},{"location":"misc/agile/","title":"Agile methodology","text":""},{"location":"misc/agile/#agile-methodology_1","title":"Agile methodology","text":"<p>Agile methodology is an iterative and flexible approach to software development that emphasizes collaboration, customer feedback, and the delivery of working software. It promotes adaptability and continuous improvement, making it a popular choice for development teams seeking efficiency and customer-centricity.</p> <p>Agile methodology is a set of principles and practices that guide software development projects. It was introduced as a response to traditional, rigid project management approaches that often led to delayed deliveries, scope changes, and dissatisfaction among stakeholders. Agile methods prioritize customer satisfaction, teamwork, and the ability to respond to change. This article explores the key aspects of Agile methodology and its benefits for students, developers, and organizations.</p>"},{"location":"misc/agile/#key-concepts-and-principles","title":"Key Concepts and Principles","text":""},{"location":"misc/agile/#1-iterative-development","title":"1. Iterative Development:","text":"<ul> <li> <p>Description: Agile projects are divided into small increments, often referred to as \"iterations\" or \"sprints.\" Each iteration typically lasts 2-4 weeks and results in a potentially shippable product increment.</p> </li> <li> <p>Key Benefits:</p> <ul> <li>Allows for frequent delivery of working software.</li> <li>Encourages early and continuous customer feedback.</li> <li>Enables flexibility in adapting to changing requirements.</li> </ul> </li> </ul>"},{"location":"misc/agile/#2-collaborative-teams","title":"2. Collaborative Teams:","text":"<ul> <li> <p>Description: Agile teams are cross-functional, consisting of members with various skills and roles. Collaboration among team members, stakeholders, and customers is essential.</p> </li> <li> <p>Key Benefits:</p> <ul> <li>Enhances communication and knowledge sharing.</li> <li>Promotes a shared understanding of project goals and priorities.</li> <li>Encourages collective responsibility for project success.</li> </ul> </li> </ul>"},{"location":"misc/agile/#3-customer-centric-approach","title":"3. Customer-Centric Approach:","text":"<ul> <li> <p>Description: Agile places a strong emphasis on understanding and meeting customer needs. Customer feedback is actively sought and integrated throughout the development process.</p> </li> <li> <p>Key Benefits:</p> <ul> <li>Results in products that better meet customer expectations.</li> <li>Reduces the risk of building features that aren't valuable to users.</li> <li>Fosters long-term customer relationships and loyalty.</li> </ul> </li> </ul>"},{"location":"misc/agile/#4-adaptability-and-flexibility","title":"4. Adaptability and Flexibility:","text":"<ul> <li> <p>Description: Agile methodologies embrace change. They recognize that requirements and priorities can evolve, and they aim to accommodate these changes efficiently.</p> </li> <li> <p>Key Benefits:</p> <ul> <li>Allows for rapid response to market changes and emerging opportunities.</li> <li>Reduces the resistance to change often seen in traditional development.</li> </ul> </li> </ul>"},{"location":"misc/agile/#5-continuous-improvement","title":"5. Continuous Improvement:","text":"<ul> <li> <p>Description: Agile teams regularly reflect on their processes and seek ways to improve efficiency and effectiveness. This practice is often referred to as \"retrospectives.\"</p> </li> <li> <p>Key Benefits:</p> <ul> <li>Encourages a culture of continuous learning and adaptation.</li> <li>Helps teams identify and address bottlenecks and inefficiencies.</li> </ul> </li> </ul>"},{"location":"misc/agile/#agile-frameworks-and-methods","title":"Agile Frameworks and Methods","text":"<p>Several Agile frameworks and methods exist, with Scrum, Kanban, and Extreme Programming (XP) being some of the most widely adopted:</p> <ul> <li> <p>Scrum: A framework that divides work into fixed-length iterations called sprints, with a focus on time-boxed, collaborative work and frequent feedback.</p> </li> <li> <p>Kanban: A visual management method that aims to limit work in progress (WIP) and optimize the flow of work through a process.</p> </li> <li> <p>Extreme Programming (XP): A methodology that emphasizes close collaboration between developers and customers, with a focus on continuous integration, testing, and frequent small releases.</p> </li> </ul>"},{"location":"misc/agile/#benefits-of-agile-methodology","title":"Benefits of Agile Methodology","text":"<ul> <li> <p>Customer Satisfaction: Agile's customer-centric approach ensures that the product aligns with customer needs, leading to higher satisfaction.</p> </li> <li> <p>Faster Delivery: Iterative development and regular releases enable faster time-to-market for new features and improvements.</p> </li> <li> <p>Improved Quality: Continuous testing and review processes contribute to higher software quality.</p> </li> <li> <p>Enhanced Flexibility: Agile teams can adapt to changing requirements and market conditions more effectively.</p> </li> <li> <p>Higher Collaboration: Collaborative teams are more innovative and produce better solutions.</p> </li> <li> <p>Reduced Risk: Frequent testing and feedback reduce the likelihood of major project failures.</p> </li> </ul> <p>Agile methodology has revolutionized the software development industry by promoting adaptability, collaboration, and customer-centricity. Students, developers, and organizations can benefit from Agile's principles and practices, resulting in improved project outcomes, increased customer satisfaction, and a more responsive and efficient development process. Embrace Agile to stay competitive and meet the evolving needs of today's fast-paced software market.</p>"},{"location":"misc/security-scan/","title":"Security Scanning Tools","text":""},{"location":"misc/security-scan/#java-code-security-scanning-tools","title":"Java code security scanning tools","text":"<p>Java code security scanning tools are essential for identifying and mitigating vulnerabilities in Java applications. They help developers, students, and IT professionals ensure the safety and reliability of their code. This article explores popular Java code security scanning tools, their features, and how to use them effectively.</p> <p>Java is a widely used programming language, powering a vast array of applications, from web and mobile apps to enterprise systems. However, like any software, Java applications can have security vulnerabilities that may be exploited by attackers. To address this concern, developers and security professionals rely on Java code security scanning tools. These tools analyze Java code to identify and mitigate potential security risks, ensuring that applications remain robust and protected.</p>"},{"location":"misc/security-scan/#1-findbugs-spotbugs","title":"1. FindBugs (SpotBugs)","text":"<ul> <li>Description: FindBugs, now known as SpotBugs, is a widely used static analysis tool for Java. It detects common coding mistakes and potential vulnerabilities in Java source code.</li> <li>Key Features: SpotBugs identifies issues such as null pointer dereferences, incorrect use of APIs, and other code anomalies.</li> <li>Usage: SpotBugs can be integrated into popular IDEs (Integrated Development Environments) like Eclipse and IntelliJ IDEA, as well as build tools like Apache Maven.</li> </ul>"},{"location":"misc/security-scan/#2-sonarqube","title":"2. SonarQube","text":"<ul> <li>Description: SonarQube is an open-source platform that offers code quality and security analysis for Java and other programming languages.</li> <li>Key Features: SonarQube provides comprehensive code quality reports and security vulnerability detection. It supports a wide range of plugins for additional functionality.</li> <li>Usage: Users can run SonarQube locally or as a part of a continuous integration (CI) pipeline to automatically analyze code quality and security during development.</li> </ul>"},{"location":"misc/security-scan/#3-checkmarx","title":"3. Checkmarx","text":"<ul> <li>Description: Checkmarx is a commercial static application security testing (SAST) tool that supports Java and various other languages.</li> <li>Key Features: Checkmarx offers advanced scanning capabilities to identify security vulnerabilities, including SQL injection, cross-site scripting (XSS), and more.</li> <li>Usage: Checkmarx is often integrated into the development workflow to scan code at various stages of development, including code commits and builds.</li> </ul>"},{"location":"misc/security-scan/#4-fortify","title":"4. Fortify","text":"<ul> <li>Description: Fortify by Micro Focus is an enterprise-grade application security platform that includes static code analysis for Java.</li> <li>Key Features: Fortify provides in-depth analysis and prioritization of vulnerabilities, helping organizations focus on critical issues first.</li> <li>Usage: Fortify is typically used in large enterprises and organizations with complex codebases to maintain security standards.</li> </ul>"},{"location":"misc/security-scan/#5-owasp-dependency-check","title":"5. OWASP Dependency-Check","text":"<ul> <li>Description: OWASP Dependency-Check is an open-source tool that focuses on identifying known vulnerabilities in Java dependencies (libraries).</li> <li>Key Features: It scans project dependencies to check for published vulnerabilities in open-source libraries.</li> <li>Usage: Developers use OWASP Dependency-Check to ensure that their applications do not include vulnerable third-party libraries.</li> </ul> <p>Veracode is a well-known application security testing (AST) platform that helps organizations identify and remediate security vulnerabilities in their software applications. It offers a range of services and tools designed to assess and improve the security of applications throughout the development lifecycle. Below, I provide details about Veracode and its key features:</p>"},{"location":"misc/security-scan/#veracode","title":"Veracode","text":"<ul> <li> <p>Description: Veracode is a cloud-based application security platform that provides static analysis, dynamic analysis, and software composition analysis (SCA) to help organizations secure their software applications.</p> </li> <li> <p>Key Features:</p> </li> </ul>"},{"location":"misc/security-scan/#1-static-analysis-sast","title":"1. Static Analysis (SAST):","text":"<ul> <li> <p>Description: Static analysis, also known as Static Application Security Testing, involves scanning the source code or binary code of an application without executing it.</p> </li> <li> <p>Key Features:</p> <ul> <li>Identifies vulnerabilities in the source code, including common coding mistakes and security flaws.</li> <li>Provides a detailed analysis of code, including specific lines and methods where vulnerabilities are found.</li> <li>Supports a wide range of programming languages, including Java, C/C++, .NET, and more.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#2-dynamic-analysis-dast","title":"2. Dynamic Analysis (DAST):","text":"<ul> <li> <p>Description: Dynamic analysis, or Dynamic Application Security Testing, involves testing a running application to identify vulnerabilities that may not be apparent in the source code.</p> </li> <li> <p>Key Features:</p> <ul> <li>Scans applications in their runtime environment, simulating real-world attack scenarios.</li> <li>Detects security flaws that can be exploited when the application is interacting with external systems.</li> <li>Provides results in the context of the application's behavior during the scan.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#3-software-composition-analysis-sca","title":"3. Software Composition Analysis (SCA):","text":"<ul> <li> <p>Description: SCA focuses on identifying security vulnerabilities in open-source components and libraries used in an application.</p> </li> <li> <p>Key Features:</p> <ul> <li>Scans application dependencies to detect known vulnerabilities in open-source components.</li> <li>Offers insights into the severity and impact of identified vulnerabilities.</li> <li>Helps organizations track and manage open-source software risks.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#4-static-analysis-pipeline-scan","title":"4. Static Analysis Pipeline Scan:","text":"<ul> <li> <p>Description: This feature enables organizations to integrate static analysis into their continuous integration and continuous delivery (CI/CD) pipelines.</p> </li> <li> <p>Key Features:</p> <ul> <li>Scans code automatically as part of the development pipeline.</li> <li>Provides fast feedback to developers, allowing them to address issues early in the development process.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#5-comprehensive-reporting-and-remediation","title":"5. Comprehensive Reporting and Remediation:","text":"<ul> <li> <p>Description: Veracode offers comprehensive reporting capabilities to help organizations understand their application security posture.</p> </li> <li> <p>Key Features:</p> <ul> <li>Generates detailed reports with vulnerability findings, risk assessments, and remediation guidance.</li> <li>Provides guidance on how to fix identified vulnerabilities.</li> <li>Supports collaboration between security teams and developers for efficient issue resolution.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#6-support-for-various-development-environments","title":"6. Support for Various Development Environments:","text":"<ul> <li> <p>Description: Veracode supports a wide range of development environments, including web applications, mobile apps, and APIs.</p> </li> <li> <p>Key Features:</p> <ul> <li>Scans applications developed using different programming languages and frameworks.</li> <li>Ensures that security assessments are applicable to diverse application types.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#7-continuous-monitoring","title":"7. Continuous Monitoring:","text":"<ul> <li> <p>Description: Veracode offers continuous monitoring capabilities to help organizations keep track of their application security over time.</p> </li> <li> <p>Key Features:</p> <ul> <li>Monitors applications for new vulnerabilities and risks.</li> <li>Provides insights into the evolving threat landscape.</li> <li>Supports ongoing security improvements.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#8-integration-with-development-tools","title":"8. Integration with Development Tools:","text":"<ul> <li> <p>Description: Veracode integrates seamlessly with various development and DevOps tools, enabling organizations to incorporate security into their existing workflows.</p> </li> <li> <p>Key Features:</p> <ul> <li>Integrates with popular IDEs, CI/CD tools, and issue tracking systems.</li> <li>Provides actionable security feedback to developers within their preferred development environments.</li> </ul> </li> <li> <p>Deployment: Veracode is offered as a cloud-based service, making it easily accessible to organizations without the need for on-premises infrastructure.</p> </li> <li> <p>Licensing: Veracode typically offers subscription-based licensing models, with pricing based on factors such as the number of applications scanned, the scan frequency, and the level of analysis required.</p> </li> <li> <p>Customer Base: Veracode serves a wide range of customers, including enterprises, software development companies, financial institutions, healthcare organizations, and government agencies.</p> </li> <li> <p>Certifications: Veracode has received certifications and compliances that attest to its commitment to security and quality, including SOC 2 Type II, ISO 27001, and FedRAMP.</p> </li> <li> <p>Support and Training: Veracode provides customer support, training resources, and educational materials to help users get the most out of their platform.</p> </li> </ul> <p>Veracode is widely recognized in the field of application security testing, offering a comprehensive suite of tools and services to help organizations identify and address security vulnerabilities in their software applications, ultimately improving their security posture.</p> <p>Java code security scanning tools are invaluable for identifying and addressing vulnerabilities in Java applications. Whether you're a student, developer, or IT professional, integrating these tools into your workflow helps ensure that your Java projects remain secure and resilient in the face of evolving security threats. Explore the options, select the right tool for your needs, and make security a fundamental part of your software development process.</p>"},{"location":"misc/security-scan/#sonarqube","title":"SonarQube","text":"<p>SonarQube is an open-source platform for continuous code quality assessment and static code analysis. It helps developers, students, and organizations improve the quality, maintainability, and security of their software projects. This article delves into the details of SonarQube, its features, and how it can benefit software development processes.</p> <p>SonarQube, formerly known as Sonar, is an open-source platform designed to assess and enhance the quality of software code. It provides static code analysis, code coverage, code duplication detection, and security vulnerability scanning. SonarQube integrates seamlessly into the software development lifecycle, allowing developers to identify issues early, maintain code quality, and adhere to coding standards.</p>"},{"location":"misc/security-scan/#1-static-code-analysis","title":"1. Static Code Analysis:","text":"<ul> <li> <p>Description: SonarQube performs static code analysis to identify a wide range of code quality issues and vulnerabilities in source code, including programming bugs, code smells, and security vulnerabilities.</p> </li> <li> <p>Key Features:</p> <ul> <li>Supports various programming languages, including Java, JavaScript, Python, C#, and more.</li> <li>Provides detailed code quality reports with issues categorized by severity and type.</li> <li>Offers automated code review and feedback to developers within their development environment.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#2-code-quality-metrics","title":"2. Code Quality Metrics:","text":"<ul> <li> <p>Description: SonarQube collects and displays code quality metrics, allowing teams to track the evolution of their codebase's health over time.</p> </li> <li> <p>Key Features:</p> <ul> <li>Measures code complexity, maintainability, reliability, and security.</li> <li>Generates visualizations, charts, and graphs to visualize code quality trends.</li> <li>Helps prioritize technical debt and improvement efforts.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#3-security-vulnerability-scanning","title":"3. Security Vulnerability Scanning:","text":"<ul> <li> <p>Description: SonarQube includes security analysis rules to identify security vulnerabilities and coding practices that could lead to security issues.</p> </li> <li> <p>Key Features:</p> <ul> <li>Detects security vulnerabilities such as SQL injection, cross-site scripting (XSS), and insecure configurations.</li> <li>Provides guidance on remediation and secure coding practices.</li> <li>Supports compliance with security standards and regulations.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#4-code-duplication-detection","title":"4. Code Duplication Detection:","text":"<ul> <li> <p>Description: SonarQube identifies duplicate code blocks within a project, helping reduce redundancy and improving code maintainability.</p> </li> <li> <p>Key Features:</p> <ul> <li>Flags duplicated code snippets and highlights potential refactoring opportunities.</li> <li>Supports code consolidation and refactoring efforts.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#5-integration-with-development-tools","title":"5. Integration with Development Tools:","text":"<ul> <li> <p>Description: SonarQube integrates seamlessly with various development tools, allowing developers to receive code quality feedback within their preferred environments.</p> </li> <li> <p>Key Features:</p> <ul> <li>Integrates with popular IDEs, CI/CD pipelines, and version control systems like Jenkins, Git, and Azure DevOps.</li> <li>Provides real-time analysis and feedback during development.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#6-customizable-rules-and-quality-profiles","title":"6. Customizable Rules and Quality Profiles:","text":"<ul> <li> <p>Description: SonarQube allows users to define custom coding rules and quality profiles tailored to their project's requirements.</p> </li> <li> <p>Key Features:</p> <ul> <li>Customize coding standards and quality criteria to align with organizational guidelines.</li> <li>Fine-tune analysis settings for specific projects or codebases.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#7-plugin-ecosystem","title":"7. Plugin Ecosystem:","text":"<ul> <li> <p>Description: SonarQube supports a rich ecosystem of plugins that extend its functionality for different programming languages, frameworks, and additional features.</p> </li> <li> <p>Key Features:</p> <ul> <li>Access a wide range of plugins for language support, custom rules, and third-party integrations.</li> <li>Enhance the platform's capabilities based on project needs.</li> </ul> </li> </ul>"},{"location":"misc/security-scan/#using-sonarqube","title":"Using SonarQube","text":"<p>To make the most of SonarQube:</p> <ol> <li> <p>Install and Configure: Install SonarQube and configure it for your development environment.</p> </li> <li> <p>Integrate into Workflow: Integrate SonarQube into your CI/CD pipelines, version control systems, and development IDEs.</p> </li> <li> <p>Analyze Code: Run code analysis regularly to detect code quality issues, vulnerabilities, and duplications.</p> </li> <li> <p>Review and Remediate: Review analysis reports, prioritize issues, and work on code improvements and security fixes.</p> </li> <li> <p>Track Progress: Monitor code quality metrics and security vulnerabilities over time to measure progress and identify areas for improvement.</p> </li> <li> <p>Customize Rules: Tailor coding rules and quality profiles to match your project's requirements.</p> </li> <li> <p>Collaborate: Foster collaboration between developers, testers, and other stakeholders to address code quality and security issues effectively.</p> </li> </ol> <p>SonarQube is a powerful tool for improving code quality, maintainability, and security in software development projects. Whether you're a student, developer, or part of an organization, SonarQube can help you build robust, secure, and maintainable software by providing automated code analysis and valuable insights. Embrace SonarQube as an integral part of your software development process to enhance the quality and reliability of your codebase.</p>"},{"location":"nodejs/","title":"Node.js","text":""},{"location":"nodejs/#nodejs_1","title":"Node.js","text":"<p>Node.js is a powerful and versatile open-source runtime environment that allows developers to execute JavaScript code on the server-side. It has gained immense popularity among students, developers, and professionals alike due to its unique features and capabilities.</p> <p>Node.js, often referred to simply as \"Node,\" is a runtime environment built on the V8 JavaScript engine by Google. It enables the execution of JavaScript code outside of web browsers, making it possible to use JavaScript for server-side programming. This revolutionary approach has transformed web development by unifying the language used on both the client and server sides of web applications.</p>"},{"location":"nodejs/#key-features","title":"Key Features","text":"<ol> <li> <p>Non-blocking I/O: Node.js operates on an event-driven, non-blocking I/O model. This means it can efficiently handle multiple requests concurrently without waiting for each one to complete, resulting in high performance and responsiveness.</p> </li> <li> <p>Fast Execution: Built on the V8 engine, Node.js compiles JavaScript into machine code, allowing for speedy execution. This makes it suitable for building high-performance web applications and APIs.</p> </li> <li> <p>NPM (Node Package Manager): Node.js includes NPM, a package manager that hosts an extensive collection of open-source libraries and modules. Developers can easily access and integrate these modules into their projects, saving time and effort.</p> </li> <li> <p>Cross-platform: Node.js is compatible with various operating systems, including Windows, macOS, and Linux. This cross-platform nature ensures flexibility in development and deployment.</p> </li> <li> <p>Active Community: Node.js boasts a vibrant and active developer community. This means you can find ample resources, tutorials, and support to aid your learning and development journey.</p> </li> </ol>"},{"location":"nodejs/#use-cases-for-nodejs","title":"Use Cases for Node.js","text":"<ol> <li> <p>Web Servers: Node.js is commonly used to create lightweight and efficient web servers. Its non-blocking nature allows it to handle a large number of concurrent connections, making it ideal for serving web pages and handling API requests.</p> </li> <li> <p>API Development: Node.js excels at building RESTful APIs and backend services. It facilitates seamless communication between the front-end and back-end components of web applications.</p> </li> <li> <p>Real-time Applications: Thanks to its event-driven architecture, Node.js is well-suited for real-time applications such as chat applications, online gaming, and live streaming.</p> </li> <li> <p>Microservices: Node.js is an excellent choice for developing microservices architectures, where small, independent services work together to create a larger application.</p> </li> <li> <p>IoT (Internet of Things): Node.js's ability to handle asynchronous operations and real-time data processing makes it increasingly popular for IoT applications.</p> </li> </ol>"},{"location":"nodejs/#getting-started-with-nodejs","title":"Getting Started with Node.js","text":"<p>If you're eager to explore Node.js, here are the essential steps to begin your journey:</p>"},{"location":"nodejs/#1-installation","title":"1. Installation:","text":"<ul> <li> <p>Visit the official Node.js website (https://nodejs.org/) and download the installer for your operating system (Windows, macOS, or Linux).</p> </li> <li> <p>Follow the installation instructions to set up Node.js on your computer.</p> </li> </ul>"},{"location":"nodejs/#2-verification","title":"2. Verification:","text":"<ul> <li>Open your terminal or command prompt and type the following commands to confirm a successful installation:</li> </ul> <pre><code>   node -v\n   npm -v\n</code></pre> <p>These commands should display the versions of Node.js and NPM, verifying that installation was successful.</p>"},{"location":"nodejs/#3-creating-your-first-nodejs-application","title":"3. Creating Your First Node.js Application:","text":"<ul> <li> <p>Establish a new directory for your Node.js project and navigate to it using your terminal.</p> </li> <li> <p>Inside the project directory, create a new file, e.g., <code>app.js</code>, and open it with your preferred code editor.</p> </li> <li> <p>Write a basic \"Hello World\" program in <code>app.js</code>:</p> </li> </ul> <pre><code>   // app.js\n   console.log(\"Hello, Node.js!\");\n</code></pre> <ul> <li>Save the file.</li> </ul>"},{"location":"nodejs/#4-running-your-nodejs-application","title":"4. Running Your Node.js Application:","text":"<ul> <li> <p>In your terminal, navigate to the project directory containing <code>app.js</code>.</p> </li> <li> <p>Execute the Node.js application by running:</p> </li> </ul> <pre><code>   node app.js\n</code></pre> <p>You should see the \"Hello, Node.js!\" message displayed in the terminal.</p>"},{"location":"nodejs/#5-exploring-the-nodejs-ecosystem","title":"5. Exploring the Node.js Ecosystem:","text":"<ul> <li> <p>To harness the full potential of Node.js, delve into the extensive ecosystem of packages and libraries available via NPM (Node Package Manager). You can install packages using the <code>npm install</code> command and incorporate them into your projects.</p> </li> <li> <p>For instance, create a <code>package.json</code> file to manage your project's dependencies and employ NPM to install them:</p> </li> </ul> <pre><code>   npm init -y    # Initializes a package.json file\n   npm install express    # Installs the Express.js framework\n</code></pre> <p>This sets up a basic Node.js project with Express.js, a prominent web framework.</p> <p>In summary, Node.js is a versatile and influential runtime environment that has redefined web development by enabling JavaScript for server-side programming. Its event-driven, non-blocking architecture, coupled with a rich ecosystem and active community, makes it an invaluable tool for a wide array of applications in the realm of web development and beyond. Embrace Node.js, embark on your coding journey, and unlock a world of possibilities. Happy coding!</p>"},{"location":"nodejs/#event-driven-programming","title":"Event-Driven Programming","text":"<p>Event-driven programming is a fundamental concept in Node.js that underpins its asynchronous and non-blocking nature. It revolves around the idea of handling events and responding to them in real-time, making it a powerful paradigm for building responsive and efficient applications. In this explanation, we'll delve into event-driven programming in Node.js to help students, developers, and enthusiasts grasp this essential concept.</p> <p>Event-driven programming is a programming paradigm where the flow of a program is determined by events, such as user actions, sensor inputs, or messages from other parts of the application. In Node.js, this concept is central to its design, allowing developers to create applications that can handle multiple concurrent operations without blocking the execution of other tasks.</p>"},{"location":"nodejs/#key-components-of-event-driven-programming","title":"Key Components of Event-Driven Programming","text":""},{"location":"nodejs/#1-events","title":"1. Events","text":"<ul> <li>In Node.js, events are occurrences or signals that something has happened within an application. These events can be user interactions (like clicking a button), system events (like receiving data from a network socket), or custom events that developers define.</li> </ul>"},{"location":"nodejs/#2-event-emitters","title":"2. Event Emitters","text":"<ul> <li>Event emitters are objects in Node.js that can emit (or trigger) events. They are instances of the <code>EventEmitter</code> class, which is part of the Node.js core modules. Developers can create custom event emitters to handle specific events in their applications.</li> </ul>"},{"location":"nodejs/#3-event-listeners","title":"3. Event Listeners","text":"<ul> <li>Event listeners are functions that are registered to respond to specific events. These functions are associated with event emitters and are executed when the corresponding event occurs. Event listeners define how the application should react to events.</li> </ul>"},{"location":"nodejs/#how-event-driven-programming-works","title":"How Event-Driven Programming Works","text":"<ol> <li>Event Registration:</li> </ol> <p>To implement event-driven programming, developers first define event emitters and register event listeners. Event emitters are objects that emit events, and listeners are functions that will be executed when those events occur.</p> <pre><code>   const EventEmitter = require('events');\n   const myEmitter = new EventEmitter();\n\n   // Registering an event listener\n   myEmitter.on('myEvent', () =&gt; {\n       console.log('Event occurred!');\n   });\n</code></pre> <ol> <li>Event Emission:</li> </ol> <p>Somewhere in the application, an event emitter emits an event using the <code>.emit()</code> method. This signals that a specific event has taken place.</p> <pre><code>   // Emitting the 'myEvent' event\n   myEmitter.emit('myEvent');\n</code></pre> <ol> <li>Event Handling:</li> </ol> <p>When an event is emitted, all registered event listeners for that event are executed synchronously. This allows the application to respond immediately to the event.</p> <pre><code>   Output:\n   Event occurred!\n</code></pre> <ol> <li>Asynchronous Nature:</li> </ol> <p>Node.js is inherently asynchronous, so event listeners can perform time-consuming tasks without blocking the application. This ensures that other parts of the application can continue running without waiting for the event handler to finish.</p>"},{"location":"nodejs/#use-cases-for-event-driven-programming","title":"Use Cases for Event-Driven Programming","text":"<p>Event-driven programming in Node.js is particularly beneficial for:</p> <ul> <li> <p>Real-time Applications: Applications that require immediate responses to user actions or incoming data, such as chat applications or online games.</p> </li> <li> <p>Concurrency: Handling multiple concurrent tasks efficiently without blocking the main thread, making it suitable for servers and network communication.</p> </li> <li> <p>Scalability: Building scalable applications that can handle numerous simultaneous connections or requests.</p> </li> </ul> <p>In summary, event-driven programming is a core concept in Node.js that enables developers to create responsive, non-blocking, and efficient applications. By understanding events, event emitters, and event listeners, developers can harness the power of Node.js to build applications that can handle real-time interactions, scale effectively, and deliver optimal performance. Embracing event-driven programming is a crucial step towards becoming proficient in Node.js development.</p>"},{"location":"nodejs/#npm-node-package-manager","title":"NPM (Node Package Manager)","text":"<p>NPM (Node Package Manager) is an integral part of the Node.js ecosystem, serving as a powerful tool for managing packages and dependencies in Node.js applications. In this explanation, we'll explore NPM in detail to provide students, developers, and enthusiasts with a clear understanding of its significance and functionality.</p>"},{"location":"nodejs/#what-is-npm","title":"What is NPM?","text":"<p>NPM stands for Node Package Manager. It is a command-line tool and a vast online repository of open-source JavaScript packages and modules that can be easily integrated into Node.js applications. NPM simplifies the process of adding, updating, and managing third-party libraries, making it an indispensable resource for Node.js developers.</p>"},{"location":"nodejs/#key-features-of-npm","title":"Key Features of NPM","text":"<p>NPM offers a wide range of features and benefits that contribute to its popularity within the Node.js community:</p>"},{"location":"nodejs/#1-package-management","title":"1. Package Management:","text":"<ul> <li>NPM allows developers to install, update, and remove packages with a straightforward command-line interface. It simplifies the management of project dependencies, streamlining the development process.</li> </ul>"},{"location":"nodejs/#2-dependency-resolution","title":"2. Dependency Resolution:","text":"<ul> <li>NPM automatically resolves and installs the dependencies of a package. When you install a package, NPM checks for its required dependencies and installs them as well, creating a structured dependency tree.</li> </ul>"},{"location":"nodejs/#3-version-control","title":"3. Version Control:","text":"<ul> <li>NPM facilitates precise version control for packages. Developers can specify exact version numbers, ranges, or semantic versioning (SemVer) constraints in their project's <code>package.json</code> file to ensure compatibility and stability.</li> </ul>"},{"location":"nodejs/#4-package-publishing","title":"4. Package Publishing:","text":"<ul> <li>Developers can easily publish their own packages to the NPM registry, making them accessible to the global Node.js community. This fosters collaboration and the sharing of reusable code.</li> </ul>"},{"location":"nodejs/#5-script-execution","title":"5. Script Execution:","text":"<ul> <li>NPM allows developers to define and run custom scripts in the project's <code>package.json</code> file. This is particularly useful for automating common development tasks such as testing, building, and deployment.</li> </ul>"},{"location":"nodejs/#6-security-scanning","title":"6. Security Scanning:","text":"<ul> <li>NPM includes security features that scan packages for known vulnerabilities, helping developers identify and mitigate potential security risks in their projects.</li> </ul>"},{"location":"nodejs/#7-offline-mode","title":"7. Offline Mode:","text":"<ul> <li>NPM caches downloaded packages locally, enabling developers to work offline or in environments with limited internet access. This enhances development productivity.</li> </ul>"},{"location":"nodejs/#how-npm-works","title":"How NPM Works","text":"<p>NPM operates through a set of commands executed in the terminal. Here are some common NPM commands:</p> <ul> <li> <p><code>npm init</code>: Initializes a new Node.js project and generates a <code>package.json</code> file to manage project metadata and dependencies.</p> </li> <li> <p><code>npm install &lt;package-name&gt;</code>: Installs a package and its dependencies locally within the project directory.</p> </li> <li> <p><code>npm install -g &lt;package-name&gt;</code>: Installs a package globally, making it available for use across different projects.</p> </li> <li> <p><code>npm update &lt;package-name&gt;</code>: Updates a specific package to the latest version.</p> </li> <li> <p><code>npm search &lt;keyword&gt;</code>: Searches the NPM registry for packages related to a specific keyword.</p> </li> <li> <p><code>npm publish</code>: Publishes a package to the NPM registry (requires an NPM account).</p> </li> <li> <p><code>npm run &lt;script-name&gt;</code>: Executes custom scripts defined in the <code>scripts</code> section of the <code>package.json</code> file.</p> </li> </ul>"},{"location":"nodejs/#benefits-of-using-npm","title":"Benefits of Using NPM","text":"<ul> <li> <p>Efficiency: NPM simplifies package management, saving developers time and effort in handling dependencies.</p> </li> <li> <p>Community and Collaboration: The NPM registry hosts a vast ecosystem of packages created and maintained by developers worldwide. It fosters collaboration and code sharing.</p> </li> <li> <p>Version Control: Precise version control ensures that projects are using compatible packages, reducing the risk of compatibility issues.</p> </li> <li> <p>Security: NPM's security features help identify and mitigate potential vulnerabilities in project dependencies.</p> </li> <li> <p>Automation: Developers can automate various tasks through NPM scripts, enhancing workflow efficiency.</p> </li> </ul> <p>NPM plays a pivotal role in the Node.js ecosystem, offering a seamless solution for managing packages and dependencies. Its user-friendly interface, extensive package repository, version control capabilities, and security features make it an indispensable tool for Node.js developers. Embracing NPM empowers developers to efficiently build, maintain, and share JavaScript-based applications, contributing to the growth and innovation within the Node.js community.</p>"},{"location":"nodejs/#child-threads","title":"Child Threads","text":"<p>Node.js, known for its single-threaded, event-driven architecture, also offers a mechanism to handle child threads for parallel processing. In this explanation, we'll delve into how Node.js manages child threads to facilitate concurrent execution, making it relevant for students, developers, and enthusiasts interested in optimizing performance in Node.js applications.</p>"},{"location":"nodejs/#what-are-child-threads","title":"What Are Child Threads?","text":"<p>Child threads, also known as worker threads, are separate threads of execution that can run concurrently with the main (or parent) thread in a Node.js application. Unlike the main event loop, which is single-threaded, child threads allow developers to perform CPU-intensive or parallelizable tasks without blocking the main thread's execution.</p>"},{"location":"nodejs/#why-use-child-threads","title":"Why Use Child Threads?","text":"<p>Node.js's event-driven model excels at handling I/O-bound operations efficiently. However, CPU-bound tasks can potentially block the main thread, leading to reduced responsiveness and performance. Child threads provide a solution by offloading such tasks to separate threads, allowing the main thread to continue processing events and responding to I/O operations.</p>"},{"location":"nodejs/#nodejs-and-the-worker_threads-module","title":"Node.js and the <code>worker_threads</code> Module","text":"<p>Node.js introduced the <code>worker_threads</code> module to enable the creation and management of child threads. This module offers a built-in and efficient way to leverage multiple threads in Node.js applications.</p>"},{"location":"nodejs/#key-components-of-the-worker_threads-module","title":"Key Components of the <code>worker_threads</code> Module","text":""},{"location":"nodejs/#1-worker-threads","title":"1. Worker Threads:","text":"<ul> <li>Worker threads are instances of the <code>Worker</code> class provided by the <code>worker_threads</code> module. Each worker thread is a separate JavaScript execution context, with its own event loop and memory space.</li> </ul>"},{"location":"nodejs/#2-communication","title":"2. Communication:","text":"<ul> <li>Child threads can communicate with the main thread and other child threads through a message-passing mechanism. They can send and receive structured data using the <code>postMessage()</code> and <code>on('message')</code> methods.</li> </ul>"},{"location":"nodejs/#3-shared-memory","title":"3. Shared Memory:","text":"<ul> <li>While each worker thread has its own memory space, Node.js also provides a <code>SharedArrayBuffer</code> that allows data to be shared among multiple threads. This shared memory feature can be useful for certain scenarios.</li> </ul>"},{"location":"nodejs/#how-nodejs-handles-child-threads","title":"How Node.js Handles Child Threads","text":"<p>Here's a step-by-step explanation of how Node.js manages child threads:</p>"},{"location":"nodejs/#1-creating-child-threads","title":"1. Creating Child Threads:","text":"<ul> <li>Developers create child threads by instantiating instances of the <code>Worker</code> class provided by the <code>worker_threads</code> module.</li> </ul> <pre><code>const { Worker, isMainThread, parentPort } = require('worker_threads');\n\nif (isMainThread) {\n  // This code runs in the main thread\n  const worker = new Worker('./child.js');\n  // Handle messages received from the child thread\n  worker.on('message', (message) =&gt; {\n    console.log('Received from child:', message);\n  });\n  // Send a message to the child thread\n  worker.postMessage('Hello from main!');\n} else {\n  // This code runs in the child thread\n  parentPort.on('message', (message) =&gt; {\n    console.log('Received from main:', message);\n    // Send a message back to the main thread\n    parentPort.postMessage('Hello from child!');\n  });\n}\n</code></pre>"},{"location":"nodejs/#2-communication_1","title":"2. Communication:","text":"<ul> <li>Child threads communicate with the main thread and other child threads using the <code>postMessage()</code> and <code>on('message')</code> methods.</li> </ul>"},{"location":"nodejs/#3-parallel-execution","title":"3. Parallel Execution:","text":"<ul> <li>Child threads run concurrently with the main thread, allowing for parallel execution of tasks. This is especially useful for CPU-intensive operations.</li> </ul>"},{"location":"nodejs/#4-event-loop","title":"4. Event Loop:","text":"<ul> <li>Each child thread has its own event loop, enabling it to handle asynchronous operations independently.</li> </ul>"},{"location":"nodejs/#5-shared-memory-optional","title":"5. Shared Memory (Optional):","text":"<ul> <li>Node.js provides a <code>SharedArrayBuffer</code> for sharing data among threads when necessary. Care should be taken to synchronize access to shared data to avoid race conditions.</li> </ul>"},{"location":"nodejs/#use-cases-for-child-threads","title":"Use Cases for Child Threads","text":"<p>Child threads in Node.js are valuable for tasks such as:</p> <ul> <li>CPU-intensive calculations and data processing.</li> <li>Parallelizing tasks to improve performance.</li> <li>Utilizing multiple CPU cores efficiently.</li> <li>Running background tasks without affecting the main thread's responsiveness.</li> </ul> <p>Node.js's ability to handle child threads through the <code>worker_threads</code> module extends its capabilities beyond single-threaded event-driven programming. Child threads provide a means to perform CPU-bound tasks concurrently, improving the overall performance and responsiveness of Node.js applications. By understanding and utilizing child threads effectively, developers can optimize their applications to handle a broader range of workloads and deliver enhanced user experiences.</p>"},{"location":"nodejs/#nodejs-vs-traditional-web-servers","title":"Node.js vs. Traditional Web Servers","text":"<p>Node.js and traditional web server technologies like Apache or IIS differ significantly in their architecture, performance, and use cases. This comparison aims to provide students, developers, and enthusiasts with a clear understanding of these differences.</p>"},{"location":"nodejs/#architecture","title":"Architecture","text":"<ul> <li>Event-Driven and Non-Blocking: Node.js is built on an event-driven, non-blocking I/O model. It uses a single-threaded event loop to efficiently handle multiple concurrent connections. This architecture is well-suited for applications that require real-time, asynchronous communication, such as chat applications and streaming services.</li> </ul>"},{"location":"nodejs/#traditional-web-servers-eg-apache-iis","title":"Traditional Web Servers (e.g., Apache, IIS)","text":"<ul> <li>Multi-Process or Multi-Threaded: Traditional web servers like Apache and IIS typically rely on multi-process or multi-threaded architectures. Each incoming request spawns a new process or thread, which can lead to higher resource consumption and potential scalability challenges.</li> </ul>"},{"location":"nodejs/#performance","title":"Performance","text":""},{"location":"nodejs/#nodejs_2","title":"Node.js","text":"<ul> <li> <p>Highly Scalable: Node.js excels in handling a large number of concurrent connections efficiently due to its non-blocking nature. It's well-suited for building highly scalable web applications and APIs.</p> </li> <li> <p>Fast Execution: Node.js is known for its fast execution of JavaScript code, thanks to the V8 JavaScript engine. This makes it suitable for building high-performance web applications.</p> </li> </ul>"},{"location":"nodejs/#traditional-web-servers-eg-apache-iis_1","title":"Traditional Web Servers (e.g., Apache, IIS)","text":"<ul> <li> <p>Resource Intensive: Traditional web servers may consume more system resources when dealing with a high volume of concurrent requests due to their multi-process or multi-threaded nature. This can lead to increased memory and CPU usage.</p> </li> <li> <p>Slower Execution: Traditional servers may exhibit slower execution times for dynamic web applications compared to Node.js.</p> </li> </ul>"},{"location":"nodejs/#use-cases","title":"Use Cases","text":""},{"location":"nodejs/#nodejs_3","title":"Node.js","text":"<ul> <li> <p>Real-Time Applications: Node.js is well-suited for real-time applications like chat applications, online gaming, and live streaming, where immediate responsiveness is crucial.</p> </li> <li> <p>API Development: Node.js is popular for building RESTful APIs and backend services, facilitating seamless communication between front-end and back-end components.</p> </li> <li> <p>Microservices: Node.js is a suitable choice for developing microservices architectures, where small, independent services work together to form a larger application.</p> </li> </ul>"},{"location":"nodejs/#traditional-web-servers-eg-apache-iis_2","title":"Traditional Web Servers (e.g., Apache, IIS)","text":"<ul> <li> <p>Static Content: Traditional servers are often used to serve static content, such as HTML files, CSS, and images.</p> </li> <li> <p>PHP, .NET, and Java Applications: Traditional servers are commonly employed for hosting PHP, .NET, and Java-based web applications.</p> </li> <li> <p>Content Management Systems (CMS): CMS platforms like WordPress and Drupal are often hosted on traditional web servers.</p> </li> </ul>"},{"location":"nodejs/#ecosystem-and-extensions","title":"Ecosystem and Extensions","text":""},{"location":"nodejs/#nodejs_4","title":"Node.js","text":"<ul> <li> <p>Rich Ecosystem: Node.js has a vast ecosystem of packages and libraries available through npm (Node Package Manager), which simplifies the integration of third-party code into applications.</p> </li> <li> <p>JavaScript Everywhere: Node.js allows developers to use JavaScript on both the server and client sides, promoting code reusability and consistency.</p> </li> </ul>"},{"location":"nodejs/#traditional-web-servers-eg-apache-iis_3","title":"Traditional Web Servers (e.g., Apache, IIS)","text":"<ul> <li> <p>Varied Ecosystem: Traditional web servers support a wide range of programming languages and technologies, providing flexibility in the choice of tools and frameworks.</p> </li> <li> <p>Specialized Modules: Apache, for example, offers modules like mod_php and mod_rewrite, while IIS provides features tailored for Windows environments.</p> </li> </ul>"},{"location":"nodejs/#community-and-support","title":"Community and Support","text":""},{"location":"nodejs/#nodejs_5","title":"Node.js","text":"<ul> <li>Active Community: Node.js has a vibrant and active developer community, resulting in frequent updates, a wealth of resources, and a large pool of skilled developers.</li> </ul>"},{"location":"nodejs/#traditional-web-servers-eg-apache-iis_4","title":"Traditional Web Servers (e.g., Apache, IIS)","text":"<ul> <li>Established Communities: Traditional servers like Apache have been in use for a long time, resulting in established communities and extensive documentation.</li> </ul> <p>In summary, Node.js and traditional web servers differ in their architectural approach, performance characteristics, use cases, ecosystem, and community support. Node.js is a strong choice for real-time applications, API development, and microservices, offering scalability and speed. Traditional web servers, on the other hand, remain valuable for hosting static content and supporting a variety of programming languages and technologies. The choice between Node.js and traditional servers should be based on the specific requirements and goals of a project.</p>"},{"location":"nodejs/#callbacks","title":"Callbacks","text":"<p>Callbacks in Node.js are functions that are passed as arguments to other functions and are executed once the asynchronous operation within the function is completed. They are crucial for handling asynchronous tasks in Node.js, such as reading files, making HTTP requests, or interacting with databases.</p> <p>In the world of Node.js and asynchronous programming, callbacks play a pivotal role in ensuring that operations that take time to complete, such as file reading, database queries, or network requests, do not block the execution of the rest of your code. They allow you to work with non-blocking code, making your applications more efficient and responsive.</p> <p>Here's how callbacks work in Node.js:</p> <ol> <li> <p>Passing Functions as Arguments: In Node.js, functions are first-class citizens, which means you can treat them like any other variable. You can pass functions as arguments to other functions, just like you would with numbers or strings.</p> </li> <li> <p>Asynchronous Operations: Many operations in Node.js are asynchronous, meaning they do not block the main thread of your application. Instead, they run in the background, allowing your code to continue executing other tasks.</p> </li> <li> <p>Callback Function Structure: A callback is a function that you pass as an argument to another function that performs an asynchronous operation. This callback function is executed once the operation is complete, serving as a notification that the task has finished.</p> </li> </ol> <pre><code>   // Example of using a callback for reading a file asynchronously\n   const fs = require('fs');\n\n   fs.readFile('example.txt', 'utf8', (error, data) =&gt; {\n       if (error) {\n           console.error('Error reading the file: ', error);\n       } else {\n           console.log('File contents: ', data);\n       }\n   });\n</code></pre> <p>In this example, the <code>readFile</code> function takes a callback as its last argument. When the file reading operation is finished, the callback is executed with either an error or the read data.</p> <ol> <li> <p>Error Handling: Callbacks often receive an error as their first argument, which allows you to handle errors gracefully. If an error occurs during the asynchronous operation, you can check for it in the callback and take appropriate action.</p> </li> <li> <p>Callback Hell (Callback Pyramid): When dealing with multiple asynchronous operations, nesting callbacks can lead to complex and hard-to-read code. This is often referred to as \"Callback Hell\" or \"Callback Pyramid.\" To avoid this, you can use techniques like Promises or async/await, which provide a more structured way to handle asynchronous code.</p> </li> </ol>"},{"location":"nodejs/#handling-callbacks-effectively","title":"Handling Callbacks Effectively:","text":"<p>To use callbacks effectively in Node.js, here are some best practices:</p> <ol> <li> <p>Modularize Your Code: Break down your code into smaller, reusable functions. This makes it easier to manage callbacks and keep your codebase organized.</p> </li> <li> <p>Error Handling: Always handle errors in your callbacks. Node.js conventions dictate that errors should be the first argument passed to the callback function. Check for errors and handle them gracefully.</p> </li> <li> <p>Avoid Callback Hell: As mentioned earlier, nesting callbacks can make your code hard to maintain. Consider using libraries like <code>async</code> or adopting Promises to handle complex asynchronous operations more cleanly.</p> </li> <li> <p>Promises: Promises are a modern alternative to callbacks that provide a more structured way to work with asynchronous code. They allow you to chain operations together and handle errors in a more organized manner.</p> </li> </ol> <pre><code>// Example using Promises for file reading\nconst fs = require('fs').promises;\n\nfs.readFile('example.txt', 'utf8')\n    .then((data) =&gt; {\n        console.log('File contents: ', data);\n    })\n    .catch((error) =&gt; {\n        console.error('Error reading the file: ', error);\n    });\n</code></pre> <ol> <li>Async/Await: Building upon Promises, async/await is a feature in modern JavaScript that makes working with asynchronous code even more readable. It allows you to write asynchronous code in a synchronous style.</li> </ol> <pre><code>// Example using async/await for file reading\nconst fs = require('fs').promises;\n\nasync function readFileAsync() {\n    try {\n        const data = await fs.readFile('example.txt', 'utf8');\n        console.log('File contents: ', data);\n    } catch (error) {\n        console.error('Error reading the file: ', error);\n    }\n}\n\nreadFileAsync();\n</code></pre> <ol> <li>Use Named Functions: When defining your callback functions, give them meaningful names. This makes your code more self-documenting and easier for others to understand.</li> </ol>"},{"location":"nodejs/#promises-and-asyncawait-as-callback-alternatives","title":"Promises and Async/Await as Callback Alternatives:","text":"<p>In the Node.js ecosystem, callbacks are the foundation of handling asynchronous operations. However, as your codebase grows and becomes more complex, there are alternatives that offer cleaner and more organized ways to manage asynchronous tasks: Promises and async/await.</p>"},{"location":"nodejs/#promises","title":"Promises:","text":"<p>Promises are a way to handle asynchronous operations in a more structured manner. They provide a clear separation between the initiation of an asynchronous task and handling its resolution or rejection. A Promise can be in one of three states: pending, resolved (fulfilled), or rejected.</p> <p>Here's how to use Promises in Node.js:</p> <pre><code>const fs = require('fs').promises;\n\n// Using a Promise to read a file\nfs.readFile('example.txt', 'utf8')\n    .then((data) =&gt; {\n        console.log('File contents: ', data);\n    })\n    .catch((error) =&gt; {\n        console.error('Error reading the file: ', error);\n    });\n</code></pre> <p>Promises allow you to chain multiple asynchronous operations together and handle errors using the <code>.then()</code> and <code>.catch()</code> methods, resulting in cleaner and more readable code.</p>"},{"location":"nodejs/#asyncawait","title":"Async/Await:","text":"<p>Async/await is a syntactical enhancement built on top of Promises, introduced in modern JavaScript. It provides a more synchronous-looking way to write asynchronous code. With async/await, you can write asynchronous code that resembles traditional synchronous code, making it easier to understand and maintain.</p> <p>Here's an example of using async/await to read a file in Node.js:</p> <pre><code>const fs = require('fs').promises;\n\nasync function readFileAsync() {\n    try {\n        const data = await fs.readFile('example.txt', 'utf8');\n        console.log('File contents: ', data);\n    } catch (error) {\n        console.error('Error reading the file: ', error);\n    }\n}\n\nreadFileAsync();\n</code></pre> <p>In this example, the <code>async</code> keyword is used to define an asynchronous function, and <code>await</code> is used to pause execution until the Promise is resolved. It provides a more linear and intuitive flow when working with asynchronous tasks.</p>"},{"location":"nodejs/#choosing-the-right-approach","title":"Choosing the Right Approach:","text":"<p>While Promises and async/await offer cleaner alternatives to callbacks, it's essential to choose the approach that best suits your project and team's familiarity. If you're working with existing callback-based code, transitioning to Promises or async/await may be a gradual process.</p> <p>In summary, callbacks, Promises, and async/await are all valuable tools in Node.js for handling asynchronous operations. Promises and async/await can help you write more maintainable and readable asynchronous code, but it's important to consider your project's specific requirements and the expertise of your development team when choosing the right approach.</p>"},{"location":"nodejs/#middleware","title":"Middleware","text":"<p>Middleware in Node.js is a crucial component of web applications, providing a way to handle requests and responses in a modular and extensible manner. It acts as a bridge between the incoming HTTP request and the final response, allowing developers to perform various tasks such as authentication, logging, and data manipulation before the request reaches its destination.</p> <p>Middleware in Node.js is a fundamental concept, especially when building web applications using frameworks like Express.js. It plays a pivotal role in processing incoming HTTP requests and outgoing responses. Middleware functions are like building blocks that you can stack together to create a pipeline through which requests flow, with each middleware function performing a specific task or transformation.</p> <p>Here's a more detailed explanation of middleware in Node.js:</p> <ol> <li> <p>Request-Response Cycle: In a web application, when a client (e.g., a web browser) sends an HTTP request to a server, that request goes through various stages before generating a response. Middleware functions intercept and process the request and response during this cycle.</p> </li> <li> <p>Modular and Reusable: Middleware functions are modular and reusable pieces of code. Developers can write middleware for specific tasks and reuse them across different routes and applications. This promotes code organization and maintainability.</p> </li> <li> <p>Order of Execution: Middleware functions are executed in the order they are defined. The order matters because each middleware can modify the request or response before passing it to the next middleware or the final request handler.</p> </li> <li> <p>Common Middleware Tasks: Middleware can perform a wide range of tasks, including:</p> <ul> <li>Authentication: Checking if a user is logged in or has the necessary permissions before allowing access to certain routes.</li> <li>Logging: Capturing information about incoming requests, such as IP addresses, timestamps, and request methods, for debugging and monitoring purposes.</li> <li>Parsing Data: Parsing data from request bodies (e.g., JSON or form data) and making it available to route handlers.</li> <li>Error Handling: Catching and handling errors that occur during request processing, ensuring that the application doesn't crash.</li> <li>Caching: Storing frequently accessed data or responses in memory to improve performance.</li> <li>Compression: Compressing responses to reduce bandwidth usage.</li> <li>Routing: Determining which route handler should be called based on the request URL.</li> <li>Security: Implementing security measures, such as setting HTTP headers to prevent common web vulnerabilities.</li> </ul> </li> <li> <p>Express.js and Middleware: Express.js, a popular Node.js web framework, makes extensive use of middleware. Middleware can be added to an Express application using the <code>app.use()</code> method or by specifying it for specific routes. Express middleware can be built-in, third-party, or custom-written to suit your application's needs.</p> </li> <li> <p>Next Function: Middleware functions typically accept three arguments: <code>request</code>, <code>response</code>, and <code>next</code>. The <code>next</code> function is a callback that must be called to pass control to the next middleware in the chain. If <code>next</code> is not called, the request will not progress to the subsequent middleware or route handler.</p> </li> </ol> <p>Here's a simple example of how middleware is used in Express.js to log incoming requests:</p> <pre><code>const express = require('express');\nconst app = express();\n\n// Custom middleware to log requests\napp.use((req, res, next) =&gt; {\n    console.log(`Request received: ${req.method} ${req.url}`);\n    next(); // Pass control to the next middleware or route handler\n});\n\napp.get('/', (req, res) =&gt; {\n    res.send('Hello, World!');\n});\n\napp.listen(3000, () =&gt; {\n    console.log('Server is listening on port 3000');\n});\n</code></pre> <p>In this example, the custom middleware logs incoming requests before allowing them to proceed to the route handler.</p> <p>In summary, middleware in Node.js, particularly when used with frameworks like Express.js, is a powerful tool for handling various aspects of request processing in web applications. It enables developers to modularize and organize their code, making it more maintainable and extensible. Understanding how to use and create middleware is essential for building robust and feature-rich web applications.</p>"},{"location":"nodejs/#types-of-middleware","title":"Types of Middleware:","text":"<p>In the Node.js ecosystem, you'll encounter various types of middleware, each serving a specific purpose. Here are some common types of middleware and their roles:</p> <ol> <li> <p>Built-in Middleware: Express.js provides a set of built-in middleware functions that cover essential tasks, such as parsing request bodies, handling cookies, and serving static files. These can be easily added to your application using <code>app.use()</code>.</p> </li> <li> <p>Third-party Middleware: The Node.js community offers a wide range of third-party middleware packages that extend the functionality of your application. These include authentication middleware like Passport.js, request validation middleware like Joi or express-validator, and many others. You can incorporate these packages into your application to leverage their features.</p> </li> <li> <p>Custom Middleware: You can create your custom middleware functions tailored to your application's specific needs. These functions can perform tasks unique to your project, such as logging, error handling, or data transformation. Custom middleware allows you to maintain full control over the request-response cycle.</p> </li> <li> <p>Error Handling Middleware: Specialized middleware can be dedicated to error handling. These middleware functions are defined with four parameters (<code>err</code>, <code>req</code>, <code>res</code>, and <code>next</code>) and are used to catch and handle errors that occur in your application. Error handling middleware ensures that your application remains robust and doesn't crash due to unhandled exceptions.</p> </li> <li> <p>Authentication Middleware: Authentication middleware is vital for securing your application. It verifies the identity of users based on their credentials or tokens and grants or denies access to protected routes. Passport.js is a popular choice for implementing authentication middleware in Node.js applications.</p> </li> <li> <p>Routing Middleware: Routing middleware is responsible for determining which route handler should be executed based on the incoming request's URL and HTTP method. Express.js uses routing middleware to match incoming requests to the appropriate route handlers.</p> </li> <li> <p>Security Middleware: Security middleware adds an extra layer of protection to your application by setting security-related HTTP headers, preventing common web vulnerabilities like Cross-Site Scripting (XSS) and Cross-Site Request Forgery (CSRF), and implementing rate limiting to mitigate brute-force attacks.</p> </li> </ol>"},{"location":"nodejs/#middleware-execution-order","title":"Middleware Execution Order:","text":"<p>Understanding the order in which middleware functions are executed is crucial for building reliable applications:</p> <ol> <li> <p>Top-down Order: Middleware functions are executed in the order they are defined using the <code>app.use()</code> method or within specific route handlers. The first middleware added is the first to be executed.</p> </li> <li> <p>Next Function: To pass control to the next middleware or route handler, you must call the <code>next()</code> function within a middleware function. If <code>next()</code> is not called, the request will become stuck, and subsequent middleware or route handlers will not be executed.</p> </li> <li> <p>Short-circuiting: Middleware can short-circuit the execution chain by not calling <code>next()</code>. This is often used in scenarios like authentication middleware, where if authentication fails, no further middleware or route handlers should be executed for that request.</p> </li> </ol>"},{"location":"nodejs/#middleware-in-real-world-applications","title":"Middleware in Real-world Applications:","text":"<p>In real-world Node.js applications, middleware can become a powerful tool for managing complexity and ensuring security and maintainability. Developers can mix and match different types of middleware to create a robust and feature-rich web server.</p> <p>Here's a common example of how middleware might be used in an Express.js application:</p> <pre><code>const express = require('express');\nconst app = express();\n\n// Custom logging middleware\napp.use((req, res, next) =&gt; {\n    console.log(`Request received: ${req.method} ${req.url}`);\n    next();\n});\n\n// Middleware for parsing JSON requests\napp.use(express.json());\n\n// Authentication middleware\napp.use(passport.authenticate('jwt', { session: false }));\n\n// Route handlers\napp.get('/', (req, res) =&gt; {\n    res.send('Hello, World!');\n});\n\napp.get('/profile', (req, res) =&gt; {\n    res.send('User profile page');\n});\n\napp.listen(3000, () =&gt; {\n    console.log('Server is listening on port 3000');\n});\n</code></pre> <p>In this example, middleware functions are used for logging, parsing JSON requests, and authentication before the final route handlers are executed. This modular approach keeps the code organized and enhances the application's functionality.</p> <p>In conclusion, middleware is a fundamental concept in Node.js, especially when working with web frameworks like Express.js. It empowers developers to handle various aspects of request processing, making applications more modular, secure, and maintainable. Understanding the different types of middleware and their execution order is essential for building robust and feature-rich Node.js applications.</p>"},{"location":"nodejs/#middleware-best-practices","title":"Middleware Best Practices:","text":"<p>When working with middleware in Node.js, it's essential to follow best practices to ensure that your application remains efficient, maintainable, and secure. Here are some key best practices for working with middleware:</p> <ol> <li> <p>Use Middleware Sparingly: While middleware is a powerful tool, it's important not to overuse it. Only add middleware that serves a specific purpose in your application. Overloading your application with unnecessary middleware can impact performance.</p> </li> <li> <p>Order Matters: Pay careful attention to the order in which you add middleware. The sequence of middleware functions can significantly affect how requests are processed. For example, authentication middleware should be placed before route-specific middleware to ensure that authentication is checked first.</p> </li> <li> <p>Keep Middleware Functions Simple: Each middleware function should have a clear and specific purpose. Avoid creating monolithic middleware functions that try to do too much. Smaller, focused middleware functions are easier to understand and maintain.</p> </li> <li> <p>Middleware Composition: You can compose multiple middleware functions into a single middleware function using the <code>app.use()</code> method. This can help reduce redundancy and improve code organization. For example:</p> </li> </ol> <pre><code>const logRequest = (req, res, next) =&gt; {\n    console.log(`Request received: ${req.method} ${req.url}`);\n    next();\n};\n\nconst parseJSON = express.json();\n\napp.use(logRequest, parseJSON);\n</code></pre> <ol> <li> <p>Error Handling Middleware: Ensure that your application has error handling middleware in place to catch and handle errors gracefully. This prevents unhandled exceptions from crashing your server and provides meaningful error responses to clients.</p> </li> <li> <p>Middleware Testing: Test your middleware functions thoroughly. Middleware can have a significant impact on the behavior of your application, so it's crucial to ensure that it functions as expected. Use testing frameworks like Mocha and Chai or Jest to write unit tests for your middleware.</p> </li> <li> <p>Middleware Versioning: If you make changes to your middleware, consider versioning it to avoid breaking existing functionality for other parts of your application that depend on it.</p> </li> <li> <p>Use Existing Middleware Libraries: Whenever possible, leverage existing, well-maintained middleware libraries from the Node.js ecosystem. These libraries have often been tested in production environments and may offer more robust solutions than custom implementations.</p> </li> <li> <p>Keep Security in Mind: Be cautious when using third-party middleware, especially those that manipulate request data. Ensure that the middleware you use is secure and doesn't introduce vulnerabilities to your application.</p> </li> <li> <p>Documentation: Document your middleware functions and their usage. Clear documentation helps other developers on your team understand how to use and extend the middleware in your application.</p> </li> <li> <p>Regular Maintenance: Keep your middleware up to date with the latest versions and security patches. Outdated middleware can pose security risks and compatibility issues.</p> </li> <li> <p>Middleware Naming Conventions: Establish clear naming conventions for your middleware functions to make it easier for developers to identify their purpose. For example, prefix middleware functions with terms like \"auth\" for authentication middleware or \"logger\" for logging middleware.</p> </li> </ol> <p>By following these best practices, you can effectively work with middleware in your Node.js applications, ensuring that it enhances your application's functionality while maintaining code quality and security. Middleware plays a crucial role in building scalable and maintainable web applications, so it's worth investing time and effort into using it effectively.</p>"},{"location":"nodejs/#middleware-debugging-and-troubleshooting","title":"Middleware Debugging and Troubleshooting:","text":"<p>Debugging and troubleshooting middleware-related issues can be challenging but essential for maintaining a healthy Node.js application. Here are some strategies and techniques to help you diagnose and resolve problems with middleware:</p> <ol> <li> <p>Logging: Use extensive logging within your middleware functions to capture information about the execution flow, request details, and any errors that may occur. This can be especially helpful in identifying the source of issues.</p> </li> <li> <p>Error Handling: Implement comprehensive error handling in your middleware functions. Ensure that unhandled errors are caught and properly logged or returned as appropriate error responses to clients.</p> </li> <li> <p>Error Stack Traces: When an error occurs in your middleware, include stack traces in your error logs. Stack traces provide valuable information about where the error occurred and the call chain that led to it.</p> </li> <li> <p>Middleware Isolation: Temporarily isolate suspect middleware to pinpoint the source of a problem. Comment out or remove middleware functions one by one and test your application to see if the issue persists. This process can help identify the problematic middleware.</p> </li> <li> <p>Inspect Request and Response: Use debugging tools and techniques to inspect the incoming request and outgoing response objects within your middleware functions. You can log or inspect the properties and data of these objects to check for unexpected behavior.</p> </li> <li> <p>Debugging Tools: Employ Node.js debugging tools like <code>console.log</code>, <code>console.error</code>, or dedicated debugging libraries like <code>debug</code> to output relevant information. You can also use integrated development environments (IDEs) that support debugging Node.js applications.</p> </li> <li> <p>Middleware Order: Double-check the order in which you've added middleware to your application. As mentioned earlier, the sequence matters, and incorrect ordering can lead to unexpected behavior.</p> </li> <li> <p>Dependency Versioning: Ensure that the versions of external middleware libraries and dependencies you use are compatible with each other and with your Node.js version. Mismatched versions can result in issues.</p> </li> <li> <p>Test Cases: Write unit tests and integration tests for your middleware functions. Test cases help you verify that each middleware performs its intended tasks correctly and doesn't introduce regressions.</p> </li> <li> <p>Debugging Middleware-specific Issues: If you suspect a particular middleware is causing problems, create isolated test cases specifically for that middleware. Debugging the middleware in isolation can make it easier to identify issues.</p> </li> <li> <p>Use Linters: Static code analysis tools and linters like ESLint can help identify potential issues in your middleware code, such as coding style violations or common mistakes.</p> </li> <li> <p>Peer Review: Collaborate with team members or peers to review your middleware code. Fresh eyes may spot issues that you missed, and discussions can lead to insights on how to improve or troubleshoot problematic middleware.</p> </li> <li> <p>Community Support: If you're encountering issues with third-party middleware libraries, consult the documentation, GitHub repository, or community forums associated with those libraries. Other developers may have experienced and resolved similar problems.</p> </li> </ol> <p>Remember that debugging and troubleshooting can be a iterative process. Be patient, methodical, and systematic in your approach. Start with the most likely sources of the problem and gradually narrow down the root cause. By applying these debugging and troubleshooting techniques, you can effectively identify and resolve middleware-related issues in your Node.js applications.</p>"},{"location":"nodejs/#event-loop","title":"Event Loop","text":"<p>The event loop in Node.js is a crucial part of its architecture, allowing it to handle asynchronous operations efficiently. It's a continuous process that constantly checks the message queue for events, executes callbacks, and manages I/O operations without blocking the main thread. This enables Node.js to be highly performant and handle numerous connections simultaneously.</p> <p>The event loop is a core concept in Node.js, responsible for its non-blocking, asynchronous behavior. It's essential to understand how the event loop works to harness the full power of Node.js for building scalable and high-performance applications.</p>"},{"location":"nodejs/#key-concepts","title":"Key Concepts:","text":"<ol> <li> <p>Single-Threaded: Node.js operates on a single-threaded event loop model. This means that it runs all JavaScript code in a single main thread. However, it can still handle numerous connections and perform I/O operations efficiently because of its non-blocking nature.</p> </li> <li> <p>Event-Driven: Node.js is event-driven, meaning it responds to events like incoming HTTP requests, file system operations, and timers. These events trigger the execution of specific callback functions.</p> </li> </ol>"},{"location":"nodejs/#event-loop-phases","title":"Event Loop Phases:","text":"<p>The event loop in Node.js consists of several phases, each responsible for handling different types of events. These phases ensure that asynchronous operations are executed in an organized and efficient manner. Here's an overview of the main phases:</p> <ol> <li> <p>Timers: In this phase, the event loop checks for timers that have expired. Timers are created using functions like <code>setTimeout()</code> and <code>setInterval()</code>. If a timer has expired, its callback function is pushed to the message queue for execution.</p> </li> <li> <p>Pending I/O Callbacks: This phase handles I/O-related callbacks. When an asynchronous I/O operation, such as reading a file or making a network request, is completed, its callback is placed in the message queue for execution in this phase.</p> </li> <li> <p>Idle, Prepare: These are internal phases used for housekeeping and preparation work. They are rarely used directly by developers.</p> </li> <li> <p>Poll: In the poll phase, the event loop waits for events to occur. If there are no timers or pending I/O operations, it can block and wait for new events. This is where most of the asynchronous I/O operations take place.</p> </li> <li> <p>Check, Close Callbacks: In the check phase, certain callbacks are executed immediately after the poll phase, primarily to handle setImmediate() callbacks. The close callbacks phase deals with close events like closing a socket or a file.</p> </li> </ol>"},{"location":"nodejs/#message-queue","title":"Message Queue:","text":"<p>The message queue is a critical part of the event loop. When an event or callback is ready to be executed, it is placed in the message queue. The event loop constantly checks the message queue and processes these events one by one. This ensures that callbacks are executed in the order they were added to the queue.</p>"},{"location":"nodejs/#event-loop-execution-flow","title":"Event Loop Execution Flow:","text":"<p>Here's a simplified overview of how the event loop works:</p> <ol> <li> <p>The event loop starts in the \"poll\" phase, waiting for events to occur.</p> </li> <li> <p>When an event, such as an incoming HTTP request, occurs, Node.js triggers the associated callback function.</p> </li> <li> <p>The callback function is executed asynchronously and may perform I/O operations or other tasks.</p> </li> <li> <p>Upon completion of the callback, it is placed in the message queue.</p> </li> <li> <p>The event loop checks the message queue and executes the callbacks one by one, starting with the next available callback.</p> </li> <li> <p>This process continues, allowing Node.js to efficiently handle multiple connections and asynchronous tasks without blocking the main thread.</p> </li> </ol>"},{"location":"nodejs/#benefits-of-the-event-loop","title":"Benefits of the Event Loop:","text":"<ul> <li> <p>Non-blocking: The event loop allows Node.js to perform I/O operations without blocking the main thread, ensuring that your application remains responsive to other requests and events.</p> </li> <li> <p>Scalability: Node.js can handle a large number of concurrent connections and events efficiently, making it suitable for building scalable applications.</p> </li> <li> <p>High Performance: By utilizing the event loop, Node.js can execute callbacks quickly, resulting in high performance for real-time applications like chat applications and online games.</p> </li> <li> <p>Resource Efficiency: Node.js consumes fewer resources compared to traditional multi-threaded models, making it more resource-efficient.</p> </li> </ul> <p>In summary, the event loop is the heart of Node.js, enabling it to handle asynchronous operations efficiently. By understanding its phases and how it processes events, developers can write non-blocking, high-performance applications that can handle a large number of concurrent connections.</p>"},{"location":"nodejs/#event-loop-example","title":"Event Loop Example:","text":"<p>To better illustrate how the event loop works in practice, let's consider a simple example involving timers and I/O operations:</p> <pre><code>// Example 1: Timers\nconsole.log('Start');\n\nsetTimeout(() =&gt; {\n    console.log('Timer 1 (setTimeout) fired');\n}, 1000);\n\nsetImmediate(() =&gt; {\n    console.log('Immediate 1 (setImmediate) fired');\n});\n\nconsole.log('End');\n</code></pre> <p>In this example, we have two timers, one created using <code>setTimeout()</code> and the other using <code>setImmediate()</code>. Here's the expected output and explanation:</p> <ol> <li>The code begins executing, and 'Start' is logged to the console.</li> <li>The <code>setTimeout()</code> timer is set to fire after 1000 milliseconds (1 second), and the <code>setImmediate()</code> callback is set to execute immediately after the current phase (in this case, the poll phase).</li> <li>'End' is logged to the console.</li> <li>The event loop enters the poll phase and waits for events to occur.</li> <li>After approximately 1 second, the event loop detects that the <code>setTimeout()</code> timer has expired. Its callback is placed in the message queue.</li> <li>The event loop finishes the poll phase and checks the message queue. It finds the <code>setTimeout()</code> callback and executes it, logging 'Timer 1 (setTimeout) fired'.</li> <li>Finally, the event loop processes the <code>setImmediate()</code> callback, logging 'Immediate 1 (setImmediate) fired'.</li> </ol> <p>This example demonstrates the order of execution in the event loop, emphasizing that timers are not guaranteed to execute immediately when their time expires. The event loop schedules callbacks based on the phases and their priority.</p> <p>Let's explore another example involving I/O operations:</p> <pre><code>const fs = require('fs');\n\n// Example 2: I/O Operations\nconsole.log('Start');\n\nfs.readFile('example.txt', 'utf8', (err, data) =&gt; {\n    if (err) {\n        console.error('Error reading file:', err);\n        return;\n    }\n    console.log('File content:', data);\n});\n\nconsole.log('End');\n</code></pre> <p>In this example, we read the contents of a file asynchronously using <code>fs.readFile()</code>. Here's the expected output and explanation:</p> <ol> <li>The code starts executing, and 'Start' is logged to the console.</li> <li>The <code>fs.readFile()</code> function is called, initiating an asynchronous file reading operation. The callback function is provided to handle the result when the operation completes.</li> <li>'End' is logged to the console.</li> <li>The event loop enters the poll phase and waits for events to occur, including the completion of the file reading operation.</li> <li>When the file reading operation is finished, its callback function is placed in the message queue.</li> <li>The event loop checks the message queue and executes the file reading callback, either logging the file content or an error message, depending on the outcome of the operation.</li> </ol> <p>This example demonstrates how the event loop efficiently manages I/O operations without blocking the main thread, ensuring that other tasks can continue to execute concurrently.</p> <p>Understanding the event loop and its phases is essential for Node.js developers, as it forms the basis for handling asynchronous operations and building responsive and high-performance applications.</p>"},{"location":"nodejs/#event-loop-customization-and-additional-considerations","title":"Event Loop Customization and Additional Considerations:","text":"<p>While the event loop in Node.js operates automatically, there are ways to customize its behavior and additional considerations to keep in mind:</p> <ol> <li> <p>Event Loop Phases Customization: In some cases, you may want to customize the behavior of specific phases of the event loop. Node.js provides methods like <code>process.nextTick()</code>, <code>setImmediate()</code>, and <code>setInterval()</code> to control when certain tasks are executed. These can be useful for fine-tuning the order of execution of callbacks.</p> </li> <li> <p>Blocking Code: Although Node.js is designed to be non-blocking, you should be cautious when using synchronous code or CPU-intensive operations within your callbacks. Such code can block the event loop and affect the overall performance of your application. Consider offloading CPU-intensive tasks to worker threads or child processes.</p> </li> <li> <p>Memory Management: Asynchronous operations in Node.js can lead to memory leaks if not managed properly. It's important to release resources and remove references to objects when they are no longer needed. Tools like the built-in <code>EventEmitter</code> class can help manage event subscriptions and prevent memory leaks.</p> </li> <li> <p>Error Handling: Proper error handling is crucial in asynchronous code. Always handle errors within your callbacks, and consider using libraries like <code>async/await</code> or Promises to simplify error handling and avoid unhandled exceptions.</p> </li> <li> <p>Event Loop Lag: In high-traffic applications, the event loop can become congested, leading to event loop lag. Monitor your application's performance and consider load balancing or scaling strategies to address this issue.</p> </li> <li> <p>Concurrency and Thread Safety: While Node.js is single-threaded, it is designed to be concurrent. Ensure that your code is thread-safe when sharing resources among multiple asynchronous operations. Proper synchronization mechanisms may be necessary in certain scenarios.</p> </li> <li> <p>Event Loop Debugging: Node.js provides built-in debugging tools and libraries like <code>async_hooks</code> for tracing and debugging the event loop. Familiarize yourself with these tools to troubleshoot performance or concurrency issues.</p> </li> <li> <p>Event Loop Libraries: Explore third-party libraries and tools designed to work with the event loop. Libraries like <code>p-event</code> and <code>event-loop-inspector</code> can help manage event-driven code and provide insights into event loop behavior.</p> </li> <li> <p>Node.js Versions: Be aware of changes and improvements in different Node.js versions. Upgrade to newer versions to benefit from performance enhancements, bug fixes, and security updates.</p> </li> </ol> <p>In conclusion, understanding the event loop in Node.js is essential for building efficient and scalable applications. It enables you to leverage asynchronous programming to handle I/O operations and concurrency effectively. By mastering the event loop and considering customization options and best practices, you can create robust and high-performance Node.js applications that can handle a wide range of tasks and workloads.</p>"},{"location":"nodejs/#promises_1","title":"Promises","text":"<p>Promises in Node.js are a powerful tool for managing asynchronous operations and improving code readability. They represent a future value or outcome of an asynchronous task and allow you to handle success and error cases more elegantly than traditional callback-based approaches. Promises follow a well-defined pattern with methods like <code>.then()</code> and <code>.catch()</code> to chain and handle asynchronous tasks.</p> <p>Promises are a fundamental concept in modern JavaScript and Node.js for handling asynchronous operations in a more organized and readable way. They provide a structured approach to managing the flow of asynchronous code, making it easier to reason about and maintain.</p>"},{"location":"nodejs/#key-concepts_1","title":"Key Concepts:","text":"<ol> <li> <p>Asynchronous Operations: In Node.js, many tasks are asynchronous, such as reading files, making network requests, or querying databases. Asynchronous tasks do not block the main thread, allowing your program to continue executing other code while waiting for the task to complete.</p> </li> <li> <p>Callback-Based Approach: Before Promises, asynchronous operations were often managed using callbacks. While callbacks are functional, they can lead to callback hell (a.k.a. pyramid of doom) when multiple asynchronous tasks are nested within one another, making code difficult to read and maintain.</p> </li> <li> <p>Promise Object: A Promise is an object representing the eventual completion or failure of an asynchronous operation. It serves as a placeholder for the result or error that will be available in the future.</p> </li> </ol>"},{"location":"nodejs/#promise-states","title":"Promise States:","text":"<p>Promises can be in one of three states:</p> <ol> <li> <p>Pending: The initial state when a Promise is created, indicating that the asynchronous operation has not yet completed.</p> </li> <li> <p>Fulfilled: The state when the asynchronous operation has successfully completed, and the Promise holds a resolved value (e.g., data from a successful API call).</p> </li> <li> <p>Rejected: The state when an error occurred during the asynchronous operation, and the Promise holds a reason or error object (e.g., network error or validation failure).</p> </li> </ol>"},{"location":"nodejs/#creating-promises","title":"Creating Promises:","text":"<p>You can create a Promise using its constructor, which takes a single function (executor) with two parameters: <code>resolve</code> and <code>reject</code>. Inside the executor function, you perform your asynchronous operation and call <code>resolve</code> when it succeeds or <code>reject</code> when it fails.</p> <pre><code>const myPromise = new Promise((resolve, reject) =&gt; {\n    // Asynchronous operation, e.g., fetching data\n    fetch('https://api.example.com/data')\n        .then(response =&gt; response.json())\n        .then(data =&gt; resolve(data)) // Resolve with data\n        .catch(error =&gt; reject(error)); // Reject with error\n});\n</code></pre>"},{"location":"nodejs/#chaining-promises","title":"Chaining Promises:","text":"<p>Promises are designed to be chained together using the <code>.then()</code> method. Each <code>.then()</code> callback receives the resolved value of the previous Promise, allowing you to sequence multiple asynchronous tasks.</p> <pre><code>myPromise\n    .then(data =&gt; {\n        // Process data from the first Promise\n        return processData(data);\n    })\n    .then(result =&gt; {\n        // Continue with another asynchronous task\n        return performAnotherAsyncTask(result);\n    })\n    .then(finalResult =&gt; {\n        // Final result after all asynchronous tasks\n        console.log(finalResult);\n    })\n    .catch(error =&gt; {\n        // Handle errors from any Promise in the chain\n        console.error(error);\n    });\n</code></pre>"},{"location":"nodejs/#benefits-of-promises","title":"Benefits of Promises:","text":"<ul> <li> <p>Readability: Promises make asynchronous code more readable by structuring it in a linear, chainable manner.</p> </li> <li> <p>Error Handling: Promises provide a centralized <code>.catch()</code> method to handle errors across the entire chain, making error management more consistent.</p> </li> <li> <p>Avoiding Callback Hell: Promises alleviate callback hell, allowing you to write cleaner and more maintainable code, especially when dealing with complex asynchronous operations.</p> </li> <li> <p>Composition: Promises encourage the composition of small, reusable functions that return Promises, promoting modularity and code reuse.</p> </li> </ul>"},{"location":"nodejs/#promiseall-and-promiserace","title":"Promise.all() and Promise.race():","text":"<p>Node.js also provides utility functions like <code>Promise.all()</code> and <code>Promise.race()</code>:</p> <ul> <li> <p><code>Promise.all()</code>: Accepts an array of Promises and returns a new Promise that resolves when all Promises in the array have resolved, or rejects when any of them rejects.</p> </li> <li> <p><code>Promise.race()</code>: Accepts an array of Promises and returns a new Promise that resolves or rejects as soon as one of the Promises in the array resolves or rejects.</p> </li> </ul> <p>These utilities are useful for handling scenarios where you need to coordinate multiple asynchronous operations.</p> <p>In conclusion, Promises are a vital part of Node.js and modern JavaScript for managing asynchronous operations effectively. They provide a cleaner and more organized way to work with asynchronous code, reducing callback complexity and improving code readability. Understanding how to create, chain, and handle Promises is essential for writing robust and maintainable Node.js applications.</p>"},{"location":"nodejs/#promiseall-and-promiserace_1","title":"Promise.all() and Promise.race():","text":"<p>In addition to the fundamental use of Promises, Node.js also provides two powerful methods, <code>Promise.all()</code> and <code>Promise.race()</code>, to handle multiple Promises simultaneously.</p>"},{"location":"nodejs/#promiseall","title":"Promise.all():","text":"<p><code>Promise.all()</code> is used when you have an array of Promises, and you want to wait for all of them to resolve successfully before proceeding. It returns a new Promise that resolves with an array of results in the same order as the input Promises.</p> <pre><code>const promises = [\n    fetchDataFromAPI('endpoint1'),\n    fetchDataFromAPI('endpoint2'),\n    fetchDataFromAPI('endpoint3')\n];\n\nPromise.all(promises)\n    .then(results =&gt; {\n        // All Promises have resolved successfully\n        console.log(results); // Array of results\n    })\n    .catch(error =&gt; {\n        // At least one Promise has rejected\n        console.error(error);\n    });\n</code></pre> <p>In this example, <code>Promise.all()</code> waits for all Promises in the <code>promises</code> array to resolve and collects their results. If any of the Promises reject, the <code>.catch()</code> block handles the error.</p>"},{"location":"nodejs/#promiserace","title":"Promise.race():","text":"<p><code>Promise.race()</code> is used when you want to respond as soon as the first Promise in an array resolves or rejects. It returns a new Promise that resolves or rejects with the result of the first Promise that settles.</p> <pre><code>const promises = [\n    fetchDataFromAPI('fastEndpoint'),\n    fetchDataFromAPI('slowEndpoint')\n];\n\nPromise.race(promises)\n    .then(result =&gt; {\n        // The first Promise resolved or rejected\n        console.log(result);\n    })\n    .catch(error =&gt; {\n        // The first Promise rejected\n        console.error(error);\n    });\n</code></pre> <p>In this example, <code>Promise.race()</code> will resolve or reject as soon as the first Promise in the <code>promises</code> array settles. If the 'fastEndpoint' Promise resolves first, you'll get its result. If the 'slowEndpoint' Promise rejects before the other resolves, you'll get its error.</p>"},{"location":"nodejs/#asyncawait-with-promises","title":"Async/Await with Promises:","text":"<p>Async/await is a syntactic feature built on top of Promises, introduced in modern JavaScript. It provides a more synchronous-looking way to work with asynchronous code.</p> <pre><code>async function fetchData() {\n    try {\n        const result = await fetchDataFromAPI('endpoint');\n        console.log(result);\n    } catch (error) {\n        console.error(error);\n    }\n}\n</code></pre> <p>In this example, the <code>async</code> function <code>fetchData()</code> uses the <code>await</code> keyword to wait for the Promise to resolve or reject. It provides a cleaner and more structured way to work with Promises, making the code resemble synchronous code.</p>"},{"location":"nodejs/#promisify","title":"Promisify:","text":"<p>In some cases, you may work with callback-based APIs in Node.js that can be converted into Promises using the <code>util.promisify</code> utility:</p> <pre><code>const util = require('util');\nconst fs = require('fs');\n\nconst readFilePromise = util.promisify(fs.readFile);\n\nreadFilePromise('example.txt', 'utf8')\n    .then(data =&gt; {\n        console.log(data);\n    })\n    .catch(error =&gt; {\n        console.error(error);\n    });\n</code></pre> <p><code>util.promisify</code> transforms functions that follow the Node.js callback pattern (error-first) into Promises, making it easier to work with such APIs in a Promise-based codebase.</p>"},{"location":"nodejs/#error-handling-in-promises","title":"Error Handling in Promises:","text":"<p>Proper error handling in Promises is essential. You can use the <code>.catch()</code> method to handle errors globally in a Promise chain, but you can also handle errors individually for each <code>.then()</code> block if needed.</p> <pre><code>fetchDataFromAPI('endpoint')\n    .then(result =&gt; {\n        // Handle success\n        console.log(result);\n    })\n    .catch(error =&gt; {\n        // Handle errors from this Promise\n        console.error(error);\n    });\n</code></pre> <p>By understanding Promises and how to work with them effectively, Node.js developers can write more organized, maintainable, and readable asynchronous code, leading to more robust and efficient applications. Promises simplify asynchronous programming, reduce callback hell, and provide a standardized way to manage async tasks and errors.</p> <p>Certainly! Continuing from the previous answer related to Promises, here are a few more important concepts and best practices to consider:</p>"},{"location":"nodejs/#promise-chaining","title":"Promise Chaining:","text":"<p>Promise chaining is a powerful feature of Promises that allows you to sequence multiple asynchronous operations in a clean and readable way. Each <code>.then()</code> block can return another Promise, enabling you to create a chain of asynchronous tasks.</p> <pre><code>fetchDataFromAPI('endpoint1')\n    .then(result1 =&gt; {\n        // Process result1 and return another Promise\n        return fetchDataFromAPI('endpoint2');\n    })\n    .then(result2 =&gt; {\n        // Process result2 and return another Promise\n        return fetchDataFromAPI('endpoint3');\n    })\n    .then(result3 =&gt; {\n        // Final result after all asynchronous tasks\n        console.log(result3);\n    })\n    .catch(error =&gt; {\n        // Handle errors from any Promise in the chain\n        console.error(error);\n    });\n</code></pre> <p>This chaining pattern makes it easy to follow the flow of asynchronous operations, avoiding callback nesting and enhancing code maintainability.</p>"},{"location":"nodejs/#returning-values-from-promises","title":"Returning Values from Promises:","text":"<p>Promises allow you to return values that can be passed along the Promise chain. This is particularly useful when you want to carry data from one step to another.</p> <pre><code>function fetchDataAndProcess() {\n    return fetchDataFromAPI('endpoint')\n        .then(result =&gt; {\n            // Process result and return data\n            const processedData = processResult(result);\n            return processedData;\n        });\n}\n\nfetchDataAndProcess()\n    .then(data =&gt; {\n        // Data from the previous Promise is available here\n        console.log(data);\n    })\n    .catch(error =&gt; {\n        console.error(error);\n    });\n</code></pre> <p>By returning values from Promises, you can ensure that data flows smoothly through your asynchronous code.</p>"},{"location":"nodejs/#async-functions","title":"Async Functions:","text":"<p>Async functions, introduced in modern JavaScript, provide a more concise way to work with Promises. You can define an async function with the <code>async</code> keyword, and within it, you can use <code>await</code> to pause execution until a Promise settles.</p> <pre><code>async function fetchDataAndProcess() {\n    try {\n        const result = await fetchDataFromAPI('endpoint');\n        const processedData = processResult(result);\n        return processedData;\n    } catch (error) {\n        throw error;\n    }\n}\n\nfetchDataAndProcess()\n    .then(data =&gt; {\n        console.log(data);\n    })\n    .catch(error =&gt; {\n        console.error(error);\n    });\n</code></pre> <p>Async functions simplify Promise-based code by making it look more like synchronous code, which can enhance readability and maintainability.</p>"},{"location":"nodejs/#promise-best-practices","title":"Promise Best Practices:","text":"<p>Here are some best practices to keep in mind when working with Promises:</p> <ul> <li> <p>Always handle errors using <code>.catch()</code> or <code>try...catch</code> within async functions to prevent unhandled promise rejections.</p> </li> <li> <p>Avoid using Promises for synchronous tasks. Promises are designed for asynchronous operations and may not provide any benefits for synchronous code.</p> </li> <li> <p>When dealing with multiple asynchronous tasks, consider using <code>Promise.all()</code> to wait for all tasks to complete or <code>Promise.race()</code> to respond to the first task that settles.</p> </li> <li> <p>If you need to execute tasks sequentially, use Promise chaining to maintain a clear and organized flow of operations.</p> </li> <li> <p>Promisify callback-based APIs using <code>util.promisify</code> or dedicated libraries like <code>bluebird</code> when working with older Node.js libraries.</p> </li> <li> <p>Be mindful of memory management when working with long-running Promises or large datasets. Proper resource handling is essential.</p> </li> </ul> <p>By following these best practices and mastering the use of Promises, you can write cleaner, more efficient, and maintainable asynchronous code in Node.js, enhancing the overall quality of your applications.</p>"},{"location":"nodejs/#securing-a-nodejs-application","title":"Securing a Node.js application","text":"<p>Securing a Node.js application is crucial to protect against potential threats. It involves a combination of best practices, including input validation, using secure dependencies, implementing authentication and authorization, enabling HTTPS, and conducting regular security audits.</p> <p>Securing a Node.js application is of paramount importance to safeguard sensitive data and prevent security breaches. Here are essential steps and best practices to ensure the security of your Node.js application:</p>"},{"location":"nodejs/#1-input-validation","title":"1. Input Validation:","text":"<p>Sanitize and validate all user inputs, including data from forms, URLs, and APIs. Use validation libraries like <code>joi</code> or built-in validation methods to ensure data integrity and prevent common vulnerabilities like SQL injection and Cross-Site Scripting (XSS) attacks.</p>"},{"location":"nodejs/#2-use-secure-dependencies","title":"2. Use Secure Dependencies:","text":"<p>Regularly update and audit your project's dependencies, including npm packages. Vulnerabilities in dependencies can be exploited, leading to security breaches. Tools like npm audit can help identify and address known vulnerabilities.</p>"},{"location":"nodejs/#3-authentication-and-authorization","title":"3. Authentication and Authorization:","text":"<p>Implement strong authentication mechanisms for user access. Use popular libraries like Passport.js for authentication and define granular authorization rules to restrict access to sensitive resources. Implement role-based access control (RBAC) when needed.</p>"},{"location":"nodejs/#4-protect-against-cross-site-request-forgery-csrf","title":"4. Protect Against Cross-Site Request Forgery (CSRF):","text":"<p>Use anti-CSRF tokens in forms and AJAX requests to prevent CSRF attacks. Libraries like <code>csurf</code> can help you implement CSRF protection in your Node.js application.</p>"},{"location":"nodejs/#5-secure-sessions","title":"5. Secure Sessions:","text":"<p>Use secure session management techniques to store session data, and always use secure, HttpOnly, and SameSite cookies. Consider using session stores like Redis for better security and scalability.</p>"},{"location":"nodejs/#6-enable-https","title":"6. Enable HTTPS:","text":"<p>Always use HTTPS to encrypt data in transit. Obtain an SSL/TLS certificate and configure your Node.js server to use it. Tools like Let's Encrypt offer free SSL certificates.</p>"},{"location":"nodejs/#7-secure-file-uploads","title":"7. Secure File Uploads:","text":"<p>If your application allows file uploads, validate file types, limit file sizes, and store uploaded files in a secure location outside the webroot. Prevent execution of uploaded files by renaming them.</p>"},{"location":"nodejs/#8-implement-security-headers","title":"8. Implement Security Headers:","text":"<p>Set security headers in your application's HTTP responses to protect against common web vulnerabilities. Headers like Content Security Policy (CSP), X-Content-Type-Options, and X-Frame-Options enhance security.</p>"},{"location":"nodejs/#9-rate-limiting-and-brute-force-protection","title":"9. Rate Limiting and Brute-Force Protection:","text":"<p>Implement rate limiting to restrict the number of requests from a single IP address to prevent brute-force attacks on login pages or APIs. Tools like <code>express-rate-limit</code> can help with this.</p>"},{"location":"nodejs/#10-logging-and-monitoring","title":"10. Logging and Monitoring:","text":"<p>Implement comprehensive logging to record application activities and security-related events. Set up monitoring and alerts to detect and respond to security incidents promptly.</p>"},{"location":"nodejs/#11-regular-security-audits","title":"11. Regular Security Audits:","text":"<p>Conduct regular security audits and penetration testing to identify vulnerabilities and weaknesses in your application. Address issues promptly and update your security measures accordingly.</p>"},{"location":"nodejs/#12-error-handling","title":"12. Error Handling:","text":"<p>Handle errors gracefully without revealing sensitive information. Implement custom error handling and avoid displaying stack traces to users.</p>"},{"location":"nodejs/#13-secure-database-access","title":"13. Secure Database Access:","text":"<p>Implement secure database connections and use parameterized queries or Object Relational Mapping (ORM) libraries to prevent SQL injection attacks.</p>"},{"location":"nodejs/#14-keep-secrets-secure","title":"14. Keep Secrets Secure:","text":"<p>Store sensitive information such as API keys, passwords, and tokens in environment variables or a secure configuration management system. Avoid hardcoding secrets in your code.</p>"},{"location":"nodejs/#15-containerization-and-isolation","title":"15. Containerization and Isolation:","text":"<p>Consider containerization with technologies like Docker to isolate your application and its dependencies. Containerization can enhance security and simplify deployment.</p>"},{"location":"nodejs/#16-content-security-policy-csp","title":"16. Content Security Policy (CSP):","text":"<p>Implement a Content Security Policy (CSP) to mitigate the risk of Cross-Site Scripting (XSS) attacks. A CSP defines which sources of content are allowed to be executed on your web page. By specifying trusted sources for scripts, styles, images, and other resources, you can reduce the likelihood of malicious scripts running in your application.</p> <pre><code>app.use(helmet.contentSecurityPolicy({\n    directives: {\n        defaultSrc: [\"'self'\"],\n        scriptSrc: [\"'self'\", 'trusted-scripts.com'],\n        styleSrc: [\"'self'\", 'trusted-styles.com'],\n        imgSrc: ['img.com', 'data:'],\n        objectSrc: [\"'none'\"],\n        upgradeInsecureRequests: true,\n    },\n}));\n</code></pre>"},{"location":"nodejs/#17-two-factor-authentication-2fa","title":"17. Two-Factor Authentication (2FA):","text":"<p>Implement Two-Factor Authentication (2FA) for user accounts, especially for sensitive applications. 2FA adds an extra layer of security by requiring users to provide a second authentication factor, such as a one-time code sent to their mobile device, in addition to their password.</p>"},{"location":"nodejs/#18-content-security-policy-csp","title":"18. Content Security Policy (CSP):","text":"<p>Implement a Content Security Policy (CSP) to mitigate the risk of Cross-Site Scripting (XSS) attacks. A CSP defines which sources of content are allowed to be executed on your web page. By specifying trusted sources for scripts, styles, images, and other resources, you can reduce the likelihood of malicious scripts running in your application.</p> <pre><code>app.use(helmet.contentSecurityPolicy({\n    directives: {\n        defaultSrc: [\"'self'\"],\n        scriptSrc: [\"'self'\", 'trusted-scripts.com'],\n        styleSrc: [\"'self'\", 'trusted-styles.com'],\n        imgSrc: ['img.com', 'data:'],\n        objectSrc: [\"'none'\"],\n        upgradeInsecureRequests: true,\n    },\n}));\n</code></pre>"},{"location":"nodejs/#19-security-headers","title":"19. Security Headers:","text":"<p>Set appropriate security headers in your application's responses. Use libraries like Helmet.js to easily configure security headers such as X-Content-Type-Options, X-Frame-Options, and X-XSS-Protection. These headers help protect your application against common web vulnerabilities.</p>"},{"location":"nodejs/#20-web-application-firewall-waf","title":"20. Web Application Firewall (WAF):","text":"<p>Consider using a Web Application Firewall (WAF) to add an extra layer of protection for your Node.js application. A WAF can help block malicious traffic, detect and mitigate common web application attacks, and provide additional security controls.</p>"},{"location":"nodejs/#21-api-security","title":"21. API Security:","text":"<p>If your Node.js application includes APIs, secure them with authentication tokens, rate limiting, and proper validation of incoming requests. Use technologies like OAuth 2.0 or JSON Web Tokens (JWT) for authentication and authorization.</p>"},{"location":"nodejs/#22-keep-dependencies-updated","title":"22. Keep Dependencies Updated:","text":"<p>Regularly update your Node.js runtime and all dependencies, including third-party packages, frameworks, and libraries. Vulnerabilities in outdated software can be exploited by attackers.</p>"},{"location":"nodejs/#23-security-training","title":"23. Security Training:","text":"<p>Invest in security training for your development team. Educate your developers about common security threats and best practices to ensure that security is built into the development process.</p>"},{"location":"nodejs/#24-incident-response-plan","title":"24. Incident Response Plan:","text":"<p>Have a well-defined incident response plan in place. Know how to respond to security incidents, including data breaches or other security breaches. Ensure that you can quickly detect, contain, and recover from security events.</p>"},{"location":"nodejs/#25-regular-security-audits-and-testing","title":"25. Regular Security Audits and Testing:","text":"<p>Perform regular security audits and testing, including penetration testing and code reviews. Identify and address security vulnerabilities early in the development lifecycle.</p>"},{"location":"nodejs/#26-data-encryption","title":"26. Data Encryption:","text":"<p>Ensure that sensitive data, such as user passwords and personal information, is properly encrypted both at rest and in transit. Use strong encryption algorithms and secure protocols like TLS/SSL for data transmission.</p>"},{"location":"nodejs/#27-error-handling","title":"27. Error Handling:","text":"<p>Implement proper error handling in your Node.js application. Avoid revealing sensitive information in error messages that could be exploited by attackers. Instead, log errors internally while providing user-friendly error messages to clients.</p>"},{"location":"nodejs/#28-security-headers-for-cross-origin-requests","title":"28. Security Headers for Cross-Origin Requests:","text":"<p>When dealing with cross-origin requests (e.g., from a web application to an API), use Cross-Origin Resource Sharing (CORS) headers to specify which origins are allowed to access your resources. Be cautious and restrict access to trusted origins only.</p> <pre><code>app.use(cors({\n    origin: 'https://trusted-website.com',\n    methods: ['GET', 'POST'],\n}));\n</code></pre>"},{"location":"nodejs/#29-password-hashing","title":"29. Password Hashing:","text":"<p>When storing user passwords, always hash them using strong and well-established password hashing algorithms like bcrypt. Avoid storing plain text passwords, and consider using salting to further enhance security.</p>"},{"location":"nodejs/#30-content-security-policy-csp-reporting","title":"30. Content Security Policy (CSP) Reporting:","text":"<p>Implement CSP reporting to monitor and report policy violations. This allows you to identify and address potential security issues in your application by receiving violation reports from the browser.</p>"},{"location":"nodejs/#31-security-headers-for-file-downloads","title":"31. Security Headers for File Downloads:","text":"<p>When serving files for download, set appropriate security headers to prevent content from being executed as scripts. Use the <code>Content-Disposition</code> header to suggest a filename and control how browsers handle the file.</p> <pre><code>res.setHeader('Content-Disposition', 'attachment; filename=\"document.pdf\"');\n</code></pre>"},{"location":"nodejs/#32-container-security","title":"32. Container Security:","text":"<p>If your Node.js application is deployed in containers (e.g., Docker), ensure that container images are regularly updated and patched to address security vulnerabilities. Follow container security best practices.</p>"},{"location":"nodejs/#33-third-party-services","title":"33. Third-Party Services:","text":"<p>If your application relies on third-party services or APIs, review their security practices and consider their impact on your application's security. Ensure that you handle external data securely.</p>"},{"location":"nodejs/#34-regular-security-training","title":"34. Regular Security Training:","text":"<p>Continuously educate your development and operations teams about security best practices. Provide training and awareness programs to keep your team informed about the latest security threats and mitigation techniques.</p>"},{"location":"nodejs/#35-compliance-with-regulations","title":"35. Compliance with Regulations:","text":"<p>If your application handles sensitive or personal data, ensure that it complies with relevant data protection regulations, such as GDPR, HIPAA, or CCPA. Implement data protection measures accordingly.</p>"},{"location":"nodejs/#36-continuous-monitoring","title":"36. Continuous Monitoring:","text":"<p>Implement continuous security monitoring and threat detection mechanisms. Tools like intrusion detection systems (IDS) and security information and event management (SIEM) systems can help detect and respond to security incidents in real-time.</p>"},{"location":"nodejs/#37-security-incident-response-plan","title":"37. Security Incident Response Plan:","text":"<p>Have a well-defined security incident response plan in place. Ensure that your team knows how to respond to security incidents promptly, including communication, mitigation, and reporting.</p> <p>Securing a Node.js application is an ongoing effort that requires a combination of best practices, tools, and a security-focused mindset. Regularly assess and update your security measures to adapt to evolving threats and vulnerabilities. Remember that security is a shared responsibility, involving developers, administrators, and end-users, to maintain a robust and protected application environment.</p>"},{"location":"nodejs/express/","title":"Express.js","text":""},{"location":"nodejs/express/#expressjs_1","title":"Express.js","text":"<p>Express is a popular web application framework for Node.js that simplifies the process of building robust and scalable web applications. It provides a set of features and middleware to handle routing, HTTP requests, middleware management, and more, making it an excellent choice for creating web APIs, web applications, and backend services.</p> <p>Express is a web application framework for Node.js that serves as a foundational building block for creating web applications and APIs. It is designed to simplify the development of server-side applications in Node.js by providing a set of powerful features and tools. Here's a detailed explanation of the use and benefits of the Express framework in Node.js:</p>"},{"location":"nodejs/express/#1-web-application-development","title":"1. Web Application Development:","text":"<p>Express is commonly used for building web applications. It simplifies the process of handling HTTP requests and responses, making it easier to create dynamic and interactive websites. Developers can define routes, templates, and controllers to structure their web applications efficiently.</p>"},{"location":"nodejs/express/#2-restful-api-development","title":"2. RESTful API Development:","text":"<p>Express is a popular choice for building RESTful APIs. It provides a clean and organized way to define API endpoints and handle incoming HTTP requests (GET, POST, PUT, DELETE, etc.). With middleware support, you can easily implement authentication, validation, and other common API functionalities.</p>"},{"location":"nodejs/express/#3-routing","title":"3. Routing:","text":"<p>Express offers a robust routing system that allows developers to define how the application responds to different HTTP requests and URL patterns. You can create routes for various parts of your application, making it easy to handle different types of requests and actions.</p> <pre><code>const express = require('express');\nconst app = express();\n\napp.get('/', (req, res) =&gt; {\n    res.send('Hello, World!');\n});\n\napp.get('/about', (req, res) =&gt; {\n    res.send('About Us');\n});\n\n// More routes can be added here\n</code></pre>"},{"location":"nodejs/express/#4-middleware","title":"4. Middleware:","text":"<p>Middleware functions in Express allow you to modify incoming requests and outgoing responses in a modular way. This enables you to add functionalities such as authentication, logging, error handling, and data parsing at specific points in the request-response cycle.</p> <pre><code>app.use(express.json()); // Parse JSON data from requests\napp.use(express.urlencoded({ extended: true })); // Parse URL-encoded data\napp.use(middlewareFunction); // Custom middleware\n</code></pre>"},{"location":"nodejs/express/#5-template-engines","title":"5. Template Engines:","text":"<p>Express can be integrated with various template engines like EJS, Handlebars, Pug (formerly Jade), and more. Template engines facilitate the dynamic generation of HTML pages and views, making it easier to build server-rendered web applications.</p>"},{"location":"nodejs/express/#6-database-integration","title":"6. Database Integration:","text":"<p>Express can be used with various databases and ORMs (Object-Relational Mapping libraries) like MongoDB, Mongoose, PostgreSQL, Sequelize, and others. This makes it versatile for building applications that require database interactions.</p>"},{"location":"nodejs/express/#7-scalability","title":"7. Scalability:","text":"<p>Express is designed to be lightweight and unopinionated, allowing developers to choose the components and libraries that best suit their needs. This flexibility makes it well-suited for both small-scale projects and large-scale, high-performance applications.</p>"},{"location":"nodejs/express/#8-community-and-ecosystem","title":"8. Community and Ecosystem:","text":"<p>Express has a vast and active community of developers, which results in a rich ecosystem of middleware, extensions, and plugins. This makes it easy to find solutions and resources for common development challenges.</p>"},{"location":"nodejs/express/#9-security","title":"9. Security:","text":"<p>While Express provides the building blocks for web applications, developers are responsible for implementing security measures. Express itself does not enforce security, but it offers middleware options and best practices to help secure applications against common threats.</p>"},{"location":"nodejs/express/#10-error-handling","title":"10. Error Handling:","text":"<p>Express provides built-in error handling mechanisms and middleware for handling errors gracefully. You can define error-handling middleware to centralize error processing and ensure that errors do not crash your application.</p> <pre><code>app.use((err, req, res, next) =&gt; {\n    // Custom error handling logic\n    console.error(err);\n    res.status(500).send('Internal Server Error');\n});\n</code></pre>"},{"location":"nodejs/express/#11-session-management","title":"11. Session Management:","text":"<p>Express can be used with various session management solutions, such as Express Sessions or third-party middleware like <code>express-session</code>. This enables you to manage user sessions and authentication in your web applications.</p>"},{"location":"nodejs/express/#12-websocket-support","title":"12. WebSocket Support:","text":"<p>While Express primarily deals with HTTP requests and responses, it can be extended to support WebSockets through libraries like <code>socket.io</code>. This allows real-time communication between the server and clients, making it suitable for applications that require instant updates and notifications.</p>"},{"location":"nodejs/express/#13-extensible-and-customizable","title":"13. Extensible and Customizable:","text":"<p>Express is highly extensible, allowing you to add custom middleware, routers, and functionality to meet the specific requirements of your application. You can create modular and organized code structures tailored to your project's needs.</p>"},{"location":"nodejs/express/#14-testing-and-debugging","title":"14. Testing and Debugging:","text":"<p>Express applications are relatively easy to test using testing frameworks like Mocha, Chai, or Jest. You can write unit tests and integration tests to ensure the reliability and correctness of your application.</p>"},{"location":"nodejs/express/#15-proxy-and-api-gateway","title":"15. Proxy and API Gateway:","text":"<p>Express can be used as a proxy or API gateway to route and manage incoming requests to various backend services. This is particularly useful when building microservices architectures or handling multiple APIs.</p>"},{"location":"nodejs/express/#16-websocket-support","title":"16. WebSocket Support:","text":"<p>While Express primarily deals with HTTP requests and responses, it can be extended to support WebSockets through libraries like <code>socket.io</code>. This allows real-time communication between the server and clients, making it suitable for applications that require instant updates and notifications.</p>"},{"location":"nodejs/express/#17-community-and-documentation","title":"17. Community and Documentation:","text":"<p>Express has a large and active community of developers, which means you can easily find tutorials, documentation, and solutions to common problems. The official Express documentation is comprehensive and regularly updated.</p>"},{"location":"nodejs/express/#18-middleware-ecosystem","title":"18. Middleware Ecosystem:","text":"<p>Express boasts a vast middleware ecosystem, offering a wide range of pre-built middleware components to enhance your application's functionality. Whether you need authentication, compression, logging, or CORS handling, there's likely a middleware package available to streamline the process.</p>"},{"location":"nodejs/express/#19-compatibility-with-frontend-frameworks","title":"19. Compatibility with Frontend Frameworks:","text":"<p>Express can be easily integrated with popular frontend frameworks and libraries like React, Angular, and Vue.js. This allows you to build full-stack applications, where Express serves as the backend API while your frontend framework handles the user interface.</p>"},{"location":"nodejs/express/#20-restful-architecture","title":"20. RESTful Architecture:","text":"<p>Express's flexibility and routing system make it well-suited for implementing RESTful architectures. You can define clean and structured APIs with clear endpoints, making it easier to follow best practices for RESTful API design.</p>"},{"location":"nodejs/express/#21-hosting-and-deployment","title":"21. Hosting and Deployment:","text":"<p>Deploying Express applications is straightforward. You can host your applications on various platforms, including cloud services like AWS, Heroku, or Azure, or deploy them to your own servers. Express applications are highly portable and can be run on different hosting environments.</p>"},{"location":"nodejs/express/#22-single-page-applications-spas","title":"22. Single-Page Applications (SPAs):","text":"<p>Express can serve as the backend for single-page applications (SPAs). By providing RESTful APIs and handling routing on the server, you can create SPAs that deliver a seamless user experience with client-side navigation while benefiting from server-side rendering for SEO and initial page load speed.</p>"},{"location":"nodejs/express/#23-community-driven-development","title":"23. Community-Driven Development:","text":"<p>With a vibrant community, Express is continuously evolving. Developers frequently contribute to the framework, which means you can benefit from updates, bug fixes, and new features. It also ensures that Express remains relevant and up-to-date with modern web development practices.</p>"},{"location":"nodejs/express/#24-proxy-and-reverse-proxy","title":"24. Proxy and Reverse Proxy:","text":"<p>Express can be configured to act as a proxy or reverse proxy server. This is useful when you need to route incoming requests to different backend servers or services based on specific criteria, such as URL paths or headers.</p> <p>In summary, Express is a versatile and widely adopted framework for Node.js that simplifies web application and API development. Its flexibility, extensive middleware ecosystem, and ease of use make it an excellent choice for developers looking to create efficient and robust Node.js applications. Whether you're building a simple web app, a RESTful API, or a full-stack application, Express provides the tools and features needed to streamline development and deliver high-performance solutions.</p>"},{"location":"projects/banks/","title":"Banking, Finance Services and Insurance","text":"<p>...</p>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#learning-corner-empowering-knowledge-sharing","title":"Learning Corner: Empowering Knowledge Sharing","text":"","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#user-registration-and-preferences","title":"User Registration and Preferences","text":"<ul> <li> <p>User Signup: Create a new account to embark on your learning journey.</p> </li> <li> <p>Role Selection: Choose to be a Learner or a Mentor, defining your role in the community.</p> </li> <li> <p>Learning Schedule: Set your preferred learning hours, whether it's during the day or night.</p> </li> <li> <p>Mentor Availability: Mentors can specify their teaching hours for optimal engagement.</p> </li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#mentor-qualifications","title":"Mentor Qualifications","text":"<ul> <li>Mentor Criteria: Mentors must showcase their expertise by adding programming languages, tech stacks, or years of experience to their profile.</li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#learning-and-seeking-help","title":"Learning and Seeking Help","text":"<ul> <li> <p>Learner Access: Sign in as a Learner to start your learning experience.</p> </li> <li> <p>Seeking Guidance: Learners can request help from a Mentor by posting questions or seeking assistance.</p> </li> <li> <p>Resource Suggestions: Receive relevant links and articles when posting questions, aiding learners while they await responses.</p> </li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#interactive-learning-community","title":"Interactive Learning Community","text":"<ul> <li> <p>Chat Functionality: Learners and Mentors can engage in real-time conversations within the platform.</p> </li> <li> <p>Messaging: Learners can send messages to Mentors for personalized guidance.</p> </li> <li> <p>Mentor Access: Sign in as a Mentor to offer your expertise and mentorship.</p> </li> <li> <p>Message Management: Mentors can view and respond to messages from learners.</p> </li> <li> <p>Online Presence: See who else is currently online when signed in, fostering a sense of community.</p> </li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#profile-management-and-account-actions","title":"Profile Management and Account Actions","text":"<ul> <li> <p>Profile Editing: Users can manage and update their account profile details for accuracy and relevance.</p> </li> <li> <p>Keyword Optimization: If no resources are available, suggest users try different keywords or search terms.</p> </li> <li> <p>Account Deletion: Users have the option to delete their account if needed.</p> </li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#blogging-and-knowledge-sharing","title":"Blogging and Knowledge Sharing","text":"<ul> <li> <p>Blogging: Users can contribute to their blogs, sharing insights, experiences, and knowledge.</p> </li> <li> <p>Reading Others' Blogs: Explore blog posts created by fellow users to gain valuable insights.</p> </li> <li> <p>Interactions: Users can express their opinions by liking or disliking blog posts, encouraging interaction.</p> </li> </ul> <p>The Learning Corner platform aims to create a vibrant learning community where learners and mentors collaborate, share knowledge, and grow together. Whether you're seeking guidance or offering mentorship, this platform provides a comprehensive learning experience.</p>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#barclays-application-enhancements","title":"Barclays Application Enhancements","text":"<p>Working on Barclays application projects for pre-trade market functionality enhancements demonstrates your involvement in optimizing trading processes. This might include improving algorithms, enhancing order validation, or optimizing trade execution for better market outcomes.</p>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#crb-module-development","title":"CRB Module Development","text":"<p>Developing new feature changes for the CRB module showcases your ability to innovate within a specific domain. You've likely worked on adding functionalities, improving user experiences, or enhancing the module's overall performance.</p>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#microservices-in-action","title":"Microservices in Action","text":"<p>The migration from a monolithic application to microservices architecture involved decomposing the application into smaller, manageable services. Let's explore some of these key microservices:</p>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#order-management-service-oms","title":"Order Management Service (OMS)","text":"<ul> <li>Business Functionality: Responsible for processing and managing trade orders from clients.</li> <li>Business Flow: Receives trade orders through various communication protocols, validates them, performs necessary checks, and stores them in a database. It can also generate and send order confirmations to clients.</li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#trade-execution-service","title":"Trade Execution Service","text":"<ul> <li>Business Functionality: Executes approved trade orders received from the OMS.</li> <li>Business Flow: Retrieves trade orders from the OMS, ensures the availability of necessary funds or assets, and executes trades in the market. After execution, it updates trade statuses and sends notifications back to the OMS.</li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#risk-management-service","title":"Risk Management Service","text":"<ul> <li>Business Functionality: Evaluates and manages trade-related risks and the overall portfolio.</li> <li>Business Flow: Receives trade details from the OMS or Trade Execution Service, assesses their risk profiles, performs risk calculations (e.g., VaR), and applies mitigation strategies if necessary.</li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#account-management-service","title":"Account Management Service","text":"<ul> <li>Business Functionality: Manages client accounts and portfolio information.</li> <li>Business Flow: Handles client account registration, updates, and closures. Stores and maintains data related to client portfolios, positions, and transaction history.</li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#reporting-service","title":"Reporting Service","text":"<ul> <li>Business Functionality: Generates various reports for clients and internal stakeholders.</li> <li>Business Flow: Collects data from different microservices, processes it, and generates reports based on specific requirements. Reports may include account statements, trade histories, risk reports, and performance summaries.</li> </ul>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/banks/#notification-service","title":"Notification Service","text":"<ul> <li>Business Functionality: Sends out notifications to clients and relevant parties for various events.</li> <li>Business Flow: Monitors system events, such as trade execution status, account updates, and market news. Notifies clients via emails, SMS, or other communication channels.</li> </ul> <p>Your journey in migrating a monolithic application to a microservices architecture, combined with your work on Barclays projects and CRB module development, demonstrates your proficiency in Java-based technologies and your ability to tackle complex financial systems. The successful integration of technologies like Maven, Spring Boot, Hibernate, and Kafka has played a pivotal role in achieving a more agile and scalable system. Your expertise in these areas is invaluable for modernizing and optimizing financial applications.</p>","tags":["Banking","Finance Services","Insurance"]},{"location":"projects/company/","title":"company","text":"","tags":["company"]},{"location":"projects/company/#government-and-public-sector","title":"Government and Public Sector:","text":"<p>Government agencies, public services, and organizations focused on civic technology and public administration.</p>","tags":["company"]},{"location":"projects/company/#siemens","title":"Siemens","text":"<p>Siemens is a global conglomerate that offers a wide range of services and products in various industries. As an international powerhouse, Siemens has a significant presence in the fields of technology, energy, healthcare, and more. Here, we will delve into the various services and sectors where Siemens plays a vital role:</p>","tags":["company"]},{"location":"projects/company/#energy-services","title":"Energy Services","text":"<p>Siemens is a key player in the energy sector, providing solutions for power generation, transmission, and distribution. They offer services related to:</p> <ul> <li> <p>Power Generation: Siemens offers a range of technologies for power generation, including gas turbines, steam turbines, and wind turbines. They focus on increasing energy efficiency and reducing environmental impact.</p> </li> <li> <p>Energy Management: Siemens helps businesses and utilities optimize their energy consumption through innovative solutions in automation, control systems, and grid management.</p> </li> </ul>","tags":["company"]},{"location":"projects/company/#healthcare-services","title":"Healthcare Services","text":"<p>In the healthcare industry, Siemens is known for its advanced medical equipment and solutions, including:</p> <ul> <li> <p>Medical Imaging: Siemens produces cutting-edge medical imaging devices such as MRI machines, CT scanners, and ultrasound systems that aid in diagnosis and treatment.</p> </li> <li> <p>Healthcare IT: They provide healthcare information technology solutions to manage patient data, improve clinical workflows, and enhance healthcare outcomes.</p> </li> </ul>","tags":["company"]},{"location":"projects/company/#transportation-services","title":"Transportation Services","text":"<p>Siemens plays a vital role in the transportation sector, offering solutions for efficient and sustainable mobility. This includes:</p> <ul> <li> <p>Rail Solutions: Siemens provides railway systems, including high-speed trains, light rail, and signaling technology, to improve the efficiency and safety of transportation networks.</p> </li> <li> <p>Traffic Management: They develop intelligent traffic management systems to reduce congestion, enhance road safety, and improve urban mobility.</p> </li> </ul>","tags":["company"]},{"location":"projects/company/#industrial-services","title":"Industrial Services","text":"<p>Siemens offers various industrial services to improve manufacturing processes and automation:</p> <ul> <li> <p>Automation and Control: Siemens specializes in industrial automation, control systems, and software to optimize manufacturing operations.</p> </li> <li> <p>Digitalization: They assist industries in transitioning to Industry 4.0 by implementing digital solutions for smart manufacturing and data analytics.</p> </li> </ul>","tags":["company"]},{"location":"projects/company/#building-technologies","title":"Building Technologies","text":"<p>Siemens focuses on creating comfortable, efficient, and sustainable building environments through services such as:</p> <ul> <li> <p>Building Automation: They provide building management systems, HVAC solutions, and energy-efficient technologies for smart buildings.</p> </li> <li> <p>Fire Safety and Security: Siemens offers fire protection, security, and access control systems to ensure the safety of people and assets within buildings.</p> </li> </ul>","tags":["company"]},{"location":"projects/company/#financial-services","title":"Financial Services","text":"<p>Siemens Financial Services (SFS) complements their core businesses by providing financing solutions for Siemens equipment and technology investments.</p>","tags":["company"]},{"location":"projects/company/#research-and-development","title":"Research and Development","text":"<p>Siemens invests heavily in research and development to drive innovation across all sectors, contributing to advancements in technology and sustainability.</p> <p>Siemens is a global leader in delivering cutting-edge solutions across these various sectors, contributing to technological progress, sustainability, and improved quality of life. If you require more specific information about any of these services or need assistance with any other topic, please feel free to ask.</p>","tags":["company"]},{"location":"projects/company/#five9","title":"Five9","text":"<p>Five9 is a well-known company in the field of cloud-based contact center solutions. They offer a range of services and technologies designed to enhance customer service and support operations. In San Ramon, California, where Five9 is headquartered, they provide various services and support. Here's an overview of what you can expect from Five9 in San Ramon, CA:</p>","tags":["company"]},{"location":"projects/company/#1-cloud-contact-center-software","title":"1. Cloud Contact Center Software","text":"<p>Five9 is renowned for its cloud-based contact center software. They offer a comprehensive suite of tools and features that enable organizations to efficiently manage customer interactions. This includes inbound and outbound call management, interactive voice response (IVR) systems, omnichannel support (phone, email, chat, social media), and workforce management.</p>","tags":["company"]},{"location":"projects/company/#2-customer-engagement-solutions","title":"2. Customer Engagement Solutions","text":"<p>Five9's services are geared towards enhancing customer engagement. In San Ramon, organizations can leverage their technology to build stronger customer relationships. This involves features like intelligent routing to connect customers with the most appropriate agents, real-time analytics for performance monitoring, and tools to personalize customer interactions.</p>","tags":["company"]},{"location":"projects/company/#3-integration-services","title":"3. Integration Services","text":"<p>Five9 provides integration capabilities to connect their contact center software with other systems and applications that organizations use. This ensures a seamless flow of data and information, improving overall efficiency and providing agents with the necessary information to assist customers effectively.</p>","tags":["company"]},{"location":"projects/company/#4-professional-services","title":"4. Professional Services","text":"<p>Five9 offers professional services that can be especially beneficial to businesses in San Ramon. These services may include implementation, training, and ongoing support to help organizations make the most of their contact center solutions.</p>","tags":["company"]},{"location":"projects/company/#5-analytics-and-reporting","title":"5. Analytics and Reporting","text":"<p>Five9's software includes robust analytics and reporting features. Organizations in San Ramon can use these tools to gain insights into customer interactions, agent performance, and overall contact center efficiency. Data-driven decision-making is a key focus of their services.</p>","tags":["company"]},{"location":"projects/company/#6-compliance-and-security","title":"6. Compliance and Security","text":"<p>Five9 places a strong emphasis on compliance and security. They provide services to help organizations meet regulatory requirements and maintain the security of customer data. This is particularly important for businesses in San Ramon that handle sensitive customer information.</p>","tags":["company"]},{"location":"projects/company/#7-scalability-and-flexibility","title":"7. Scalability and Flexibility","text":"<p>Five9's solutions are designed to be scalable and flexible, allowing organizations to adapt to changing business needs. Whether a company is experiencing growth or needs to scale down, Five9's services can accommodate these changes.</p>","tags":["company"]},{"location":"projects/company/#8-remote-work-solutions","title":"8. Remote Work Solutions","text":"<p>In light of the evolving work landscape, Five9 also offers solutions to support remote and hybrid contact center operations. This can be of great relevance to businesses in San Ramon seeking flexibility in their workforce arrangements.</p>","tags":["company"]},{"location":"projects/company/#american-eagle","title":"American Eagle","text":"<p>American Eagle is a popular clothing and accessories retailer with stores across the United States. In Harrisburg, Pennsylvania, American Eagle provides a range of services and offerings to cater to its customers. Here's an overview of the services you can expect from American Eagle in Harrisburg, PA.</p>","tags":["company"]},{"location":"projects/company/#1-clothing-and-apparel","title":"1. Clothing and Apparel","text":"<p>American Eagle is primarily known for its clothing and apparel. In Harrisburg, PA, you can visit their physical store to browse and purchase a wide variety of clothing items for men and women. This includes jeans, tops, outerwear, activewear, and accessories. They often feature the latest fashion trends and a range of sizes to accommodate different body types.</p>","tags":["company"]},{"location":"projects/company/#2-denim-and-jeans","title":"2. Denim and Jeans","text":"<p>American Eagle is particularly well-known for its denim and jeans collection. They offer a diverse selection of fits, styles, and washes. Shoppers in Harrisburg can explore different denim options to find the perfect pair of jeans that suit their preferences and body type.</p>","tags":["company"]},{"location":"projects/company/#3-aerie-by-american-eagle-outfitters","title":"3. Aerie by American Eagle Outfitters","text":"<p>Aerie is a sub-brand of American Eagle that specializes in intimate apparel and loungewear. Customers in Harrisburg can find a variety of bras, underwear, sleepwear, and activewear designed for comfort and style.</p>","tags":["company"]},{"location":"projects/company/#4-online-shopping-and-e-commerce","title":"4. Online Shopping and E-commerce","text":"<p>American Eagle has a user-friendly website and an online store that serves customers in Harrisburg and beyond. You can shop online, browse their entire catalog, and take advantage of online-exclusive deals and promotions.</p>","tags":["company"]},{"location":"projects/company/#5-in-store-shopping-experience","title":"5. In-Store Shopping Experience","text":"<p>If you prefer a physical shopping experience, the American Eagle store in Harrisburg provides a well-organized and welcoming atmosphere. Store associates are available to assist with sizing, styling, and product information.</p>","tags":["company"]},{"location":"projects/company/#6-returns-and-exchanges","title":"6. Returns and Exchanges","text":"<p>American Eagle typically offers a straightforward returns and exchanges policy. If you purchase an item in Harrisburg and need to return or exchange it, you can usually do so at the store, following their established guidelines.</p>","tags":["company"]},{"location":"projects/company/#7-sales-and-promotions","title":"7. Sales and Promotions","text":"<p>American Eagle frequently runs sales, discounts, and promotions on their products. Shoppers in Harrisburg can take advantage of these offers to get their favorite clothing items at a discounted price.</p> <p>It's worth noting that American Eagle's services and offerings may vary from time to time, so it's a good idea to check their official website or contact the specific Harrisburg, PA store for the most up-to-date information on their services, hours of operation, and any special events or promotions they may have.</p>","tags":["company"]},{"location":"projects/company/#walmart","title":"Walmart","text":"<p>Walmart, one of the world's largest retail corporations, offers a wide range of services in addition to their core retail operations. Here, we'll explore some of the key services provided by Walmart:</p>","tags":["company"]},{"location":"projects/company/#1-retail-stores","title":"1. Retail Stores:","text":"<p>Walmart is primarily known for its extensive network of retail stores. They offer a diverse range of products, including groceries, electronics, clothing, household goods, and more. These physical stores are a cornerstone of Walmart's business.</p>","tags":["company"]},{"location":"projects/company/#2-online-shopping","title":"2. Online Shopping:","text":"<p>Walmart has a robust online presence through their website and mobile app. Customers can browse and purchase products online, with options for in-store pickup or home delivery. This online platform has expanded Walmart's reach, making it convenient for customers to shop from the comfort of their homes.</p>","tags":["company"]},{"location":"projects/company/#3-grocery-delivery-and-pickup","title":"3. Grocery Delivery and Pickup:","text":"<p>Walmart provides grocery delivery and pickup services through initiatives like Walmart Grocery Delivery and Walmart Grocery Pickup. Customers can order groceries online and have them delivered to their doorstep or prepare an order for pickup at a nearby store.</p>","tags":["company"]},{"location":"projects/company/#4-pharmacy-services","title":"4. Pharmacy Services:","text":"<p>Many Walmart stores have in-house pharmacies offering prescription and over-the-counter medications. They also provide services such as flu shots and health screenings.</p>","tags":["company"]},{"location":"projects/company/#5-money-services","title":"5. Money Services:","text":"<p>Walmart offers financial services like check cashing, money transfers, bill payments, and prepaid card services through Walmart MoneyCenter. This makes it convenient for customers to manage their financial needs.</p>","tags":["company"]},{"location":"projects/company/#6-automotive-services","title":"6. Automotive Services:","text":"<p>Some Walmart stores have automotive centers where customers can get oil changes, tire services, and other automotive maintenance and repair services.</p>","tags":["company"]},{"location":"projects/company/#7-walmart-subscription","title":"7. Walmart+ Subscription:","text":"<p>Walmart offers a subscription service called Walmart+ that provides various benefits to members, including free delivery, discounts on fuel, and access to tools like Walmart Scan &amp; Go for faster in-store shopping.</p>","tags":["company"]},{"location":"projects/company/#8-walmart-health-centers","title":"8. Walmart Health Centers:","text":"<p>Walmart has opened a few Walmart Health Centers in select locations, providing primary care, dental, and mental health services at affordable prices.</p>","tags":["company"]},{"location":"projects/company/#9-photo-services","title":"9. Photo Services:","text":"<p>Customers can use Walmart's photo services to print photos, create personalized gifts, and even design custom photo books.</p>","tags":["company"]},{"location":"projects/company/#10-financial-products","title":"10. Financial Products:","text":"<p>Walmart offers a range of financial products, including credit cards and prepaid debit cards, in collaboration with financial institutions.</p> <p>In summary, Walmart is not just a retail store; it's a versatile company that offers a wide array of services to cater to the diverse needs of its customers. Whether you're shopping for groceries, seeking healthcare services, managing your finances, or even printing photos, Walmart has something to offer.</p>","tags":["company"]},{"location":"projects/company/#horizon-blue-cross-blue-shield-bcbs","title":"Horizon Blue Cross Blue Shield (BCBS)","text":"<p>Horizon Blue Cross Blue Shield (Horizon BCBS) is a prominent health insurance provider in the United States, primarily serving the residents of New Jersey. They offer a wide range of healthcare services and insurance plans to cater to the diverse needs of their members.</p>","tags":["company"]},{"location":"projects/company/#health-insurance-plans","title":"Health Insurance Plans","text":"<p>Horizon BCBS offers various health insurance plans, including: - Individual and Family Plans: These are designed for individuals and families who need coverage for medical services, prescription drugs, preventive care, and more. - Medicare Plans: Horizon BCBS provides Medicare Advantage plans and Medicare Supplement insurance to seniors and eligible individuals. - Employer-Sponsored Plans: They offer group health insurance plans for employers, covering their employees' healthcare needs. - Medicaid Plans: For low-income individuals and families, Horizon BCBS provides Medicaid managed care plans.</p>","tags":["company"]},{"location":"projects/company/#services-and-benefits","title":"Services and Benefits","text":"<p>Horizon BCBS provides an array of services and benefits to its members:</p>","tags":["company"]},{"location":"projects/company/#1-medical-services","title":"1. Medical Services","text":"<ul> <li>Primary Care Physician (PCP) Network: Members can choose a primary care physician from the network for routine check-ups and referrals to specialists.</li> <li>Specialist Care: Access to a network of specialists for specialized medical care.</li> <li>Hospital Coverage: Coverage for inpatient and outpatient hospital services.</li> <li>Emergency Care: Coverage for emergency room visits.</li> </ul>","tags":["company"]},{"location":"projects/company/#2-prescription-drug-coverage","title":"2. Prescription Drug Coverage","text":"<ul> <li>Formulary: A list of covered prescription drugs.</li> <li>Pharmacy Network: Access to a network of pharmacies for prescription refills.</li> </ul>","tags":["company"]},{"location":"projects/company/#3-preventive-care","title":"3. Preventive Care","text":"<ul> <li>Horizon BCBS emphasizes preventive services, including vaccinations, screenings, and wellness programs.</li> </ul>","tags":["company"]},{"location":"projects/company/#4-telehealth-services","title":"4. Telehealth Services","text":"<ul> <li>Many Horizon BCBS plans offer telehealth services, allowing members to consult with healthcare providers remotely.</li> </ul>","tags":["company"]},{"location":"projects/company/#5-mental-health-and-behavioral-health-services","title":"5. Mental Health and Behavioral Health Services","text":"<ul> <li>Coverage for mental health and substance abuse treatment services.</li> </ul>","tags":["company"]},{"location":"projects/company/#6-additional-benefits","title":"6. Additional Benefits","text":"<ul> <li>Some plans offer extra benefits such as vision and dental coverage, fitness programs, and discounts on health-related services.</li> </ul> <p>Horizon BCBS is committed to promoting overall well-being and providing its members with access to quality healthcare. It's essential to review the specific plan details and benefits associated with your Horizon BCBS policy, as they may vary depending on the plan you've chosen. If you have any further questions or need more specific information about Horizon BCBS and their services, please feel free to ask.</p>","tags":["company"]},{"location":"projects/company/#usaa","title":"USAA","text":"<p>USAA (United Services Automobile Association) offers a wide range of financial and insurance services primarily to members of the U.S. military and their families. Here's an overview of some of the key services provided by USAA:</p>","tags":["company"]},{"location":"projects/company/#1-banking-services","title":"1. Banking Services","text":"<ul> <li>USAA offers various banking services, including checking and savings accounts, certificates of deposit (CDs), and money market accounts. They also provide ATM fee reimbursement for a certain number of withdrawals each month.</li> <li>You can manage your banking needs online or through their mobile app, making it convenient for members who are stationed around the world.</li> </ul>","tags":["company"]},{"location":"projects/company/#2-insurance-products","title":"2. Insurance Products","text":"<ul> <li>USAA is known for its insurance offerings, including auto insurance, homeowners insurance, renters insurance, and life insurance. They offer competitive rates and discounts for military members and their families.</li> <li>Their insurance services extend to cover various types of property, vehicles, and personal belongings.</li> </ul>","tags":["company"]},{"location":"projects/company/#3-investment-services","title":"3. Investment Services","text":"<ul> <li>USAA provides investment products and services, such as mutual funds, individual retirement accounts (IRAs), and brokerage accounts. Members can access investment tools and resources to help them plan for their financial future.</li> </ul>","tags":["company"]},{"location":"projects/company/#4-retirement-planning","title":"4. Retirement Planning","text":"<ul> <li>USAA assists members in planning for retirement by offering retirement accounts like IRAs and 401(k) rollovers. They provide retirement calculators and educational resources to help individuals make informed decisions about their financial future.</li> </ul>","tags":["company"]},{"location":"projects/company/#5-auto-loans-and-mortgages","title":"5. Auto Loans and Mortgages","text":"<ul> <li>USAA offers competitive auto loans and mortgages to its members. They provide tools to help you calculate loan payments and find the right financing option for your needs.</li> </ul>","tags":["company"]},{"location":"projects/company/#6-financial-advice","title":"6. Financial Advice","text":"<ul> <li>Members can access financial advice and planning services through USAA's team of financial advisors. They can help with goal setting, investment strategies, and other financial planning needs.</li> </ul>","tags":["company"]},{"location":"projects/company/#7-member-community","title":"7. Member Community","text":"<ul> <li>USAA fosters a strong sense of community among its members. They have online forums and resources where members can connect, share experiences, and receive support.</li> </ul>","tags":["company"]},{"location":"projects/company/#8-digital-banking","title":"8. Digital Banking","text":"<ul> <li>USAA's digital banking platform allows members to conduct most of their financial transactions online or via the mobile app. This is particularly convenient for members who may be deployed or stationed in remote locations.</li> </ul> <p>USAA's commitment to serving the military community has made it a trusted institution for its members. Their services are tailored to the unique needs and challenges faced by those in the armed forces. If you have specific questions about any of these services or need more information, feel free to ask, and I'll be happy to provide further details and insights.</p>","tags":["company"]},{"location":"projects/company/#target-services","title":"Target Services","text":"<p>Target is a well-known retail chain that offers a variety of services to its customers in Minneapolis, Minnesota. Here are some of the primary services provided by Target stores in the Minneapolis area:</p>","tags":["company"]},{"location":"projects/company/#1-retail-shopping","title":"1. Retail Shopping:","text":"<ul> <li>Target stores in Minneapolis offer a wide range of retail products, including clothing, electronics, home goods, groceries, and more. Customers can shop for everyday essentials and find a variety of brands and products.</li> </ul>","tags":["company"]},{"location":"projects/company/#2-grocery-shopping","title":"2. Grocery Shopping:","text":"<ul> <li>Many Target locations in Minneapolis have grocery sections where customers can purchase fresh produce, packaged foods, and household items. Target's grocery department includes a selection of organic and healthy options.</li> </ul>","tags":["company"]},{"location":"projects/company/#3-online-shopping-and-delivery","title":"3. Online Shopping and Delivery:","text":"<ul> <li>Target offers an online shopping platform where customers can browse and purchase products for home delivery or in-store pickup. This service provides convenience for those who prefer to shop from the comfort of their homes.</li> </ul>","tags":["company"]},{"location":"projects/company/#4-pharmacy-services_1","title":"4. Pharmacy Services:","text":"<ul> <li>Target stores with pharmacies in Minneapolis provide prescription services, over-the-counter medications, and health and wellness products. Customers can also get flu shots and vaccinations at select locations.</li> </ul>","tags":["company"]},{"location":"projects/company/#5-electronics-and-technology","title":"5. Electronics and Technology:","text":"<ul> <li>Target offers a range of electronics and technology products, including smartphones, tablets, laptops, gaming consoles, and accessories. Customers can explore the latest gadgets and tech accessories.</li> </ul>","tags":["company"]},{"location":"projects/company/#6-home-and-furniture","title":"6. Home and Furniture:","text":"<ul> <li>Target stores feature a selection of home decor, furniture, and furnishings. Customers can find items to decorate and furnish their homes, from kitchen essentials to bedding and furniture.</li> </ul>","tags":["company"]},{"location":"projects/company/#7-clothing-and-apparel","title":"7. Clothing and Apparel:","text":"<ul> <li>Target is known for its affordable and stylish clothing options for men, women, and children. Customers can shop for clothing, shoes, and accessories in various styles and sizes.</li> </ul>","tags":["company"]},{"location":"projects/company/#8-beauty-and-personal-care","title":"8. Beauty and Personal Care:","text":"<ul> <li>Target offers a wide range of beauty and personal care products, including cosmetics, skincare, haircare, and grooming essentials. Customers can explore beauty brands and products.</li> </ul>","tags":["company"]},{"location":"projects/company/#9-household-essentials","title":"9. Household Essentials:","text":"<ul> <li>Target stocks household essentials such as cleaning supplies, kitchenware, and home organization products. Customers can find items to maintain and organize their living spaces.</li> </ul>","tags":["company"]},{"location":"projects/company/#10-customer-services","title":"10. Customer Services:","text":"<pre><code>- Target provides customer services, including returns and exchanges, assistance with online orders, and inquiries about products and services.\n</code></pre> <p>Please note that the specific services and product offerings may vary depending on the individual Target store location in Minneapolis, MN. It's a good idea to check the Target website or contact your nearest store for the most up-to-date information on services, hours of operation, and available products.</p>","tags":["company"]},{"location":"projects/company/#verizon","title":"Verizon","text":"<p>Verizon is a telecommunications company that offers a range of services including:</p>","tags":["company"]},{"location":"projects/company/#wireless-services","title":"Wireless Services:","text":"<p>Verizon provides wireless phone and data services. They offer various plans, including unlimited data plans, and have a wide coverage area in the United States.</p>","tags":["company"]},{"location":"projects/company/#internet-services","title":"Internet Services:","text":"<p>Verizon offers high-speed internet services to residential and business customers. They provide both DSL and fiber-optic internet connections.</p>","tags":["company"]},{"location":"projects/company/#tv-services","title":"TV Services:","text":"<p>Verizon also offers TV services, known as Verizon Fios TV. They provide a selection of channels and on-demand content for their customers.</p>","tags":["company"]},{"location":"projects/company/#home-phone-services","title":"Home Phone Services:","text":"<p>Verizon offers home phone services, which can be bundled with their internet and TV services.</p>","tags":["company"]},{"location":"projects/company/#business-solutions","title":"Business Solutions:","text":"<p>For businesses, Verizon provides a range of services including business internet, phone, and networking solutions.</p>","tags":["company"]},{"location":"projects/company/#wells-fargo","title":"Wells Fargo","text":"<p>Wells Fargo is a prominent financial institution that offers a wide range of financial services and products to its customers. Some of the key services provided by Wells Fargo include:</p>","tags":["company"]},{"location":"projects/company/#1-banking-services_1","title":"1. Banking Services","text":"<ul> <li>Checking Accounts: Wells Fargo offers various checking account options to suit different customer needs, from basic accounts with no monthly fees to premium accounts with additional benefits.</li> <li>Savings Accounts: Customers can open savings accounts to save money and earn interest on their deposits.</li> <li>Online Banking: Wells Fargo provides online banking services, allowing customers to manage their accounts, pay bills, and transfer funds conveniently.</li> <li>Mobile Banking: The bank has a user-friendly mobile app that enables customers to perform banking transactions on their smartphones.</li> </ul>","tags":["company"]},{"location":"projects/company/#2-credit-and-lending","title":"2. Credit and Lending","text":"<ul> <li>Credit Cards: Wells Fargo offers a range of credit card options with various rewards and benefits, including cashback, travel rewards, and more.</li> <li>Personal Loans: Customers can apply for personal loans to finance various expenses, such as home improvement, debt consolidation, or education.</li> <li>Mortgages: Wells Fargo provides mortgage services for buying or refinancing homes, with different types of mortgages available.</li> <li>Auto Loans: The bank offers auto loans to help customers purchase new or used vehicles.</li> </ul>","tags":["company"]},{"location":"projects/company/#3-investment-services_1","title":"3. Investment Services","text":"<ul> <li>Wealth Management: Wells Fargo provides wealth management services, including investment advice, portfolio management, and retirement planning.</li> <li>Financial Planning: The bank assists customers in creating comprehensive financial plans tailored to their goals and needs.</li> </ul>","tags":["company"]},{"location":"projects/company/#4-business-services","title":"4. Business Services","text":"<ul> <li>Business Banking: Wells Fargo offers a range of services for businesses, including business checking and savings accounts, merchant services, and business loans.</li> <li>Commercial Banking: Larger corporations can access specialized commercial banking services to manage their financial needs.</li> </ul>","tags":["company"]},{"location":"projects/company/#5-insurance-and-protection","title":"5. Insurance and Protection","text":"<ul> <li>Insurance Services: Wells Fargo offers insurance products such as auto insurance, home insurance, and life insurance to help customers protect their assets and loved ones.</li> <li>Identity Theft Protection: The bank provides services to help customers safeguard their personal information and prevent identity theft.</li> </ul>","tags":["company"]},{"location":"projects/company/#6-investments-and-trading","title":"6. Investments and Trading","text":"<ul> <li>Stocks and Bonds: Wells Fargo provides investment options for customers interested in trading stocks, bonds, and other securities.</li> <li>Retirement Accounts: The bank offers retirement account options, including IRAs and 401(k) plans, to help customers save for their retirement.</li> </ul>","tags":["company"]},{"location":"projects/company/#7-international-services","title":"7. International Services","text":"<ul> <li>Foreign Exchange: Wells Fargo assists customers with foreign currency exchange for international travel or business purposes.</li> <li>International Banking: The bank offers international banking services, including foreign accounts and wire transfers.</li> </ul>","tags":["company"]},{"location":"projects/government/","title":"Government and Public Sector:","text":""},{"location":"projects/government/#government-and-public-sector_1","title":"Government and Public Sector:","text":"<p>Government agencies, public services, and organizations focused on civic technology and public administration.</p>"},{"location":"projects/healthcare/","title":"Healthcare","text":""},{"location":"projects/healthcare/#patient-experience-platform-or-pxp","title":"Patient Experience Platform, or PxP","text":"<p>PxP is a comprehensive platform designed to enhance the patient experience by leveraging online capabilities for various aspects of medical practice management and patient-clinician interactions. It encompasses several key components:</p>"},{"location":"projects/healthcare/#pxp-portal","title":"PxP Portal","text":"<p>The primary objective of the PxP Portal is to strengthen the bond between patients and clinicians while providing secure and convenient online communication channels. This fosters deeper engagement between patients and their care teams, encouraging compliance with appointments and treatment plans. Within the PxP Patient Portal, patients can:</p> <ul> <li>Submit patient-generated health data, including updated health history, demographics, and consent forms.</li> <li>Access and review account balances and statements.</li> <li>Make secure online payments, with support for budget billing plans to spread payments over time.</li> <li>View upcoming and past appointments, request new appointments, and even request medication refills.</li> <li>Access and share health data as needed.</li> </ul> <p>By facilitating improved communication, the PxP Portal contributes to better patient-provider relationships, resulting in enhanced patient satisfaction, loyalty, and ultimately, improved health outcomes.</p>"},{"location":"projects/healthcare/#pxp-pay","title":"PxP Pay","text":"<p>PxP Pay serves as a payment service that aims to provide higher margins on transactions for Medfusion while remaining cost-effective for medical practices compared to alternatives like Paypal or QuickBooks. It seeks to optimize the financial aspects of medical practice operations.</p>"},{"location":"projects/healthcare/#pxp-appointments","title":"PxP Appointments","text":"<p>The PxP Appointments module comprises two main features:</p> <ol> <li> <p>Appointment Reminders: This feature automates the process of sending email or text reminders to patients about upcoming appointments. These reminders are typically sent at strategic intervals before the appointment, such as 3 days, 1 day, and 1 hour in advance. This helps reduce no-shows and improves appointment adherence.</p> </li> <li> <p>PreCheck: PreCheck empowers patients to complete necessary forms, update demographic information, provide insurance details, and pay their copay online ahead of their scheduled appointments. This streamlines the administrative tasks associated with patient visits and enhances efficiency for both patients and healthcare providers.</p> </li> </ol>"},{"location":"projects/healthcare/#pxp-patient-self-scheduling","title":"PxP Patient Self Scheduling","text":"<p>This feature enables patients to book appointments online, eliminating the need for them to call the practice directly. Moreover, it seamlessly integrates with the practice's Electronic Health Record (EHR) and Practice Management (PM) systems, automating the appointment booking process and reducing the burden on practice staff.</p>"},{"location":"projects/healthcare/#fiber-management-system-fms","title":"Fiber Management System (FMS)","text":"<p>The Fiber Management System (FMS) is a versatile solution designed for efficiently managing a large volume of optical fibers in cable installations. It offers flexibility and reliability across various access network environments, making it a cost-effective and organized rack for the management and protection of high-density fiber optic installations.</p>"},{"location":"projects/healthcare/#description","title":"Description:","text":"<p>The FMS is engineered to provide maximum protection in rugged field applications while maintaining a neat and organized appearance in central offices and equipment closets. This system simplifies fiber management by offering a comprehensive range of components, all available from a single source. These components include couplings, cable assemblies, pigtails, splices, and more.</p> <p>The FMS can be wall-mounted inside buildings or customer premises and is available in various sizes, including 6-Fibre, 8-Fibre, 12-Fibre, 24-Fibre, and 48-Fibre configurations.</p>"},{"location":"projects/healthcare/#features","title":"Features:","text":"<ul> <li>Product Management</li> <li>Complete Inventory Management</li> <li>Simple Manufacture Management</li> <li>Payment Records</li> <li>Product and Sales Order Management</li> <li>PDF and Excel Report Data</li> <li>Vendor Management and Bills</li> <li>Materials Check-in/Check-out and Invoicing</li> <li>Order Approval System with Notification</li> </ul>"},{"location":"projects/healthcare/#dimensions","title":"Dimensions:","text":"<ul> <li>Width: 375mm</li> <li>Height: 600mm</li> <li>Depth: 175mm</li> <li>Capacity: Minimum \u2013 48 fibres, Maximum \u2013 96 fibres</li> <li>Cable Entry Ports: Incoming \u2013 2 Nos., Outgoing \u2013 2 Nos.</li> <li>Material of Box: M.S. Construction with powder coating.</li> <li>Standard Accessories: Splice Protection Sleeve, FC-PC Adapters, Set of Chemicals &amp; Consumables</li> </ul>"},{"location":"projects/healthcare/#application","title":"Application:","text":"<p>The FMS is primarily used for the termination and distribution of optic fiber cables and patch cords at subscriber premises, making it a crucial component of fiber optic network installations.</p>"},{"location":"projects/healthcare/#additional-information","title":"Additional Information:","text":"<ul> <li>Item Code: ofca-fdms</li> <li>Pay Mode Terms: D/A, D/P, T/T (Bank Transfer), Other</li> <li>Port of Dispatch: Allahabad</li> <li>Production Capacity: 1000 per month</li> <li>Delivery Time: Depends on Ordered Quantity</li> <li>Packaging Details: As per buyer's requirement</li> </ul> <p>The Fiber Management System (FMS) appears to be a comprehensive solution for managing and protecting fiber optic installations, offering a wide range of features and configurations to meet the needs of various applications.</p>"},{"location":"projects/it-industry/","title":"IT industry","text":""},{"location":"projects/it-industry/#it-industry_1","title":"IT industry","text":""},{"location":"projects/retail/","title":"Retail and E-commerce","text":""},{"location":"projects/retail/#retail-and-e-commerce_1","title":"Retail and E-commerce","text":"<p>ompanies that sell products or services online, manage inventories, and engage in e-commerce activities.</p>"},{"location":"projects/retail/#yard-management-system-yms","title":"Yard Management System (YMS)","text":"<p>Walmart's Distribution Centers (DCs) face the challenge of inefficient trailer yard management, leading to high yard truck and fuel consumption, delayed deliveries, and inventory discrepancies. To address this issue, a Yard Management System (YMS) is proposed, leveraging a microservice architecture. This system comprises several microservices, each focusing on specific aspects of yard management.</p>"},{"location":"projects/retail/#equipment-management-service-ems","title":"Equipment Management Service (EMS)","text":"<p>EMS is responsible for managing yard equipment, including trailers, refrigerated units, yard trucks, and forklifts. Its key functionalities include:</p> <ul> <li>Equipment Database: Maintains a comprehensive database of yard equipment, including specifications and maintenance history.</li> <li>Real-time Tracking: Utilizes GPS or RFID technology to monitor equipment location and status in real-time.</li> <li>Detention Time Calculation: Calculates equipment-related detention times and costs.</li> <li>Integration with Maintenance Systems: Integrates with maintenance systems for scheduling and tracking preventive maintenance.</li> </ul> <p>Sample Flow:</p> <ol> <li>YOO requests equipment availability for a specific task.</li> <li>EMS checks equipment status and identifies a suitable option.</li> <li>YOO assigns the equipment to the task and updates DMS for driver allocation.</li> <li>EMS tracks equipment usage and calculates detention times.</li> <li>Maintenance systems receive updates from EMS for scheduling preventive maintenance.</li> </ol> <p>API Endpoints:</p> <ul> <li>GET /equipment: Retrieve list of equipment</li> <li>GET /equipment/{id}: Get details of a specific equipment item</li> <li>PUT /equipment/{id}/location: Update equipment location</li> <li>POST /equipment/{id}/maintenance: Record maintenance activity</li> <li>GET /equipment/detention: Calculate detention times and costs</li> </ul>"},{"location":"projects/retail/#driver-management-service-dms","title":"Driver Management Service (DMS)","text":"<p>DMS is responsible for managing yard drivers, their profiles, certifications, and availability. Key functionalities include:</p> <ul> <li>Driver Profile Management: Manages yard driver profiles, certifications, and availability.</li> <li>Task Assignment: Assigns drivers to tasks based on skillset, location, and workload.</li> <li>Performance Tracking: Tracks driver activity and performance metrics.</li> <li>Communication: Provides driver notifications and communication channels.</li> </ul> <p>Sample Flow:</p> <ol> <li>YOO requests a driver for an assigned equipment and task.</li> <li>DMS identifies qualified drivers based on availability and skillset.</li> <li>DMS assigns the driver to the task and sends notifications.</li> <li>YOO updates EMS with driver assignment.</li> <li>DMS tracks driver activity and collects performance data.</li> </ol> <p>API Endpoints:</p> <ul> <li>GET /drivers: Retrieve list of drivers</li> <li>GET /drivers/{id}: Get details of a specific driver</li> <li>PUT /drivers/{id}/availability: Update driver availability</li> <li>PUT /drivers/{id}/task: Assign driver to a task</li> <li>GET /drivers/{id}/performance: Access driver performance data</li> </ul>"},{"location":"projects/retail/#trailer-management-service-tms","title":"Trailer Management Service (TMS)","text":"<p>TMS focuses on managing trailers, including their specifications, location, status, and auditing. Key functionalities include:</p> <ul> <li>Trailer Database: Maintains a comprehensive database of trailers.</li> <li>Real-time Tracking: Tracks trailer location and status in real-time.</li> <li>Audit and Reporting: Records trailer audits, generates reports on movements and utilization.</li> </ul> <p>Sample Flow:</p> <ol> <li>YOO requests a trailer for loading based on cargo type and weight.</li> <li>TMS identifies available trailers that meet requirements.</li> <li>YOO selects a trailer and confirms loading.</li> <li>TMS updates location and status, triggers refrigeration unit if needed.</li> <li>During unloading, TMS conducts an audit and records discrepancies.</li> <li>Reports on trailer movements and utilization are generated for analysis.</li> </ol> <p>API Endpoints:</p> <ul> <li>GET /trailers: Retrieve list of trailers</li> <li>GET /trailers/{id}: Get details of a specific trailer</li> <li>PUT /trailers/{id}/location: Update trailer location</li> <li>PUT /trailers/{id}/status: Update trailer status</li> <li>POST /trailers/{id}/audit: Record trailer audit results</li> <li>GET /trailers/reports: Access trailer movement and utilization reports</li> </ul>"},{"location":"projects/retail/#refrigeration-management-service-rms","title":"Refrigeration Management Service (RMS)","text":"<p>RMS is responsible for monitoring and controlling the temperature of refrigerated trailers. Key functionalities include:</p> <ul> <li>Temperature Monitoring: Monitors and controls the temperature of refrigerated trailers.</li> <li>Alerts and Logs: Generates alerts for out-of-range temperatures or equipment malfunctions, logs temperature data for traceability.</li> </ul> <p>Sample Flow:</p> <ol> <li>YOO assigns a refrigerated trailer to a task.</li> <li>RMS retrieves configured temperature settings for the cargo type.</li> <li>RMS continuously monitors the trailer's refrigeration unit in real-time, collecting temperature data.</li> <li>If the temperature deviates from the set range, RMS triggers alerts and logs data.</li> </ol> <p>API Endpoints:</p> <ul> <li>Details of RMS endpoints are not provided but would include configuration, temperature monitoring, and alerting functionalities.</li> </ul>"},{"location":"projects/retail/#yard-operations-orchestration-service-yoo","title":"Yard Operations Orchestration Service (YOO)","text":"<p>YOO acts as the central coordinator for all yard operations, orchestrating communication and data flow between other microservices. Its functionalities include:</p> <ul> <li>Resource Allocation: Queries microservices to identify available equipment, drivers, and trailers that meet task requirements.</li> <li>Assignment and Execution: Assigns tasks to selected resources and sends instructions to relevant microservices.</li> <li>Real-time Monitoring: Continuously monitors task progress, collecting data from all involved microservices.</li> <li>Exception Handling: Identifies issues and triggers corrective actions.</li> <li>Reporting and Analytics: Generates reports on performance metrics.</li> </ul> <p>Sample Flow:</p> <ol> <li>Task Initiation: YOO receives a request for a new yard operation task.</li> <li>Resource Allocation: YOO queries microservices to identify available resources.</li> <li>Assignment and Execution: YOO assigns the task to selected resources and monitors progress.</li> <li>Exception Handling: YOO handles issues and triggers corrective actions.</li> <li>Task Completion and Reporting: YOO updates the status and generates reports.</li> </ol> <p>API Endpoints:</p> <ul> <li>POST /tasks: Create a new yard operation task</li> <li>GET /tasks/{id}: Get details of a specific task</li> <li>PUT /tasks/{id}/status: Update the status of a task</li> <li>GET /tasks/reports: Access reports on yard operations performance</li> <li>GET /tasks/analytics: Access analytical data on resource utilization and efficiency</li> </ul>"},{"location":"projects/retail/#additional-notes","title":"Additional Notes","text":"<ul> <li>YOO can be implemented using event-driven architecture with message queues or pub/sub mechanisms for efficient communication between microservices.</li> <li>It should be configurable to accommodate different business rules and optimization goals.</li> <li>Security measures should be in place to ensure data integrity and access control.</li> </ul> <p>This detailed description provides an overview of the proposed Yard Management System (YMS) microservices and their functionalities. Further implementation and integration of these microservices will be crucial for optimizing yard operations and addressing the business problem effectively.</p>"},{"location":"projects/telecommunication/","title":"Telecommunication","text":""},{"location":"projects/telecommunication/#telecommunication_1","title":"Telecommunication","text":"<p>Organizations providing telecommunication services, such as mobile networks, landlines, and internet service providers.</p>"},{"location":"projects/telecommunication/#premium-visual-voicemail-pvvm","title":"Premium Visual Voicemail (PVVM)","text":""},{"location":"projects/telecommunication/#microservices","title":"Microservices:","text":"<ol> <li> <p>Voicemail Message Delivery (VMD): Delivering Messages with Precision</p> <ul> <li>VMD ensures voicemail messages reach your device seamlessly, prioritizing efficient delivery and synchronization.</li> </ul> </li> <li> <p>Message Playback Service (MPS): Your Voicemail, Your Way</p> <ul> <li>MPS offers a user-friendly interface, allowing you to listen, control, and manage voicemail messages at your convenience.</li> </ul> </li> <li> <p>Contact Management (CM): Keeping Contacts Up-to-Date</p> <ul> <li>CM simplifies contact management, ensuring caller information accuracy for an enhanced voicemail experience.</li> </ul> </li> </ol>"},{"location":"projects/telecommunication/#secure-wi-fi-guarding-your-online-presence","title":"Secure Wi-Fi: Guarding Your Online Presence","text":""},{"location":"projects/telecommunication/#microservices_1","title":"Microservices:","text":"<ol> <li> <p>Wi-Fi Network Detection (WND): Shielding Your Connection</p> <ul> <li>WND detects Wi-Fi networks, triggering a secure connection for uninterrupted browsing.</li> </ul> </li> <li> <p>VPN Connection Manager (VPN): Your Virtual Guardian</p> <ul> <li>VPN establishes a protective shield, safeguarding your data from potential threats while connected to public Wi-Fi.</li> </ul> </li> <li> <p>Data Encryption Service (DES): Locking Your Data Safely</p> <ul> <li>DES encrypts your data, providing an impenetrable layer of security during Wi-Fi usage.</li> </ul> </li> </ol>"},{"location":"projects/telecommunication/#device-insurance-protecting-your-valuables","title":"Device Insurance: Protecting Your Valuables","text":""},{"location":"projects/telecommunication/#microservices_2","title":"Microservices:","text":"<ol> <li> <p>Insurance Subscription (IS): Tailored Coverage for Peace of Mind</p> <ul> <li>IS offers personalized insurance subscriptions, ensuring your devices are protected.</li> </ul> </li> <li> <p>Claims Processing (CP): Swift Resolution for Device Mishaps</p> <ul> <li>CP streamlines the claims process, ensuring quick resolution in case of device damage.</li> </ul> </li> <li> <p>Integration with Third-Party Provider (ITPP): Seamless Collaboration for Comprehensive Coverage</p> <ul> <li>ITPP connects with third-party provider Likewise, ensuring accurate synchronization of insurance data.</li> </ul> </li> </ol>"},{"location":"projects/telecommunication/#integration-and-support-a-unified-ecosystem","title":"Integration and Support: A Unified Ecosystem","text":"<ul> <li>Microservices within each project communicate seamlessly via APIs, creating a unified ecosystem for enhanced functionality.</li> <li>Subscription services are managed centrally, ensuring consistent billing and access control across applications.</li> </ul>"},{"location":"projects/telecommunication/#current-onboarding-amazon-fuse","title":"Current Onboarding: Amazon Fuse","text":"<ul> <li>The integration of Amazon Fuse introduces new and exciting possibilities, enhancing the existing projects and expanding their capabilities.</li> </ul>"},{"location":"qa/","title":"Quality Assurance","text":"<p>Quality Assurance (QA)</p>"},{"location":"qa/cucumber/","title":"Cucumber","text":""},{"location":"qa/cucumber/#cucumber_1","title":"Cucumber","text":"<p>Cucumber is primarily used for Behavior-Driven Development (BDD) and is well-suited for automating functional and acceptance tests. It fits into the testing process by providing a structured and collaborative approach to defining, executing, and documenting test cases.  </p>"},{"location":"qa/jmeter/","title":"JMeter","text":""},{"location":"qa/jmeter/#jmeter_1","title":"JMeter","text":"<p>Apache JMeter is primarily known for its performance testing capabilities, but it can also be used for functional API testing. It's an open-source tool that supports a wide range of protocols.</p>"},{"location":"qa/microservices/apigee/","title":"Apigee","text":""},{"location":"qa/microservices/apigee/#apigee_1","title":"Apigee","text":""},{"location":"qa/microservices/jest/","title":"Jest","text":""},{"location":"qa/microservices/jest/#jest_1","title":"Jest","text":""},{"location":"qa/microservices/karate/","title":"Karate","text":""},{"location":"qa/microservices/karate/#karate_1","title":"Karate","text":""},{"location":"qa/microservices/mocha-chai/","title":"Mocha/Chai","text":""},{"location":"qa/microservices/mocha-chai/#mochachai_1","title":"Mocha/Chai","text":"<p>Mocha is a flexible JavaScript test framework, and Chai is an assertion library that integrates seamlessly with Mocha. Together, they provide a powerful combination for testing JavaScript applications, including both front-end and back-end code.</p> <p>BDD and TDD: Mocha supports both Behavior-Driven Development (BDD) and Test-Driven Development (TDD) testing styles, allowing you to choose the most suitable approach for your project.</p> <p>Customization: Mocha is highly customizable, allowing you to use different assertion libraries (like Chai) and reporter plugins to tailor your test setup.</p> <p>Back-End Testing: Mocha is often used for testing server-side code, making it a versatile choice for full-stack JavaScript applications.</p>"},{"location":"qa/microservices/postman/","title":"Postman","text":""},{"location":"qa/microservices/postman/#postman_1","title":"Postman","text":""},{"location":"qa/microservices/rest-assured/","title":"RestAssured","text":""},{"location":"qa/microservices/rest-assured/#restassured_1","title":"RestAssured","text":""},{"location":"qa/microservices/testng/","title":"estNG","text":""},{"location":"qa/microservices/testng/#junit-and-testng","title":"JUnit and TestNG","text":"<p>These are widely used testing frameworks for Java applications, covering unit, integration, and end-to-end testing. They are commonly used in conjunction with tools like Selenium for web testing.</p>"},{"location":"qa/mobile/appium/","title":"Appium","text":""},{"location":"qa/mobile/appium/#appium_1","title":"Appium","text":""},{"location":"qa/mobile/robot-framework/","title":"Robot Framework:","text":""},{"location":"qa/mobile/robot-framework/#robot-framework_1","title":"Robot Framework:","text":""},{"location":"qa/website/cypress/","title":"Cypress","text":""},{"location":"qa/website/cypress/#cypress_1","title":"Cypress","text":""},{"location":"qa/website/protractor/","title":"Protractor","text":""},{"location":"qa/website/protractor/#protractor_1","title":"Protractor","text":"<p>An end-to-end test framework for Angular and AngularJS applications.</p>"},{"location":"qa/website/selenium/","title":"Selenium","text":""},{"location":"qa/website/selenium/#selenium_1","title":"Selenium","text":"<p>Widely used for web application testing, it supports multiple programming languages and browsers.</p>"},{"location":"qa/website/webdriverIO/","title":"WebdriverIO","text":""},{"location":"qa/website/webdriverIO/#webdriverio_1","title":"WebdriverIO","text":"<p>A Node.js-based automation framework for web and mobile app testing.</p>"},{"location":"react/","title":"React","text":""},{"location":"react/#react_1","title":"React","text":"<p>React is a popular JavaScript library primarily used for building user interfaces. It was developed by Facebook and is widely adopted in the web development community. In this article, we'll delve into the main features of React, making it easy for students, developers, and others to grasp its essence.</p> <p>React offers several powerful features that make it a preferred choice for developing dynamic and interactive web applications:</p>"},{"location":"react/#1-component-based-architecture","title":"1. Component-Based Architecture","text":"<p>React is centered around a component-based architecture, where the user interface is divided into reusable and self-contained components. This modular approach simplifies development, encourages code reusability, and facilitates collaboration among developers.</p>"},{"location":"react/#2-virtual-dom-document-object-model","title":"2. Virtual DOM (Document Object Model)","text":"<p>One of React's standout features is the Virtual DOM. Instead of directly manipulating the browser's DOM, React creates a virtual representation of it in memory. When changes occur in the application's state, React calculates the most efficient way to update the virtual DOM, minimizing actual DOM manipulations. This leads to improved performance and a smoother user experience.</p>"},{"location":"react/#3-declarative-syntax","title":"3. Declarative Syntax","text":"<p>React uses a declarative syntax, which means developers specify what the UI should look like based on the application's state, rather than writing imperative code to update the UI. This makes the code more intuitive, easier to understand, and less error-prone.</p>"},{"location":"react/#4-component-lifecycle","title":"4. Component Lifecycle","text":"<p>React components have a well-defined lifecycle with methods that allow developers to control behavior at different stages, such as component creation, updates, and unmounting. This fine-grained control is valuable for managing side effects, data fetching, and optimizing performance.</p>"},{"location":"react/#5-jsx-javascript-xml","title":"5. JSX (JavaScript XML)","text":"<p>React introduces JSX, a syntax extension that allows developers to write HTML-like code within JavaScript. This combination simplifies the creation of UI components by providing a more natural and expressive way to define the structure and appearance of the interface.</p>"},{"location":"react/#6-unidirectional-data-flow","title":"6. Unidirectional Data Flow","text":"<p>React follows a unidirectional data flow, where data flows in a single direction, typically from parent to child components. This clear data flow pattern enhances predictability and simplifies debugging, making it easier to maintain complex applications.</p>"},{"location":"react/#7-react-native","title":"7. React Native","text":"<p>React's versatility extends beyond web development. React Native is a framework built on top of React that enables the development of mobile applications for both iOS and Android using the same codebase. This allows developers to leverage their React skills to build native mobile apps.</p>"},{"location":"react/#8-large-and-active-community","title":"8. Large and Active Community","text":"<p>React boasts a large and vibrant community of developers and libraries. This means that developers have access to a wealth of resources, third-party packages, and support, making it easier to solve problems and stay up-to-date with best practices.</p> <p>In conclusion, React's component-based architecture, Virtual DOM, declarative syntax, and other features make it a powerful tool for building efficient and maintainable user interfaces. Whether you're a student learning web development or an experienced developer, React is a valuable skill to acquire for modern web application development.</p>"},{"location":"react/#9-one-way-data-binding","title":"9. One-Way Data Binding","text":"<p>React enforces a one-way data binding mechanism, ensuring that data flows in a predictable manner. This prevents unexpected side effects and helps maintain a clear data flow, especially in complex applications.</p>"},{"location":"react/#10-react-ecosystem","title":"10. React Ecosystem","text":"<p>React is not just a standalone library; it has a rich ecosystem of tools and libraries that complement its capabilities. Tools like Redux for state management, React Router for routing, and Axios for data fetching seamlessly integrate with React, enhancing its functionality and extending its capabilities.</p>"},{"location":"react/#11-developer-tools","title":"11. Developer Tools","text":"<p>React provides robust developer tools, such as React DevTools and React Profiler, which assist developers in debugging and profiling their applications. These tools make it easier to identify performance bottlenecks, inspect component hierarchies, and trace data flow.</p>"},{"location":"react/#12-community-and-resources","title":"12. Community and Resources","text":"<p>React has a thriving online community where developers can seek help, share knowledge, and collaborate on projects. Countless tutorials, documentation, and online courses are available to help individuals learn React effectively, making it accessible to a wide range of skill levels.</p>"},{"location":"react/#13-integration-with-other-technologies","title":"13. Integration with Other Technologies","text":"<p>React can be seamlessly integrated with other technologies and frameworks, such as GraphQL for efficient data querying, and server-side rendering for improved SEO and initial page load times. This flexibility allows developers to build versatile and high-performance applications.</p>"},{"location":"react/#14-performance-optimization","title":"14. Performance Optimization","text":"<p>React's Virtual DOM and efficient rendering mechanism contribute to exceptional performance. With the ability to update only the parts of the UI that have changed, React minimizes unnecessary re-rendering and optimizes the application's speed and responsiveness.</p>"},{"location":"react/#15-testing-and-debugging","title":"15. Testing and Debugging","text":"<p>React encourages the use of testing frameworks like Jest and Enzyme, which facilitate unit testing and component testing. This built-in support for testing makes it easier to identify and fix issues, ensuring that your application remains robust and bug-free.</p>"},{"location":"react/#16-server-side-rendering-ssr","title":"16. Server-Side Rendering (SSR)","text":"<p>React supports server-side rendering, allowing you to render your components on the server and send a fully rendered HTML page to the client. SSR improves SEO, initial page load times, and the user experience, particularly for content-heavy websites.</p>"},{"location":"react/#17-accessibility-a11y-support","title":"17. Accessibility (a11y) Support","text":"<p>React emphasizes accessibility, making it easier to create web applications that are usable by people with disabilities. A wide range of accessibility-friendly libraries and tools are available to assist developers in ensuring their applications are inclusive and compliant with accessibility standards.</p>"},{"location":"react/#18-code-reusability","title":"18. Code Reusability","text":"<p>With React's component-based architecture and the ability to create custom components, you can achieve high levels of code reusability. Reusing components across different parts of your application or even in entirely different projects can significantly reduce development time and maintenance efforts.</p>"},{"location":"react/#19-strong-developer-tooling","title":"19. Strong Developer Tooling","text":"<p>React benefits from a robust set of developer tools that enable you to inspect component hierarchies, track component state, and monitor performance. These tools are invaluable for debugging and optimizing React applications during development and beyond.</p>"},{"location":"react/#20-progressive-web-app-pwa-support","title":"20. Progressive Web App (PWA) Support","text":"<p>React can be used to build Progressive Web Apps (PWAs), which are web applications that offer a native app-like experience, including offline capabilities, push notifications, and smooth performance. This extends the reach of your web applications to various platforms and devices.</p> <p>In conclusion, React's expansive feature set, coupled with its focus on performance, testing, accessibility, and code reusability, positions it as a top choice for developing modern web and mobile applications. Whether you're a student, a developer looking to enhance your skills, or someone interested in creating user-friendly and efficient applications, React provides the tools and resources to help you succeed in your endeavors.</p>"},{"location":"react/#virtual-dom","title":"Virtual DOM","text":"<p>The Virtual DOM (VDOM) is a fundamental concept in React, a popular JavaScript library for building user interfaces. It plays a crucial role in enhancing the performance and efficiency of web applications by minimizing unnecessary updates to the actual DOM (Document Object Model).</p> <p>The Virtual DOM is a lightweight, in-memory representation of the real DOM. In a React application, instead of directly manipulating the actual DOM elements when changes occur, React creates and uses a Virtual DOM to keep track of the desired UI state. This Virtual DOM is a tree-like structure of JavaScript objects that mirrors the structure of the actual UI.</p>"},{"location":"react/#how-does-it-work","title":"How does it work?","text":"<p>When you make changes to your React component's state or props, React doesn't immediately update the real DOM. Instead, it goes through a process known as reconciliation, which involves comparing the current Virtual DOM with the previous one.</p> <ol> <li> <p>Rendering the Virtual DOM: When you initially render a React component, it creates a Virtual DOM representation of your UI.</p> </li> <li> <p>Updating the Virtual DOM: When changes occur, React constructs a new Virtual DOM tree to represent the updated state.</p> </li> <li> <p>Reconciliation: React efficiently compares the new Virtual DOM with the previous one. It identifies the differences (called \"diffing\") between the two trees.</p> </li> <li> <p>Re-rendering: Only the specific parts of the Virtual DOM that have changed are updated in the actual DOM. This selective update process minimizes the need for costly and time-consuming direct DOM manipulation.</p> </li> </ol>"},{"location":"react/#advantages","title":"Advantages","text":"<p>The Virtual DOM provides several advantages:</p>"},{"location":"react/#1-performance-optimization","title":"1. Performance Optimization:","text":"<p>By reducing the number of actual DOM updates, React significantly improves the performance of web applications. Since modifying the real DOM is a slow operation, the Virtual DOM's ability to batch changes and update only what's necessary results in faster rendering.</p>"},{"location":"react/#2-cross-platform-compatibility","title":"2. Cross-Platform Compatibility:","text":"<p>React's Virtual DOM abstraction makes it easier to support multiple platforms and environments. Whether your app runs in a web browser, on mobile devices, or even on the server (using Node.js), the Virtual DOM ensures a consistent development model.</p>"},{"location":"react/#3-developer-friendly","title":"3. Developer-Friendly:","text":"<p>React's use of the Virtual DOM simplifies the development process. Developers can focus on describing how the UI should look in different states, and React takes care of efficiently updating the DOM.</p> <p>Let's see a simple example of how the Virtual DOM works in React:</p> <pre><code>import React, {useState} from 'docs/react/index';\n\nfunction Counter() {\n    const [count, setCount] = useState(0);\n\n    const handleClick = () =&gt; {\n        setCount(count + 1);\n    };\n\n    return (\n        &lt;div&gt;\n            &lt;p&gt;Count: {count}&lt;/p&gt;\n            &lt;button onClick={handleClick}&gt;Increment&lt;/button&gt;\n        &lt;/div&gt;\n    );\n}\n\nexport default Counter;\n</code></pre> <p>In this example, when the button is clicked, React updates the Virtual DOM and then only modifies the part of the actual DOM displaying the count value, resulting in a smooth and efficient user experience.</p>"},{"location":"react/#virtual-dom-reconciliation-process","title":"Virtual DOM Reconciliation Process","text":"<p>To provide a more detailed understanding, let's dive deeper into the Virtual DOM reconciliation process with an example:</p> <p>Suppose you have a list of items in your React component, and you want to update one item's text when a button is clicked:</p> <pre><code>import React, {useState} from 'docs/react/index';\n\nfunction ItemList() {\n    const [items, setItems] = useState([\n        {id: 1, text: 'Item 1'},\n        {id: 2, text: 'Item 2'},\n        {id: 3, text: 'Item 3'},\n    ]);\n\n    const handleUpdate = () =&gt; {\n        const updatedItems = [...items];\n        updatedItems[1].text = 'Updated Item 2';\n        setItems(updatedItems);\n    };\n\n    return (\n        &lt;div&gt;\n            &lt;ul&gt;\n                {items.map((item) =&gt; (\n                    &lt;li key={item.id}&gt;{item.text}&lt;/li&gt;\n                ))}\n            &lt;/ul&gt;\n            &lt;button onClick={handleUpdate}&gt;Update Item 2&lt;/button&gt;\n        &lt;/div&gt;\n    );\n}\n\nexport default ItemList;\n</code></pre> <p>When you click the \"Update Item 2\" button, React performs the following steps:</p> <ol> <li> <p>It updates the Virtual DOM with the new state of the <code>items</code> array.</p> </li> <li> <p>It compares the new Virtual DOM with the previous one, identifying that only one <code>&lt;li&gt;</code> element text has changed.</p> </li> <li> <p>Instead of re-rendering the entire list, React intelligently updates only the specific <code>&lt;li&gt;</code> element whose text has changed in the real DOM.</p> </li> </ol> <p>This process minimizes unnecessary DOM manipulations and results in faster and more efficient updates.</p>"},{"location":"react/#react-reconciliation-strategies","title":"React Reconciliation Strategies","text":"<p>React uses several strategies during reconciliation to optimize updates further:</p>"},{"location":"react/#1-key-prop","title":"1. Key Prop:","text":"<p>In the example above, you may have noticed the <code>key</code> prop in the <code>&lt;li&gt;</code> elements. Keys help React identify which items have changed, moved, or been added or removed in lists. Providing unique keys to each element helps React efficiently update the Virtual DOM.</p>"},{"location":"react/#2-batched-updates","title":"2. Batched Updates:","text":"<p>React batches multiple state updates and Virtual DOM comparisons into a single pass, reducing the number of times the reconciliation process occurs. This batched approach enhances performance.</p>"},{"location":"react/#3-component-lifecycle-methods","title":"3. Component Lifecycle Methods:","text":"<p>React provides lifecycle methods like <code>shouldComponentUpdate</code> and <code>PureComponent</code> that allow you to control when a component should or should not update, preventing unnecessary rendering.</p> <p>The Virtual DOM is a powerful concept in React, optimizing the way user interfaces are built and updated. By using a Virtual DOM representation and a smart reconciliation process, React ensures that changes are made efficiently, resulting in high-performance web applications.</p>"},{"location":"react/#virtual-dom-vs-actual-dom","title":"Virtual DOM vs. Actual DOM","text":"<p>Let's compare the Virtual DOM to the Actual DOM to highlight the benefits of using a Virtual DOM:</p>"},{"location":"react/#actual-dom","title":"Actual DOM:","text":"<ul> <li>The Actual DOM is the real representation of a web page's structure.</li> <li>Whenever there's a change in the data or state, the Actual DOM is directly updated, leading to potentially slow and inefficient operations, especially for complex web applications.</li> <li>Frequent updates to the Actual DOM can cause performance bottlenecks and a poor user experience.</li> </ul>"},{"location":"react/#virtual-dom_1","title":"Virtual DOM:","text":"<ul> <li>The Virtual DOM is a lightweight copy of the Actual DOM.</li> <li>React updates the Virtual DOM instead of the Actual DOM when there are changes in the application's data or state.</li> <li>The Virtual DOM allows React to batch multiple updates and perform a single, optimized update to the Actual DOM, reducing the rendering time and improving performance.</li> </ul>"},{"location":"react/#reacts-philosophy","title":"React's Philosophy","text":"<p>React's philosophy is to make the development process more predictable and developer-friendly while ensuring high-performance user interfaces. The Virtual DOM aligns with these principles by abstracting away the complexities of direct DOM manipulation and providing a structured, efficient way to update the UI.</p>"},{"location":"react/#use-cases-for-the-virtual-dom","title":"Use Cases for the Virtual DOM","text":"<p>Understanding when and why to use the Virtual DOM is crucial:</p>"},{"location":"react/#1-complex-user-interfaces","title":"1. Complex User Interfaces:","text":"<p>When building applications with a complex user interface that frequently changes, React's Virtual DOM shines. It minimizes the performance impact of frequent updates.</p>"},{"location":"react/#2-real-time-applications","title":"2. Real-Time Applications:","text":"<p>Real-time applications like chat applications, stock market dashboards, or online gaming benefit from the Virtual DOM's ability to handle rapid data changes and updates.</p>"},{"location":"react/#3-cross-platform-development","title":"3. Cross-Platform Development:","text":"<p>If you plan to develop for multiple platforms (web, mobile, desktop) using technologies like React Native, React's Virtual DOM abstraction ensures consistency and ease of development across platforms.</p> <p>In summary, the Virtual DOM is a crucial concept in React that enhances the performance and developer experience when building web applications. By providing a structured approach to updating the UI and minimizing direct DOM manipulations, React ensures that your applications are both efficient and maintainable.</p>"},{"location":"react/#props-vs-state","title":"Props vs State","text":"<p>In React, props and state are fundamental concepts for managing and passing data within your components. Props are used to pass data from parent to child components, while state is used for managing a component's internal data and reactivity. Understanding the difference between them is crucial for building effective and maintainable React applications.</p>"},{"location":"react/#props","title":"Props","text":"<p>Props, short for \"properties,\" are a way to pass data from a parent component to a child component in React. They are read-only and help in making your components reusable. Here's a breakdown of key points:</p> <ul> <li> <p>Passing Data: Props allow you to pass data or values (strings, numbers, objects, functions, etc.) from a parent component to a child component.</p> </li> <li> <p>Immutable: Props are immutable, which means once they are set in a child component, they cannot be changed from within that component.</p> </li> <li> <p>Example: Suppose you have a <code>User</code> component that displays user information, and you pass the user's name and email as props from a parent component:</p> </li> </ul> <pre><code>function ParentComponent() {\n  const user = { name: 'John Doe', email: 'johndoe@example.com' };\n\n  return &lt;User name={user.name} email={user.email} /&gt;;\n}\n\nfunction User(props) {\n  return (\n    &lt;div&gt;\n      &lt;h2&gt;{props.name}&lt;/h2&gt;\n      &lt;p&gt;Email: {props.email}&lt;/p&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"react/#state","title":"State","text":"<p>State is used to manage a component's internal data that can change over time and trigger re-renders when updated. Here are the key points about state:</p> <ul> <li> <p>Internal Data: State is used to store and manage data within a component. It's mutable and can be changed using the <code>setState</code> method.</p> </li> <li> <p>Reactivity: When state data changes, React automatically re-renders the component to reflect those changes in the UI.</p> </li> <li> <p>Example: Suppose you have a <code>Counter</code> component that displays and updates a count value:</p> </li> </ul> <pre><code>import React, {Component} from 'docs/react/index';\n\nclass Counter extends Component {\n    constructor() {\n        super();\n        this.state = {\n            count: 0,\n        };\n    }\n\n    incrementCount = () =&gt; {\n        this.setState({count: this.state.count + 1});\n    };\n\n    render() {\n        return (\n            &lt;div&gt;\n                &lt;p&gt;Count: {this.state.count}&lt;/p&gt;\n                &lt;button onClick={this.incrementCount}&gt;Increment&lt;/button&gt;\n            &lt;/div&gt;\n        );\n    }\n}\n\nexport default Counter;\n</code></pre>"},{"location":"react/#differences-between-props-and-state","title":"Differences Between Props and State","text":"<p>To further clarify the distinctions between props and state, let's delve into their differences in more detail:</p> <ol> <li> <p>Source of Data:</p> <ul> <li> <p>Props: Data in props is passed from parent components to child components. It flows in one direction, from top to bottom in your component hierarchy.</p> </li> <li> <p>State: State is internal to a component and is managed within that component itself. It doesn't depend on external sources and can change over time.</p> </li> </ul> </li> <li> <p>Mutability:</p> <ul> <li> <p>Props: Props are immutable, meaning that child components cannot modify the data received via props. They are essentially read-only.</p> </li> <li> <p>State: State is mutable, and components can modify their own state using the <code>setState</code> method. When state changes, it triggers a re-render of the component.</p> </li> </ul> </li> <li> <p>Use Cases:</p> <ul> <li> <p>Props: They are primarily used for passing data and configuration to child components. For example, passing user information, settings, or configuration data.</p> </li> <li> <p>State: State is used for managing dynamic and changing data within a component. It's ideal for handling user input, toggling UI elements, or maintaining data that can change during the component's lifecycle.</p> </li> </ul> </li> <li> <p>Updates and Re-renders:</p> <ul> <li> <p>Props: Changes in props are not controlled by the component that receives them. They are updated externally by the parent component. Changes in props can cause the child component to re-render, but it's not directly controlled by the child component.</p> </li> <li> <p>State: A component can control its own state and trigger re-renders when the state changes. This gives you fine-grained control over how and when your component updates in response to data changes.</p> </li> </ul> </li> <li> <p>Default Values:</p> <ul> <li> <p>Props: You can set default values for props using PropTypes or default function parameters in functional components.</p> </li> <li> <p>State: You initialize state in class components within the constructor or use the <code>useState</code> hook in functional components with an initial value.</p> </li> </ul> </li> <li> <p>Accessing Data:</p> <ul> <li> <p>Props: Data from props is accessed using the <code>props</code> object in functional components or <code>this.props</code> in class components.</p> </li> <li> <p>State: State data is accessed using <code>this.state</code> in class components or the state variable returned by the <code>useState</code> hook in functional components.</p> </li> </ul> </li> </ol> <p>Understanding these differences is crucial for effectively designing and building React applications. Using props for passing data and state for managing component-specific dynamic data helps maintain a clear and predictable flow of information within your application.</p>"},{"location":"react/#best-practices-for-props","title":"Best Practices for Props:","text":"<ol> <li> <p>Keep Props Simple: Props should ideally contain simple data or functions to maintain a clear and understandable interface between parent and child components.</p> </li> <li> <p>Documentation: Document the props your components accept, including their data types and descriptions, using tools like PropTypes or TypeScript.</p> </li> <li> <p>Immutable Props: Treat props as read-only. If a child component needs to modify data received via props, consider lifting the state to a higher-level component.</p> </li> <li> <p>Destructuring Props: In functional components, use object destructuring to simplify the access to props. For example, <code>function MyComponent({ prop1, prop2 }) { /* ... */ }</code>.</p> </li> </ol>"},{"location":"react/#best-practices-for-state","title":"Best Practices for State:","text":"<ol> <li> <p>Initialize State Correctly: In class components, initialize state in the constructor. In functional components, use the <code>useState</code> hook and ensure that it receives an initial value.</p> </li> <li> <p>Avoid Direct State Mutations: Never directly modify state using <code>this.state</code> in class components. Use <code>setState</code> to update state to ensure proper reactivity.</p> </li> <li> <p>Functional setState: When updating state that depends on the previous state value, use the functional form of <code>setState</code> to prevent race conditions.</p> </li> </ol> <pre><code>this.setState((prevState) =&gt; ({\n  count: prevState.count + 1,\n}));\n</code></pre> <ol> <li> <p>State Consolidation: If multiple state values are closely related, consider consolidating them into a single state object to simplify management.</p> </li> <li> <p>Avoid Excessive State: Don't overuse state within components. Keep state localized to the minimal amount needed to maintain the component's functionality.</p> </li> <li> <p>Consider Using State Management Libraries: For complex applications, consider using state management libraries like Redux or Mobx to manage application-wide state.</p> </li> </ol>"},{"location":"react/#when-to-choose-props-vs-state","title":"When to Choose Props vs. State:","text":"<ul> <li>Use props when data needs to flow from parent to child components.</li> <li>Use state when dealing with dynamic, component-specific data that can change over time.</li> <li>Consider using a combination of props and state when building complex UI components.</li> </ul> <p>By following these best practices and understanding the nuances of props and state in React, you can build more maintainable and predictable applications that efficiently manage and display data.</p>"},{"location":"react/jest/","title":"Jest","text":""},{"location":"react/jest/#jest_1","title":"Jest","text":"<p>Jest is a widely-used testing framework in the React ecosystem. It's specifically designed for JavaScript, making it an excellent choice for testing React applications. Jest simplifies the testing process by offering an easy-to-use and feature-rich testing environment that covers unit testing, integration testing, and more.</p>"},{"location":"react/jest/#introduction","title":"Introduction:","text":"<p>Jest is an open-source JavaScript testing framework created by Facebook. Its primary purpose is to ensure that your code works as expected, even as your application grows. Jest is particularly popular in the React ecosystem due to its seamless integration and the following key features:</p>"},{"location":"react/jest/#key-features","title":"Key Features:","text":""},{"location":"react/jest/#1-zero-configuration","title":"1. Zero Configuration:","text":"<p>Jest comes with sensible defaults, meaning you can start writing tests without any complex setup. It's as simple as installing Jest, and you're good to go.</p>"},{"location":"react/jest/#2-fast-and-parallel-execution","title":"2. Fast and Parallel Execution:","text":"<p>Jest is built to execute tests quickly by running them in parallel. This is especially valuable as your test suite grows, ensuring you get fast feedback on your code.</p>"},{"location":"react/jest/#3-snapshot-testing","title":"3. Snapshot Testing:","text":"<p>Snapshot testing allows you to capture the output of a component or function and compare it to a previously saved \"snapshot.\" If any changes occur, Jest will highlight them, making it easy to spot unexpected changes in your UI.</p>"},{"location":"react/jest/#4-mocking-capabilities","title":"4. Mocking Capabilities:","text":"<p>Jest makes it effortless to create and manage mocks, which are essential for isolating the code under test and ensuring that tests are focused on a specific unit of functionality.</p>"},{"location":"react/jest/#5-built-in-matchers","title":"5. Built-in Matchers:","text":"<p>Jest provides a rich set of built-in matchers that make it easy to write assertions in your tests. For example, you can use <code>expect(value).toBe(expected)</code> to check if <code>value</code> is equal to <code>expected</code>.</p>"},{"location":"react/jest/#practical-example","title":"Practical Example:","text":"<p>Let's create a simple test case for a React component using Jest. Suppose we have a <code>Button</code> component that should render a \"Click Me\" button:</p> <pre><code>// Button.js\nimport React from 'docs/react/index';\n\nfunction Button() {\n    return &lt;button&gt;Click Me&lt;/button&gt;;\n}\n\nexport default Button;\n</code></pre> <p>Now, we want to test if the <code>Button</code> component renders correctly. Here's a Jest test for it:</p> <pre><code>// Button.test.js\nimport React from 'docs/react/index';\nimport {render} from '@testing-library/react';\nimport Button from './Button';\n\ntest('Button renders correctly', () =&gt; {\n    const {getByText} = render(&lt;Button/&gt;);\n    const buttonElement = getByText('Click Me');\n    expect(buttonElement).toBeInTheDocument();\n});\n</code></pre> <p>In this example, we use Jest's <code>render</code> function from <code>@testing-library/react</code> to render the <code>Button</code> component and then use the <code>expect</code> function to make an assertion. Jest handles the test execution, providing informative output if the test fails.</p> <p>Jest simplifies the testing process in the React ecosystem, making it accessible to developers of all levels. Its features, including zero configuration, fast execution, snapshot testing, mocking capabilities, and built-in matchers, make it a powerful tool for maintaining the reliability and stability of your React applications. By using Jest, you can write tests with confidence, ensuring your code functions as intended, even as it evolves and grows.</p>"},{"location":"react/jest/#advanced-features-of-jest","title":"Advanced Features of Jest:","text":"<p>While we've covered the basics of Jest, there are some advanced features that can take your testing to the next level:</p>"},{"location":"react/jest/#6-mocking-modules","title":"6. Mocking Modules:","text":"<p>Jest allows you to mock entire modules or specific functions within modules. This is particularly useful when you want to isolate components or functions from their dependencies during testing. Here's an example of mocking a module:</p> <pre><code>// api.js\nexport function fetchData() {\n  // ... implementation ...\n}\n\n// Component.js\nimport { fetchData } from './api';\n\nfunction Component() {\n  // ... component logic that uses fetchData ...\n}\n\nexport default Component;\n</code></pre> <p>To mock the <code>api.js</code> module in a test:</p> <pre><code>jest.mock('./api');\n\ntest('Component uses fetchData', () =&gt; {\n  // Set up a mock implementation for fetchData\n  fetchData.mockReturnValue('Mocked Data');\n\n  // ... test the Component that uses fetchData ...\n});\n</code></pre>"},{"location":"react/jest/#7-testing-asynchronous-code","title":"7. Testing Asynchronous Code:","text":"<p>React applications often involve asynchronous operations like fetching data from an API. Jest makes it straightforward to test asynchronous code using techniques like <code>async/await</code>, <code>Promises</code>, and timers.</p> <pre><code>// Async function to test\nasync function fetchData() {\n  return new Promise((resolve) =&gt; {\n    setTimeout(() =&gt; {\n      resolve('Data');\n    }, 1000);\n  });\n}\n\ntest('fetchData resolves with data', async () =&gt; {\n  const data = await fetchData();\n  expect(data).toBe('Data');\n});\n</code></pre>"},{"location":"react/jest/#8-custom-matchers","title":"8. Custom Matchers:","text":"<p>Jest allows you to create custom matchers tailored to your specific testing needs. These matchers can improve the readability of your tests and make them more expressive.</p> <pre><code>// Custom matcher for checking if an array contains all unique values\nexpect.extend({\n  toHaveAllUniqueValues(received) {\n    const unique = new Set(received);\n    const pass = unique.size === received.length;\n    if (pass) {\n      return {\n        message: () =&gt; `Expected [${received}] to contain all unique values`,\n        pass: true,\n      };\n    } else {\n      return {\n        message: () =&gt; `Expected [${received}] to contain duplicate values`,\n        pass: false,\n      };\n    }\n  },\n});\n\ntest('Array has all unique values', () =&gt; {\n  expect([1, 2, 3, 4]).toHaveAllUniqueValues();\n});\n</code></pre>"},{"location":"react/jest/#9-code-coverage","title":"9. Code Coverage:","text":"<p>Jest provides code coverage reports, which help you identify which parts of your codebase are covered by tests. This ensures that you're testing the most critical parts of your application and can help uncover untested code paths.</p> <p>To generate a code coverage report, you can run Jest with the <code>--coverage</code> flag:</p> <pre><code>npm test -- --coverage\n</code></pre> <p>Jest is a versatile and feature-rich testing framework that empowers React developers to write reliable and maintainable tests. Its user-friendly approach, combined with its advanced features like module mocking, asynchronous testing, custom matchers, and code coverage reports, makes it an indispensable tool for ensuring the quality of your React applications. By mastering Jest, you can boost your development productivity and deliver more robust and bug-free software.</p>"},{"location":"react/jest/#tips-for-effective-testing-with-jest","title":"Tips for Effective Testing with Jest:","text":"<p>As you continue your journey with Jest, here are some additional tips to keep in mind for effective testing:</p>"},{"location":"react/jest/#10-organize-your-tests","title":"10. Organize Your Tests:","text":"<p>Maintain a structured directory for your tests. Group related tests in folders and name test files consistently, such as <code>Component.test.js</code> for a component named <code>Component</code>. This organization simplifies navigation and maintenance.</p>"},{"location":"react/jest/#11-use-descriptive-test-names","title":"11. Use Descriptive Test Names:","text":"<p>Write clear and descriptive test names that convey the purpose of the test. Well-named tests make it easier to understand failures and identify the tested behavior.</p> <pre><code>test('Button component should be clickable', () =&gt; {\n  // Test logic here\n});\n</code></pre>"},{"location":"react/jest/#12-test-edge-cases","title":"12. Test Edge Cases:","text":"<p>Don't just test the happy path; consider edge cases and potential errors. Test scenarios with unexpected inputs or conditions to ensure your code handles them gracefully.</p>"},{"location":"react/jest/#13-continuous-integration-ci-and-automated-testing","title":"13. Continuous Integration (CI) and Automated Testing:","text":"<p>Integrate Jest into your continuous integration workflow to automatically run tests whenever code changes are pushed. Popular CI tools like Travis CI, CircleCI, and GitHub Actions support Jest out of the box.</p>"},{"location":"react/jest/#14-mocking-external-services","title":"14. Mocking External Services:","text":"<p>When dealing with external services like APIs or databases, use Jest's mocking capabilities to avoid making actual network requests or database calls during tests. Mocking ensures that your tests remain isolated and predictable.</p>"},{"location":"react/jest/#15-keep-tests-fast","title":"15. Keep Tests Fast:","text":"<p>Efficiency matters, especially as your test suite grows. Ensure your tests run quickly by minimizing unnecessary setup and teardown, using async/await judiciously, and considering parallel test execution.</p>"},{"location":"react/jest/#16-refactor-and-maintain-tests","title":"16. Refactor and Maintain Tests:","text":"<p>Just like your code, your tests may need refactoring as your application evolves. Keep your tests up to date with code changes, and refactor them for readability and maintainability.</p>"},{"location":"react/jest/#17-leverage-test-runners","title":"17. Leverage Test Runners:","text":"<p>Jest supports running specific tests or test suites using patterns or tags. Use test runners to focus on specific areas of your application during development or troubleshooting.</p>"},{"location":"react/jest/#18-read-jest-documentation","title":"18. Read Jest Documentation:","text":"<p>Explore Jest's official documentation thoroughly. It's a valuable resource for understanding advanced features, configuration options, and best practices.</p>"},{"location":"react/jest/#19-learn-from-community-resources","title":"19. Learn from Community Resources:","text":"<p>Join online communities, forums, and social media groups dedicated to Jest and React testing. Engaging with the community can provide valuable insights and solutions to common testing challenges.</p>"},{"location":"react/jest/#20-consider-test-driven-development-tdd","title":"20. Consider Test-Driven Development (TDD):","text":"<p>Consider adopting Test-Driven Development (TDD) practices. Write tests before implementing features to ensure that your code meets the intended requirements.</p> <p>Incorporating these tips into your testing workflow will help you become a more proficient Jest user and a more effective developer overall. Jest's robust capabilities, when combined with best practices, empower you to write high-quality code with confidence.</p> <p>Now that you have a comprehensive understanding of Jest and testing in the React ecosystem, you're well-equipped to tackle complex testing scenarios and maintain the reliability and stability of your React applications. Happy testing!</p>"},{"location":"react/jest/#installing-jest-in-a-react-project","title":"Installing Jest in a React Project","text":"<p>Jest is a popular testing framework for React projects. To install Jest, you need to set up a few dependencies and configurations. This guide will walk you through the installation process step by step, ensuring you have Jest up and running in your React project.</p>"},{"location":"react/jest/#installation-steps","title":"Installation Steps:","text":""},{"location":"react/jest/#1-create-a-react-project-if-not-already-done","title":"1. Create a React Project (if not already done):","text":"<p>If you don't have a React project yet, you can create one using Create React App or any other method of your choice. For example, using Create React App:</p> <pre><code>npx create-react-app my-react-app\ncd my-react-app\n</code></pre>"},{"location":"react/jest/#2-install-jest-and-react-testing-library","title":"2. Install Jest and React Testing Library:","text":"<p>Jest is often used in conjunction with React Testing Library for testing React components. You need to install these packages as development dependencies:</p> <pre><code>npm install --save-dev jest @testing-library/react @testing-library/jest-dom\n</code></pre> <ul> <li><code>jest</code>: The core Jest library.</li> <li><code>@testing-library/react</code>: A library for interacting with React components in tests.</li> <li><code>@testing-library/jest-dom</code>: Provides custom Jest matchers for DOM elements.</li> </ul>"},{"location":"react/jest/#3-configuration-optional","title":"3. Configuration (Optional):","text":"<p>In most cases, Jest doesn't require extensive configuration, thanks to its zero-configuration setup. However, if you need custom configurations, you can create a <code>jest.config.js</code> file in your project's root directory.</p> <p>Here's a minimal example of a <code>jest.config.js</code> file:</p> <pre><code>module.exports = {\n  // Add your custom Jest configurations here (if needed)\n};\n</code></pre>"},{"location":"react/jest/#4-update-packagejson-optional","title":"4. Update <code>package.json</code> (Optional):","text":"<p>You can add the following scripts to your <code>package.json</code> file to easily run Jest tests:</p> <pre><code>\"scripts\": {\n  \"test\": \"jest\",\n  \"test:watch\": \"jest --watchAll\"\n}\n</code></pre> <p>Now you can run tests using <code>npm test</code> and run tests in watch mode with <code>npm run test:watch</code>.</p>"},{"location":"react/jest/#writing-your-first-jest-test","title":"Writing Your First Jest Test:","text":"<p>Now that Jest is installed, you can write your first test. Create a test file with the <code>.test.js</code> extension (e.g., <code>App.test.js</code>) in the same directory as the component you want to test.</p> <p>Here's a simple example of a Jest test for a React component:</p> <pre><code>// App.js (the component you want to test)\nimport React from 'docs/react/index';\n\nfunction App() {\n    return &lt;div&gt;Hello, Jest!&lt;/div&gt;;\n}\n\nexport default App;\n\n// App.test.js (the Jest test file)\nimport React from 'docs/react/index';\nimport {render} from '@testing-library/react';\nimport App from './App';\n\ntest('renders greeting text', () =&gt; {\n    const {getByText} = render(&lt;App/&gt;);\n    const greetingElement = getByText(/Hello, Jest!/i);\n    expect(greetingElement).toBeInTheDocument();\n});\n</code></pre> <p>In this example, we import the <code>render</code> function from <code>@testing-library/react</code> to render the <code>App</code> component and use Jest's <code>expect</code> assertions to test if the \"Hello, Jest!\" text is present in the rendered component.</p>"},{"location":"react/jest/#running-tests","title":"Running Tests:","text":"<p>With Jest and the test script set up, you can run your tests:</p> <pre><code>npm test\n</code></pre> <p>Jest will execute all test files with the <code>.test.js</code> or <code>.spec.js</code> extension.</p> <p>Congratulations! You've successfully installed Jest in your React project and written your first test. You can now expand your test suite to cover different components, functionality, and edge cases, ensuring the reliability of your React application.</p>"},{"location":"react/jest/#unit-testing-with-jest-in-react","title":"Unit Testing with Jest in React","text":"<p>Unit testing is a fundamental aspect of software development, and Jest is a powerful tool for writing unit tests for React components. This guide explores what unit tests are, why they are essential, and how Jest simplifies the process of writing and running unit tests for React components.</p>"},{"location":"react/jest/#understanding-unit-testing","title":"Understanding Unit Testing:","text":"<p>Unit testing is the practice of testing individual units or components of a software application in isolation. In the context of React development, a unit typically refers to a single function, method, or component. The primary goal of unit testing is to ensure that each unit of code behaves correctly in isolation, irrespective of the larger application.</p>"},{"location":"react/jest/#why-unit-testing-is-essential","title":"Why Unit Testing is Essential:","text":"<p>Unit testing offers several benefits in software development:</p> <ol> <li> <p>Isolation: Unit tests allow you to isolate specific parts of your code and test them independently. This isolation makes it easier to identify and fix issues.</p> </li> <li> <p>Early Detection of Bugs: By testing individual units early in the development process, you can catch and fix bugs before they propagate and become harder to debug.</p> </li> <li> <p>Documentation: Unit tests serve as documentation for your code. They provide clear examples of how your code should be used and what behavior is expected.</p> </li> <li> <p>Refactoring Confidence: When you make changes or refactor code, unit tests act as a safety net. Passing tests indicate that your changes haven't introduced regressions.</p> </li> </ol>"},{"location":"react/jest/#writing-unit-tests-with-jest","title":"Writing Unit Tests with Jest:","text":"<p>Jest is a JavaScript testing framework that simplifies the process of writing and running unit tests. Here's how Jest helps in writing unit tests for React components:</p>"},{"location":"react/jest/#1-setup-and-teardown","title":"1. Setup and Teardown:","text":"<p>Jest provides functions like <code>beforeEach</code> and <code>afterEach</code> to set up and tear down test environments. This ensures that each test starts with a clean slate, preventing side effects from affecting other tests.</p>"},{"location":"react/jest/#2-matchers","title":"2. Matchers:","text":"<p>Jest offers a wide range of matchers that allow you to make assertions about the values returned by your code. Common matchers include <code>toBe</code>, <code>toEqual</code>, <code>toContain</code>, and <code>toThrow</code>. These help you express your test expectations clearly.</p>"},{"location":"react/jest/#3-mocking-dependencies","title":"3. Mocking Dependencies:","text":"<p>Jest makes it easy to mock external dependencies, such as API calls, to isolate the code under test. You can create mock functions and control their behavior within your tests.</p>"},{"location":"react/jest/#4-snapshot-testing","title":"4. Snapshot Testing:","text":"<p>Snapshot testing is a unique feature of Jest. It allows you to capture the rendered output of a component and compare it to a stored \"snapshot.\" If the output changes unexpectedly, Jest alerts you, helping you spot UI regressions.</p>"},{"location":"react/jest/#5-asynchronous-testing","title":"5. Asynchronous Testing:","text":"<p>Many React components involve asynchronous operations, like data fetching. Jest provides support for testing asynchronous code using techniques like <code>async/await</code> or by returning Promises from test functions.</p>"},{"location":"react/jest/#example-unit-testing-a-react-component-with-jest","title":"Example: Unit Testing a React Component with Jest:","text":"<p>Let's consider a simple React component named <code>Counter</code> that increments a count when a button is clicked. We'll write a unit test for this component using Jest and React Testing Library.</p> <pre><code>// Counter.js\nimport React, {useState} from 'docs/react/index';\n\nfunction Counter() {\n    const [count, setCount] = useState(0);\n\n    const increment = () =&gt; {\n        setCount(count + 1);\n    };\n\n    return (\n        &lt;div&gt;\n            &lt;p&gt;Count: {count}&lt;/p&gt;\n            &lt;button onClick={increment}&gt;Increment&lt;/button&gt;\n        &lt;/div&gt;\n    );\n}\n\nexport default Counter;\n</code></pre> <pre><code>// Counter.test.js\nimport React from 'docs/react/index';\nimport {render, fireEvent} from '@testing-library/react';\nimport Counter from './Counter';\n\ntest('Counter increments count on button click', () =&gt; {\n    const {getByText} = render(&lt;Counter/&gt;);\n    const incrementButton = getByText('Increment');\n    const countText = getByText('Count: 0');\n\n    fireEvent.click(incrementButton); // Simulate a button click\n\n    expect(countText).toHaveTextContent('Count: 1');\n});\n</code></pre> <p>In this example, we:</p> <ul> <li>Render the <code>Counter</code> component using React Testing Library.</li> <li>Simulate a button click using <code>fireEvent.click</code>.</li> <li>Use Jest's <code>expect</code> and <code>toHaveTextContent</code> to verify that the count increases as expected.</li> </ul>"},{"location":"react/jest/#running-jest-unit-tests","title":"Running Jest Unit Tests:","text":"<p>You can run Jest unit tests using the <code>npm test</code> command. Jest will discover and execute all test files within your project.</p> <pre><code>npm test\n</code></pre> <p>Jest will provide test results, including pass/fail status and any error messages.</p> <p>By using Jest for unit testing, you can ensure the correctness of individual React components, improve code quality, and confidently refactor and enhance your application as it evolves.</p>"},{"location":"react/jest/#best-practices-for-writing-effective-unit-tests-with-jest","title":"Best Practices for Writing Effective Unit Tests with Jest:","text":"<p>As you continue writing unit tests with Jest for your React components, consider these best practices to ensure your tests are effective and maintainable:</p>"},{"location":"react/jest/#1-test-one-thing-at-a-time","title":"1. Test One Thing at a Time:","text":"<p>Keep each test focused on verifying a single behavior or aspect of your component. This makes tests easier to understand and pinpoint failures.</p>"},{"location":"react/jest/#2-use-descriptive-test-names","title":"2. Use Descriptive Test Names:","text":"<p>Give your tests clear and descriptive names that explain what they are testing. A well-named test serves as documentation for your code.</p>"},{"location":"react/jest/#3-avoid-testing-implementation-details","title":"3. Avoid Testing Implementation Details:","text":"<p>Focus on testing the public interface of your components, such as the rendered output and user interactions, rather than internal implementation details. Testing implementation details can lead to fragile tests that break easily when you refactor.</p>"},{"location":"react/jest/#4-maintain-a-balance-between-shallow-and-deep-rendering","title":"4. Maintain a Balance between Shallow and Deep Rendering:","text":"<p>React Testing Library encourages shallow rendering by default, which helps you test the component's behavior from the user's perspective. However, there may be cases where you need to test deeper component hierarchies. Use <code>mount</code> or <code>shallow</code> rendering from libraries like <code>enzyme</code> when necessary.</p>"},{"location":"react/jest/#5-keep-tests-dry-dont-repeat-yourself","title":"5. Keep Tests DRY (Don't Repeat Yourself):","text":"<p>Avoid duplicating code in your tests. If you find yourself repeating the same setup or assertions in multiple tests, consider using Jest's <code>beforeEach</code> or creating helper functions.</p>"},{"location":"react/jest/#6-use-mocks-wisely","title":"6. Use Mocks Wisely:","text":"<p>While mocking is valuable for isolating code under test, be cautious not to overuse it. Mock only external dependencies and functions that interact with external services. Mocking everything can lead to unrealistic tests.</p>"},{"location":"react/jest/#7-test-edge-cases","title":"7. Test Edge Cases:","text":"<p>Think about edge cases, boundary conditions, and error scenarios when writing tests. Ensuring that your component behaves correctly in exceptional situations is crucial for robust code.</p>"},{"location":"react/jest/#8-refactor-tests-as-code-evolves","title":"8. Refactor Tests as Code Evolves:","text":"<p>Just like your application code, tests may need refactoring as your project evolves. Keep your tests up to date and refactor them as needed to maintain their effectiveness.</p>"},{"location":"react/jest/#9-monitor-code-coverage","title":"9. Monitor Code Coverage:","text":"<p>Jest provides code coverage reports that indicate which parts of your code are covered by tests. Aim for high code coverage to ensure you've tested most of your application's logic.</p>"},{"location":"react/jest/#10-write-tests-before-code-tdd","title":"10. Write Tests Before Code (TDD):","text":"<p>Consider adopting Test-Driven Development (TDD) practices by writing tests before implementing new features or fixing bugs. This approach can lead to well-designed and thoroughly tested code.</p> <p>By following these best practices and leveraging Jest's capabilities, you can create a robust suite of unit tests for your React components. Unit testing with Jest not only improves the reliability of your code but also enhances your development workflow by providing rapid feedback and documentation for your components.</p>"},{"location":"react/jest/#mocking-external-dependencies-in-jest-tests","title":"Mocking External Dependencies in Jest Tests","text":""},{"location":"react/jest/#summary","title":"Summary:","text":"<p>In Jest, you can mock external dependencies or functions to isolate the code you're testing and control their behavior. This guide explains various techniques for mocking external dependencies in your Jest tests, ensuring that your tests remain focused and predictable.</p>"},{"location":"react/jest/#why-mock-external-dependencies","title":"Why Mock External Dependencies?","text":"<p>Mocking external dependencies is essential for unit testing because it allows you to:</p> <ol> <li> <p>Isolate Code: Ensure that the code you're testing is isolated from external services, databases, or APIs. This prevents your tests from making real network requests or causing unintended side effects.</p> </li> <li> <p>Control Behavior: Define specific behaviors or return values for external dependencies to create predictable test scenarios. This helps you test various conditions and edge cases.</p> </li> <li> <p>Improve Test Performance: Mocking can help tests run faster by avoiding slow or time-consuming operations in external dependencies.</p> </li> </ol>"},{"location":"react/jest/#mocking-techniques-in-jest","title":"Mocking Techniques in Jest:","text":"<p>Jest provides multiple ways to mock external dependencies or functions. Here are some common techniques:</p>"},{"location":"react/jest/#1-manual-mocks","title":"1. Manual Mocks:","text":"<p>You can create manual mocks for modules by placing a <code>__mocks__</code> directory adjacent to the module you want to mock. Jest will automatically use these mocks when the module is imported in your tests.</p> <p>For example, if you want to mock an API module:</p> <pre><code>// api.js\nexport function fetchData() {\n  // Actual implementation\n}\n\n// __mocks__/api.js\nexport function fetchData() {\n  return Promise.resolve('Mocked Data');\n}\n</code></pre>"},{"location":"react/jest/#2-jestmock","title":"2. jest.mock():","text":"<p>The <code>jest.mock()</code> function allows you to mock a module explicitly within your test file. It replaces the imported module with a mock implementation.</p> <pre><code>// api.js\nexport function fetchData() {\n  // Actual implementation\n}\n\n// test.js\njest.mock('./api'); // Mock the 'api' module\n\ntest('Mocked API', () =&gt; {\n  const { fetchData } = require('./api'); // Use the mocked module\n  fetchData.mockReturnValue('Mocked Data');\n\n  // Your test logic here\n});\n</code></pre>"},{"location":"react/jest/#3-spyon","title":"3. spyOn():","text":"<p>The <code>jest.spyOn()</code> method is useful for mocking methods of an object, such as class methods. It allows you to track calls to the method and control its behavior.</p> <pre><code>// userService.js\nexport class UserService {\n  fetchUser(id) {\n    // Actual implementation\n  }\n}\n\n// test.js\nimport { UserService } from './userService';\n\ntest('Mocked UserService', () =&gt; {\n  const userService = new UserService();\n  const mockFetchUser = jest.spyOn(userService, 'fetchUser');\n  mockFetchUser.mockResolvedValue({ id: 1, name: 'John' });\n\n  // Your test logic here\n});\n</code></pre>"},{"location":"react/jest/#4-mock-functions","title":"4. Mock Functions:","text":"<p>Jest provides the <code>jest.fn()</code> function to create mock functions. You can use these functions to replace real functions or methods and define their behavior.</p> <pre><code>// service.js\nexport function doSomething() {\n  // Actual implementation\n}\n\n// test.js\nimport { doSomething } from './service';\n\ntest('Mocked doSomething', () =&gt; {\n  const mockDoSomething = jest.fn();\n  mockDoSomething.mockReturnValue('Mocked Result');\n  doSomething.mockImplementation(mockDoSomething);\n\n  // Your test logic here\n});\n</code></pre>"},{"location":"react/jest/#advanced-mocking-with-mock-modules","title":"Advanced Mocking with Mock Modules:","text":"<p>Jest also allows you to mock entire modules and specify custom behaviors for their functions. You can use <code>jest.mock()</code> with an implementation factory to achieve this.</p> <pre><code>// api.js\nexport function fetchData() {\n  // Actual implementation\n}\n\n// test.js\njest.mock('./api', () =&gt; ({\n  fetchData: jest.fn().mockResolvedValue('Mocked Data'),\n}));\n\ntest('Mocked API Module', async () =&gt; {\n  const { fetchData } = require('./api');\n  const result = await fetchData();\n\n  expect(result).toBe('Mocked Data');\n});\n</code></pre>"},{"location":"react/jest/#cleaning-up-mocks","title":"Cleaning Up Mocks:","text":"<p>Jest automatically resets (clears) mock functions and modules between tests. However, if you need to clear a specific mock's state or behavior, you can use <code>mockFn.mockClear()</code> to reset its call history or <code>mockFn.mockReset()</code> to reset both call history and behavior.</p> <pre><code>// Clearing a single mock function's call history\nmockDoSomething.mockClear();\n\n// Resetting a single mock function's call history and behavior\nmockDoSomething.mockReset();\n</code></pre> <p>Mocking external dependencies is a crucial part of unit testing in Jest. By isolating your code under test and controlling the behavior of external dependencies, you can create reliable and predictable tests. Whether you use manual mocks, <code>jest.mock()</code>, <code>spyOn()</code>, or mock functions, Jest offers versatile tools to help you mock external dependencies effectively in your tests.</p>"},{"location":"react/jest/#using-mock-return-values-and-implementations","title":"Using Mock Return Values and Implementations:","text":"<p>In addition to mocking functions and modules, Jest allows you to define custom return values and implementations for your mock functions. This can be particularly useful when you want to simulate different scenarios and test various code paths.</p>"},{"location":"react/jest/#mock-return-values","title":"Mock Return Values:","text":"<p>You can use the <code>mockReturnValue()</code> method to set a specific return value for a mock function. This return value will be used when the function is called.</p> <pre><code>const mockFunction = jest.fn();\nmockFunction.mockReturnValue(42);\n\n// When called, it will always return 42\nconsole.log(mockFunction()); // 42\nconsole.log(mockFunction()); // 42\n</code></pre>"},{"location":"react/jest/#mock-implementations","title":"Mock Implementations:","text":"<p>With the <code>mockImplementation()</code> method, you can define a custom implementation for a mock function. This allows you to simulate different behaviors when the function is called.</p> <pre><code>const mockFunction = jest.fn();\nmockFunction.mockImplementation((a, b) =&gt; a + b);\n\nconsole.log(mockFunction(2, 3)); // 5\nconsole.log(mockFunction(4, 7)); // 11\n</code></pre>"},{"location":"react/jest/#conditional-mocking","title":"Conditional Mocking:","text":"<p>You can combine mock return values and implementations to create conditional mocks that behave differently based on the input parameters or the number of times the function is called.</p> <pre><code>const mockFunction = jest.fn();\nmockFunction\n  .mockReturnValueOnce('First Call')\n  .mockReturnValueOnce('Second Call')\n  .mockReturnValue('Subsequent Calls');\n\nconsole.log(mockFunction()); // 'First Call'\nconsole.log(mockFunction()); // 'Second Call'\nconsole.log(mockFunction()); // 'Subsequent Calls'\nconsole.log(mockFunction()); // 'Subsequent Calls'\n</code></pre>"},{"location":"react/jest/#using-mocks-for-testing-asynchronous-code","title":"Using Mocks for Testing Asynchronous Code:","text":"<p>Jest also allows you to mock asynchronous functions and promises. You can use <code>mockResolvedValue()</code> or <code>mockRejectedValue()</code> to simulate resolved or rejected promises, respectively.</p> <pre><code>const mockAsyncFunction = jest.fn();\nmockAsyncFunction.mockResolvedValue('Resolved Data');\n\n// In an async test, you can use await to resolve the promise\ntest('Async Mock', async () =&gt; {\n  const result = await mockAsyncFunction();\n  expect(result).toBe('Resolved Data');\n});\n</code></pre>"},{"location":"react/jest/#advanced-mocking-with-jestspyon","title":"Advanced Mocking with <code>jest.spyOn()</code>:","text":"<p><code>jest.spyOn()</code> is a powerful tool for mocking methods of objects, such as class methods. It not only mocks the method but also allows you to track its calls and control its behavior.</p> <pre><code>class Calculator {\n  add(a, b) {\n    return a + b;\n  }\n}\n\ntest('Mocking Class Method', () =&gt; {\n  const calculator = new Calculator();\n  const spyAdd = jest.spyOn(calculator, 'add');\n\n  // Set a custom implementation for the spy\n  spyAdd.mockImplementation((a, b) =&gt; a * b);\n\n  const result = calculator.add(3, 4);\n\n  // Verify the spy was called with the expected arguments\n  expect(spyAdd).toHaveBeenCalledWith(3, 4);\n  // Verify the result based on the custom implementation\n  expect(result).toBe(12);\n\n  // Restore the original method implementation\n  spyAdd.mockRestore();\n});\n</code></pre> <p>Mocking in Jest is a powerful feature that allows you to control the behavior of functions and modules during tests. By using mock functions, return values, and implementations, you can create flexible and predictable test scenarios. Whether you need to simulate different outcomes, isolate your code under test, or track method calls, Jest provides the tools to make your testing process effective and reliable.</p>"},{"location":"react/lifecycle/","title":"Lifecycle Methods","text":""},{"location":"react/lifecycle/#lifecycle-methods_1","title":"Lifecycle Methods","text":"<p>React lifecycle methods are special functions that allow you to hook into different stages of a component's life, from creation to deletion. They provide opportunities to perform actions like setting up initial state, making API calls, and cleaning up resources. Understanding these methods is crucial for managing component behavior effectively.</p> <p>React class components have several lifecycle methods categorized into three main phases: Mounting, Updating, and Unmounting. Functional components also have similar lifecycle behaviors with the introduction of React Hooks.</p>"},{"location":"react/lifecycle/#mounting-phase","title":"Mounting Phase","text":"<ol> <li> <p>constructor: The constructor is called when the component is initialized. It's used for setting up initial state and binding methods.</p> </li> <li> <p>render: The render method returns the JSX representation of the component's UI. It's called each time the component needs to be re-rendered.</p> </li> <li> <p>componentDidMount: This method is called after the component has been rendered to the DOM. It's often used for making initial API calls or setting up event listeners.</p> </li> </ol>"},{"location":"react/lifecycle/#updating-phase","title":"Updating Phase","text":"<ol> <li> <p>shouldComponentUpdate: This method is called before re-rendering a component. You can use it to control whether the component should update based on the new props and state.</p> </li> <li> <p>render: As mentioned earlier, the render method is called during updates as well when the component needs to re-render.</p> </li> <li> <p>componentDidUpdate: After a component updates, this method is called. It's useful for performing actions after a re-render, like updating the DOM in response to state changes.</p> </li> </ol>"},{"location":"react/lifecycle/#unmounting-phase","title":"Unmounting Phase","text":"<ol> <li>componentWillUnmount: This method is invoked just before a component is removed from the DOM. It's used for cleanup tasks like removing event listeners or clearing timers.</li> </ol>"},{"location":"react/lifecycle/#example-usage","title":"Example Usage","text":"<p>Let's illustrate the usage of these methods with a practical example:</p> <pre><code>import React, {Component} from 'docs/react/index';\n\nclass LifecycleExample extends Component {\n    constructor(props) {\n        super(props);\n        this.state = {count: 0};\n    }\n\n    componentDidMount() {\n        // Called after component is added to the DOM\n        console.log('Component mounted');\n    }\n\n    componentDidUpdate(prevProps, prevState) {\n        // Called after component updates\n        console.log('Component updated');\n    }\n\n    componentWillUnmount() {\n        // Called before component is removed from the DOM\n        console.log('Component unmounted');\n    }\n\n    render() {\n        return (\n            &lt;div&gt;\n                &lt;p&gt;Count: {this.state.count}&lt;/p&gt;\n                &lt;button onClick={() =&gt; this.setState({count: this.state.count + 1})}&gt;\n                    Increment\n                &lt;/button&gt;\n            &lt;/div&gt;\n        );\n    }\n}\n\nexport default LifecycleExample;\n</code></pre> <p>In this example, we've used the <code>componentDidMount</code>, <code>componentDidUpdate</code>, and <code>componentWillUnmount</code> methods to demonstrate their respective lifecycle phases. These methods help manage the component's behavior throughout its life cycle.</p>"},{"location":"react/lifecycle/#react-hooks-and-functional-components","title":"React Hooks and Functional Components","text":"<p>With the introduction of React Hooks, functional components can also mimic similar lifecycle behavior using hooks like <code>useEffect</code>. Here's how the above example would look in a functional component:</p> <pre><code>import React, {useState, useEffect} from 'docs/react/index';\n\nfunction LifecycleExample() {\n    const [count, setCount] = useState(0);\n\n    useEffect(() =&gt; {\n        // Called after component is added to the DOM\n        console.log('Component mounted');\n\n        return () =&gt; {\n            // Called before component is removed from the DOM\n            console.log('Component unmounted');\n        };\n    }, []); // Empty dependency array means this effect runs once, like componentDidMount\n\n    useEffect(() =&gt; {\n        // Called after every render (including initial render)\n        console.log('Component updated');\n    });\n\n    return (\n        &lt;div&gt;\n            &lt;p&gt;Count: {count}&lt;/p&gt;\n            &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Increment&lt;/button&gt;\n        &lt;/div&gt;\n    );\n}\n\nexport default LifecycleExample;\n</code></pre> <p>In this functional component, we use the <code>useState</code> hook to manage state and the <code>useEffect</code> hook to mimic lifecycle methods. The empty dependency array <code>[]</code> in the first <code>useEffect</code> hook ensures it runs only once, similar to <code>componentDidMount</code>.</p> <p>The second <code>useEffect</code> hook runs after every render, similar to <code>componentDidUpdate</code>. Cleanup can also be performed within <code>useEffect</code> by returning a function, similar to <code>componentWillUnmount</code>.</p> <p>Understanding React's lifecycle methods (in both class and functional components) is essential for controlling the behavior of your components throughout their life cycles. Whether you're initializing state, fetching data, or cleaning up resources, these methods provide hooks into various stages of your component's existence, ensuring your components function as expected in different scenarios. React Hooks have made it easier to achieve similar behavior in functional components, making them a powerful tool for modern React development.</p>"},{"location":"react/lifecycle/#real-life-scenario-using-react-lifecycle-methods","title":"Real-Life Scenario: Using React Lifecycle Methods","text":"<p>Let's dive deeper into a real-life scenario to showcase how React's lifecycle methods can be used effectively. Imagine you're building a social media application, and you want to load a user's posts when they visit their profile page. You can use lifecycle methods to handle data fetching and UI updates:</p> <pre><code>import React, {Component} from 'docs/react/index';\n\nclass UserProfile extends Component {\n    constructor(props) {\n        super(props);\n        this.state = {\n            userId: props.userId,\n            userPosts: [],\n            isLoading: true,\n        };\n    }\n\n    componentDidMount() {\n        // Simulate an API call to fetch user posts\n        fetch(`/api/users/${this.state.userId}/posts`)\n            .then((response) =&gt; response.json())\n            .then((data) =&gt; {\n                this.setState({\n                    userPosts: data,\n                    isLoading: false,\n                });\n            });\n    }\n\n    render() {\n        const {userPosts, isLoading} = this.state;\n\n        return (\n            &lt;div&gt;\n                {isLoading ? (\n                    &lt;p&gt;Loading user posts...&lt;/p&gt;\n                ) : (\n                    &lt;div&gt;\n                        &lt;h2&gt;User Posts&lt;/h2&gt;\n                        &lt;ul&gt;\n                            {userPosts.map((post) =&gt; (\n                                &lt;li key={post.id}&gt;{post.title}&lt;/li&gt;\n                            ))}\n                        &lt;/ul&gt;\n                    &lt;/div&gt;\n                )}\n            &lt;/div&gt;\n        );\n    }\n}\n\nexport default UserProfile;\n</code></pre> <p>In this example:</p> <ol> <li> <p>In the constructor, we initialize the component's state with an initial <code>userId</code>, an empty array for <code>userPosts</code>, and a loading indicator (<code>isLoading</code>).</p> </li> <li> <p>In <code>componentDidMount</code>, we simulate an API call to fetch the user's posts data. When the data is retrieved, we update the state with the fetched posts and set <code>isLoading</code> to <code>false</code>. This will trigger a re-render of the component with the user's posts displayed.</p> </li> <li> <p>In the <code>render</code> method, we conditionally render content based on the <code>isLoading</code> flag. If data is still loading, we display a loading message; otherwise, we render the user's posts.</p> </li> </ol> <p>By utilizing lifecycle methods like <code>componentDidMount</code>, we ensure that the data fetching happens after the component is mounted, preventing unnecessary API requests during the initial rendering phase. This pattern ensures a smoother user experience and is a common use case for handling asynchronous operations in React applications.</p> <p>By incorporating React's lifecycle methods into your components, you can effectively manage data fetching, UI updates, and resource cleanup, making your applications more robust and responsive.</p>"},{"location":"react/lifecycle/#class-component-vs-functional-component","title":"Class Component vs Functional Component","text":"<p>In React, there are two primary ways to create components: class components and functional components. Class components are created using ES6 classes and have a richer set of features, while functional components are simpler and use JavaScript functions. Here's a brief comparison:</p> <ul> <li>Class Component: Created with a class and extends <code>React.Component</code>. Used for complex state management, lifecycle methods, and class-based features.</li> <li>Functional Component: Created as a plain JavaScript function. Ideal for simple UI components and stateless rendering.</li> </ul> <p>Now, let's dive deeper into the details.</p>"},{"location":"react/lifecycle/#class-component","title":"Class Component","text":"<p>Class components in React are defined as JavaScript classes that extend <code>React.Component</code>. They have been the traditional way of creating components in React and offer a wide range of features:</p> <ol> <li> <p>State Management: Class components have built-in state management using <code>this.state</code> and <code>this.setState()</code>. This allows you to store and update component-specific data.</p> </li> <li> <p>Lifecycle Methods: Class components have lifecycle methods like <code>componentDidMount</code>, <code>componentDidUpdate</code>, and <code>componentWillUnmount</code>. These methods allow you to control component behavior at various stages of its lifecycle.</p> </li> <li> <p>Complex Logic: They are suitable for components with complex logic, such as forms, interactive components, or components that require access to lifecycle events.</p> </li> </ol> <p>Here's an example of a class component:</p> <pre><code>import React, {Component} from 'docs/react/index';\n\nclass ClassComponent extends Component {\n    constructor(props) {\n        super(props);\n        this.state = {count: 0};\n    }\n\n    render() {\n        return (\n            &lt;div&gt;\n                &lt;p&gt;Count: {this.state.count}&lt;/p&gt;\n                &lt;button onClick={() =&gt; this.setState({count: this.state.count + 1})}&gt;\n                    Increment\n                &lt;/button&gt;\n            &lt;/div&gt;\n        );\n    }\n}\n\nexport default ClassComponent;\n</code></pre>"},{"location":"react/lifecycle/#functional-component","title":"Functional Component","text":"<p>Functional components are simpler and more lightweight. They are just JavaScript functions that return JSX. Key points:</p> <ol> <li> <p>No State: Functional components do not have built-in state. They receive data through props and are primarily used for rendering UI based on those props.</p> </li> <li> <p>Hooks: To manage state and side-effects in functional components, React introduced Hooks like <code>useState</code>, <code>useEffect</code>, and <code>useContext</code>. These hooks enable you to add state and lifecycle-like behavior to functional components.</p> </li> <li> <p>Reusability: Functional components are highly reusable and can be composed easily into larger components.</p> </li> </ol> <p>Here's an example of a functional component using hooks:</p> <pre><code>import React, {useState} from 'docs/react/index';\n\nfunction FunctionalComponent() {\n    const [count, setCount] = useState(0);\n\n    return (\n        &lt;div&gt;\n            &lt;p&gt;Count: {count}&lt;/p&gt;\n            &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Increment&lt;/button&gt;\n        &lt;/div&gt;\n    );\n}\n\nexport default FunctionalComponent;\n</code></pre>"},{"location":"react/lifecycle/#choosing-between-class-and-functional-components","title":"Choosing Between Class and Functional Components","text":"<ul> <li>Use class components when you need advanced features like state management and lifecycle methods.</li> <li>Prefer functional components for simple UI rendering or when hooks can fulfill your state and logic requirements.</li> <li>As of React 16.8, functional components with hooks are the recommended way of building components in React due to their simplicity and flexibility.</li> </ul>"},{"location":"react/lifecycle/#react-hooks","title":"React Hooks","text":"<p>Hooks are a feature in React, a popular JavaScript library for building user interfaces. They allow developers to add state and lifecycle features to functional components, which were previously only available in class components. Hooks provide a cleaner and more concise way to manage component logic, making it easier for developers to write and maintain React applications.</p> <p>React Hooks were introduced in React version 16.8 and have since become a fundamental part of React development. They come in various flavors, but the most commonly used ones are <code>useState</code>, <code>useEffect</code>, <code>useContext</code>, and <code>useRef</code>.</p>"},{"location":"react/lifecycle/#usestate","title":"useState","text":"<p><code>useState</code> is used to manage state within a functional component. It lets you declare a state variable and provides a way to update it. Here's an example:</p> <pre><code>import React, {useState} from 'docs/react/index';\n\nfunction Counter() {\n    const [count, setCount] = useState(0);\n\n    return (\n        &lt;div&gt;\n            &lt;p&gt;Count: {count}&lt;/p&gt;\n            &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Increment&lt;/button&gt;\n        &lt;/div&gt;\n    );\n}\n</code></pre>"},{"location":"react/lifecycle/#useeffect","title":"useEffect","text":"<p><code>useEffect</code> allows you to perform side effects in your components, such as data fetching, DOM manipulation, or setting up subscriptions. It runs after the component renders. Example:</p> <pre><code>import React, {useState, useEffect} from 'docs/react/index';\n\nfunction ExampleComponent() {\n    const [data, setData] = useState([]);\n\n    useEffect(() =&gt; {\n        // Fetch data from an API\n        fetch('https://api.example.com/data')\n            .then((response) =&gt; response.json())\n            .then((result) =&gt; setData(result));\n    }, []); // Empty dependency array means it runs once on mount\n\n    return (\n        &lt;div&gt;\n            {data.map((item) =&gt; (\n                &lt;p key={item.id}&gt;{item.name}&lt;/p&gt;\n            ))}\n        &lt;/div&gt;\n    );\n}\n</code></pre>"},{"location":"react/lifecycle/#usecontext","title":"useContext","text":"<p><code>useContext</code> is used to access a React context within a functional component. It allows you to share data between components without the need for prop drilling. Example:</p> <pre><code>import React, {useContext} from 'docs/react/index';\n\nconst ThemeContext = React.createContext('light');\n\nfunction ThemedButton() {\n    const theme = useContext(ThemeContext);\n\n    return &lt;button style={{background: theme}}&gt;Themed Button&lt;/button&gt;;\n}\n</code></pre>"},{"location":"react/lifecycle/#useref","title":"useRef","text":"<p><code>useRef</code> provides a way to create mutable references to elements or values that persist across renders. It's often used to interact with the DOM or manage previous values. Example:</p> <pre><code>import React, {useRef, useEffect} from 'docs/react/index';\n\nfunction FocusInput() {\n    const inputRef = useRef();\n\n    useEffect(() =&gt; {\n        inputRef.current.focus();\n    }, []);\n\n    return &lt;input ref={inputRef}/&gt;;\n}\n</code></pre> <p>React Hooks have revolutionized the way developers work with React components. They offer a more straightforward and functional approach to managing state and side effects, making code cleaner and more maintainable. By understanding and using hooks effectively, developers can create more efficient and readable React applications.</p>"},{"location":"react/lifecycle/#custom-hooks","title":"Custom Hooks","text":"<p>Apart from the built-in hooks mentioned earlier, developers can create their custom hooks. Custom hooks are reusable pieces of logic that can be shared across different components. Let's create a custom hook to illustrate this concept.</p> <pre><code>import {useState, useEffect} from 'docs/react/index';\n\nfunction useFetchData(url) {\n    const [data, setData] = useState([]);\n    const [loading, setLoading] = useState(true);\n\n    useEffect(() =&gt; {\n        fetch(url)\n            .then((response) =&gt; response.json())\n            .then((result) =&gt; {\n                setData(result);\n                setLoading(false);\n            });\n    }, [url]);\n\n    return {data, loading};\n}\n</code></pre> <p>Now, you can use <code>useFetchData</code> in multiple components to fetch data from various URLs without duplicating the fetch logic.</p> <pre><code>import React from 'docs/react/index';\nimport useFetchData from './useFetchData';\n\nfunction MyComponent() {\n    const {data, loading} = useFetchData('https://api.example.com/data');\n\n    if (loading) {\n        return &lt;p&gt;Loading...&lt;/p&gt;;\n    }\n\n    return (\n        &lt;div&gt;\n            {data.map((item) =&gt; (\n                &lt;p key={item.id}&gt;{item.name}&lt;/p&gt;\n            ))}\n        &lt;/div&gt;\n    );\n}\n</code></pre>"},{"location":"react/lifecycle/#rules-of-hooks","title":"Rules of Hooks","text":"<p>While using hooks, it's essential to follow the Rules of Hooks:</p> <ol> <li>Only call hooks at the top level of a function component or a custom hook.</li> <li>Only call hooks from React functions (not regular JavaScript functions).</li> <li>Ensure that hooks are called in the same order on every render.</li> </ol> <p>Adhering to these rules ensures that your components behave predictably and that hooks work as expected.</p>"},{"location":"react/lifecycle/#benefits-of-hooks","title":"Benefits of Hooks","text":"<ol> <li>Improved code organization: Hooks allow you to organize your code based on the logic it represents, rather than by lifecycle methods.</li> <li>Reusability: Custom hooks make it easy to share logic between components.</li> <li>Cleaner code: Hooks often lead to shorter and more readable component code.</li> <li>Easier testing: Since hooks are just functions, they are easier to test compared to class components.</li> </ol> <p>In conclusion, React Hooks are a powerful addition to React that simplify component logic and make it more maintainable. By understanding and mastering the different hooks available, you can become a more effective React developer and create better user interfaces.</p>"},{"location":"spring/","title":"Spring","text":"<p>{: .no_toc }</p>      Table of contents    <p>{: .text-delta } 1. TOC</p> <p>The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform.</p> <p>A key element of Spring is infrastructural support at the application level: Spring focuses on the \"plumbing\" of enterprise applications so that teams can focus on application-level business logic, without unnecessary ties to specific deployment environments.</p>"},{"location":"spring/#features","title":"Features","text":""},{"location":"spring/#core-technologies","title":"Core technologies","text":"<p>Dependency injection, events, resources, i18n, validation, data binding, type conversion, SpEL, AOP.</p>"},{"location":"spring/#testing","title":"Testing","text":"<p>mock objects, TestContext framework, Spring MVC Test, WebTestClient.</p>"},{"location":"spring/#data-access","title":"Data Access","text":"<p>transactions, DAO support, JDBC, ORM, Marshalling XML.</p>"},{"location":"spring/#spring-mvc-and-spring-webflux-web-frameworks","title":"Spring MVC and Spring WebFlux web frameworks.","text":""},{"location":"spring/#integration","title":"Integration","text":"<p>remoting, JMS, JCA, JMX, email, tasks, scheduling, cache.</p>"},{"location":"spring/#languages","title":"Languages","text":"<p>Kotlin, Groovy, dynamic languages.</p>"},{"location":"spring/#inversion-of-control-ioc-and-dependency-injectiondi","title":"Inversion Of Control (IOC) and Dependency Injection(DI)","text":"<p>These are the design patterns that are used to remove dependency from the programming code. They make the code easier to test and maintain. Let's understand this with the following code:</p> <pre><code>class Employee{  \n    Address address;  \n    Employee(){  \n        address=new Address();  \n    }  \n}  \n</code></pre> <p>In such case, there is dependency between the Employee and Address (tight coupling). In the Inversion of Control scenario, we do this something like this: <pre><code>class Employee{  \n    Address address;  \n    Employee(Address address){  \n        this.address=address;  \n    }  \n}  \n</code></pre></p> <p>Thus, IOC makes the code loosely coupled. In such case, there is no need to modify the code if our logic is moved to new environment.</p> <p>In Spring framework, IOC container is responsible to inject the dependency. We provide metadata to the IOC container either by XML file or annotation.</p>"},{"location":"spring/#inversion-of-control","title":"Inversion of Control","text":"<p>Inversion of Control is a principle in software engineering which transfers the control of objects or portions of a program to a container or framework.</p>"},{"location":"spring/#advantages-of-inversion-of-control","title":"Advantages of Inversion of Control","text":"<ol> <li>decoupling the execution of a task from its implementation</li> <li>making it easier to switch between different implementations</li> <li>greater modularity of a program</li> <li>greater ease in testing a program by isolating a component or mocking its dependencies, and allowing components to communicate through contracts</li> </ol> <p>We can achieve Inversion of Control through various mechanisms such as: Strategy design pattern, Service Locator pattern, Factory pattern, and Dependency Injection (DI).</p>"},{"location":"spring/#dependency-injection","title":"Dependency Injection","text":"<p>Dependency injection is a pattern we can use to implement IoC, where the control being inverted is setting an object's dependencies.</p> <p>Connecting objects with other objects, or \u201cinjecting\u201d objects into other objects, is done by an assembler rather than by the objects themselves.</p>"},{"location":"spring/#advantage-of-dependency-injection","title":"Advantage of Dependency Injection","text":"<ul> <li>makes the code loosely coupled so easy to maintain</li> <li>makes the code easy to test</li> </ul>"},{"location":"spring/#spring-ioc-container","title":"Spring IoC Container","text":"<p>In the Spring framework, the interface ApplicationContext represents the IoC container. The Spring container is responsible for instantiating, configuring and assembling objects known as beans, as well as managing their life cycles.</p> <p>The Spring framework provides several implementations of the ApplicationContext interface: ClassPathXmlApplicationContext and FileSystemXmlApplicationContext for standalone applications, and WebApplicationContext for web applications.</p> <p>In order to assemble beans, the container uses configuration metadata, which can be in the form of XML configuration or annotations.</p> <p>Here's one way to manually instantiate a container:</p> <pre><code>ApplicationContext context\n        = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\n</code></pre> <p>Dependency Injection in Spring can be done through constructors, setters or fields.</p>"},{"location":"spring/#stackoverflow","title":"Stackoverflow","text":"<p>The Inversion-of-Control (IoC) pattern, is about providing any kind of callback (which \"implements\" and/or controls reaction), instead of acting ourselves directly (in other words, inversion and/or redirecting control to the external handler/controller).</p> <p>For example, rather than having the application call the implementations provided by a library (also known as toolkit), a framework calls the implementations provided by the application.</p> <p>The Dependency-Injection (DI) pattern is a more specific version of IoC pattern, where implementations are passed into an object through constructors/setters/service lookups, which the object will 'depend' on in order to behave correctly.</p> <p>Every DI implementation can be considered IoC, but one should not call it IoC, because implementing Dependency-Injection is harder than callback (Don't lower your product's worth by using the general term \"IoC\" instead).</p> <p>IoC without using DI, for example, would be the Template pattern because the implementation can only be changed through sub-classing.</p> <p>DI frameworks are designed to make use of DI and can define interfaces (or Annotations in Java) to make it easy to pass in the implementations.</p> <p>IoC containers are DI frameworks that can work outside of the programming language. In some you can configure which implementations to use in metadata files (e.g. XML) which are less invasive. With some you can do IoC that would normally be impossible like inject an implementation at pointcuts.</p> <p>See also this Martin Fowler's article.</p>"},{"location":"spring/#advantages-of-spring-framework","title":"Advantages of Spring Framework","text":"<p>There are many advantages of Spring Framework. They are as follows:</p> Name Details Predefined Templates Spring framework provides templates for JDBC, Hibernate, JPA etc. technologies. So there is no need to write too much code. It hides the basic steps of these technologies. Let's take the example of JdbcTemplate, you don't need to write the code for exception handling, creating connection, creating statement, committing transaction, closing connection etc. You need to write the code of executing query only. Thus, it save a lot of JDBC code. Loose Coupling The Spring applications are loosely coupled because of dependency injection. Easy to test The Dependency Injection makes easier to test the application. The EJB or Struts application require server to run the application but Spring framework doesn't require server. Lightweight Spring framework is lightweight because of its POJO implementation. The Spring Framework doesn't force the programmer to inherit any class or implement any interface. That is why it is said non-invasive. Fast Development The Dependency Injection feature of Spring Framework and it support to various frameworks makes the easy development of JavaEE application. Powerful abstraction It provides powerful abstraction to JavaEE specifications such as JMS, JDBC, JPA and JTA. Declarative support It provides declarative support for caching, validation, transactions and formatting."},{"location":"spring/#dependency-injection_1","title":"Dependency Injection","text":"<p>Dependency Injection is the most important feature of Spring framework. Dependency Injection is a design pattern where the dependencies of a class are injected from outside, like from an xml file. It ensures loose-coupling between classes.</p> <p>In a Spring MVC application, the controller class has dependency of service layer classes and the service layer classes have dependencies of DAO layer classes.</p> <p>Suppose class A is dependent on class B. In normal coding, you will create an object of class B using \u2018new\u2019 keyword and call the required method of class B. However, what if you can tell someone to pass the object of class B in class A? Dependency injection does this. You can tell Spring, that class A needs class B object and Spring will create the instance of class B and provide it in class A.</p> <p>In this example, we can see that we are passing the control of objects to Spring framework, this is called Inversion of Control (IOC) and Dependency injection is one of the principles that enforce IOC.</p>"},{"location":"spring/#types-of-dependency-injection","title":"Types of Dependency Injection","text":"<p>Spring framework provides 2 ways to inject dependencies: - By Constructor - By Setter method</p>"},{"location":"spring/#constructor-based-di","title":"Constructor-based DI","text":"<p>when the required dependencies are provided as arguments to the constructor, then it is known as constructor-based dependency injection, see the examples below:</p> <p>Using XML based configuration: Injecting a dependency is done through the bean-configuration file, for this  xml tag is used: <pre><code> &lt;bean id=\"classB\" class=\"com.demo.B\" /&gt;\n\n&lt;bean id=\"classA\" class=\"com.demo.A\"&gt;\n         &lt;constructor-arg ref=\"classB\" /&gt; \n&lt;/bean&gt;\n</code></pre> <p>In case of more than 1 dependency, the order sequence of constructor arguments should be followed to inject the dependencies. Java Class A: <pre><code>package com.demo;\npublic Class A{\n    B b;\n    A(B b){\n        this.b=b;\n        }\n}\n</code></pre> Java Class B:</p> <pre><code>package com.demo;\npublic Class B{\n\n}\n</code></pre> <p>Using Java Based Configuration:</p> <p>When using Java based configuration, the constructor needs to be annotated with <code>@Autowired</code> annotation to inject the dependencies,</p> <p>Classes A and B will be annotated with <code>@Component</code> (or any other stereotype annotation), so that they will be managed by Spring.</p> <p><pre><code>package com.demo;\npackage org.springframework.beans.factory.annotation.Autowired;\npackage  org.springframework.stereotype.Component;\n\n@Component\npublic Class A{\n    B b;\n    @Autowired\n    A(B b){\n            this.b=b;\n    }\n}\n</code></pre> Java class B:</p> <pre><code>package com.demo;\npackage org.springframework.stereotype.Component;\n\n@Component\npublic Class B{\n\n}\n</code></pre> <p>Before Spring version 4.3, <code>@Autowired</code> annotation was needed for constructor dependency injection, however, in newer Spring versions, @Autowired is optional, if the class has only one constructor. But, if the class has multiple constructors, we need to explicitly</p> <p>But, if the class has multiple constructors, we need to explicitly add <code>@Autowired</code> to one of the constructors so that Spring knows which constructor to use for injecting the dependencies.</p>"},{"location":"spring/#setter-method-injection","title":"Setter-method injection","text":"<p>in this, the required dependencies are provided as the field parameters to the class and the values are set using setter methods of those properties. See the examples below.</p> <p>Using XML based configuration: Injecting a dependency is done through the bean configuration file and  xml tag is used where \u2018name\u2019 attribute defines the name of the field of java class. <pre><code> &lt;bean id=\"classB\" class=\"com.demo.B\" /&gt;\n\n&lt;bean id=\"classA\" class=\"com.demo.A\"&gt;\n&lt;property name=\"b\"&gt;\n         &lt;constructor-arg ref=\"classB\" /&gt;\n&lt;/property&gt;\n&lt;/bean&gt;\n</code></pre> <p>Java Class A: <pre><code>package com.demo;\npublic Class A{\n    B b;\n    public void setB(B b){\n        this.b=b;\n        }\n}\n</code></pre> Java Class B:</p> <p><pre><code>package com.demo;\npublic Class B{\n\n        }\n</code></pre> Using Java based configuration:</p> <p>The setter method needs to be annotated with <code>@Autowired</code> annotation.</p> <p><pre><code>package com.demo;\npackage org.springframework.beans.factory.annotation.Autowired;\npackage  org.springframework.stereotype.Component;\n\n@Component\npublic Class A{\n    B b;\n    @Autowired\n    public void setB(B b){\n            this.b=b;\n    }\n}\n</code></pre> Java class B:</p> <pre><code>package com.demo;\npackage org.springframework.stereotype.Component;\n\n@Component\npublic Class B{\n\n}\n</code></pre> <p>There is also a Field injection, where Spring injects the required dependencies directly into the fields when those fields are annotated with <code>@Autowired</code> annotation.</p>"},{"location":"spring/#constructor-vs-setter-injection","title":"Constructor Vs Setter injection","text":"<p>The differences are: - Partial dependency is not possible with Constructor based injection, but it is possible with Setter based injection. Suppose there are 4 properties in a class and the class has setter methods and a constructor with 4 parameters. In this case, if you want to inject only one/two property, then it is only possible with setter methods (unless you can define a new parametrized constructor with the needed properties) - Cyclic dependency is also not possible with Constructor based injection. Suppose class A has dependency on class B and class B has dependency on class A and we are using constructor based injection, then when Spring tries to create object of class A, it sees that it needs class B object, then it tries to resolve that dependency first. But when it tries to create object of class B, it finds that it needs class A object, which is still under construction. Here Spring recognizes that a circular reference may have occurred and you will get an error in this case. This problem can easily be solved by using Setter based injection because dependencies are not injected at the object creation time - While using Constructor injection, you will have to remember the order of parameters in a constructor when the number of constructor parameters increases. This is not the case with Setter injection - Constructor injection helps in creating immutable objects, because a bean object is created using constructor and once the object is created, its dependencies cannot be altered anymore. Whereas with Setter injection, it\u2019s possible to inject dependency after object creation which leads to mutable objects.</p> <p>Use constructor-based injection, when you want your class to not even be instantiated if the class dependencies are not resolved because Spring container will ensure that all the required dependencies are passed to the constructor.</p>"},{"location":"spring/#beanfactory-and-applicationcontext","title":"BeanFactory and ApplicationContext","text":"<p>The differences are:</p> <ul> <li>BeanFactory is the most basic version of IOC containers which should be preferred when memory consumption is critical whereas ApplicationContext extends BeanFactory, so you get all the benefits of BeanFactory plus some advanced features for enterprise applications</li> <li>BeanFactory instantiates beans on-demand i.e. when the method getBean(beanName) is called, it is also called Lazy initializer whereas ApplicationContext instantiates beans at the time of creating the container where bean scope is Singleton, so it is an Eager initializer</li> <li>BeanFactory only supports 2 bean scopes, singleton and prototype whereas ApplicationContext supports all bean scopes</li> <li>ApplicationContext automatically registers BeanFactoryPostProcessor and BeanPostProcessor at startup, whereas BeanFactory does not register these interfaces automatically</li> <li>Annotation based dependency injection is not supported by BeanFactory whereas ApplicationContext supports it</li> <li>If you are using plain BeanFactory, features like transactions and AOP will not take effect (not without some extra steps), even if nothing is wrong with the configuration whereas in ApplicationContext, it will work</li> <li>ApplicationContext provides additional features like MessageSource access (i18n or Internationalization) and Event Publication</li> </ul> <p>Use an ApplicationContext unless you have a really good reason for not doing so.</p>"},{"location":"spring/#spring-bean-life-cycle","title":"Spring Bean life-cycle","text":"<p>Spring beans are java classes that are managed by Spring container and the bean life-cycle is also managed by Spring container.</p> <p>The bean life-cycle has below steps: - Bean instantiated by container - Required dependencies of this bean are injected by container - Custom Post initialization code to be executed (if required) - Bean methods are used - Custom Pre destruction code to be executed (if required)</p> <p>When you want to execute some custom code that should be executed before the bean is in usable state, you can specify an init() method and if some custom code needs to be executed before the bean is destroyed, then a destroy() method can be specified. There are various ways to define these init() and destroy() method for a bean:</p> <p>By using xml file, bean tag has 2 attributes that can be used to specify its init  and destroy methods, You can give any name to your initialization and destroy methods, and here is our Test class</p> <pre><code>package com.demo;\npublic Class Test{\n    public void init() throws Exception{\n        System.out.prinln(\"Init Method\");\n    }\n    public void destroy() throws Exception{\n        System.out.prinln(\"Destroy Method\");\n    }\n}\n</code></pre> <p>By implementing InitializingBean and DisposableBean interfaces</p> <p>InitializingBean interface has afterPropertiesSet() method which can be used to execute some initialization task for a bean and DisposableBean interface has a destroy() method which can be used to execute some cleanup task.</p> <p>Here is our Test class,</p> <pre><code>package com.demo;\n</code></pre>"},{"location":"spring/#spring-bean-scopes","title":"Spring Bean Scopes","text":"<p>Spring framework supports 5 scopes: - singleton \u2013 only one bean instance per Spring IOC container - prototype \u2013 it produces a new instance each and every time a bean is requested - request \u2013 a single instance will be created and made available during complete life-cycle of an HTTP request - session \u2013 a single instance will be created and made available during complete life-cycle of an HTTP session - global session \u2013 a single instance will be created during the life-cycle of a ServletContext</p> <p><code>@Scope</code> annotation or scope attribute of bean tag can be used to define bean scopes in Spring.</p> <p>Default scope of a bean is <code>Singleton</code> that means only one instance per context.</p>"},{"location":"spring/#what-happens-when-we-inject-a-prototype-scope-bean-in-a-singleton-scope-bean","title":"What happens when we inject a prototype scope bean in a singleton scope bean?","text":"<p>When you define a bean scope to be singleton, that means only one instance will be created and whenever we request for that bean, that same instance will be returned by the Spring container, however, a prototype scoped bean returns a new instance every time it is requested.</p> <p>Spring framework gets only one chance to inject the dependencies, so if you try to inject a prototyped scoped bean inside a singleton scoped bean, Spring will instantiate the singleton bean and will inject one instance of prototyped scoped bean. This one instance of prototyped scoped bean is the only instance that is ever supplied to the singleton scoped bean.</p> <p>So here, whenever the singleton bean is requested, <code>you will get the same instance of prototyped scoped bean</code>.</p>"},{"location":"spring/#how-to-inject-a-prototype-scope-bean-in-a-singleton-scope-bean","title":"How to inject a prototype scope bean in a singleton scope bean?","text":"<p>We have discussed in the previous question that when a prototyped scoped bean is injected in a singleton scoped bean, then on each request of singleton bean, we will get the same instance of prototype scoped bean, but there are certain ways where we can get a new instance of prototyped scoped bean also.</p> <p>The solutions are: - Injecting an ApplicationContext in Singleton bean and then getting the new instance of prototyped scoped bean from this ApplicationContext - Lookup method injection using @Lookup - Using scoped proxy</p> <p>Injecting ApplicationContext:</p> <p>To inject the ApplicationContext in Singleton bean, we can either use @Autowired annotation or we can implement ApplicationContextAware interface,</p> <pre><code>package com.demo;\n\nimport org.springframework.beans.BeansException;\nimport org.springframework.context.ApplicationContextAware;\nimport org.springframework.context.ApplicationContext;\nimport org.springframework.sterotype.Component;\n\n@Component\npublic class SingletonBean implements ApplicationContextAware{\n\n    private ApplicationContext applicationContext;\n    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException{\n        this.applicationContext=applicationContext;\n    }\n\n    public PrototypeBeann getProtoTypeBean(){\n        return. applicationContext.getBean(PrototypeBean.class);\n    }\n}\n</code></pre> <p>Here, whenever the getPrototypeBean() method is called, it will return a new instance of PrototypeBean. But this approach contradicts with Spring IOC (Inversion of Control), as we are requesting the dependencies directly from the container.</p> <p>Lookup Method Injection using @Lookup:</p> <pre><code>package com.demo;\n\nimport org.springframework.beans.factory.annotations.Lookup;\nimport org.springframework.sterotype.Component;\n\n@Component\npublic class SingletonBean {\n    @Lookup\n    public PrototypeBeann getProtoTypeBean(){\n        return null;\n    }\n}\n</code></pre> <p>Here, Spring will dynamically overrides getPrototypeBean() method annotated with @Lookup and it will look up the bean which is the return type of this method. Spring uses CGLIB library to do this.</p> <p>Using Scoped Proxy</p> <pre><code>package com.demo;\n\nimport org.springframework.beans.factory.ConfigurableBeanFactory;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Scope;\nimport org.springframework.context.annotation.ScopedProxyMode;\nimport org.springframework.sterotype.Component;\n\nimport java.beans.BeanProperty;\n\n@Component\npublic class SingletonBean {\n\n    private ApplicationContext applicationContext;\n\n    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {\n        this.applicationContext = applicationContext;\n    }\n\n    @Bean\n    @Scope(value=ConfigurableBeanFactory.ScopedProxyMode,\n    proxyMode=ScopedProxyMode.TARGET_CLASS)\n    public PrototypeBean getProtoTypeBean() {\n        return new PrototypeBean();\n    }\n}\n</code></pre> <p>Spring uses CGLIB to create the proxy object and the proxy object delegates method calls to the real object. In the above example, we are using ScopedProxyMode.TARGET_CLASS which causes an AOP proxy to be injected at the target injection point. The default Proxy mode is ScopedProxyMode.NO .</p> <p>To avoid CGLIB usage, configure the proxy mode with ScopedProxyMode.INTERFACES and it will use JDK dynamic proxy.</p>"},{"location":"spring/#stereotype-annotations","title":"Stereotype Annotations","text":"<p><code>@Component</code>, <code>@Controller</code>, <code>@Service</code> and <code>@Repository</code> annotations are called stereotype annotations and they are present in org.springframework.stereotype package.</p> <p>@Component: it is a general purpose stereotype annotation which indicates that the class annotated with it, is a spring managed component.</p> <p>@Controller, @Service and @Repository are special types of @Component, these 3 themselves are annotated with @Component,</p> <pre><code>package org.springframework.stereotype;\n\nimport java.lang.annotation.Documented;\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Target;\n\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Indexed\npublic @interface Component {\n    String value() default \"\";\n} \n</code></pre> <pre><code>package org.springframework.stereotype;\n\nimport java.lang.annotation.Documented;\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Target;\nimport org.springframework.core.annotation.AliasFor;\n\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Component\npublic @interface Controller {\n    @AliasFor(\n            annotation = Component.class\n    )\n    String value() default \"\";\n}\n</code></pre> <pre><code>package org.springframework.stereotype;\n\nimport java.lang.annotation.Documented;\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Target;\nimport org.springframework.core.annotation.AliasFor;\n\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Component\npublic @interface Service {\n    @AliasFor(\n        annotation = Component.class\n    )\n    String value() default \"\";\n}\n</code></pre> <pre><code>package org.springframework.stereotype;\n\nimport java.lang.annotation.Documented;\nimport java.lang.annotation.ElementType;\nimport java.lang.annotation.Retention;\nimport java.lang.annotation.RetentionPolicy;\nimport java.lang.annotation.Target;\nimport org.springframework.core.annotation.AliasFor;\n\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Component\npublic @interface Repository {\n    @AliasFor(\n        annotation = Component.class\n    )\n    String value() default \"\";\n}\n</code></pre> <p>So, the classes annotated with these annotations gets picked up in Component scanning and they are managed by Spring.</p> <ul> <li> <p>@Controller: the classes annotated with <code>@Controller</code> will act as Spring MVC controllers. DispatcherServlet looks for <code>@RequestMapping</code> in classes that are annotated with <code>@Controller</code>. That means you cannot replace <code>@Controller</code> with <code>@Component</code>, if you just replace it with <code>@Component</code> then yes it will be managed by Spring but it will not be able to handle the requests.   (Note: if a class is registered with Spring using <code>@Component</code>,  then @RequestMapping annotations within class can be picked up, if the class itself is annotated with @RequestMapping)</p> </li> <li> <p>@Service: The service layer classes that contain the business logic should be annotated with <code>@Service</code>. Apart from the fact that it is used to indicate that the class contains business logic, there is no special meaning to this annotation, however it is possible that Spring may add some additional feature to <code>@Service</code> in future, so it is always good idea to follow the convention.</p> </li> <li> <p>@Repository: The classes annotated with this annotation defines data repositories. It is used in DAO layer classes. @Repository has one special feature that it catches platform specific exceptions and re-throw them as one of the Spring\u2019s unified unchecked exception i.e. <code>DataAccessException</code> .</p> </li> </ul>"},{"location":"spring/#controller-vs-restcontroller-annotation","title":"@Controller vs @RestController annotation","text":"<p>The differences are:</p> <ul> <li><code>@Controller</code> annotation is used to mark a class as Spring MVC controller where the response is a view name which will display the Model object prepared by controller, whereas @RestController annotation is a specialization of @Controller and it is used in RESTful web services where the response is usually JSON/XML.</li> <li><code>@RestController</code> is made up of 2 annotations, @Controller and @ResponseBody. @ResponseBody annotation is used to attach the generated output directly into the body of http response.</li> <li><code>@Controller</code> can be used with @ResponseBody which will have same effect as @RestController. @ResponseBody annotation can be used at the class level or at the individual methods also. When it is used at the method level, Spring will use HTTP Message Converters to convert the return value to HTTP response body (serialize the object to response body).</li> </ul>"},{"location":"spring/#qualifier-annotation","title":"@Qualifier annotation","text":"<p>Let\u2019s consider an example to understand @Qualifier annotation better. Suppose we have an interface called Shape and there are 2 classes Rectangle and Circle that are implementing this interface. We are autowiring our Shape interface in our controller class using @Autowired, now here a conflict will happen, because there are 2 beans of the same type.</p> <pre><code>public interface Shape{\n\n}\n\n@Service \npublic class Rectangle implements Shape{\n\n\n}\n\n@Service \npublic class Circle implements Shape{\n\n}\n\n\n@RestController\npublic class ShapeCOntroller{\n\n\n@Autowired\nShape shape;\n\n}\n</code></pre> <p>When you try to start your application, you will get</p> <pre><code>Could not autowire. There is more than one bean of 'Shape' type.\nBeans:\ncircle (Circle.java) rectangle  (Rectangle.java) \n</code></pre> <p>Now, to resolve this you can give names to your Rectangle and Circle class, like:</p> <pre><code>public interface Shape{\n\n}\n\n@Service(\"rectangle\")\npublic class Rectangle implements Shape{\n\n\n}\n\n@Service(\"circle\") \npublic class Circle implements Shape{\n\n}\n</code></pre> <p>And you will use @Qualifier annotation to specify which bean should be autowired, like: <pre><code>@RestController\npublic class ShapeCOntroller{\n    @Autowired\n    @Qualifier(\"circle\")\n    Shape shape;\n}\n</code></pre></p> <p>Now, Spring will not get confused as to what bean it has to autowire. NOTE , you can also use @Qualifier annotation to give names to your Rectangle and Circle classes, like <pre><code>@RestController\npublic class ShapeCOntroller{\n    @Autowired\n    @Qualifier(\"rectangle\")\n    Shape shape;\n}\n</code></pre></p>"},{"location":"spring/#transactional-annotation","title":"@Transactional annotation","text":"<p>Spring provides Declarative Transaction Management via <code>@Transactional</code> annotation. When a method is applied with <code>@Transactional</code>, then it will execute inside a database transaction. <code>@Transactional</code> annotation can be applied at the class level also, in that case, all methods of that class will be executed inside a database transaction.</p> <p>How @Transactional works:</p> <p>When <code>@Transactional</code> annotation is detected by Spring, then it creates a proxy object around the actual bean object. So, whenever the method annotated with <code>@Transactional</code> is called, the request first comes to the proxy object and this proxy object invokes the same method on the target bean. These proxy objects can be supplied with interceptors. Spring creates a TransactionInterceptor and passes it to the generated proxy object. So, when the <code>@Transactional</code> annotated method is called, it gets called on the proxy object first, which in turn invokes the TransactionInterceptor that begins a transaction. Then the proxy object calls the actual method of the target bean. When the method finishes, the TransactionInterceptor commits/rollbacks the transaction.</p> <p>One thing to remember here is that the Spring wraps the bean in the proxy, the bean has no knowledge of it. So, only the external calls go through the proxy. As for the internal calls (<code>@Transactional</code> method calling the same bean method), they are called using \u2018this\u2019. Using <code>@Transactional</code> annotation, the transaction\u2019s propagation and isolation can be set directly, like:</p> <p><pre><code> @Transactional(propogation = Propogationn.REQUIRES_NEW,\n        isolation = Isolation.READ_UNCOMMITTES\n        rollbackFor = Exception.class)\n public String process(){\n            return \"Success\";\n        }\n</code></pre> Also, you can specify a \u2018rollbackFor\u2019 attribute and specify which exception types must cause a transaction rollback (a transaction with Runtime exceptions and errors are by default rolled back). If your process() method is calling another bean method, then you can also annotate that method with <code>@Transactional</code> and set the propagation level to decide whether this method should execute in the same transaction or it requires a new transaction.</p>"},{"location":"spring/#controlleradvice-annotation","title":"@ControllerAdvice annotation","text":"<p><code>@ControllerAdvice</code> annotation is used to intercept and handle the exceptions thrown by the controllers across the application, so it is a global exception handler. You can also specify @ControllerAdvice for a specific package,</p> <pre><code>@ControllerAdvice(basePackage = com.demo.controller\")\npublic class Test{\n\n}\n</code></pre> <p>Or a specific controller, <pre><code>@ControllerAdvice(assignableTypes=  = DemoController.class)\npublic class Test{\n\n}\n</code></pre></p> <p>Or even a specific annotation, <pre><code>@ControllerAdvice(annotations=  = RestController.class)\npublic class Test{\n\n}\n</code></pre> <code>@ExceptionHandler</code> annotation is used to handle specific exceptions thrown by controllers, like, <pre><code>@ControllerAdvice\npublic class Test{\n    ExceptioHandler(SQLException.class)\n    public String handleSQLException(){\n        return null;\n    }\n\n    ExceptioHandler(UserNotFoundException.class)\n    public String handleUserNotFoundException(){\n        return null;\n    }\n}\n</code></pre></p> <p>Here, we have defined a global exception handler using <code>@ControllerAdvice</code>. If a SQLException gets thrown from a controller, then <code>handleSQLException()</code> method will be called. In this method, you can customize the exception and send a particular error page/error code. Also, custom exceptions can be handled.</p> <p>If you don\u2019t want to create a global exception handler, then you can also define some <code>@ExceptionHandler</code> methods in a particular controller itself.</p>"},{"location":"spring/#bean-annotation","title":"@Bean annotation","text":"<p><code>@Bean</code> annotation is used when you want to explicitly declare and register a bean into application context, so that it will be managed by Spring.</p> <p>Some points to remember: - When using <code>@Bean</code>, you have the control over the bean creation logic. - <code>@Bean</code> is a method level annotation, the body of the method contains the logic for creating the bean instance and this method returns the instance which will be registered in the spring application context. - Using <code>@Bean</code>, you can register the classes from 3<sup>rd</sup> party libraries into the application context - <code>@Bean</code> annotation is usually declared in configuration classes.</p>"},{"location":"spring/#component-vs-bean-annotation","title":"@Component vs @Bean annotation","text":"<p>The differences are:</p> <ul> <li><code>@Component</code> auto-detects and configures the beans using classpath scanning, whereas @Bean explicitly declares a single bean rather than letting Spring do it automatically</li> <li><code>@Component</code> is a class level annotation, whereas @Bean is a method level annotation</li> <li><code>@Component</code> has different specializations called stereotype annotations like <code>@Controller</code>, <code>@Service</code> and @Repository, whereas @Bean has no specializations</li> <li><code>@Bean</code> lets you create and configure beans exactly how you choose it to be, whereas in @Component, Spring has the control</li> <li><code>@Bean</code> lets you configure classes from 3<sup>rd</sup> party libraries where you are not the owner of the source code, but you can\u2019t use @Component in this case</li> </ul>"},{"location":"spring/#spring-boot-security-using-oauth2-with-jwt","title":"Spring Boot Security using OAuth2 with JWT","text":"<p>OAuth2 is an authorization framework superseding it first version OAuth, created back in 2006. It defines the authorization flows between clients and one or more HTTP services in order to gain access to protected resources.</p> <p>The main goal of the OAuth2 framework is to provide a simple flow of authorization that can be implemented on the web application, mobile phones, desktop application, and even on the devices used in our living rooms.</p> <p>OAuth2 defines the  server-side roles:</p> <ul> <li>Resource Owner: The service responsible for controlling resources\u2019 access</li> <li>Resource Server: The service who actually supplies the resources</li> <li>Authorization Server: The service handling authorization process acting as a middleman between client and resource owner</li> <li>JSON Web Token, or JWT, is a specification for the representation of claims to be transferred between two parties. The claims are encoded as a JSON object used as the payload of an encrypted structure, enabling the claims to be digitally signed or encrypted.</li> </ul>"},{"location":"spring/#oauth2-terminology","title":"OAuth2 Terminology","text":"<ul> <li>Resource Owner The user who authorizes an application to access his account. The access is limited to the <code>scope</code>.</li> <li>Resource Server: A server that handles authenticated requests after the <code>client</code> has obtained an <code>access token</code>.</li> <li>Client An application that access protected resources on behalf of the resource owner.</li> <li>Authorization Server A server which issues access tokens after successfully authenticating a <code>client</code> and <code>resource owner</code>, and authorizing the request.</li> <li>Access Token A unique token used to access protected resources</li> <li>Scope A Permission</li> <li>JWT JSON Web Token is a method for representing claims securely between two parties.</li> <li>Grant type A <code>grant</code> is a method of acquiring an access token.</li> </ul>"},{"location":"spring/#json-web-tokenjwt","title":"Json Web Token(JWT)","text":"<p>JSON Web Token (JWT) is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object.a stateless authentication mechanism as the user state is never saved in server memory.A JWT token consists of 3 parts seperated with a dot(.) i.e. Header.payload.signature</p> <p>Header has 2 parts type of token and hashing algorithm used.The JSON structure comprising these two keys are Base64Encoded.</p> <p><pre><code>{\n\"alg\": \"HS256\",\n\"typ\": \"JWT\"\n}\n</code></pre> Payload contains the claims.Primarily, there are three types of claims: reserved, public, and private claims. Reserved claims are predefined claims such as iss (issuer), exp (expiration time), sub (subject), aud (audience).In private claims, we can create some custom claims such as subject, role, and others.</p> <p><pre><code>{\n\"sub\": \"Alex123\",\n\"scopes\": [\n{\n\"authority\": \"ROLE_ADMIN\"\n}\n],\n\"iss\": \"http://devglan.com\",\n\"iat\": 1508607322,\n\"exp\": 1508625322\n}\n</code></pre> Signature ensures that the token is not changed on the way.For example if you want to use the HMAC SHA256 algorithm, the signature will be created in the following way:</p> <pre><code>HMACSHA256(\nbase64UrlEncode(header) + \".\" +\nbase64UrlEncode(payload),\nsecret)\n</code></pre> <p>sample JWT token <pre><code>eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJBbGV4MTIzIiwic2N.v9A80eU1VDo2Mm9UqN2FyEpyT79IUmhg\n</code></pre></p>"},{"location":"spring/#spring-boot-rest-authentication-with-jwt-token-flow","title":"Spring Boot Rest Authentication with JWT Token Flow","text":"<ul> <li>Customers sign in by submitting their credentials to the provider.</li> <li>Upon successful authentication, it generates JWT containing user details and privileges for accessing the services and sets the JWT expiry date in payload.</li> <li>The server signs and encrypts the JWT if necessary and sends it to the client as a response with credentials to the initial request.</li> <li>Based on the expiration set by the server, the customer/client stores the JWT for a restricted or infinite amount of time.</li> <li>The client sends this JWT token in the header for all subsequent requests.</li> <li>The client authenticates the user with this token. So we don't need the client to send the user name and password to the server during each authentication process, but only once the server sends the client a JWT.</li> </ul>"},{"location":"spring/#web-server-and-application-server","title":"Web server and  application server","text":"Web Server Application Server Supports HTTP protocol. When the Web server receives an HTTP request, it responds with an HTTP response, such as sending back an HTML page (static content) or delegates the dynamic response generation to some other program such as CGI scripts or Servlets or JSPs in the application server. Exposes business logic and dynamic content to the client through various protocols such as HTTP, TCP/IP, IIOP, JRMP etc. Uses various scalability and fault-tolerance techniques. Uses various scalability and fault-tolerance techniques. In addition provides resource pooling, component life cycle management, transaction management, messaging, security etc.Provides services for components like Web container for servlet components and EJB container for EJB components."},{"location":"spring/#spring-transaction-management","title":"Spring Transaction Management","text":"<p>A transaction is a logical unit of work that either completely succeeds or fails. Think about a banking transaction. Here, the unit of work is money debiting from Account A and money crediting to Account B. If one of them fails, the entire process fails. We call it a rollback of all the steps in the transaction if anything fails in between.</p>"},{"location":"spring/#global-transactions","title":"Global Transactions","text":"<p>There can be applications (very unlikely) where the transaction can happen between different databases. This is called distributed transaction processing. The transaction manager cannot sit within the application to handle it, rather it sits in the application server level. JTA or java transaction API is required with the support of JNDI to lookup different databases, and the transaction manager decides the commit or rollback of the distributed transaction. This is a complex process and requires knowledge at the application server level.</p>"},{"location":"spring/#local-transactions","title":"Local Transactions","text":"<p>Local transactions happen between the application and a singled RDBMS, such as a simple JDBC connection. With local transaction, all the transaction code is within our code.</p> <p>In both global and local transaction, we have to manage the transaction by ourselves. If I am using JDBC, then the transaction management API is for JDBC. If I am using Hibernate, then the hibernate transaction API and JTA at application server is for global transactions.</p> <p>Spring framework overcomes all of the these problems by providing an abstraction over the different transaction APIs, providing a consistent programming model. The abstraction is via org.springframework.transaction.PlatformTransactionManager interface. Here is the snippet of the interface:</p> <p><pre><code>public interface PlatformTransactionManager {\n    TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException;\n\n    void commit(TransactionStatus status) throws TransactionException;\n\n    void rollback(TransactionStatus status) throws TransactionException;\n}\n</code></pre> There are various spring managed transaction managers that implement PlatformTransactionManager. Some of them are:</p> <ul> <li>org.springframework.orm.jpa.JpaTransactionManager \u2014 For JPA transactions</li> <li>org.springframework.jdbc.datasource.DataSourceTransactionManager \u2014 For JDBC transactions</li> <li>org.springframework.orm.hibernate5.HibernateTransactionManager \u2014 For Hibernate transactions and it binds with SessionFactory</li> <li>org.springframework.transaction.jta.JtaTransactionManager \u2014 For JTA transactions.</li> <li>org.springframework.transaction.jta.WebLogicJtaTransactionManager \u2014 For Oracle Weblogic managed transaction</li> <li>org.springframework.transaction.jta.WebSphereUowTransactionManager \u2014 For IBM Websphere Application Server managed transactions.</li> <li>org.springframework.jms.connection.JmsTransactionManager \u2014 For JMS messaging transaction by binding JMS connection factory.</li> </ul> <p>Spring transactions can be managed by 2 approaches: programmatic and declarative.</p>"},{"location":"spring/#programmatic-approach","title":"Programmatic Approach","text":"<p>Spring provides a programmatic approach in 2 ways :</p> <ol> <li>Using the TransactionTemplate</li> <li>Using a <code>PlatformTransactionManager</code> implementation directly</li> </ol> <p>The programmatic approach is not widely used, as the transaction management sits with the business logic. In an application where we have transactions for a few CRUD operations, the programmatic approach is preferred as transaction proxies can be a heavy operation.</p>"},{"location":"spring/#declarative-approach-transactional","title":"Declarative Approach (@Transactional)","text":"<p>The declarative approach is widely used because transaction management stays out of business logic. It uses AOP proxies behind to drive transactions around method invocation with appropriate TransactionManager. It can be done either with annotation or with XML. But nowadays, most of the applications are annotation based, so I am covering how it works with the annotations.</p> <ul> <li>1. Use <code>@EnableTransactionManagement</code> at the top of the configuration class, which has <code>@Configuration</code> annotation. This is the same as the XML tag:</li> </ul> <pre><code> &lt;tx:annotation-driven transaction-manager=\"txManager\"/&gt;\n</code></pre> <pre><code>@Configuration\n@EnableTransactionmanagement\npublic class SpringConfiguration{\n...........\n        ...........\n} \n</code></pre> <ul> <li>2. Define the datasource and transaction manager</li> </ul> <pre><code>    @Bean\n     public FooRepository fooRepository() {\n         // configure and return a class having @Transactional methods\n         return new JdbcFooRepository(dataSource());\n     }\n\n     @Bean\n     public DataSource dataSource() {\n         // configure and return the necessary JDBC DataSource\n     }\n\n     @Bean\n     public PlatformTransactionManager txManager() {\n         return new DataSourceTransactionManager(dataSource());\n     }\n} \n</code></pre> <ul> <li>3. Use the @Transactional annotation above the methods and concrete classes. If applied at class level, all the methods will be by default transactional.</li> </ul> <p>Let's try to understand how the annotation works with a simple example:</p> <p>Assume we have a sample service lass</p> <pre><code> Class SampleService {\n    @Transactional\n    public void serviceMethod(){\n        //call to dao layer \n    }\n}\n</code></pre> <p>When SampleService is injected in another class, Spring will inject it in the below manner internally:</p> <pre><code> class ProxySampleService extends SampleService{\n    private SampleService sampleService;\n    public ProxySampleService(SampleService s){\n        this.sampleService=s;\n    }\n    @Override\n    public void sampleMethod(){\n        try{\n            //open transaction \n            sampleService.sampleMethod();\n            //close transaction\n        }\n        catch(Exception e){\n            //rollback\n        }\n\n    }\n\n}\n</code></pre> <p>This is the proxy design that works behind the scenes.</p> <p>Now let's see how we can fine tune the @Transactional annotation by changing the setting of the attributes.</p> <p>Settings of the attributes in @Transactional annotation:</p>"},{"location":"spring/#propagation","title":"propagation","text":"<p>Optional setting for propagation. This is a very important attribute in setting the transactional behavior. I will cover a use case of it below. - REQUIRED \u2014 support a current transaction, create a new one if none exist - REQUIRES_NEW \u2014 create a new transaction and suspend the current transaction if none exist - MANDATORY \u2014 support a current transaction, throw an exception if none exists - NESTED \u2014 executes within a nested transaction if a current transaction exists - SUPPORTS \u2014 supports currents transaction but execute non-transactionally if none exists</p>"},{"location":"spring/#isolation","title":"isolation","text":"<p>transaction isolation level. It decides the level to what the transaction should be isolated to other transactions - DEFAULT \u2014 default isolation level of the datasource - READ_COMMITTED \u2014 indicates dirty reads to be prevented, non-repeatable, and phantom reads can occur. - READ_UNCOMMITTED \u2014 indicates that dirty reads, non-repeatable, and phantom reads can occur - REPEATABLE_READ \u2014 indicates dirty and non-repeatable reads are prevented but phantom reads can occur - SERIALIZABLE \u2014 indicates dirty read phantom read, and non-repeatable reads are prevented</p> <p>we also have  other settings</p> <ul> <li>readOnly whether the transaction is read-only or read/write</li> <li>timeout \u2014 transaction timeout</li> <li>rollbackFor \u2014 arrays of exception class objects that must cause a rollback of the transaction</li> <li>rollbackForClassName \u2014 arrays of exception class names that must cause a rollback of the transaction</li> <li>noRollbackFor \u2014 arrays of exception class objects that must not cause a rollback of the transaction</li> <li>noRollbackForClassName \u2014 arrays of exception class names that must not cause a rollback of the transaction</li> </ul>"},{"location":"spring/#misc-questions","title":"Misc Questions","text":""},{"location":"spring/#what-happens-if-we-use-service-annotation-on-a-repository-class-in-spring-boot","title":"What happens if we use  service annotation on a repository class  in spring boot ?","text":"<p>If you annotate a repository class with the <code>@Service</code> annotation in Spring Boot, it will still be treated as a repository class. However, by convention, it is more common to use the <code>@Repository</code> annotation for DAO (Data Access Object) classes in Spring, as this provides a more clear indication of the class's purpose.</p> <p>Annotating a repository class with @Service could lead to confusion and make it harder for other developers to understand the purpose of the class. Additionally, in a large codebase with many different types of classes, having clear, well-defined annotations can help with organization and maintainability.</p> <p>That being said, if you annotate a repository class with <code>@Service</code>, it will still work as expected, since both <code>@Service</code> and <code>@Repository</code> are simply specializations of the <code>@Component</code> annotation, which tells Spring to include the class in component scanning and create a bean for it.</p>"},{"location":"spring/Spring-aop/","title":"Spring AOP","text":"<p>{: .no_toc }</p>      Table of contents    <p>{: .text-delta } 1. TOC</p>"},{"location":"spring/Spring-aop/#introducing-spring-aop","title":"Introducing Spring AOP","text":"<p>Spring AOP (Aspect-Oriented Programming) is a mechanism for modularizing cross-cutting concerns in your application. It allows you to define aspects, which are classes that encapsulate behavior that cuts across multiple classes. An aspect can be thought of as a module that implements a particular feature, such as logging, security, or transaction management.</p> <p>Spring AOP works by using proxies to dynamically weave the aspects into the target objects at runtime. A proxy is an object that acts as an intermediary between the client and the target object, and it can be used to intercept method invocations and add additional behavior. When you use Spring AOP, the framework generates proxies for your target objects and advises them with the aspects you've defined. This means that the aspects are woven into the bytecode of the target objects, and their behavior is executed when the target objects are used.</p> <p>In short, Spring AOP provides a flexible way to add behavior to your application without affecting the code of the target objects. It helps to keep your code organized and clean by encapsulating cross-cutting concerns into separate aspects.</p> <p>Aspect oriented Programming is programming paradigm which is analogous to object oriented programming. Key unit of object oriented programming is class, similarly key unit for AOP is Aspect. Aspect enable modularisation of concerns such as transaction management, it cut across multiple classes and types. It also refers as a crosscutting concerns.</p>"},{"location":"spring/Spring-aop/#why-aop","title":"Why AOP?","text":"<p>It provides pluggable way to apply concern before, after or around business logic. Lets understand with the help of logging. You have put logging in different classes but for some reasons, if you want to remove logging now, you have to make changes in all classes but you can easily solve this by using aspect. If you want to remove logging, you just need to unplug that aspect.</p>"},{"location":"spring/Spring-aop/#aop-concepts","title":"AOP concepts","text":"<p>Spring AOP has the following key components:</p> <ol> <li> <p>Aspects: Aspects are classes that encapsulate the behavior for a particular feature or concern, such as logging, security, or transaction management.</p> </li> <li> <p>Join Points: A join point is a point in the execution of the program where an aspect can be applied. Examples of join points include method invocations, field access, and exception handling.</p> </li> <li> <p>Pointcuts: Pointcuts are expressions that determine which join points an aspect should be applied to. They can be defined using regular expressions, method signatures, or a combination of both.</p> </li> <li> <p>Advice: Advice is the actual code that gets executed when a join point matched by a pointcut is reached. There are five types of advice in Spring AOP: before, after, after-returning, after-throwing, and around.</p> </li> <li> <p>Proxies: Proxies are objects that act as intermediaries between the client and the target object. They are generated by the AOP framework and advised with the aspects you've defined. When you use a proxy, the behavior of the aspects is executed when the target object is used.</p> </li> <li> <p>Weaving: Weaving is the process of applying aspects to target objects to create advised objects. Spring AOP supports both compile-time weaving, where the aspects are woven into the bytecode of the target objects during compilation, and runtime weaving, where the aspects are woven into the target objects at runtime using proxies.</p> </li> </ol> <p>When you use Spring AOP, you define aspects that encapsulate the behavior you want to add to your application. You also define pointcuts that determine when the aspects should be applied, and you define advice that specifies the behavior to be executed when the join points matched by the pointcuts are reached. The AOP framework generates proxies for your target objects and advises them with the aspects you've defined, which means that the aspects are woven into the target objects and their behavior is executed when the target objects are used.</p> <ul> <li>Aspect: An Aspect is a class that implements concerns that cut across different classes such as logging. It is just a name.</li> <li>Joint Point : It is a point in execution of program such as execution of method. In Spring AOP, a join point always represents a method execution.</li> <li>Advice : Action taken by  aspect at particular join point. For example: Before execution of getEmployeeName() method, put logging. So here, we are using before advice.</li> <li>Pointcut : Pointcut is an expression that decides execution of advice at matched joint point. Spring uses the AspectJ pointcut expression language by default.</li> <li>Target object : These are the objects on which advices are applied. For example: There are the object on which you want to apply logging on joint point.</li> <li>AOP proxy : Spring will create JDK dynamic proxy to create proxy class around target object with advice invocations.</li> <li>Weaving : The process of creating proxy objects from target object may be termed as weaving.</li> </ul>"},{"location":"spring/Spring-aop/#types-of-advices","title":"Types of Advices","text":"<p>Advice is action taken by aspect at particular joint point. - Before Advice: it executes before a join point. - After Returning Advice: it executes after a joint point completes without any exception. - After Throwing Advice: it executes if method exits by throwing an exception. - After Advice: it executes after a join point regardless of outcome. - Around Advice: It executes before and after a join point.</p>"},{"location":"spring/Spring-aop/#spring-aop-examples","title":"Spring AOP Examples","text":""},{"location":"spring/Spring-aop/#logging","title":"Logging","text":"<p>Here is an example of an aspect that implements logging using Spring AOP:</p> <pre><code>@Aspect\n@Component\npublic class LoggingAspect {\n\n    @Before(\"execution(* com.example.demo.service.*.*(..))\")\n    public void logBefore(JoinPoint joinPoint) {\n        Logger logger = LoggerFactory.getLogger(joinPoint.getSignature().getDeclaringType());\n        logger.info(\"Entering method: {}\", joinPoint.getSignature().toShortString());\n    }\n\n    @After(\"execution(* com.example.demo.service.*.*(..))\")\n    public void logAfter(JoinPoint joinPoint) {\n        Logger logger = LoggerFactory.getLogger(joinPoint.getSignature().getDeclaringType());\n        logger.info(\"Exiting method: {}\", joinPoint.getSignature().toShortString());\n    }\n}\n</code></pre> <p>This aspect uses the @Before and @After annotations to define advice that should be executed before and after methods in the com.example.demo.service package. The advice uses the SLF4J logger to log messages indicating when methods are entered and exited.</p> <pre><code>@Aspect\n@Component\npublic class LoggingAspect {\n\n  @Before(\"execution(* com.example.demo.service.*.*(..))\")\n  public void logBefore(JoinPoint joinPoint) {\n    Logger logger = LoggerFactory.getLogger(joinPoint.getSignature().getDeclaringType());\n    logger.info(\"Entering method: {} with arguments: {}\", \n                joinPoint.getSignature().toShortString(), \n                Arrays.toString(joinPoint.getArgs()));\n  }\n\n  @After(\"execution(* com.example.demo.service.*.*(..))\")\n  public void logAfter(JoinPoint joinPoint) {\n    Logger logger = LoggerFactory.getLogger(joinPoint.getSignature().getDeclaringType());\n    logger.info(\"Exiting method: {} with result: {}\", \n                joinPoint.getSignature().toShortString(), \n                joinPoint.getSignature().toShortString());\n  }\n}\n</code></pre> <p>This aspect uses the @Before and @After annotations to define advice that should be executed before and after methods in the com.example.demo.service package. The advice logs messages indicating when methods are entered and exited, along with their arguments and results.</p>"},{"location":"spring/Spring-aop/#transactions","title":"Transactions","text":"<p>Here is an example of an aspect that implements transaction management using Spring AOP:</p> <pre><code>@Aspect\n@Component\n@Transactional\npublic class TransactionAspect {\n\n    @Around(\"execution(* com.example.demo.service.*.*(..))\")\n    public Object logAround(ProceedingJoinPoint joinPoint) throws Throwable {\n        try {\n            return joinPoint.proceed();\n        } catch (Exception ex) {\n            // rollback the transaction here\n            throw ex;\n        }\n    }\n}\n</code></pre> <p>This aspect uses the @Around annotation to define advice that should be executed around methods in the com.example.demo.service package. The advice uses the ProceedingJoinPoint to proceed with the original method call and manage the transaction by rolling it back in case of an exception. The @Transactional annotation is used to enable transaction management for the aspect.</p> <p>Note that in order to use transactions in your application, you will also need to configure a transaction manager, such as JPA, Hibernate, or JDBC, and enable transaction management in your Spring Boot configuration.</p>"},{"location":"spring/Spring-aop/#exception-handling","title":"Exception handling","text":"<pre><code>@Aspect\n@Component\npublic class ExceptionHandlingAspect {\n\n  @AfterThrowing(pointcut = \"execution(* com.example.demo.service.*.*(..))\", throwing = \"ex\")\n  public void handleException(JoinPoint joinPoint, Exception ex) {\n    Logger logger = LoggerFactory.getLogger(joinPoint.getSignature().getDeclaringType());\n    logger.error(\"Exception in method: {} with message: {}\", \n                 joinPoint.getSignature().toShortString(), \n                 ex.getMessage());\n  }\n}\n</code></pre> <p>This aspect uses the @AfterThrowing annotation to define advice that should be executed after a method in the com.example.demo.service package throws an exception. The advice logs an error message indicating the method that threw the exception and the exception message.</p>"},{"location":"spring/Spring-aop/#performance-monitoring-example","title":"Performance monitoring example:","text":"<pre><code>@Aspect\n@Component\npublic class PerformanceMonitoringAspect {\n\n  @Around(\"execution(* com.example.demo.service.*.*(..))\")\n  public Object logAround(ProceedingJoinPoint joinPoint) throws Throwable {\n    long startTime = System.currentTimeMillis();\n    Object result = joinPoint.proceed();\n    long elapsedTime = System.currentTimeMillis() - startTime;\n    Logger logger = LoggerFactory.getLogger(joinPoint.getSignature().getDeclaringType());\n    logger.info(\"Method: {} took {} ms to execute\", \n                joinPoint.getSignature().toShortString(), \n                elapsedTime);\n    return result;\n  }\n}\n</code></pre> <p>This aspect uses the @Around annotation to define advice that should be executed around methods in the com.example.demo.service package.</p>"},{"location":"spring/spring-batch/","title":"Spring Batch","text":"<p>{: .no_toc }</p>      Table of contents    <p>{: .text-delta } 1. TOC</p>"},{"location":"spring/spring-batch/#introduction-to-spring-batch","title":"Introduction to Spring Batch","text":"<p>Spring Batch provides reusable functions that are essential in processing large volumes of records, including logging/tracing, transaction management, job processing statistics, job restart, skip, and resource management. It also provides more advanced technical services and features that will enable extremely high-volume and high performance batch jobs through optimization and partitioning techniques. Simple as well as complex, high-volume batch jobs can leverage the framework in a highly scalable manner to process significant volumes of information.</p>"},{"location":"spring/spring-batch/#features","title":"Features","text":"<ul> <li>Transaction management</li> <li>Chunk based processing</li> <li>Declarative I/O</li> <li>Start/Stop/Restart</li> <li>Retry/Skip</li> <li>Web based administration interface (Spring Cloud Data Flow)</li> </ul>"},{"location":"spring/spring-batch/#spring-batch-components","title":"spring batch components","text":"<p>Spring Batch is a framework for batch processing in the Spring framework. It provides reusable functions for processing large volumes of data in batch jobs. The main components of Spring Batch include:</p> <ol> <li> <p>Job: A job is a batch process that is made up of one or more steps.</p> </li> <li> <p>Step: A step is a single unit of work that is executed as part of a job. It can be as simple as reading data from a file and writing it to a database, or as complex as performing multiple tasks in parallel.</p> </li> <li> <p>ItemReader: An ItemReader reads data from a source and provides it to the ItemProcessor.</p> </li> <li> <p>ItemProcessor: An ItemProcessor processes the data read by the ItemReader and returns the processed data.</p> </li> <li> <p>ItemWriter: An ItemWriter writes the processed data to a destination.</p> </li> <li> <p>JobRepository: A JobRepository is responsible for maintaining the state of a job and its steps.</p> </li> <li> <p>JobLauncher: A JobLauncher is used to launch a job.</p> </li> <li> <p>JobExplorer: A JobExplorer allows you to access information about past execution of a job.</p> </li> <li> <p>JobRegistry: A JobRegistry is used to register jobs with the batch infrastructure.</p> </li> <li> <p>JobParameters: JobParameters are used to pass data to a job at runtime.</p> </li> </ol> <p>These are the main components of Spring Batch, there are many other components that can be used to customize and extend the functionality of the framework.</p> <p>It provides reusable functions that are essential in processing large volumes of records, including logging/tracing, transaction management, job processing statistics, job restart, skip, and resource management.</p> <p>The architecture of Spring Batch consists of three main components:</p> <p>Job: A job represents a batch process that is executed. It is composed of one or more steps, and each step contains a reader, a processor, and a writer.</p> <p>Step: A step is a domain object that represents an independent, sequential phase of a job and contains a reader, a processor, and a writer.</p> <p>Item: An item represents a single record that is read, processed, and written. Spring Batch provides support for reading and writing items in various formats, including XML, CSV, and database.</p> <p>In addition to these components, Spring Batch also provides a JobRepository, which is responsible for maintaining the state of the job and its execution status, and a JobLauncher, which is responsible for starting and stopping the job.</p> <p>Spring Batch also provides a number of built-in components, such as readers, processors, and writers for handling common data formats and tasks, as well as an extensible API for building custom components.</p>"},{"location":"spring/spring-batch/#example-of-how-to-use-spring-batch","title":"Example of how to use Spring Batch","text":"<p>Here's an example of how to use Spring Batch with Spring Boot to read data from a CSV file, process it, and then write it to a database:</p> <ol> <li> <p>First, create a Spring Boot application with the Spring Batch and Spring Data dependencies.</p> </li> <li> <p>Create a batch configuration class that sets up the batch job and the necessary steps.  </p> </li> </ol> <pre><code>import org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.core.io.ClassPathResource;\n\n@Configuration\npublic class BatchConfig {\n    @Autowired\n    private JobBuilderFactory jobBuilderFactory;\n\n    @Autowired\n    private StepBuilderFactory stepBuilderFactory;\n\n    @Bean\n    public Job readCSVFileJob() {\n        return jobBuilderFactory\n                .get(\"readCSVFileJob\")\n                .start(step1())\n                .build();\n    }\n\n    @Bean\n    public Step step1() {\n        return stepBuilderFactory\n                .get(\"step1\")\n                .&lt;Person, Person&gt;chunk(5)\n                .reader(reader())\n                .processor(processor())\n                .writer(writer())\n                .build();\n    }\n\n\n\n    @Bean\n    public PersonItemProcessor processor() {\n        return new PersonItemProcessor();\n    }\n\n    @Bean\n    public JdbcBatchItemWriter&lt;Person&gt; writer() {\n        JdbcBatchItemWriter&lt;Person&gt; writer = new JdbcBatchItemWriter&lt;&gt;();\n        writer.setDataSource(dataSource);\n        writer.setSql(\"INSERT INTO people (first_name, last_name) VALUES (:firstName, :lastName)\");\n        writer.setItemSqlParameterSourceProvider(new BeanPropertyItemSqlParameterSourceProvider&lt;&gt;());\n        return writer;\n    }\n\n\n\n}   \n</code></pre> <ol> <li>Create a class that represents the data you're reading from the CSV file and a class that handles the processing of the data.</li> </ol> <pre><code>public class Person {\n    private String firstName;\n    private String lastName;\n    // getters and setters\n}\n\npublic class PersonItemProcessor implements ItemProcessor&lt;Person, Person&gt; {\n    @Override\n    public Person process(final Person person) throws Exception {\n        final String firstName = person.getFirstName().toUpperCase();\n        final String lastName = person.getLastName().toUpperCase();\n\n        final Person transformedPerson = new Person(firstName, lastName);\n        return transformedPerson;\n    }\n}\n</code></pre> <ol> <li>Finally, run the job by creating a <code>CommandLineRunner</code> that calls the <code>jobLauncher.run()</code> method and passing in the job name as a parameter.</li> </ol> <pre><code>@SpringBootApplication\npublic class Application implements CommandLineRunner {\n    @Autowired\n    JobLauncher jobLauncher;\n    @Autowired\n    Job job;\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class, args);\n    }\n    @Override\n    public void run(String... args) throws Exception {\n        JobExecution execution = jobLauncher.run(job, new JobParameters());\n        System.out.println(\"Job Exit Status : \"+ execution.getStatus());\n    }\n}\n</code></pre> <p>This is a basic example of how Spring Batch and Spring Boot can be used to perform batch processing. I</p>"},{"location":"spring/spring-boot/","title":"Spring Boot","text":""},{"location":"spring/spring-boot/#introduction-to-spring-boot","title":"Introduction to Spring Boot","text":"<p>Spring Boot is an open-source Java framework designed to simplify and accelerate the development of Java applications, particularly web applications and microservices.  It provides a set of conventions, templates, and tools that make it easier to create stand-alone, production-ready applications with minimal manual configuration.  Here's a detailed explanation with examples to help you understand Spring Boot better:</p> <p>1. Simplified Configuration: - Spring Boot reduces the need for complex XML configuration files that were common in traditional Spring applications. It uses sensible defaults, so you can get started quickly without much configuration. - Example: In a Spring Boot application, you can define database connection properties in a single <code>application.properties</code> or <code>application.yml</code> file:</p> <pre><code>spring.datasource.url=jdbc:mysql://localhost:3306/mydb\nspring.datasource.username=root\nspring.datasource.password=secret\n</code></pre> <p>2. Embedded Servers: - Spring Boot includes embedded web servers (like Tomcat, Jetty, or Undertow) that allow you to package your application as a standalone executable JAR or WAR file. You don't need to deploy your application to a separate server. - Example: To include an embedded Tomcat server in your project, just add the following dependency to your <code>pom.xml</code> or <code>build.gradle</code>:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>3. Spring Boot Starters: - Starters are pre-configured templates for various application types, such as web, data, messaging, etc. They include all the necessary dependencies to get you started quickly. - Example: To create a web application, include the <code>spring-boot-starter-web</code> starter, as shown above. It automatically includes dependencies for Spring MVC, Tomcat, and other related libraries.</p> <p>4. Auto-Configuration: - Spring Boot offers auto-configuration, which means it automatically configures your application based on the classpath and libraries you include. - Example: If you include the H2 database driver on your classpath, Spring Boot will configure an in-memory H2 database for you without any additional setup.</p> <p>5. Production-Ready Features: - Spring Boot provides features like health checks, metrics, and environment-specific configuration to make your application production-ready. - Example: Spring Boot Actuator allows you to expose health endpoints (<code>/actuator/health</code>) and metrics (<code>/actuator/metrics</code>) to monitor your application's health and performance.</p> <p>6. Spring Boot CLI (Command Line Interface): - Spring Boot CLI allows you to quickly develop and prototype Spring Boot applications using a command-line interface. - Example: You can create a simple Spring Boot application with just a few commands in the CLI.</p> <p>7. Spring Boot DevTools: - DevTools offer features like automatic application restarts and live reload, making development and debugging easier. - Example: When DevTools are enabled, your application will automatically restart when you make changes to your code, reducing development downtime.</p> <p>Spring Boot, as a popular framework in the Java ecosystem, comes with several advantages and some potential disadvantages. Here's a breakdown of its advantages and disadvantages:</p>"},{"location":"spring/spring-boot/#advantages-of-spring-boot","title":"Advantages of Spring Boot","text":""},{"location":"spring/spring-boot/#simplified-configuration","title":"Simplified Configuration","text":"<p>Spring Boot provides sensible defaults and simplifies configuration through properties files (<code>.properties</code> or <code>.yml</code>). This reduces the need for verbose XML configurations, making it easier to get started quickly.</p>"},{"location":"spring/spring-boot/#rapid-development","title":"Rapid Development","text":"<p>It offers a wide range of pre-built templates and starters for various application types (web, data, messaging, etc.), enabling rapid application development. You can focus more on business logic and less on setting up infrastructure.</p>"},{"location":"spring/spring-boot/#embedded-servers","title":"Embedded Servers","text":"<p>Spring Boot includes embedded web servers (like Tomcat, Jetty, or Undertow), allowing you to package your application as a standalone JAR or WAR file. This simplifies deployment and reduces server management overhead.</p>"},{"location":"spring/spring-boot/#auto-configuration","title":"Auto-Configuration","text":"<p>Spring Boot's auto-configuration feature automatically configures your application based on the libraries and dependencies you include on the classpath. This saves time and effort in setting up common configurations.</p>"},{"location":"spring/spring-boot/#production-ready-features","title":"Production-Ready Features","text":"<p>Spring Boot provides features like health checks, metrics, security, and environment-specific configuration out-of-the-box, making it easier to create production-ready applications.</p>"},{"location":"spring/spring-boot/#community-and-ecosystem","title":"Community and Ecosystem","text":"<p>Spring Boot has a large and active community, which means extensive online resources, documentation, and third-party libraries. You can leverage the Spring ecosystem for various integrations.</p>"},{"location":"spring/spring-boot/#microservices-and-cloud-native-development","title":"Microservices and Cloud-Native Development","text":"<p>Spring Boot is well-suited for building microservices and cloud-native applications. It integrates with Spring Cloud for features like service discovery, distributed configuration, and circuit breakers.</p>"},{"location":"spring/spring-boot/#testing-support","title":"Testing Support","text":"<p>Spring Boot offers a robust testing framework with annotations and utilities for writing unit, integration, and end-to-end tests.</p>"},{"location":"spring/spring-boot/#disadvantages-of-spring-boot","title":"Disadvantages of Spring Boot","text":""},{"location":"spring/spring-boot/#learning-curve","title":"Learning Curve","text":"<p>While Spring Boot simplifies many aspects of application development, it still requires a solid understanding of Spring and Java. Beginners might find it overwhelming initially.</p>"},{"location":"spring/spring-boot/#overhead","title":"Overhead","text":"<p>Spring Boot's auto-configuration can sometimes lead to unexpected behavior if you're not aware of the defaults and assumptions it makes. In complex applications, it may be necessary to override some auto-configurations, which can be challenging.</p>"},{"location":"spring/spring-boot/#customization-challenges","title":"Customization Challenges","text":"<p>Customizing certain aspects of Spring Boot's auto-configurations or embedded servers can be complex, especially if you need fine-grained control over the configuration.</p>"},{"location":"spring/spring-boot/#resource-usage","title":"Resource Usage","text":"<p>Embedded servers consume some resources, even if your application isn't under heavy load. In cases where resource efficiency is crucial, a traditional server setup might be more appropriate.</p>"},{"location":"spring/spring-boot/#size-of-the-jar","title":"Size of the JAR","text":"<p>The generated executable JAR file for a Spring Boot application can be relatively large due to the embedded server and dependencies. This might not be ideal for very lightweight applications.</p>"},{"location":"spring/spring-boot/#dependency-management","title":"Dependency Management","text":"<p>Spring Boot's dependency management can sometimes lead to version conflicts if you're integrating with third-party libraries that have specific version requirements.</p> <p>Certainly! The Spring Boot Starter concept is a powerful feature in the Spring Boot framework that simplifies and streamlines the process of setting up and configuring dependencies for your Java applications. It's designed to make it easier for developers, including students and professionals, to get started with building Spring-based applications without the need to delve deeply into complex configuration and dependency management. Let's explore the Spring Boot Starter concept in detail.</p> <p>Understanding Spring Boot Starters:</p> <p>Imagine you're embarking on a journey to build a Java application using the Spring framework. You need various libraries and dependencies for tasks like web development, database access, security, and more. In a traditional setup, you would manually add these dependencies to your project, manage their versions, and configure them, which can be a daunting and error-prone task, especially for newcomers.</p> <p>This is where Spring Boot Starters come to the rescue. A Starter is essentially a pre-packaged set of dependencies, configurations, and templates tailored for a specific use case or type of application. Spring Boot provides a wide range of starters, each focused on a particular area of functionality. These starters encapsulate everything you need to kickstart your project, including:</p> <ol> <li> <p>Dependencies: Starters include the necessary libraries and dependencies required for the chosen functionality. This eliminates the need for you to hunt for compatible versions or worry about conflicting dependencies.</p> </li> <li> <p>Configuration: Spring Boot starters often come with sensible default configurations, reducing the complexity of setting up your application. However, you can still customize these settings according to your requirements.</p> </li> <li> <p>Template Code: Some starters provide template code, classes, and configurations to help you get started quickly. For example, a web starter might include a basic controller and application structure.</p> </li> </ol> <p>Benefits of Spring Boot Starters:</p> <p>Here are some key benefits of using Spring Boot Starters:</p> <ol> <li> <p>Saves Time: Starters save you significant development time by providing a well-structured foundation for your project.</p> </li> <li> <p>Reduces Complexity: They simplify complex configuration tasks, making it easier for beginners to work with Spring.</p> </li> <li> <p>Promotes Best Practices: Starters encourage best practices and conventions, ensuring that your application follows recommended standards.</p> </li> <li> <p>Enhances Compatibility: Starters ensure that the included dependencies are compatible and work seamlessly together.</p> </li> </ol> <p>Using Spring Boot Starters:</p> <p>To use a Spring Boot Starter, you typically perform the following steps:</p> <ol> <li> <p>Add Dependency: In your project's build configuration (e.g., <code>pom.xml</code> for Maven or <code>build.gradle</code> for Gradle), add the relevant Spring Boot Starter as a dependency.</p> </li> <li> <p>Configure as Needed: Customize the configuration, if necessary, by overriding the default settings in your application's properties file (usually <code>application.properties</code> or <code>application.yml</code>).</p> </li> <li> <p>Start Building: With the Starter in place, you can start building your application, leveraging the provided dependencies and configurations.</p> </li> </ol> <p>Examples of Spring Boot Starters:</p> <ul> <li> <p><code>spring-boot-starter-web</code>: This Starter includes everything you need to build a web application, including the Spring MVC framework and an embedded web server (e.g., Tomcat).</p> </li> <li> <p><code>spring-boot-starter-data-jpa</code>: It sets up the Java Persistence API (JPA) for database access, making it easy to work with databases in your application.</p> </li> <li> <p><code>spring-boot-starter-security</code>: This Starter provides security features like authentication and authorization, helping you secure your application.</p> </li> <li> <p><code>spring-boot-starter-test</code>: It offers testing libraries and tools for writing unit, integration, and end-to-end tests.</p> </li> </ul> <p>Conclusion:</p> <p>In essence, Spring Boot Starters are like ready-made toolkits that empower developers of all levels to kickstart their Spring-based projects efficiently. Whether you're a student learning Spring or a professional building a production-grade application, Spring Boot Starters simplify your journey by providing a solid foundation, reducing complexity, and promoting best practices. They are a valuable asset in the Spring Boot ecosystem, enabling developers to focus on solving real business problems rather than wrestling with configurations and dependencies.</p>"},{"location":"spring/spring-boot/#understanding-spring-boot-starters","title":"Understanding Spring Boot Starters","text":"<p>If you're a student, developer, or anyone interested in building Java applications with Spring Boot, understanding the concept of Spring Boot Starters is crucial. Spring Boot Starters are a powerful feature of the Spring Boot framework that simplifies and accelerates the process of setting up and configuring various dependencies in your application. In this article, we'll delve into what Spring Boot Starters are, why they are essential, and how you can leverage them to streamline your Spring Boot projects.</p>"},{"location":"spring/spring-boot/#what-are-spring-boot-starters","title":"What are Spring Boot Starters?","text":"<p>Spring Boot Starters are a set of pre-configured templates or dependency descriptors that encapsulate common sets of dependencies needed for various types of applications. These starters are designed to simplify the process of adding dependencies to your project, making it easier to bootstrap Spring Boot applications quickly. Each starter is essentially a collection of pre-defined Maven or Gradle dependencies, along with default configuration settings, designed to fulfill a specific purpose.</p>"},{"location":"spring/spring-boot/#why-are-spring-boot-starters-important","title":"Why are Spring Boot Starters important?","text":"<ol> <li> <p>Simplified Configuration: Spring Boot Starters significantly simplify the configuration process. Instead of manually adding multiple dependencies and writing extensive configuration files, you can include a single starter in your project, and Spring Boot will handle the rest. This reduces the risk of configuration errors and saves valuable development time.</p> </li> <li> <p>Opinionated Defaults: Spring Boot Starters come with opinionated default settings and configurations that align with best practices. This ensures that your application follows recommended conventions, promoting consistency and maintainability across different projects.</p> </li> <li> <p>Reduced Dependency Management: Managing dependencies can be a complex and error-prone task. Spring Boot Starters handle dependency management, ensuring that all included dependencies are compatible and work seamlessly together. This eliminates version conflicts and compatibility issues.</p> </li> <li> <p>Customization: While starters provide opinionated defaults, they are highly customizable. You can override and fine-tune the configuration to meet your specific requirements. This flexibility allows you to tailor your application to your needs without the complexity of starting from scratch.</p> </li> </ol>"},{"location":"spring/spring-boot/#how-to-use-spring-boot-starters","title":"How to Use Spring Boot Starters","text":"<p>Using Spring Boot Starters is straightforward:</p> <ol> <li> <p>Add the Starter Dependency: In your project's build configuration (typically, the <code>pom.xml</code> for Maven or <code>build.gradle</code> for Gradle), you specify the desired Spring Boot Starter as a dependency. Spring Boot's build tool integration, such as Spring Initializr, often helps you select and include starters.</p> </li> <li> <p>Leverage Auto-Configuration: Spring Boot Starters often come with auto-configuration classes that automatically configure beans and settings based on your classpath and included dependencies. You can further customize this behavior if needed.</p> </li> <li> <p>Customize as Necessary: If the starter's default configuration doesn't meet your requirements, you can customize it by providing your own configuration properties or disabling certain auto-configurations.</p> </li> </ol>"},{"location":"spring/spring-boot/#popular-spring-boot-starters","title":"Popular Spring Boot Starters","text":"<p>Spring Boot provides a wide range of starters catering to various use cases. Some popular ones include:</p> <ul> <li>Spring Boot Starter Web: For building web applications with Spring MVC and embedded web servers.</li> <li>Spring Boot Starter Data JPA: For integrating with the Java Persistence API (JPA) and relational databases.</li> <li>Spring Boot Starter Security: For adding security features like authentication and authorization to your application.</li> <li>Spring Boot Starter Test: For setting up testing frameworks like JUnit and TestNG.</li> </ul>"},{"location":"spring/spring-boot/#conclusion","title":"Conclusion","text":"<p>Spring Boot Starters are a game-changer when it comes to simplifying the development of Java applications. They encapsulate common dependencies, configurations, and best practices, enabling you to focus on writing business logic rather than managing infrastructure. By understanding how to use Spring Boot Starters effectively, you'll accelerate your development process and create robust, maintainable Spring Boot applications with ease.</p>"},{"location":"spring/spring-boot/#simplifying-application-configuration-with-spring-boot","title":"Simplifying Application Configuration with Spring Boot","text":"<p>Spring Boot is a Java framework renowned for its ability to simplify the often intricate process of configuring applications. It achieves this by offering opinionated defaults, automated setup, starter dependencies, externalized configuration, profile management, and more. In this article, we'll delve into the details of how Spring Boot simplifies application configuration, making it more accessible and efficient for developers.</p> <p>Configuring Java applications can be a challenging endeavor, involving numerous settings, dependencies, and adjustments. Spring Boot addresses these challenges by simplifying application configuration through a variety of techniques:</p>"},{"location":"spring/spring-boot/#opinionated-defaults","title":"Opinionated Defaults","text":"<p>Spring Boot employs opinionated defaults, meaning it intelligently assumes sensible configurations for your application. These defaults save developers from specifying every detail explicitly, reducing the need for boilerplate code. For instance, when building a web application, Spring Boot automatically configures a web server for you, adhering to industry best practices and standards.</p>"},{"location":"spring/spring-boot/#auto-configuration_1","title":"Auto-Configuration","text":"<p>One of Spring Boot's standout features is its auto-configuration capability. It scans your project's dependencies and, based on the detected components, configures your application automatically. This eliminates the burden of extensive manual configuration and minimizes the risk of configuration errors.</p>"},{"location":"spring/spring-boot/#starter-dependencies","title":"Starter Dependencies","text":"<p>Spring Boot introduces \"starters,\" which are pre-packaged bundles of dependencies tailored for specific use cases. Instead of manually adding and managing individual dependencies, you can include a single starter in your project. Starters encapsulate all the required dependencies and configurations, simplifying your project's structure and ensuring compatibility among components.</p>"},{"location":"spring/spring-boot/#externalized-configuration","title":"Externalized Configuration","text":"<p>Spring Boot encourages the practice of externalized configuration. Instead of hardcoding settings within your code, you can store them in external configuration files like <code>application.properties</code> or <code>application.yml</code>. This approach makes it easy to adjust configuration settings without modifying your codebase, promoting better maintainability.</p>"},{"location":"spring/spring-boot/#profile-management","title":"Profile Management","text":"<p>Spring Boot supports profiles, allowing you to define multiple sets of configuration properties for various environments. Whether you're in \"development,\" \"testing,\" or \"production,\" you can switch between profiles effortlessly. This feature streamlines the management of configuration variations to suit different deployment scenarios.</p>"},{"location":"spring/spring-boot/#annotations-and-sensible-defaults","title":"Annotations and Sensible Defaults","text":"<p>Spring Boot provides an extensive set of annotations and sensible defaults for common tasks. For instance, the <code>@SpringBootApplication</code> annotation simplifies application bootstrapping with minimal code. These annotations and defaults reduce the need for extensive configuration, resulting in a cleaner and more concise codebase.</p>"},{"location":"spring/spring-boot/#built-in-actuators","title":"Built-in Actuators","text":"<p>Spring Boot comes equipped with built-in actuator endpoints that offer insights into your application's configuration and runtime behavior. These endpoints enable monitoring and management, even in production environments, without the need for custom monitoring code.</p>"},{"location":"spring/spring-boot/#command-line-properties","title":"Command-Line Properties","text":"<p>You can pass configuration properties via the command line when starting your Spring Boot application. This feature simplifies configuration adjustments for specific runs without the hassle of modifying configuration files.</p> <p>In conclusion, Spring Boot simplifies application configuration through opinionated defaults, auto-configuration, starter dependencies, externalized properties, profile management, annotations, built-in actuators, and command-line properties. These features collectively enhance the development experience, reduce complexity, and make it easier for developers to create and maintain robust Java applications.</p>"},{"location":"spring/spring-boot/#springbootapplication","title":"@SpringBootApplication","text":"<p>In Spring Boot, the <code>@SpringBootApplication</code> annotation plays a pivotal role in simplifying the configuration and bootstrapping of your Spring application. It's a powerful and concise annotation that combines several other annotations and provides a starting point for your Spring Boot application. Understanding its purpose is essential for students, developers, and anyone working with Spring Boot.</p>"},{"location":"spring/spring-boot/#purpose-of-springbootapplication","title":"Purpose of <code>@SpringBootApplication</code>","text":"<p>The <code>@SpringBootApplication</code> annotation serves three primary purposes:</p> <ol> <li> <p>Configuration: It indicates that the class where it is applied is a configuration class for the Spring application. This means that the class will provide configuration information to Spring, and it can contain various bean definitions and application settings.</p> </li> <li> <p>Component Scanning: It enables component scanning within the package where the main application class is located. Component scanning allows Spring to discover and register beans (components, services, repositories, etc.) without the need for explicit XML configurations or Java code. This makes it easier to manage and maintain your application.</p> </li> <li> <p>Auto-Configuration: Perhaps the most significant advantage of <code>@SpringBootApplication</code> is that it combines the <code>@Configuration</code>, <code>@ComponentScan</code>, and <code>@EnableAutoConfiguration</code> annotations. The <code>@EnableAutoConfiguration</code> annotation triggers Spring Boot's auto-configuration mechanism, which automatically configures many common components and settings based on the dependencies detected in the classpath. This means less boilerplate configuration code for you, as Spring Boot intelligently configures your application based on best practices.</p> </li> </ol> <p>In summary, by using the <code>@SpringBootApplication</code> annotation, you are not only defining your application's configuration but also enabling component scanning and taking advantage of Spring Boot's powerful auto-configuration capabilities. This annotation simplifies the setup process, reduces configuration overhead, and allows you to focus on writing business logic rather than extensive configuration files.</p> <p>In your Spring Boot projects, you will often find this annotation at the entry point of your application, typically on the class containing the <code>main</code> method. It marks the starting point for your Spring Boot application, making it a central and essential element for creating efficient and maintainable Spring-based applications.</p>"},{"location":"spring/spring-boot/#internal-working-of-springbootapplication","title":"Internal Working of <code>@SpringBootApplication</code>","text":"<p>The <code>@SpringBootApplication</code> annotation in Spring Boot is a powerful and convenient way to configure and bootstrap a Spring application. Under the hood, it combines several other annotations and performs various tasks to set up the Spring environment. Let's dive into the internal workings of <code>@SpringBootApplication</code>:</p> <ol> <li> <p><code>@Configuration</code>: The <code>@Configuration</code> annotation indicates that the class should be treated as a configuration class. It allows the class to define Spring beans using <code>@Bean</code> methods. <code>@SpringBootApplication</code> implicitly includes this annotation, enabling you to configure your application.</p> </li> <li> <p><code>@ComponentScan</code>: The <code>@ComponentScan</code> annotation tells Spring to scan for components (such as <code>@Component</code>, <code>@Service</code>, <code>@Repository</code>, etc.) within the package where the main application class is located and its sub-packages. It is included within <code>@SpringBootApplication</code> to automatically discover and register these components.</p> </li> <li> <p><code>@EnableAutoConfiguration</code>: Spring Boot's powerful feature is auto-configuration, which simplifies the setup of common components and beans based on the classpath and the libraries you include in your project. The <code>@EnableAutoConfiguration</code> annotation, included within <code>@SpringBootApplication</code>, triggers this auto-configuration process.</p> </li> <li> <p>Bootstrap Class: The class containing the <code>@SpringBootApplication</code> annotation is typically the main class of your application, containing the <code>public static void main</code> method. When you run this class, it serves as the entry point for your Spring Boot application.</p> </li> </ol> <p>Here's a high-level overview of how <code>@SpringBootApplication</code> works internally:</p> <ol> <li> <p>When you run your Spring Boot application, the main class with <code>@SpringBootApplication</code> is executed.</p> </li> <li> <p>Spring Boot scans the package where the main class is located (and its sub-packages) for components, thanks to the included <code>@ComponentScan</code>.</p> </li> <li> <p>It identifies and registers any beans defined in <code>@Configuration</code> classes within the scanned packages.</p> </li> <li> <p>The <code>@EnableAutoConfiguration</code> annotation comes into play. Spring Boot's auto-configuration mechanism analyzes the classpath and the dependencies you've added. It automatically configures various beans and components based on sensible defaults and best practices.</p> </li> <li> <p>Your Spring Boot application is now up and running, with beans, components, and configurations set up according to your classpath and the specific Spring Boot starters you've included.</p> </li> </ol> <p>In summary, <code>@SpringBootApplication</code> simplifies the configuration and bootstrapping process of a Spring Boot application by encapsulating the <code>@Configuration</code>, <code>@ComponentScan</code>, and <code>@EnableAutoConfiguration</code> annotations. This annotation brings together these essential elements to make your Spring Boot project concise, maintainable, and efficient, allowing you to focus on writing business logic rather than extensive configuration.</p>"},{"location":"spring/spring-boot/#steps-to-create-a-restful-api-using-spring-boot","title":"Steps to Create a RESTful API using Spring Boot","text":"<p>Creating a RESTful API using Spring Boot is a fundamental skill for developers looking to build web services that follow REST (Representational State Transfer) principles. Spring Boot, with its robust features and simplified setup, makes this process relatively straightforward. In this guide, we'll walk you through the essential steps to create a RESTful API with Spring Boot.</p>"},{"location":"spring/spring-boot/#1-set-up-a-spring-boot-project","title":"1. Set Up a Spring Boot Project","text":"<p>To begin, ensure you have Spring Boot installed. You can create a Spring Boot project using tools like Spring Initializr or through your preferred IDE. Define your project's dependencies, including \"Spring Web\" for building web applications.</p>"},{"location":"spring/spring-boot/#2-create-a-model","title":"2. Create a Model","text":"<p>Design your data model by creating Java classes that represent the objects your API will handle. Annotate these classes with <code>@Entity</code> if you plan to use a database or <code>@Data</code> for simple POJOs. Define attributes and relationships within your model.</p>"},{"location":"spring/spring-boot/#3-create-a-repository","title":"3. Create a Repository","text":"<p>For database operations, create a repository interface that extends <code>JpaRepository</code> or a suitable Spring Data repository interface. Use Spring Data JPA to simplify database access and CRUD operations.</p>"},{"location":"spring/spring-boot/#4-create-a-controller","title":"4. Create a Controller","text":"<p>Design your API endpoints by creating a controller class. Annotate it with <code>@RestController</code> to mark it as a RESTful controller. Define methods within the controller and annotate them with HTTP request mappings such as <code>@GetMapping</code>, <code>@PostMapping</code>, <code>@PutMapping</code>, or <code>@DeleteMapping</code>. These methods will handle incoming requests and send responses.</p>"},{"location":"spring/spring-boot/#5-implement-crud-operations","title":"5. Implement CRUD Operations","text":"<p>Inside your controller methods, use the repository you created earlier to perform CRUD (Create, Read, Update, Delete) operations on your data model. Map these operations to specific HTTP endpoints.</p>"},{"location":"spring/spring-boot/#6-handle-request-and-response","title":"6. Handle Request and Response","text":"<p>Utilize request and response objects to interact with incoming data (e.g., JSON or XML payloads) and return appropriate responses. Spring Boot automatically converts objects to JSON or XML for you using Jackson or JAXB.</p>"},{"location":"spring/spring-boot/#7-exception-handling","title":"7. Exception Handling","text":"<p>Implement proper exception handling to provide meaningful error responses. You can use <code>@ControllerAdvice</code> to handle exceptions globally or use <code>@ExceptionHandler</code> within your controller.</p>"},{"location":"spring/spring-boot/#8-test-your-api","title":"8. Test Your API","text":"<p>Write unit tests and integration tests to ensure your API functions as expected. Tools like JUnit and Spring's testing framework can help you achieve comprehensive test coverage.</p>"},{"location":"spring/spring-boot/#9-run-and-deploy","title":"9. Run and Deploy","text":"<p>Start your Spring Boot application and test it locally. Once satisfied, deploy it to a server or a cloud platform like AWS, Azure, or Heroku.</p>"},{"location":"spring/spring-boot/#10-document-your-api","title":"10. Document Your API","text":"<p>Create documentation for your API to help users understand how to use it. Tools like Swagger or Springdoc can generate interactive API documentation.</p>"},{"location":"spring/spring-boot/#11-secure-your-api-optional","title":"11. Secure Your API (Optional)","text":"<p>Implement security measures like OAuth2, JWT, or Spring Security to protect your API from unauthorized access if needed.</p>"},{"location":"spring/spring-boot/#12-monitor-and-maintain","title":"12. Monitor and Maintain","text":"<p>Monitor your API's performance and usage. Keep your dependencies and Spring Boot version up to date. Address issues and continuously improve your API based on user feedback and evolving requirements.</p> <pre><code>@RestController\n@RequestMapping(\"/api\")\npublic class MyController {\n\n    @Autowired\n    private MyRepository myRepository;\n\n    @GetMapping(\"/mydata\")\n    public List&lt;MyData&gt; getAllMyData() {\n        return myRepository.findAll();\n    }\n\n    @PostMapping(\"/mydata\")\n    public MyData createMyData(@RequestBody MyData myData) {\n        return myRepository.save(myData);\n    }\n\n    @GetMapping(\"/mydata/{id}\")\n    public MyData getMyDataById(@PathVariable(value = \"id\") Long myDataId) {\n        return myRepository.findById(myDataId)\n                .orElseThrow(() -&gt; new ResourceNotFoundException(\"MyData\", \"id\", myDataId));\n    }\n\n    @PutMapping(\"/mydata/{id}\")\n    public MyData updateMyData(@PathVariable(value = \"id\") Long myDataId,\n                           @RequestBody MyData myDataDetails) {\n\n        MyData myData = myRepository.findById(myDataId)\n                .orElseThrow(() -&gt; new ResourceNotFoundException(\"MyData\", \"id\", myDataId));\n\n        myData.setName(myDataDetails.getName());\n        myData.setDescription(myDataDetails.getDescription());\n\n        MyData updatedMyData = myRepository.save(myData);\n        return updatedMyData;\n    }\n\n    @DeleteMapping(\"/mydata/{id}\")\n    public ResponseEntity&lt;?&gt; deleteMyData(@PathVariable(value = \"id\") Long myDataId) {\n        MyData myData = myRepository.findById(myDataId)\n                .orElseThrow(() -&gt; new ResourceNotFoundException(\"MyData\", \"id\", myDataId));\n\n        myRepository.delete(myData);\n\n        return ResponseEntity.ok().build();\n    }\n}\n</code></pre> <p>In conclusion, building a RESTful API using Spring Boot involves setting up the project, designing data models, creating controllers, handling CRUD operations, and addressing aspects like exception handling, testing, documentation, and security. Following these steps will help you create a robust and maintainable API that adheres to REST principles.</p>"},{"location":"spring/spring-boot/#spring-boots-auto-configuration-feature","title":"Spring Boot's auto-configuration feature","text":"<p>Spring Boot's auto-configuration is like having a helpful assistant for your Spring applications. It's a feature that takes away the burden of setting up common configurations, making your life as a developer much easier. In this guide, we'll explore Spring Boot's auto-configuration and how it simplifies the development process.</p>"},{"location":"spring/spring-boot/#what-is-auto-configuration","title":"What is Auto-Configuration?","text":"<p>Auto-configuration in Spring Boot is all about automating the setup of your application. When you're building a Spring project, you often need to configure various components, beans, and settings. Auto-configuration does this work for you based on the libraries and dependencies you include in your project.</p>"},{"location":"spring/spring-boot/#how-does-it-work","title":"How Does it Work?","text":"<p>Spring Boot's magic lies in its ability to analyze your project's classpath and dependencies. It checks if specific conditions are met, and if they are, it configures beans and components accordingly. For instance, if you include a database library, Spring Boot will notice it and set up database-related beans without you having to write extensive configuration code.</p>"},{"location":"spring/spring-boot/#benefits-of-auto-configuration","title":"Benefits of Auto-Configuration","text":"<ol> <li> <p>Saves Time: Auto-configuration drastically reduces the amount of boilerplate code you need to write. This means you can get your project up and running faster.</p> </li> <li> <p>Best Practices: Spring Boot's auto-configurations follow industry best practices and conventions, ensuring your application is well-structured and follows recommended standards.</p> </li> <li> <p>Easy Integration: Adding new libraries and dependencies is a breeze. Spring Boot takes care of the heavy lifting, making it simple to adopt new technologies.</p> </li> <li> <p>Maintenance Made Easier: Keeping your application up to date becomes less of a headache. When you update libraries and dependencies, Spring Boot handles compatibility issues.</p> </li> </ol>"},{"location":"spring/spring-boot/#customization-and-overrides","title":"Customization and Overrides","text":"<p>While auto-configuration is fantastic, there may be situations where you need to customize things. Spring Boot allows you to create your configuration classes or properties files to tweak or override auto-configured beans and components. This gives you the flexibility to adapt to your application's specific requirements.</p>"},{"location":"spring/spring-boot/#when-to-use-custom-configuration","title":"When to Use Custom Configuration","text":"<p>While Spring Boot's auto-configuration is incredibly helpful, you might want custom configurations in unique situations. When you have specific needs that aren't met by the auto-configuration, you can step in and provide your own configurations to tailor your application as necessary.</p> <p>In conclusion, Spring Boot's auto-configuration is your development ally. It simplifies the setup and configuration of Spring applications, letting you focus on the fun part: writing your application's logic. With auto-configuration, your development process becomes smoother, faster, and more enjoyable.</p>"},{"location":"spring/spring-boot/#restcontroller-vs-controller","title":"<code>@RestController</code> vs. <code>@Controller</code>","text":"<p>In the bustling world of Spring Boot applications, handling user requests and crafting responses is fundamental. But just like in a restaurant, choosing the right tools makes all the difference. Today, we'll unravel the mysteries of two crucial Spring Boot annotations \u2013 <code>@RestController</code> and <code>@Controller</code> \u2013 and help you decide which one to serve up for your specific dish.</p> <ul> <li>Both <code>@RestController</code> and <code>@Controller</code> handle web requests in Spring Boot applications.</li> <li><code>@RestController</code> is a shortcut, combining <code>@Controller</code> with <code>@ResponseBody</code>.</li> <li>The key difference lies in their output:</li> <li><code>@RestController</code> focuses on delivering data (JSON, XML, etc.) directly, ideal for building RESTful APIs.</li> <li><code>@Controller</code> serves up prepared dishes (rendered views) for users to see, perfect for traditional web applications.</li> </ul>"},{"location":"spring/spring-boot/#return-values","title":"Return Values","text":"<ul> <li><code>@RestController</code>: Methods return objects like data models, automatically converted to JSON by default. You can skip <code>@ResponseBody</code> on individual methods.</li> <li><code>@Controller</code>: Methods typically return view names (strings) referencing template files. Use <code>@ResponseBody</code> on specific methods to return raw data.</li> </ul>"},{"location":"spring/spring-boot/#use-cases","title":"Use Cases:","text":"<ul> <li><code>@RestController</code>: Building APIs for mobile apps, data exchange with other services, and microservices architectures. Think of it as your delivery service, sending data out to the world.</li> <li><code>@Controller</code>: Creating traditional web UIs, single-page applications with dynamic content. Imagine it as a restaurant kitchen, preparing delicious views for users to enjoy.</li> </ul>"},{"location":"spring/spring-boot/#choosing-the-right-ingredient","title":"Choosing the Right Ingredient","text":"<ul> <li>Pick <code>@RestController</code> when you're cooking up RESTful APIs, where data exchange is the main course.</li> <li>Opt for <code>@Controller</code> when building traditional web applications where users interact with visually appealing interfaces.</li> </ul>"},{"location":"spring/spring-boot/#remember","title":"Remember","text":"<ul> <li>You can even nest <code>@RestController</code> within a <code>@Controller</code> class for finer control within your application.</li> <li>Always decide based on your desired output: data for APIs or rendered views for web pages.</li> </ul> <p>In conclusion, <code>@RestController</code> and <code>@Controller</code> are like different utensils in your Spring Boot kitchen. Understanding their strengths and differences empowers you to choose the perfect tool for crafting a satisfying application. So, fire up your coding stove and get cookin'!**</p>"},{"location":"spring/spring-boot/#examples","title":"Examples","text":"<p>In Spring Framework, both <code>@RestController</code> and <code>@Controller</code> are annotations used to create components responsible for handling HTTP requests in a web application. However, they serve different purposes and have distinct use cases. This guide explains the purpose of the <code>@RestController</code> annotation and how it differs from <code>@Controller</code>.</p>"},{"location":"spring/spring-boot/#purpose-of-restcontroller","title":"Purpose of <code>@RestController</code>","text":"<p>The <code>@RestController</code> annotation is used in Spring to define a class as a specialized version of the <code>@Controller</code> component. While both are responsible for handling HTTP requests, <code>@RestController</code> specifically deals with RESTful web services.</p>"},{"location":"spring/spring-boot/#controller","title":"<code>@Controller</code>","text":"<p>The <code>@Controller</code> annotation is a fundamental building block of Spring-based web applications. It marks a class as a controller, indicating that it handles incoming HTTP requests, processes them, and returns an appropriate HTTP response. Controllers are typically used in traditional web applications that render HTML views.</p> <p>When you use <code>@Controller</code>, the return value of its methods is often a logical view name, which is resolved by a ViewResolver to generate an HTML page.</p> <pre><code>@Controller\npublic class MyController {\n\n    @GetMapping(\"/home\")\n    public String home() {\n        return \"index\"; // Returns a view name\n    }\n}\n</code></pre>"},{"location":"spring/spring-boot/#restcontroller","title":"<code>@RestController</code>","text":"<p>On the other hand, the <code>@RestController</code> annotation is designed specifically for building RESTful web services. It combines the <code>@Controller</code> and <code>@ResponseBody</code> annotations into one, simplifying the creation of APIs that return data in formats like JSON or XML. When you use <code>@RestController</code>, the return value of its methods is serialized directly into the HTTP response body, rather than being treated as a view name.</p> <pre><code>@RestController\npublic class MyRestController {\n\n    @GetMapping(\"/api/data\")\n    public Map&lt;String, String&gt; getData() {\n        Map&lt;String, String&gt; data = new HashMap&lt;&gt;();\n        data.put(\"message\", \"Hello, world!\");\n        return data; // Returns data serialized as JSON\n    }\n}\n</code></pre>"},{"location":"spring/spring-boot/#key-differences","title":"Key Differences","text":"<ol> <li> <p>Response Handling: The primary difference is in how they handle responses. <code>@Controller</code> returns a view, while <code>@RestController</code> returns data directly.</p> </li> <li> <p>Data Serialization: <code>@RestController</code> automatically serializes the return value (e.g., an object, list, or map) into JSON or XML format using Jackson or JAXB, making it suitable for building APIs.</p> </li> <li> <p>View Resolution: <code>@Controller</code> relies on ViewResolvers to render HTML views based on logical view names, whereas <code>@RestController</code> returns data directly to be consumed by clients.</p> </li> <li> <p>Use Case: Use <code>@Controller</code> for traditional web applications that render HTML views, and use <code>@RestController</code> when building RESTful APIs that provide data to other applications, such as mobile apps or front-end frameworks.</p> </li> </ol> <p>In summary, while both <code>@Controller</code> and <code>@RestController</code> handle HTTP requests, they serve different purposes. <code>@Controller</code> is for building web pages with views, while <code>@RestController</code> is for creating RESTful web services that return data in a format suitable for consumption by client applications. The choice between them depends on the type of web application you are developing and the desired response format.</p>"},{"location":"spring/spring-boot/#actuator","title":"Actuator","text":"<p>Spring Boot's Actuator module is a powerful and essential component that enhances the monitoring and management capabilities of your Spring Boot applications. It provides a wide range of built-in features and endpoints, making it easier for developers and administrators to understand, monitor, and manage the health and performance of their applications.</p> <p>Spring Boot Actuator plays a crucial role in simplifying the task of monitoring, managing, and securing Spring Boot applications. It achieves this through a set of built-in production-ready features, known as \"endpoints,\" and various extension points for customization.</p>"},{"location":"spring/spring-boot/#key-responsibilities-of-spring-boot-actuator","title":"Key Responsibilities of Spring Boot Actuator:","text":""},{"location":"spring/spring-boot/#1-health-and-readiness-checks","title":"1. Health and Readiness Checks","text":"<ul> <li> <p>Health Endpoint: Spring Boot Actuator includes a <code>/actuator/health</code> endpoint, which provides insights into the overall health of your application. It reports whether critical components like the database, messaging systems, and other dependencies are operational.</p> </li> <li> <p>Readiness Endpoint: Additionally, Spring Boot Actuator introduces a <code>/actuator/readiness</code> endpoint that signifies if your application is ready to handle requests. This is particularly useful during the startup process when the application might be initializing resources.</p> </li> </ul>"},{"location":"spring/spring-boot/#2-metrics-collection-and-reporting","title":"2. Metrics Collection and Reporting","text":"<ul> <li>Metrics Endpoints: Spring Boot Actuator offers various <code>/actuator/metrics</code> endpoints that collect and expose application-specific metrics. These metrics can include data about the application's memory usage, garbage collection, HTTP request/response statistics, and custom metrics that you define.</li> </ul>"},{"location":"spring/spring-boot/#3-application-information","title":"3. Application Information","text":"<ul> <li>Info Endpoint: You can use the <code>/actuator/info</code> endpoint to provide custom information about your application. This can be handy for displaying version details, environment information, or any other metadata that might be relevant for your operations team.</li> </ul>"},{"location":"spring/spring-boot/#4-environment-properties","title":"4. Environment Properties","text":"<ul> <li>Environment Endpoint: Spring Boot Actuator includes an <code>/actuator/env</code> endpoint, which displays information about the application's configuration properties. It helps you inspect and validate the configuration settings at runtime.</li> </ul>"},{"location":"spring/spring-boot/#5-logging-configuration","title":"5. Logging Configuration","text":"<ul> <li>Loggers Endpoint: The <code>/actuator/loggers</code> endpoint allows you to dynamically configure the logging levels of your application's loggers. This is beneficial for debugging and troubleshooting issues in real-time without requiring a redeployment.</li> </ul>"},{"location":"spring/spring-boot/#6-thread-dump-and-heap-dump","title":"6. Thread Dump and Heap Dump","text":"<ul> <li>Thread Dump and Heap Dump Endpoints: Spring Boot Actuator provides <code>/actuator/threaddump</code> and <code>/actuator/heapdump</code> endpoints, which generate thread dumps and heap dumps respectively. These are invaluable for diagnosing and addressing performance bottlenecks and memory-related problems.</li> </ul>"},{"location":"spring/spring-boot/#7-security-and-custom-endpoints","title":"7. Security and Custom Endpoints","text":"<ul> <li> <p>Security: Spring Boot Actuator endpoints are secure by default, requiring proper authentication. You can customize the security settings to restrict access to specific endpoints.</p> </li> <li> <p>Custom Endpoints: Additionally, Spring Boot Actuator allows you to create your custom endpoints to expose application-specific information and management actions.</p> </li> </ul>"},{"location":"spring/spring-boot/#8-integration-with-monitoring-and-alerting-systems","title":"8. Integration with Monitoring and Alerting Systems","text":"<ul> <li>Spring Boot Actuator seamlessly integrates with popular monitoring and alerting tools like Prometheus, Grafana, and ELK Stack, enabling you to build comprehensive monitoring solutions for your applications.</li> </ul> <p>In summary, Spring Boot's Actuator module empowers developers and administrators with essential tools for monitoring, managing, and securing Spring Boot applications. It simplifies the process of gaining insights into application health, performance, and configuration, making it an invaluable addition to any Spring Boot project, especially in a production environment.</p>"},{"location":"spring/spring-boot/#exception-handling-in-a-spring-boot","title":"Exception handling in a Spring Boot","text":"<p>Exception handling in a Spring Boot application involves creating custom exception classes, defining a global exception handler, and providing clear error responses to improve the application's robustness and user experience.</p> <p>Exception handling is a critical aspect of developing Spring Boot applications. It ensures that your application can gracefully handle unexpected errors and provide meaningful responses to clients. Here's a step-by-step guide on implementing exception handling in a Spring Boot application:</p>"},{"location":"spring/spring-boot/#1-create-custom-exception-classes","title":"1. Create Custom Exception Classes","text":"<p>Define custom exception classes that extend <code>RuntimeException</code> or its subclasses. These custom exceptions should capture specific error scenarios within your application. For example:</p> <pre><code>public class ResourceNotFoundException extends RuntimeException {\n    public ResourceNotFoundException(String message) {\n        super(message);\n    }\n}\n</code></pre>"},{"location":"spring/spring-boot/#2-create-global-exception-handler","title":"2. Create Global Exception Handler","text":"<p>Create a global exception handler by creating a class annotated with <code>@ControllerAdvice</code> and <code>@RestControllerAdvice</code>. This class will handle exceptions thrown from various parts of your application.</p> <pre><code>@ControllerAdvice\n@RestControllerAdvice\npublic class GlobalExceptionHandler {\n\n    @ExceptionHandler(ResourceNotFoundException.class)\n    @ResponseStatus(HttpStatus.NOT_FOUND)\n    public ErrorResponse handleResourceNotFoundException(ResourceNotFoundException ex) {\n        return new ErrorResponse(HttpStatus.NOT_FOUND, ex.getMessage());\n    }\n\n    @ExceptionHandler(Exception.class)\n    @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR)\n    public ErrorResponse handleGenericException(Exception ex) {\n        return new ErrorResponse(HttpStatus.INTERNAL_SERVER_ERROR, \"An error occurred\");\n    }\n}\n</code></pre> <p>In this example, <code>@ExceptionHandler</code> methods handle specific exception types and return appropriate HTTP status codes and error responses.</p>"},{"location":"spring/spring-boot/#3-create-error-response-model","title":"3. Create Error Response Model","text":"<p>Define an error response model to structure the error information sent to clients. This can include details like the HTTP status code, a message, and additional information.</p> <pre><code>public class ErrorResponse {\n\n    private HttpStatus status;\n    private String message;\n\n    // getters and setters\n}\n</code></pre>"},{"location":"spring/spring-boot/#4-throw-custom-exceptions","title":"4. Throw Custom Exceptions","text":"<p>Within your application's code, throw the custom exceptions when specific error conditions occur. For example:</p> <pre><code>public class ProductService {\n\n    public Product getProductById(Long id) {\n        Product product = repository.findById(id)\n            .orElseThrow(() -&gt; new ResourceNotFoundException(\"Product not found with id: \" + id));\n        return product;\n    }\n}\n</code></pre>"},{"location":"spring/spring-boot/#5-handle-built-in-exceptions","title":"5. Handle Built-In Exceptions","text":"<p>Spring Boot provides built-in exceptions, such as <code>MethodArgumentNotValidException</code> for request validation errors or <code>ConstraintViolationException</code> for validation failures. Handle these exceptions in your global exception handler to provide consistent error responses.</p>"},{"location":"spring/spring-boot/#6-customize-error-messages","title":"6. Customize Error Messages","text":"<p>Customize error messages and responses according to your application's requirements. Ensure that error messages are clear and informative, helping users or clients understand the issue.</p>"},{"location":"spring/spring-boot/#7-logging","title":"7. Logging","text":"<p>Implement appropriate logging to capture error details, making it easier to diagnose and troubleshoot issues in a production environment.</p>"},{"location":"spring/spring-boot/#8-testing","title":"8. Testing","text":"<p>Write unit tests and integration tests to validate your exception handling logic. Ensure that exceptions are correctly thrown and that the error responses match your expectations.</p> <p>By following these steps, you can effectively implement exception handling in your Spring Boot application, ensuring that it responds gracefully to errors and provides a better user experience.</p>"},{"location":"spring/spring-boot/#using-exceptionhandler-annotation","title":"Using <code>@ExceptionHandler</code> Annotation","text":"<p>The <code>@ExceptionHandler</code> annotation is used to handle exceptions thrown by a specific controller or a specific method. You can use this annotation to define a method that will handle a specific exception. Here's an example:</p> <pre><code>@RestController\npublic class MyController {\n\n    @GetMapping(\"/hello\")\n    public String sayHello() {\n        throw new MyException(\"Something went wrong!\");\n    }\n\n    @ExceptionHandler(MyException.class)\n    public ResponseEntity&lt;String&gt; handleMyException(MyException ex) {\n        return new ResponseEntity&lt;&gt;(ex.getMessage(), HttpStatus.INTERNAL_SERVER_ERROR);\n    }\n}\n</code></pre> <p>In this example, we have defined a <code>MyException</code> class that extends the <code>RuntimeException</code> class. We have also defined a <code>handleMyException</code> method that will handle the <code>MyException</code> exception. When the <code>/hello</code> endpoint is accessed, the <code>sayHello</code> method will throw a <code>MyException</code> exception. The <code>handleMyException</code> method will catch this exception and return an HTTP 500 error with the exception message.</p>"},{"location":"spring/spring-boot/#using-controlleradvice-annotation","title":"Using <code>@ControllerAdvice</code> Annotation","text":"<p>The <code>@ControllerAdvice</code> annotation is used to define global exception handling for all controllers in your application. You can use this annotation to define a class that will handle all exceptions thrown by your application. Here's an example:</p> <pre><code>@ControllerAdvice\npublic class GlobalExceptionHandler {\n\n    @ExceptionHandler(Exception.class)\n    public ResponseEntity&lt;String&gt; handleException(Exception ex) {\n        return new ResponseEntity&lt;&gt;(ex.getMessage(), HttpStatus.INTERNAL_SERVER_ERROR);\n    }\n}\n</code></pre> <p>In this example, we have defined a <code>GlobalExceptionHandler</code> class that is annotated with <code>@ControllerAdvice</code>. We have also defined a <code>handleException</code> method that will handle all exceptions thrown by our application. When an exception is thrown, the <code>handleException</code> method will catch the exception and return an HTTP 500 error with the exception message.</p>"},{"location":"spring/spring-boot/#using-responseentityexceptionhandler-class","title":"Using <code>ResponseEntityExceptionHandler</code> Class","text":"<p>The <code>ResponseEntityExceptionHandler</code> class is a built-in class in Spring Boot that provides exception handling for common exceptions. You can extend this class to provide custom exception handling for your application. Here's an example:</p> <pre><code>@ControllerAdvice\npublic class CustomExceptionHandler extends ResponseEntityExceptionHandler {\n\n    @ExceptionHandler(MyException.class)\n    public ResponseEntity&lt;String&gt; handleMyException(MyException ex) {\n        return new ResponseEntity&lt;&gt;(ex.getMessage(), HttpStatus.INTERNAL_SERVER_ERROR);\n    }\n}\n</code></pre> <p>In this example, we have defined a <code>CustomExceptionHandler</code> class that extends the <code>ResponseEntityExceptionHandler</code> class. We have also defined a <code>handleMyException</code> method that will handle the <code>MyException</code> exception. When the <code>MyException</code> exception is thrown, the <code>handleMyException</code> method will catch the exception and return an HTTP 500 error with the exception message.</p>"},{"location":"spring/spring-boot/#externalized-configuration_1","title":"Externalized Configuration","text":"<p>Spring Boot's externalized configuration allows you to manage application properties and settings separately from your code. You can load configuration properties from various sources, including property files, YAML files, environment variables, and command-line arguments. This flexibility simplifies configuration management and supports different deployment scenarios.</p> <p>Spring Boot's externalized configuration is a powerful feature that separates application configuration from code, making it easier to manage properties and settings. It also provides the ability to load configuration properties from various sources, offering flexibility and adaptability to different deployment scenarios.</p>"},{"location":"spring/spring-boot/#1-property-files-applicationproperties-or-applicationyml","title":"1. Property Files (application.properties or application.yml)","text":"<p>Spring Boot allows you to store configuration properties in property files named <code>application.properties</code> or <code>application.yml</code>. These files can be placed in the application's classpath, resources directory, or external locations. Property files follow a key-value format.</p> <p>Example application.properties: <pre><code>server.port=8080\nspring.datasource.url=jdbc:mysql://localhost:3306/mydb\n</code></pre></p> <p>Example application.yml: <pre><code>server:\n  port: 8080\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/mydb\n</code></pre></p>"},{"location":"spring/spring-boot/#2-profile-specific-configuration","title":"2. Profile-specific Configuration","text":"<p>You can define profile-specific property files to customize configuration for different environments or profiles. For example, <code>application-dev.properties</code> or <code>application-prod.yml</code> can provide settings specific to development or production.</p> <p>To activate a specific profile, set the <code>spring.profiles.active</code> property in your <code>application.properties</code> or <code>application.yml</code> file.</p>"},{"location":"spring/spring-boot/#3-environment-variables","title":"3. Environment Variables","text":"<p>Spring Boot can read configuration properties from environment variables. You can set environment variables in your deployment environment, and Spring Boot will automatically map them to corresponding properties.</p> <p>Example Environment Variable: <pre><code>export DATABASE_URL=jdbc:mysql://localhost:3306/mydb\n</code></pre></p> <p>In Spring Boot, you can access it like this: <pre><code>@Value(\"${DATABASE_URL}\")\nprivate String databaseUrl;\n</code></pre></p>"},{"location":"spring/spring-boot/#4-command-line-arguments","title":"4. Command-Line Arguments","text":"<p>You can override properties using command-line arguments when running your Spring Boot application. For example, to change the server port:</p> <pre><code>java -jar myapp.jar --server.port=9090\n</code></pre>"},{"location":"spring/spring-boot/#5-custom-property-sources","title":"5. Custom Property Sources","text":"<p>Spring Boot allows you to create custom property sources. You can load properties from databases, remote configuration servers (e.g., Spring Cloud Config), or any other source by implementing the <code>PropertySource</code> interface and registering it with the <code>Environment</code>.</p>"},{"location":"spring/spring-boot/#6-property-hierarchy","title":"6. Property Hierarchy","text":"<p>Properties are resolved in a hierarchical manner, with later sources taking precedence over earlier ones. The order of precedence, from lowest to highest, is: default properties, profile-specific properties, <code>application.properties</code> or <code>application.yml</code>, environment variables, and command-line arguments.</p> <p>By understanding and utilizing Spring Boot's externalized configuration capabilities, you can tailor your application to different environments, securely manage sensitive data, and easily make runtime adjustments. This flexibility is essential for building robust and adaptable Spring Boot applications.</p>"},{"location":"spring/spring-boot/#security-in-a-spring-boot-application","title":"Security in a Spring Boot Application","text":"<p>Securing a Spring Boot application using Spring Security is essential for protecting your application from unauthorized access and ensuring data privacy. Spring Security provides comprehensive security features, including authentication, authorization, and various authentication providers. This guide outlines the steps to implement security in a Spring Boot application.</p>"},{"location":"spring/spring-boot/#1-add-spring-security-dependency","title":"1. Add Spring Security Dependency","text":"<p>In your Spring Boot project, add the Spring Security dependency to your <code>pom.xml</code> or <code>build.gradle</code> file:</p> <pre><code>&lt;!-- Maven --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"spring/spring-boot/#2-configure-security","title":"2. Configure Security","text":"<p>Create a security configuration class that extends <code>WebSecurityConfigurerAdapter</code> to customize security settings. You can define authentication and authorization rules in this class.</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests()\n                .antMatchers(\"/public/**\").permitAll()\n                .anyRequest().authenticated()\n                .and()\n            .formLogin()\n                .loginPage(\"/login\")\n                .permitAll()\n                .and()\n            .logout()\n                .permitAll();\n    }\n}\n</code></pre> <p>In this example, we allow public access to URLs under <code>/public</code>, require authentication for all other requests, and configure a custom login page.</p>"},{"location":"spring/spring-boot/#3-user-authentication","title":"3. User Authentication","text":"<p>Implement user authentication by providing user details and passwords. You can use in-memory authentication, database authentication, LDAP, or external identity providers like OAuth 2.0.</p> <p>For in-memory authentication, you can configure users in your <code>SecurityConfig</code>:</p> <pre><code>@Override\nprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\n    auth\n        .inMemoryAuthentication()\n            .withUser(\"user\").password(\"{noop}password\").roles(\"USER\")\n            .and()\n            .withUser(\"admin\").password(\"{noop}admin\").roles(\"USER\", \"ADMIN\");\n}\n</code></pre>"},{"location":"spring/spring-boot/#4-password-encoding","title":"4. Password Encoding","text":"<p>It's crucial to securely store user passwords. Use password encoding techniques, such as BCrypt, to hash and salt passwords. Spring Security provides built-in support for password encoding:</p> <pre><code>@Bean\npublic PasswordEncoder passwordEncoder() {\n    return new BCryptPasswordEncoder();\n}\n</code></pre>"},{"location":"spring/spring-boot/#5-authorization","title":"5. Authorization","text":"<p>Define authorization rules to control access to specific resources or actions based on user roles and permissions. You can use <code>@PreAuthorize</code> annotations, expression-based access control, or configure authorization rules in <code>SecurityConfig</code>.</p>"},{"location":"spring/spring-boot/#6-customize-login-and-logout-pages","title":"6. Customize Login and Logout Pages","text":"<p>You can customize login and logout pages by specifying their URLs in the <code>SecurityConfig</code>. Implement these pages with your preferred design and functionality.</p>"},{"location":"spring/spring-boot/#7-secure-api-endpoints","title":"7. Secure API Endpoints","text":"<p>For securing RESTful APIs, you can use token-based authentication (e.g., JWT or OAuth 2.0). Spring Security provides support for securing API endpoints, including method-level security with annotations like <code>@Secured</code> or <code>@PreAuthorize</code>.</p>"},{"location":"spring/spring-boot/#8-testing-security","title":"8. Testing Security","text":"<p>Write unit and integration tests to validate your security configuration. Spring Security provides testing utilities to simulate authentication and authorization scenarios.</p> <p>By following these steps, you can implement security in your Spring Boot application effectively. Spring Security offers robust features to protect your application from various threats and ensure that only authorized users can access sensitive resources.</p>"},{"location":"spring/spring-boot/#implementing-security-in-a-spring-boot-application","title":"Implementing Security in a Spring Boot Application","text":"<p>Securing a Spring Boot application using Spring Security is essential for protecting your application from unauthorized access and ensuring data privacy. Spring Security provides comprehensive security features, including authentication, authorization, and various authentication providers. This guide outlines the steps to implement security in a Spring Boot application.</p> <p>Securing a Spring Boot application using Spring Security is vital to safeguard your application from unauthorized access and protect sensitive data. Spring Security offers a comprehensive suite of security features, including authentication, authorization, and support for various authentication providers. Here, we'll walk through the steps to implement security in a Spring Boot application.</p>"},{"location":"spring/spring-boot/#1-add-spring-security-dependency_1","title":"1. Add Spring Security Dependency","text":"<p>In your Spring Boot project, add the Spring Security dependency to your <code>pom.xml</code> or <code>build.gradle</code> file:</p> <pre><code>&lt;!-- Maven --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"spring/spring-boot/#2-configure-security_1","title":"2. Configure Security","text":"<p>Create a security configuration class that extends <code>WebSecurityConfigurerAdapter</code> to customize security settings. You can define authentication and authorization rules in this class.</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests()\n                .antMatchers(\"/public/**\").permitAll()\n                .anyRequest().authenticated()\n                .and()\n            .formLogin()\n                .loginPage(\"/login\")\n                .permitAll()\n                .and()\n            .logout()\n                .permitAll();\n    }\n}\n</code></pre> <p>In this example, we allow public access to URLs under <code>/public</code>, require authentication for all other requests, and configure a custom login page.</p>"},{"location":"spring/spring-boot/#3-user-authentication_1","title":"3. User Authentication","text":"<p>Implement user authentication by providing user details and passwords. You can use in-memory authentication, database authentication, LDAP, or external identity providers like OAuth 2.0.</p> <p>For in-memory authentication, you can configure users in your <code>SecurityConfig</code>:</p> <pre><code>@Override\nprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\n    auth\n        .inMemoryAuthentication()\n            .withUser(\"user\").password(\"{noop}password\").roles(\"USER\")\n            .and()\n            .withUser(\"admin\").password(\"{noop}admin\").roles(\"USER\", \"ADMIN\");\n}\n</code></pre>"},{"location":"spring/spring-boot/#4-password-encoding_1","title":"4. Password Encoding","text":"<p>It's crucial to securely store user passwords. Use password encoding techniques, such as BCrypt, to hash and salt passwords. Spring Security provides built-in support for password encoding:</p> <pre><code>@Bean\npublic PasswordEncoder passwordEncoder() {\n    return new BCryptPasswordEncoder();\n}\n</code></pre>"},{"location":"spring/spring-boot/#5-authorization_1","title":"5. Authorization","text":"<p>Define authorization rules to control access to specific resources or actions based on user roles and permissions. You can use <code>@PreAuthorize</code> annotations, expression-based access control, or configure authorization rules in <code>SecurityConfig</code>.</p>"},{"location":"spring/spring-boot/#6-customize-login-and-logout-pages_1","title":"6. Customize Login and Logout Pages","text":"<p>You can customize login and logout pages by specifying their URLs in the <code>SecurityConfig</code>. Implement these pages with your preferred design and functionality.</p>"},{"location":"spring/spring-boot/#7-secure-api-endpoints_1","title":"7. Secure API Endpoints","text":"<p>For securing RESTful APIs, you can use token-based authentication (e.g., JWT or OAuth 2.0). Spring Security provides support for securing API endpoints, including method-level security with annotations like <code>@Secured</code> or <code>@PreAuthorize</code>.</p>"},{"location":"spring/spring-boot/#8-testing-security_1","title":"8. Testing Security","text":"<p>Write unit and integration tests to validate your security configuration. Spring Security provides testing utilities to simulate authentication and authorization scenarios.</p> <p>By following these steps, you can implement security in your Spring Boot application effectively. Spring Security offers robust features to protect your application from various threats and ensure that only authorized users can access sensitive resources.</p>"},{"location":"spring/spring-boot/#implementing-asynchronous-processing-in-a-spring-boot-application","title":"Implementing Asynchronous Processing in a Spring Boot Application","text":"<p>Implementing asynchronous processing in a Spring Boot application allows you to improve application performance and responsiveness. Spring Boot provides support for asynchronous programming through the use of the <code>@Async</code> annotation, <code>CompletableFuture</code>, and Spring's <code>TaskExecutor</code>. This guide outlines the steps to enable asynchronous processing and provides examples of how to use these features effectively.</p> <p>Enabling asynchronous processing in a Spring Boot application is crucial for improving performance and responsiveness. Spring Boot offers various tools and techniques for asynchronous programming, including the <code>@Async</code> annotation, <code>CompletableFuture</code>, and Spring's <code>TaskExecutor</code>. In this guide, we'll explore the steps to implement asynchronous processing and demonstrate how to use these features effectively.</p>"},{"location":"spring/spring-boot/#1-add-spring-boot-starter-dependency","title":"1. Add Spring Boot Starter Dependency","text":"<p>Ensure that your Spring Boot project includes the <code>spring-boot-starter-web</code> or <code>spring-boot-starter</code> dependency. These starters include the necessary libraries for asynchronous processing.</p> <pre><code>&lt;!-- Maven --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"spring/spring-boot/#2-enable-asynchronous-support","title":"2. Enable Asynchronous Support","text":"<p>In your Spring Boot application, enable asynchronous support by annotating your main application class with <code>@EnableAsync</code>. This annotation tells Spring to enable asynchronous processing.</p> <pre><code>@SpringBootApplication\n@EnableAsync\npublic class MyApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(MyApplication.class, args);\n    }\n}\n</code></pre>"},{"location":"spring/spring-boot/#3-create-asynchronous-methods","title":"3. Create Asynchronous Methods","text":"<p>To make a method asynchronous, annotate it with <code>@Async</code> and return a <code>Future</code> or <code>CompletableFuture</code>. Spring will execute this method in a separate thread pool, allowing other threads to continue processing.</p> <pre><code>@Service\npublic class MyService {\n\n    @Async\n    public CompletableFuture&lt;String&gt; doSomethingAsync() {\n        // Perform asynchronous task\n        return CompletableFuture.completedFuture(\"Task completed\");\n    }\n}\n</code></pre>"},{"location":"spring/spring-boot/#4-configure-thread-pool","title":"4. Configure Thread Pool","text":"<p>By default, Spring Boot uses a simple thread pool for asynchronous processing. You can customize the thread pool configuration in your <code>application.properties</code> or <code>application.yml</code> file:</p> <pre><code># Configure the thread pool\nspring:\n  task:\n    execution:\n      pool:\n        core-size: 10\n        max-size: 20\n</code></pre>"},{"location":"spring/spring-boot/#5-invoke-asynchronous-methods","title":"5. Invoke Asynchronous Methods","text":"<p>You can invoke asynchronous methods from your controllers or services as needed. When calling an asynchronous method, it returns immediately, and the result can be obtained later when the task completes.</p> <pre><code>@RestController\n@RequestMapping(\"/api\")\npublic class MyController {\n\n    @Autowired\n    private MyService myService;\n\n    @GetMapping(\"/async-task\")\n    public ResponseEntity&lt;String&gt; performAsyncTask() {\n        CompletableFuture&lt;String&gt; result = myService.doSomethingAsync();\n        // Continue processing or return a response\n        return ResponseEntity.accepted().body(\"Task started\");\n    }\n}\n</code></pre>"},{"location":"spring/spring-boot/#6-handle-asynchronous-results","title":"6. Handle Asynchronous Results","text":"<p>To obtain the result of an asynchronous task, you can use <code>CompletableFuture</code>'s <code>get()</code> method to block and retrieve the value when it's ready. Alternatively, you can use callback methods to handle the result when it's available.</p> <pre><code>result.thenAcceptAsync(response -&gt; {\n    // Handle the result asynchronously\n});\n</code></pre>"},{"location":"spring/spring-boot/#7-testing-asynchronous-code","title":"7. Testing Asynchronous Code","text":"<p>When writing tests for asynchronous code, use tools like JUnit and Spring's <code>@Async</code> support for testing. Ensure that your tests wait for asynchronous tasks to complete before making assertions.</p> <p>By following these steps, you can effectively implement asynchronous processing in your Spring Boot application, improving performance and responsiveness. This is especially valuable for tasks like handling concurrent requests, offloading time-consuming operations, and achieving better scalability.</p>"},{"location":"spring/spring-boot/#handling-transactions","title":"Handling Transactions","text":"<p>Handling transactions in a Spring Boot application is essential to ensure data integrity and consistency. Spring Boot simplifies transaction management through the use of annotations like <code>@Transactional</code>. This guide outlines the steps to enable and configure transactions in a Spring Boot application, covering both programmatic and declarative transaction management.</p> <p>Ensuring proper transaction management in a Spring Boot application is crucial for maintaining data integrity and consistency. Spring Boot simplifies this process through annotations like <code>@Transactional</code>. This guide provides a step-by-step approach to enable and configure transactions in a Spring Boot application, covering both programmatic and declarative transaction management.</p>"},{"location":"spring/spring-boot/#1-add-spring-boot-starter-dependency_1","title":"1. Add Spring Boot Starter Dependency","text":"<p>Ensure that your Spring Boot project includes a JDBC or JPA starter dependency. These starters include the necessary libraries and configurations for transaction management.</p> <pre><code>&lt;!-- Maven (for JDBC) --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n&lt;!-- Maven (for JPA) --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"spring/spring-boot/#2-annotate-service-methods","title":"2. Annotate Service Methods","text":"<p>In your service layer, annotate methods that require transactional behavior with <code>@Transactional</code>. Spring will automatically manage transactions for these methods.</p> <pre><code>@Service\npublic class MyService {\n\n    @Autowired\n    private MyRepository myRepository;\n\n    @Transactional\n    public void performTransaction() {\n        // Perform database operations\n        myRepository.save(entity1);\n        myRepository.save(entity2);\n    }\n}\n</code></pre>"},{"location":"spring/spring-boot/#3-transactional-attributes","title":"3. Transactional Attributes","text":"<p>You can configure transactional attributes using the <code>@Transactional</code> annotation. For example, setting <code>propagation</code>, <code>isolation</code>, <code>readOnly</code>, or <code>rollbackFor</code> to define transaction behavior.</p> <pre><code>@Transactional(propagation = Propagation.REQUIRED, isolation = Isolation.DEFAULT, readOnly = false, rollbackFor = Exception.class)\npublic void myTransactionalMethod() {\n    // Transactional code\n}\n</code></pre>"},{"location":"spring/spring-boot/#4-programmatic-transaction-management","title":"4. Programmatic Transaction Management","text":"<p>For programmatic transaction management, you can use Spring's <code>PlatformTransactionManager</code> interface along with the <code>TransactionTemplate</code> to manually control transactions.</p> <pre><code>@Autowired\nprivate PlatformTransactionManager transactionManager;\n\npublic void programmaticTransactionExample() {\n    TransactionTemplate transactionTemplate = new TransactionTemplate(transactionManager);\n    transactionTemplate.execute(status -&gt; {\n        // Perform transactional operations\n        return null;\n    });\n}\n</code></pre>"},{"location":"spring/spring-boot/#5-rollback-transactions","title":"5. Rollback Transactions","text":"<p>To force a transaction rollback, you can throw a runtime exception within a <code>@Transactional</code> method or explicitly call <code>setRollbackOnly()</code> on the <code>TransactionStatus</code> object.</p> <pre><code>@Transactional\npublic void performTransactionWithRollback() {\n    // Perform database operations\n    if (someCondition) {\n        throw new RuntimeException(\"Transaction should be rolled back\");\n    }\n}\n</code></pre>"},{"location":"spring/spring-boot/#6-nested-transactions","title":"6. Nested Transactions","text":"<p>Spring supports nested transactions, allowing methods within a transaction to have their own transaction boundaries. Use the <code>@Transactional</code> annotation with <code>propagation = Propagation.NESTED</code> to enable this behavior.</p>"},{"location":"spring/spring-boot/#7-testing-transactions","title":"7. Testing Transactions","text":"<p>When writing unit tests, you can use Spring's <code>@Transactional</code> support for testing to ensure that transactions are correctly managed. This allows you to roll back transactions after each test to keep the test database in a consistent state.</p> <pre><code>@SpringBootTest\n@Transactional\npublic class MyServiceTest {\n\n    @Autowired\n    private MyService myService;\n\n    @Test\n    public void testTransactionalMethod() {\n        // Test your transactional method\n    }\n}\n</code></pre> <p>By following these steps, you can effectively handle transactions in your Spring Boot application, ensuring data consistency and reliability. Spring Boot's built-in support for declarative and programmatic transaction management simplifies the process, allowing you to focus on your application's business logic while maintaining transactional integrity.</p>"},{"location":"spring/spring-cloud/","title":"Spring Cloud","text":"<p>{: .no_toc }</p>      Table of contents    <p>{: .text-delta } 1. TOC</p>"},{"location":"spring/spring-cloud/#introducing-spring-cloud","title":"Introducing Spring Cloud","text":""},{"location":"spring/spring-cloud/#spring-cloud_1","title":"Spring Cloud","text":"<p>Spring team has integrated number of battle-tested open source projects from companies like Pivotal, Netflix into a Spring project known as Spring Cloud. Spring Cloud provides libraries &amp; tools to quickly build some of the common design patterns of distributed system, including the following:</p> <p>Spring Cloud Patterns and Libraries</p> Category Pattern Name Spring Cloud Library Development Patterns Distributed/versioned configuration management Spring Cloud Config Server Core Microservices Patterns Spring Boot Asynchronous/Distributed Messaging Spring Cloud Stream (AMQP and Kafka) Inter-Service Communication RestTemplate and Spring Cloud Feign Routing Patterns Service Registration &amp; Discovery Spring Cloud Netflix Eureka &amp; Consul Service Routing/ API Gateway Pattern Spring Cloud Netflix Zuul Resiliency Patterns Client side load balancing Spring Cloud Netflix Ribbon Circuit Breaker &amp; Fallback Pattern Spring Cloud Netflix Hystrix Bulkhead pattern Spring Cloud / Spring Cloud Netflix Hystrix Logging Patterns Log Correlation Spring Cloud Sleuth Microservice Tracing Spring Cloud Sleuth/Zipkin Security Patterns Authorization and Authentication Spring Cloud Security OAuth2 Credentials Management Spring Cloud Security OAuth2/ JWT Distributed Sessions Spring Cloud OAuth2 and Redis <p>Spring Cloud makes it really easy to develop, deploy and operate JVM applications for the Cloud.</p> <p>Different release trains in Spring Cloud at the time of writing this handbook are (newest to oldest) - Finchley, Edgware, Dalston and Camden. Spring Cloud is always used in conjunction with Spring Boot.</p> <p>A bare minimum <code>build.gradle</code> for any Spring Cloud project will look like:</p> <p>build.gradle</p> <pre><code>buildscript {\n    ext {\n        springBootVersion = '1.5.12.RELEASE'\n    }\n    repositories {\n        mavenCentral()\n    }\n    dependencies {\n        classpath(\"org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}\")\n    }\n}\napply plugin: 'java'\napply plugin: 'spring-boot'\ndependencyManagement {\n    imports {\n        mavenBom ':spring-cloud-dependencies:Edgware.SR3'\n    }\n}\ndependencies {\n    compile ':spring-cloud-starter-config'\n    compile ':spring-cloud-starter-eureka'\n}\n</code></pre> <ul> <li>Edgware.SR3 is the spring-cloud train version.</li> <li>Spring cloud dependencies (eureka client and config client)</li> </ul> <p>And a minimal version of <code>spring-cloud</code> Application:</p> <pre><code>@SpringBootApplication\n@EnableDiscoveryClient\npublic class Application {\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class, args);\n    }\n}\n</code></pre> <ul> <li>Enables spring-boot in your application.</li> <li>Enables discovery-client: a spring-cloud feature in your microservice that helps you discover other services in a given environment.</li> </ul>"},{"location":"spring/spring-cloud/#reference-links","title":"Reference Links","text":"<ul> <li>Spring Cloud</li> </ul>"},{"location":"spring/spring-data-jpa/","title":"Spring Data JPA","text":"<p>{: .no_toc }</p>      Table of contents    <p>{: .text-delta } 1. TOC</p> <p>When you implement a new application, you should focus on the business logic instead of technical complexity and boilerplate code. That\u2019s why the Java Persistence API (JPA) specification and Spring Data JPA are extremely popular. JPA handles most of the complexity of JDBC-based database access and object-relational mappings. On top of that, Spring Data JPA reduces the amount of boilerplate code required by JPA. That makes the implementation of your persistence layer easier and faster.</p>"},{"location":"spring/spring-data-jpa/#what-is-jpa","title":"What is JPA?","text":"<p>JPA or Java Persistence API is the Java specification for accessing, managing and persisting data between Java classes or objects and relational database. The specification was introduced as part of EJB 3.0.</p> <p>JPA is not an implementation or product, it is just a specification. It contains set of interfaces which need to be implemented. It is a framework that provides an extra layer of abstraction on the JPA implementation. The repository layer will contain three layers as mentioned below.</p> <p>Spring Data JPA: \u2013 This provides spring data repository interfaces which are implemented to create JPA repositories.</p> <p>Spring Data Commons: \u2013 It provides the infrastructure that is shared between data store specific spring data projects.</p> <p>The JPA provider which implements the JPA persistence API. Hibernate, Eclipselink, Toplink, Spring Data JPA, etc.</p> <p>Spring data JPA allows us not to write any boilerplate code by adding an additional repository layer.</p>"},{"location":"spring/spring-data-jpa/#jpa-vs-hibernate","title":"JPA Vs Hibernate","text":"Category JPA Hibernate Type JPA is a specification and defines the way to manage relational database data using java objects. Hibernate is an implementation of JPA. It is an ORM tool to persist java objects into the relational databases. Package JPA uses javax.persistence package. Hibernate uses org.hibernate package. Factory JPA uses EntityManagerFactory interface to get the entity manager to persist objects. Hibernate uses SessionFactory interface to create session object which is then used to persist objects. CRUD Operations JPA uses EntityManager interface to create/read/delete operation and maintains the persistence context. Hibernate uses Session interface to create/read/delete operation and maintains the persistence context. Language JPA uses JPQL (Java Persistence Query Language) as Object Oriented Query language for database operations. Hibernate uses HQL (Hibernate Query Language) as Object Oriented Query language for database operations."},{"location":"spring/spring-data-jpa/#features","title":"Features","text":""},{"location":"spring/spring-data-jpa/#no-code-repositories","title":"No-code Repositories","text":"<p>The repository pattern is one of the most popular persistence-related patterns. It hides the data store specific implementation details and enables you to implement your business code on a higher abstraction level.</p> <p>Implementing that pattern isn\u2019t too complicated but writing the standard CRUD operations for each entity creates a lot of repetitive code. Spring Data JPA provides you a set of repository interfaces which you only need to extend to define a specific repository for one of your entities.</p>"},{"location":"spring/spring-data-jpa/#reduced-boilerplate-code","title":"Reduced boilerplate code","text":"<p>To make it even easier, Spring Data JPA provides a default implementation for each method defined by one of its repository interfaces. That means that you no longer need to implement basic read or write operations. And even so all of these operations don\u2019t require a lot of code, not having to implement them makes life a little bit easier and it reduces the risk of stupid bugs.</p>"},{"location":"spring/spring-data-jpa/#generated-queries","title":"Generated queries","text":"<p>Another comfortable feature of Spring Data JPA is the generation of database queries based on method names. As long as your query isn\u2019t too complex, you just need to define a method on your repository interface with a name that starts with find\u2026By. Spring then parses the method name and creates a query for it.</p> <p>Here is a simple example of a query that loads a Book entity with a given title. Internally, Spring generates a JPQL query based on the method name, sets the provided method parameters as bind parameter values, executes the query and returns the result.</p> <pre><code>public interface BookRepository extends CrudRepository&lt;Book, Long&gt; {\n    Book findByTitle(String title);\n}\n</code></pre>"},{"location":"spring/spring-data-jpa/#repositories-in-spring-data-jpa","title":"Repositories in Spring Data JPA","text":"<p>Spring Data Commons project provides repository abstraction which is extended by the datastore-specific subprojects.</p> <p>We have to be familiar with the Spring Data repository interfaces as it will help us with the implementation of the interfaces. Let\u2019s have a look at the interfaces.</p>"},{"location":"spring/spring-data-jpa/#spring-data-commons","title":"Spring Data Commons","text":"<p>Following interfaces are provided as part of this project:</p> <p>Repository  :  This interface is a marker interface. - It captures the type of the managed entity and the type of the entity\u2019s id. - It helps the Spring container to discover the \u201cconcrete\u201d repository interfaces when classpath is scanned. <p>CrudRepository :  - It provides CRUD operations for the managed entity. - CrudRepository interface defines a repository that offers standard create, read, update and delete operations. <p>PagingAndSortingRepository :  - This interface declares the methods that are used to sort and paginate entities that are retrieved from the database. - The PagingAndSortingRepository extends the CrudRepository and adds findAll methods that enable you to sort the result and to retrieve it in a paginated way. Both interface are also supported by other Spring Data projects, so that you can apply the same concepts to different datastores. <p>QueryDslPredicateExecutor:  - It is not a <code>repository interface</code>.  - It declares the methods that are used to retrieve entities from the database by using QueryDsl Predicate objects."},{"location":"spring/spring-data-jpa/#spring-data-jpa_1","title":"Spring Data JPA","text":"<p>This project provides the following interfaces:</p> <p>JpaRepository  :  - This interface is a JPA specific repository interface that combines the methods declared by the common repository interfaces behind a single interface. - The JpaRepository adds JPA-specific methods, like flush() to trigger a flush on the persistence context or <code>findAll(Example&lt;S&gt; example)</code> to find entities by example, to the PagingAndSortingRepository. <p>JpaSpecificationExecutor :  - This is again not a repository interface.  - It declares the methods that are used to retrieve entities from the database by using <code>Specification&lt;T&gt;</code> objects that use the JPA criteria API. <p>The repository hierarchy looks as follows:</p> <p></p>"},{"location":"spring/spring-data-jpa/#example-using-spring-boot","title":"Example Using Spring Boot","text":""},{"location":"spring/spring-data-jpa/#maven-dependency","title":"Maven Dependency","text":"<p>We can also use the Spring Boot Starter Data JPA dependency that will automatically configure the DataSource for us.</p> <p>We need to make sure that the database we want to use is present in the classpath. In our example, we've added the H2 in-memory database:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;\n    &lt;version&gt;2.6.1&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.h2database&lt;/groupId&gt;\n&lt;artifactId&gt;h2&lt;/artifactId&gt;\n&lt;version&gt;1.4.200&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>As a result, just by doing these dependencies, our application is up and running and we can use it for other database operations.</p> <p>The explicit configuration for a standard Spring application is now included as part of Spring Boot auto-configuration.</p> <p>We can, of course, modify the auto-configuration by adding our customized explicit configuration.</p>"},{"location":"spring/spring-data-jpa/#properties-file","title":"Properties file","text":"<p>Spring Boot provides an easy way to do this using properties in the application.properties file:</p> <pre><code>spring.datasource.url=jdbc:h2:mem:db;DB_CLOSE_DELAY=-1\nspring.datasource.username=sa\nspring.datasource.password=sa\n</code></pre> <p>or for postgres</p> <pre><code>spring.datasource.url=jdbc:postgresql://localhost:5432/postgres\nspring.datasource.username=postgres\nspring.datasource.password=password\nspring.jpa.generate-ddl=true\nspring.jpa.show-sql=true\nspring.jpa.properties.hibernate.format_sql=true\n</code></pre> <p>In this example, we've changed the connection URL and credentials.</p>"},{"location":"spring/spring-data-jpa/#spring-data-jpa-repository-configuration","title":"Spring Data JPA Repository Configuration","text":"<p>To activate the Spring JPA repository support, we can use the @EnableJpaRepositories annotation and specify the package that contains the DAO interfaces:</p> <pre><code>@Configuration\n@EnableJpaRepositories\n@EnableTransactionManagement\nclass ApplicationConfig {\n\n    @Bean\n    public DataSource dataSource() {\n\n        EmbeddedDatabaseBuilder builder = new EmbeddedDatabaseBuilder();\n        return builder.setType(EmbeddedDatabaseType.HSQL).build();\n    }\n\n    @Bean\n    public LocalContainerEntityManagerFactoryBean entityManagerFactory() {\n\n        HibernateJpaVendorAdapter vendorAdapter = new HibernateJpaVendorAdapter();\n        vendorAdapter.setGenerateDdl(true);\n\n        LocalContainerEntityManagerFactoryBean factory = new LocalContainerEntityManagerFactoryBean();\n        factory.setJpaVendorAdapter(vendorAdapter);\n        factory.setPackagesToScan(\"com.acme.domain\");\n        factory.setDataSource(dataSource());\n        return factory;\n    }\n\n    @Bean\n    public PlatformTransactionManager transactionManager(EntityManagerFactory entityManagerFactory) {\n\n        JpaTransactionManager txManager = new JpaTransactionManager();\n        txManager.setEntityManagerFactory(entityManagerFactory);\n        return txManager;\n    }\n}\n</code></pre> <p>The preceding configuration class sets up an embedded HSQL database by using the EmbeddedDatabaseBuilder API of spring-jdbc. Spring Data then sets up an EntityManagerFactory and uses Hibernate as the sample persistence provider. The last infrastructure component declared here is the JpaTransactionManager. Finally, the example activates Spring Data JPA repositories by using the @EnableJpaRepositories annotation, which essentially carries the same attributes as the XML namespace. If no base package is configured, it uses the one in which the configuration class resides.</p>"},{"location":"spring/spring-data-jpa/#repository-interface","title":"Repository Interface","text":"<p>The repository interface is used for extending the CRUD interface. This interface adds the layer of a repository in the program. Spring Data JPA provides two major ways of creating queries. These queries are then used in the repository interface to fetch the data from the database.</p> <pre><code>import java.util.List;\n\nimport org.springframework.data.jpa.repository.Query;\nimport org.springframework.data.repository.CrudRepository;\nimport org.springframework.data.repository.query.Param;\nimport org.springframework.stereotype.Repository;\n\nimport com.tutorial.model.Employee;\n\n@Repository\npublic interface EmployeeRepository extends CrudRepository&lt;Employee, Long&gt;{\n    List findByLastName(String lastName);\n\n@Query(\"SELECT e FROM Employee e WHERE e.age = :age\")\n    public List findByAge(@Param(\"age\") int age);\n}\n</code></pre> <p>The <code>CrudRepository</code> is the interface from SpringData Common project. The two methods mentioned above for query creation is used at the below-mentioned places in the code.</p>"},{"location":"spring/spring-data-jpa/#controller-class","title":"Controller class","text":"<p>The controller is the most important class of the complete program. This is the class responsible for all the url mapping. We have added the repository methods for data manipulation in this class itself.</p> <pre><code>import java.util.List;\nimport java.util.Optional;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.web.bind.annotation.RequestBody;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestMethod;\nimport org.springframework.web.bind.annotation.RequestParam;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport com.tutorial.model.Employee;\nimport com.tutorial.repo.EmployeeRepository;\n\n@RestController\n@RequestMapping(\"/employee\")\npublic class WebController {\n    @Autowired\n    EmployeeRepository repository;\n\n    @RequestMapping(value=\"/save\",method = RequestMethod.POST)\n    public HttpStatus insertEmployee(@RequestBody Employee employee){\n        boolean status = repository.save(employee) != null;     \n        return status? HttpStatus.CREATED : HttpStatus.BAD_REQUEST;\n    }\n\n\n    @RequestMapping(\"/findall\")\n    public List findAll(){\n\n\n        return (List) repository.findAll();\n    }\n\n    @RequestMapping(\"/findbyid\")\n    public Optional findById(@RequestParam(\"id\") long id){\n        Optional result = repository.findById(id);\n        return result;\n    }\n\n    @RequestMapping(\"/findbylastname\")\n    public List fetchDataByLastName(@RequestParam(\"lastname\") String lastName){\n\n        return repository.findByLastName(lastName);\n    }\n    @RequestMapping(\"/findbyage\")\n    public List fetchDataByAge(@RequestParam(\"age\") int age){\n\n        return repository.findByAge(age);\n    }\n}\n</code></pre>"},{"location":"spring/spring-data-jpa/#more-details","title":"More Details:","text":"<ol> <li>What is Spring Data JPA? And why should you use it?</li> <li>5. Reference Documentation</li> </ol>"},{"location":"spring/spring-mvc/","title":"Spring MVC","text":"<p>{: .no_toc }</p>      Table of contents    <p>{: .text-delta } 1. TOC</p>"},{"location":"spring/spring-mvc/#introduction-to-spring-mvc","title":"Introduction to Spring MVC","text":"<p>Spring MVC framework is a robust Model view controller framework which helps us to develop a loosely coupled web application. It separates different aspects of web applications with the help of MVC architecture.</p> <p>Model: Model carries application data. It generally includes POJO in the form of business objects</p> <p>View: View is used to render User interface (UI). It will render application data on UI. For example JSP</p> <p>Controller: Controller takes care of processing user request and calling back end services.</p> <p>It has a central servlet called as DispatcherServlet which is well known as front controller that intercepts all the requests, identify the appropriate handler i.e. controllers and render views to the client.</p> <p>It is defined at <code>org.springframework.web.servlet.DispatcherServlet</code> in <code>org.springframework.web</code> package.</p>"},{"location":"spring/spring-mvc/#spring-mvc-flow","title":"Spring MVC flow","text":"<p>In Spring Web MVC, <code>DispatcherServlet</code> class works as the front controller. It is responsible to manage the flow of the spring mvc application.</p> <p>The <code>@Controller</code> annotation is used to mark the class as the controller in Spring 3.</p> <p>The <code>@RequestMapping</code> annotation is used to map the request url. It is applied on the method.</p>"},{"location":"spring/spring-mvc/#spring-mvc-execution-flow","title":"Spring MVC Execution Flow","text":"<ul> <li>Step 1: First request will be received by DispatcherServlet.</li> <li>Step 2: DispatcherServlet will take the help of HandlerMapping and get to know the Controller class name associated with the given request.</li> <li>Step 3: So request transfer to the Controller, and then controller will process the request by executing appropriate methods and returns ModelAndView object (contains Model data and View name) back to the DispatcherServlet.</li> <li>Step 4: Now DispatcherServlet send the model object to the ViewResolver to get the actual view page.</li> <li>Step 5: Finally DispatcherServlet will pass the Model object to the View page to display the result.</li> </ul>"},{"location":"spring/spring-mvc/#spring-web-annotations","title":"Spring Web Annotations","text":""},{"location":"spring/spring-mvc/#requestmapping","title":"@RequestMapping","text":"<p>it can be configured using:</p> <ul> <li>path, or its aliases, name, and value: which URL the method is mapped to</li> <li>method: compatible HTTP methods</li> <li>params: filters requests based on presence, absence, or value of HTTP parameters</li> <li>headers: filters requests based on presence, absence, or value of HTTP headers</li> <li>consumes: which media types the method can consume in the HTTP request body</li> <li>produces: which media types the method can produce in the HTTP response body</li> </ul> <p>Example: <pre><code>@Controller\nclass VehicleController {\n\n    @RequestMapping(value = \"/vehicles/home\", method = RequestMethod.GET)\n    String home() {\n        return \"home\";\n    }\n}\n</code></pre></p> <p>this configuration has the same effect :</p> <pre><code>@Controller\n@RequestMapping(value = \"/vehicles\", method = RequestMethod.GET)\nclass VehicleController {\n\n    @RequestMapping(\"/home\")\n    String home() {\n        return \"home\";\n    }\n}\n</code></pre> <p>Moreover, @GetMapping, @PostMapping, @PutMapping, @DeleteMapping, and @PatchMapping are different variants of @RequestMapping with the HTTP method already set to GET, POST, PUT, DELETE, and PATCH respectively.</p> <p>These are available since Spring 4.3 release.</p>"},{"location":"spring/spring-mvc/#requestbody","title":"@RequestBody","text":"<p>maps the body of the HTTP request to an object.The deserialization is automatic and depends on the content type of the request. <pre><code>@PostMapping(\"/save\")\nvoid saveVehicle(@RequestBody Vehicle vehicle) {\n    // ...\n}\n</code></pre></p>"},{"location":"spring/spring-mvc/#pathvariable","title":"@PathVariable","text":"<p>This annotation indicates that a method argument is bound to a URI template variable. We can specify the URI template with the @RequestMapping annotation and bind a method argument to one of the template parts with @PathVariable.</p> <p>We can achieve this with the name or its alias, the value argument: <pre><code>@RequestMapping(\"/{id}\")\nVehicle getVehicle(@PathVariable(\"id\") long id) {\n    // ...\n}\n</code></pre> If the name of the part in the template matches the name of the method argument, we don't have to specify it in the annotation: <pre><code>@RequestMapping(\"/{id}\")\nVehicle getVehicle(@PathVariable long id) {\n    // ...\n}\n</code></pre> Moreover, we can mark a path variable optional by setting the argument required to false:</p> <pre><code>@RequestMapping(\"/{id}\")\nVehicle getVehicle(@PathVariable(required = false) long id) {\n    // ...\n}\n</code></pre>"},{"location":"spring/spring-mvc/#requestparam","title":"@RequestParam","text":"<p>We use @RequestParam for accessing HTTP request parameters:</p> <p><pre><code>@RequestMapping\nVehicle getVehicleByParam(@RequestParam(\"id\") long id) {\n    // ...\n}\n</code></pre> It has the same configuration options as the @PathVariable annotation.</p> <p>In addition to those settings, with @RequestParam we can specify an injected value when Spring finds no or empty value in the request. To achieve this, we have to set the defaultValue argument.</p> <p>Providing a default value implicitly sets required to false: <pre><code>@RequestMapping(\"/buy\")\nCar buyCar(@RequestParam(defaultValue = \"5\") int seatCount) {\n    // ...\n}\n</code></pre></p> <p>Response Handling Annotations</p>"},{"location":"spring/spring-mvc/#responsebody","title":"@ResponseBody","text":"<p>If we mark a request handler method with @ResponseBody, Spring treats the result of the method as the response itself: <pre><code>@ResponseBody\n@RequestMapping(\"/hello\")\nString hello() {\n    return \"Hello World!\";\n}\n</code></pre></p>"},{"location":"spring/spring-mvc/#exceptionhandler","title":"@ExceptionHandler","text":"<p>With this annotation, we can declare a custom error handler method. Spring calls this method when a request handler method throws any of the specified exceptions.</p> <p>The caught exception can be passed to the method as an argument: <pre><code>@ExceptionHandler(IllegalArgumentException.class)\nvoid onIllegalArgumentException(IllegalArgumentException exception) {\n    // ...\n}\n</code></pre></p>"},{"location":"spring/spring-mvc/#responsestatus","title":"@ResponseStatus","text":"<p>We can specify the desired HTTP status of the response if we annotate a request handler method with this annotation. We can declare the status code with the code argument, or its alias, the value argument.</p> <p>Also, we can provide a reason using the reason argument.</p> <p>We also can use it along with @ExceptionHandler:</p> <pre><code>@ExceptionHandler(IllegalArgumentException.class)\n@ResponseStatus(HttpStatus.BAD_REQUEST)\nvoid onIllegalArgumentException(IllegalArgumentException exception) {\n    // ...\n}\n</code></pre> <p>Other Web Annotations</p>"},{"location":"spring/spring-mvc/#controller","title":"@Controller","text":"<p>We can define a Spring MVC controller with @Controller.@Controller is a class level annotation which tells the Spring Framework that this class serves as a controller in Spring MVC: <pre><code>@Controller\npublic class VehicleController {\n    // ...\n}\n</code></pre></p>"},{"location":"spring/spring-mvc/#restcontroller","title":"@RestController","text":"<p>The @RestController combines @Controller and @ResponseBody.</p> <pre><code>@Controller\n@ResponseBody\nclass VehicleRestController {\n    // ...\n}\n</code></pre> <p>is same as : <pre><code>@RestController\nclass VehicleRestController {\n    // ...\n}\n</code></pre></p>"},{"location":"spring/spring-mvc/#modelattribute","title":"@ModelAttribute","text":"<p>With this annotation we can access elements that are already in the model of an MVC @Controller, by providing the model key: <pre><code>@PostMapping(\"/assemble\")\nvoid assembleVehicle(@ModelAttribute(\"vehicle\") Vehicle vehicleInModel) {\n    // ...\n}\n</code></pre></p> <p>Like with @PathVariable and @RequestParam, we don't have to specify the model key if the argument has the same name: <pre><code>@PostMapping(\"/assemble\")\nvoid assembleVehicle(@ModelAttribute Vehicle vehicle) {\n    // ...\n}\n</code></pre> Besides, @ModelAttribute has another use: if we annotate a method with it, Spring will automatically add the method's return value to the model: <pre><code>@ModelAttribute(\"vehicle\")\nVehicle getVehicle() {\n    // ...\n}\n</code></pre> Like before, we don't have to specify the model key, Spring uses the method's name by default: <pre><code>@ModelAttribute\nVehicle vehicle() {\n    // ...\n}\n</code></pre> Before Spring calls a request handler method, it invokes all @ModelAttribute annotated methods in the class.</p>"},{"location":"spring/spring-mvc/#crossorigin","title":"@CrossOrigin","text":"<p>@CrossOrigin enables cross-domain communication for the annotated request handler methods: If we mark a class with it, it applies to all request handler methods in it.</p> <pre><code>@CrossOrigin\n@RequestMapping(\"/hello\")\nString hello() {\n    return \"Hello World!\";\n}\n</code></pre>"},{"location":"spring/spring-mvc/#autowired","title":"@Autowired","text":"<p>Since version 2.5, Spring provides the @Autowired annotation to discover the beans automatically and inject collaborating beans (other associated dependent beans) into our bean.</p> <p>By declaring all the beans in Spring Configuration file, Spring container can autowire relationships between collaborating beans.</p> <p>After enabling annotation based injection, now we can use @Autowired annotation. @Autowired can be used on following injection points.</p> <ol> <li>Constructors</li> <li>Methods</li> <li>Fields and</li> <li>Parameters</li> </ol> <p>and dependencies can be injected using by type OR by name OR by @Qualifier.</p> <p>In spring there are two types of autowiring. Those are - Autowiring by type : @Autowired by type uses the class type to autowire the spring boot bean class. The bean is autowired based on the type of the variable. - Autowiring by name : For Autowiring by name, the name of the variable is used for the dependency injection. The name of the authoring variable should be the same as the name of the class or the bean name configured in the @Component annotation.</p> <p>For example,</p> <p><pre><code>public interface Shape {\n    public void draw();\n}\n\n@Component\npublic class Rectangle implements Shape {\n    @Override\n    public void draw() {\n        System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;INVOKING THE RECTANGLE INSTANCE&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\");\n    }\n}\n\n@Component\npublic class Circle implements Shape{\n    @Override\n    public void draw() {\n        System.out.println(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;INVOKING THE CIRCLE INSTANCE&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\");\n    }\n}\n</code></pre> the shape interface is implemented by two classes Circle and Rectangle. So we can say both are instances of Shape or both shape. It made Rectangle and Circle as spring beans using the annotation @Component. Now let's see how to autowire these beans in another class.</p> <pre><code>@Component\npublic class ShapeService {\n    @Autowired\n    private Shape rectangle;//by name\n\n    @Autowired\n    private Rectangle myRectangle;//by type\n\n}\n</code></pre> <p>Here in ShapeService class, it is autowring the shape Rectangle in two ways. 1. Here in the first @Autowiring, the variable rectangle is autowired based on the name of the variable. Here when the spring checks the type of the variable, he can see it is Shape. But there are two shape implementations are there Rectangle and Circle. So spring doesn't get a proper solution for what component need to autowire. Then the spring check the name of the variable(rectangle) and find out any Shape component with the same name is available. Yes\u2026The Rectangle component is available. So the spring will inject the property with rectangle component. 2. In the second @Autowiring, the type of property is Rectangle. So the spring directly injects the Rectangle component to the property myRectangle.</p>"},{"location":"spring/spring-mvc/#inject-vs-autowired","title":"@Inject vs @Autowired","text":"Key @Inject @Autowired Basic It is part of Java CDI(Contexts and Dependency Injection) It is part of Spring framework Required It has no required attribute It has required attribute Default Scope Default scope of the autowired beans is Singleton Default scope of the inject beans is prototype Ambiguity In case of ambiguity in beans for injection then @Named qualifier should be added in your code. In case of ambiguity in beans for injection then @Qualifer  qualifier should be added in your code. Advantage It is a part of Java CDI so it is not dependent on any DI framework. It makes your system loosely coupled. It makes your application tightly coupled with Spring framework. In the future , if you want to move to another DI framework then you need reconfigure your application."},{"location":"spring/spring-mvc/#validated","title":"@Validated","text":"<p>@Validated annotation activates the Spring Validation AOP interceptor and it will examine method parameters to see if they have any validation annotations on them, if they do then Spring will call hibernate validator with each specific annotation for example @Size(min = 8) String password means call hibernate size validator and pass the value of the parameter password in this case hibernate validator does not need to scan java.lang.String to see if it has validation annotations on it. @Validated works on any spring @Component you can use it on @Service classes for example.</p>"},{"location":"spring/spring-mvc/#valid-vs-validated","title":"@Valid vs @Validated","text":"<p>In Spring, we use JSR-303's @Valid annotation for method level validation. We also use it to mark a member attribute for validation. However, this annotation doesn't support group validation.</p> <p>Groups help to limit the constraints applied during validation. One particular use case is UI wizards. In the first step, we may have a certain sub-group of fields. In the subsequent step, there may be another group belonging to the same bean. So we need to apply constraints on these limited fields in each step, but @Valid doesn't support this.</p> <p>In this case, for group-level, we have to use Spring's @Validated, which is a variant of JSR-303's @Valid.  This is used at the method-level. For marking member attributes, we continue to use the @Valid annotation.</p>"},{"location":"spring/spring-mvc/#component-scanning","title":"Component Scanning","text":"<p>To do dependency injection, Spring creates a so-called application context.</p> <p>During startup, Spring instantiates objects and adds them to the application context. Objects in the application context are called \u201cSpring beans\u201d or \u201ccomponents\u201d.</p> <p>Spring resolves dependencies between Spring beans and injects Spring beans into other Spring beans\u2019 fields or constructors.</p> <p>The process of searching the classpath for classes that should contribute to the application context is called component scanning.</p> <p>When developing Spring Boot applications, you need to tell the Spring Framework where to look for Spring components. Using component scan is one method of asking Spring to detect Spring managed components. Spring needs the information to locate and register all the Spring components with the application context when the application starts.</p> <p>Spring can auto scan, detect, and instantiate components from pre-defined project packages. It can auto scan all classes annotated with the stereotype annotations @Component @Controller, @Service and @Repository</p>"},{"location":"spring/spring-mvc/#componentscan","title":"@ComponentScan","text":"<p>@ComponentScan tells Spring in which packages you have annotated classes which should be managed by Spring. So, for example, if you have a class annotated with @Controller which is in a package which is not scanned by Spring, you will not be able to use it as Spring controller.</p> <p>Classes annotated with @Configuration is a new way of configuring Spring using annotations instead of XML files (it's called Java configuration). Spring needs to know which packages contain spring beans, otherwise you would have to register each bean individually. That's what @ComponentScan is used for.</p>"},{"location":"spring/spring-mvc/#componentscan-without-arguments","title":"@ComponentScan Without Arguments","text":"<p>we use the @ComponentScan annotation along with the @Configuration annotation to specify the packages that we want to be scanned. @ComponentScan without arguments tells Spring to scan the current package and all of its sub-packages. <pre><code>@Configuration\n@ComponentScan\npublic class DemoAppConfig {\n    //...\n}\n</code></pre></p>"},{"location":"spring/spring-mvc/#componentscan-with-arguments","title":"@ComponentScan With Arguments","text":"<pre><code>@Configuration\n@ComponentScan(basePackages = {\"basic.ioc.autowire\", \"basic.ioc.setter\"})\npublic class AutowireBeanConfig {\n    //other configs\n}\n</code></pre>"},{"location":"spring/spring-mvc/#componentscan-with-exclusions","title":"@ComponentScan with Exclusions","text":"<p>Use a filter,with the pattern for the classes to exclude:</p> <pre><code>    @Configuration\n@ComponentScan(basePackages = \"com.demo\",\n        includeFilters = @Filter(type = FilterType.REGEX, pattern = \".*Dao\"),\n        excludeFilters = @Filter(Repository.class))\npublic class AppConfig {\n        ...\n}\n</code></pre>"},{"location":"spring/spring-mvc/#componentscan-in-a-spring-boot-application","title":"@ComponentScan in a Spring-Boot application","text":"<p>Spring-Boot application, we don\u2019t need to specify the @Configuration annotation unless we want more control over the classpath scanning. This is because of the @SpringBootApplication , which is already a combination of below listed three annotations.</p> <ul> <li>@Configuration</li> <li>@EnableAutoConfiguration</li> <li>@ComponentScan</li> </ul>"},{"location":"spring/spring-mvc/#difference-between-component-repository-service-annotations","title":"Difference between @Component, @Repository &amp; @Service annotations?","text":"<p>From Spring Documentation:</p> <p>Spring provides  stereotype annotations: @Component, @Service, and @Controller. @Component is a generic stereotype for any Spring-managed component. @Repository, @Service, and @Controller are specializations of @Component for more specific use cases (in the persistence, service, and presentation layers, respectively). Therefore, you can annotate your component classes with @Component, but, by annotating them with @Repository, @Service, or @Controller instead, your classes are more properly suited for processing by tools or associating with aspects.</p>"},{"location":"spring/spring-mvc/#repository","title":"@Repository","text":"<p>stereotype for persistence layer</p> <p>@Repository\u2019s job is to catch persistence-specific exceptions and re-throw them as one of Spring\u2019s unified unchecked exceptions.</p> <p>For this, Spring provides <code>PersistenceExceptionTranslationPostProcessor</code>, which we are required to add in our application context (already included if we're using Spring Boot): <pre><code>&lt;bean class=\"org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor\"/&gt;\n</code></pre> This bean post processor adds an advisor to any bean that\u2019s annotated with @Repository.</p>"},{"location":"spring/spring-mvc/#service","title":"@Service","text":"<p>stereotype for service layer</p> <p>We mark beans with @Service to indicate that they're holding the business logic. Besides being used in the service layer, there isn't any other special use for this annotation.</p>"},{"location":"spring/spring-mvc/#controller_1","title":"@Controller","text":"<p>stereotype for presentation layer (spring-mvc)</p> <p>Instead of using @Component on a controller class in Spring MVC, we use @Controller, which is more readable and appropriate.</p> <p>By using that annotation we do two things, first, we declare that this class is a Spring bean and should be created and maintained by Spring ApplicationContext, but also we indicate that its a controller in MVC setup. This latter property is used by web-specific tools and functionalities.</p> <p>For example, DispatcherServlet will look for @RequestMapping on classes that are annotated using @Controller but not with @Component.</p> <p>This means @Component and @Controller are the same with respect to bean creation and dependency injection but later is a specialized form of former. Even if you replace @Controller annotation with @Compoenent, Spring can automatically detect and register the controller class but it may not work as you expect with respect to request mapping.</p>"},{"location":"spring/spring-mvc/#scheduler-in-cluster-environment-or-run-on-multiple-instances","title":"Scheduler in cluster environment or run on multiple instances","text":"<p>Spring provides an easy to implement API for scheduling jobs. It works great until we deploy multiple instances of our application. Spring, by default, cannot handle scheduler synchronization over multiple instances \u2013 it executes the jobs simultaneously on every node instead.</p> <p>In this short tutorial, we'll look at ShedLock \u2013 a Java library that makes sure our scheduled tasks run only once at the same time and is an alternative to Quartz.</p>"},{"location":"spring/spring-mvc/#spring-scheduled-task-running-in-clustered-environment-with-shedlock","title":"Spring Scheduled Task running in clustered environment with ShedLock","text":"<p>To use ShedLock with Spring, we need to add the shedlock-spring dependency:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;net.javacrumbs.shedlock&lt;/groupId&gt;\n    &lt;artifactId&gt;shedlock-spring&lt;/artifactId&gt;\n    &lt;version&gt;2.2.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"spring/spring-mvc/#configuration","title":"Configuration","text":"<p>ShedLock works only in environments with a shared database by declaring a proper LockProvider. It creates a table or document in the database where it stores the information about the current locks.</p> <p>For this example,we can usein-memory H2 database.We need to provide the H2 database and the ShedLock's JDBC dependency:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;net.javacrumbs.shedlock&lt;/groupId&gt;\n    &lt;artifactId&gt;shedlock-provider-jdbc-template&lt;/artifactId&gt;\n    &lt;version&gt;2.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n&lt;groupId&gt;com.h2database&lt;/groupId&gt;\n&lt;artifactId&gt;h2&lt;/artifactId&gt;\n&lt;version&gt;1.4.200&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Next, we need to create a database table for ShedLock to keep information about scheduler locks:</p> <pre><code>CREATE TABLE shedlock (\n   name VARCHAR(64),\n   lock_until TIMESTAMP(3) NULL,\n   locked_at TIMESTAMP(3) NULL,\n   locked_by VARCHAR(255),\n   PRIMARY KEY (name)\n)\n</code></pre> <p>application.yaml file configuration: <pre><code>spring:\n    datasource:\n        driverClassName: org.h2.Driver\n        url: jdbc:h2:mem:shedlock_DB;INIT=CREATE SCHEMA IF NOT EXISTS shedlock;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE\n        username: sa\n        password:\n</code></pre></p> <p>SchedulerConfiguration.java: <pre><code>@Configuration\npublic class SchedulerConfiguration {\n    @Bean\n    public LockProvider lockProvider(DataSource dataSource) {\n        return new JdbcTemplateLockProvider(dataSource);\n    }\n}\n</code></pre></p> <p>Application.java: <pre><code>@SpringBootApplication\n@EnableScheduling\n@EnableSchedulerLock(defaultLockAtMostFor = \"PT30S\")\npublic class Application {\n\n    public static void main(String[] args) {\n        SpringApplication.run(SpringApplication.class, args);\n    }\n}\n</code></pre></p>"},{"location":"spring/spring-mvc/#creating-tasks","title":"Creating Tasks","text":"<p>To create a scheduled task handled by ShedLock, we simply put the @Scheduled and @SchedulerLock annotations on a method:</p> <p>TaskScheduler.java: <pre><code>@Component\nclass TaskScheduler {\n\n    @Scheduled(cron = \"0 0/15 * * * ?\")\n    @SchedulerLock(name = \"TaskScheduler_scheduledTask\",\n            lockAtLeastForString = \"PT5M\", lockAtMostForString = \"PT14M\")\n    public void scheduledTask() {\n        // ...\n    }\n}\n</code></pre> <code>@Scheduled</code> supports the cron format, with this expression meaning \u201cevery 15 minutes\u201d.</p> <p>Next, taking a look at @SchedulerLock, the name parameter has to be unique, and ClassName_methodName is typically enough to achieve that. We don't want more than one run of this method happening at the same time, and ShedLock uses the unique name to achieve that.</p> <p>First, we've added lockAtLeastForString so that we can put some distance between method invocations. Using \u201c<code>PT5M</code>\u201d means that this method will hold the lock for 5 minutes, at a minimum. In other words, that means that this method can be run by ShedLock no more often than every five minutes.</p> <p>Next, we added lockAtMostForString to specify how long the lock should be kept in case the executing node dies. Using <code>PT14M</code> means that it will be locked for no longer than 14 minutes.</p> <p>In normal situations, ShedLock releases the lock directly after the task finishes. Now, we didn't have to do that because there is a default provided in <code>@EnableSchedulerLock</code>, but we've chosen to override that here.</p>"},{"location":"spring/spring-mvc/#execute-a-quartz-job-only-once-in-a-multi-instance-environment","title":"Execute a Quartz Job only once in a multi-instance environment","text":"<p>You have to configure Quartz to run in a clustered environment. Clustering currently only works with the JDBC jobstore, and works by having each node of the cluster to share the same database.</p> <ul> <li>Set the org.quartz.jobStore.isClustered property to true if you have multiple instances of Quartz that use the same set of database tables. This property is used to turn on the clustering features.</li> <li>Set the org.quartz.jobStore.clusterCheckinInterval property (milliseconds) which is the frequency at which this instance checks in with the other instances of the cluster.</li> <li>Set the org.quartz.scheduler.instanceId to AUTO so that each node in the cluster will have a unique instanceId.</li> </ul> <p>Each instance in the cluster should use the same copy of the quartz.properties file.  If you use clustering on separate machines ensure that their clocks are synchronized.</p> <p>Example Properties For A Clustered Scheduler <pre><code>#============================================================================\n# Configure Main Scheduler Properties  \n#============================================================================\n\norg.quartz.scheduler.instanceName = MyClusteredScheduler\norg.quartz.scheduler.instanceId = AUTO\n\n#============================================================================\n# Configure ThreadPool  \n#============================================================================\n\norg.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPool\norg.quartz.threadPool.threadCount = 25\norg.quartz.threadPool.threadPriority = 5\n\n#============================================================================\n# Configure JobStore  \n#============================================================================\n\norg.quartz.jobStore.misfireThreshold = 60000\n\norg.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX\norg.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.oracle.OracleDelegate\norg.quartz.jobStore.useProperties = false\norg.quartz.jobStore.dataSource = myDS\norg.quartz.jobStore.tablePrefix = QRTZ_\n\norg.quartz.jobStore.isClustered = true\norg.quartz.jobStore.clusterCheckinInterval = 20000\n\n#============================================================================\n# Configure Datasources  \n#============================================================================\n\norg.quartz.dataSource.myDS.driver = oracle.jdbc.driver.OracleDriver\norg.quartz.dataSource.myDS.URL = jdbc:oracle:thin:@polarbear:1521:dev\norg.quartz.dataSource.myDS.user = quartz\norg.quartz.dataSource.myDS.password = quartz\norg.quartz.dataSource.myDS.maxConnections = 5\norg.quartz.dataSource.myDS.validationQuery=select 0 from dual\n</code></pre></p>"},{"location":"spring/spring-mvc/#reference-links","title":"Reference Links","text":"<ol> <li>Spring MVC flow with Example</li> <li>Spring Web Annotations</li> <li>Quartz Configuration Reference</li> <li>Guide to ShedLock with Spring</li> <li>Introduction to Quartz</li> </ol>"},{"location":"spring/spring-security/","title":"Spring security","text":"<p>Spring Security</p>"},{"location":"spring/spring-security/#introducing-spring-security","title":"Introducing Spring Security","text":"<p>Spring Security is essentially just a bunch of servlet filters that enable Java applications to include authentication and authorization functionality. It is one of the most powerful, and highly customizable access-control frameworks (security framework) that provide authentication, authorization, and other security features for Java EE (Enterprise edition) based enterprise applications. The real power of Spring Security lies in its ability to be extended to meet custom needs. Its main responsibility is to authenticate and authorize incoming requests for accessing any resource, including rest API endpoints, MVC (Model-View-Controller) URLs, static resources, etc.</p>"},{"location":"spring/spring-security/#features-of-spring-security","title":"Features of Spring Security","text":"<p>Some essential features of Spring Security include:</p> <ul> <li>Supports authentication and authorization in a flexible and comprehensive manner.</li> <li>Detection and prevention of attacks including session fixation, clickjacking, cross-site request forgery, etc.</li> <li>Integrate with Servlet API.</li> <li>Offers optional integration with Spring Web MVC (Model-View-Controller).</li> <li>Java Authentication and Authorization Service (JAAS) is used for authentication purposes.</li> <li>Allows Single Sign-On so that users can access multiple applications with just one account (username and password).</li> </ul>"},{"location":"spring/spring-security/#authentication-and-authorization","title":"Authentication and Authorization","text":""},{"location":"spring/spring-security/#authentication","title":"Authentication:","text":"<pre><code>This refers to the process of verifying the identity of the user, using the credentials provided when accessing certain restricted resources. Two steps are involved in authenticating a user, namely identification and verification. An example is logging into a website with a username and a password. This is like answering the question Who are you?\n</code></pre>"},{"location":"spring/spring-security/#authorization","title":"Authorization:","text":"<pre><code>It is the ability to determine a user's authority to perform an action or to view data, assuming they have successfully logged in. This ensures that users can only access the parts of a resource that they are authorized to access. It could be thought of as an answer to the question Can a user do/read this?\n</code></pre>"},{"location":"spring/spring-security/#authentication-types","title":"Authentication Types","text":""},{"location":"spring/spring-security/#basic-authentication","title":"Basic authentication","text":"<p>RESTful web services can be authenticated in many ways, but the most basic one is basic authentication. For basic authentication, we send a username and password using the HTTP [Authorization] header to enable us to access the resource. Usernames and passwords are encoded using base64 encoding (not encryption) in Basic Authentication. The encoding is not secure since it can be easily decoded.</p> <p>Syntax:</p> <pre><code>Value = username:password  \nEncoded Value = base64(Value)  \nAuthorization Value = Basic &lt;Encoded Value&gt;  \n//Example: Authorization: Basic VGVzdFVzZXI6dGVzdDEyMw==  \n//Decode it'll give back the original username:password UserName:user123 \n</code></pre>"},{"location":"spring/spring-security/#digest-authentication","title":"digest authentication","text":"<p>RESTful web services can be authenticated in many ways, but advanced authentication methods include digest authentication. It applies a hash function to username, password, HTTP method, and URI in order to send credentials in encrypted form. It generates more complex cryptographic results by using the hashing technique which is not easy to decode.</p> <p>Syntax:</p> <pre><code>Hash1=MD5(username:realm:password)  \nHash2=MD5(method:digestURI)  \nresponse=MD5(Hash1:nonce:nonceCount:cnonce:qop:Hash2)  \n//Example, this got generated by running this example  \nAuthorization: Digest username=\"TestAdmin\", realm=\"admin-digest-realm\", nonce=\"MTYwMDEwMTUyMDM4OToxM2M1Y2I4MGFjMjk4OGI1ODQzZjc3NDUzOGFlMjZjYw==\", uri=\"/admin/hello?name=User\", response=\"2f080edbec53be2bdf3853d477e4a543\", qop=auth, nc=00000002, cnonce=\"11ecd9bf947dbcf4\" \n</code></pre>"},{"location":"spring/spring-security/#spring-security-modules","title":"Spring Security Modules","text":"<p>In Spring Security,  the Security module comprises separate jar files based on its functionality. The primary use is to allow the user to integrate according to the requirements. To include minimal spring security for your Maven project, include below dependencies in your pom.xml.</p> <p>Core \u2013 spring-security-core.jar      - This module contains core authentication and access-control related classes, basic provisioning APIs. This is mandatory for providing spring security to any J2EE based enterprise application. This module supports non-web applications, too.</p> <p>Web \u2013 spring-security-web.jar     \u2013This module contains filters and web-based authentication, like access control for URLs in a Servlet environment. This module is responsible to provide security to your Spring MVC or any other web application.</p> <p>Config- spring-security-config.jar     \u2013This module used to use the Spring Security XML name-space. It also supports.</p> <p>LDAP      \u2013 Modules supporting the LDAP authentication. We may need this if you want to have LDAP authentication for our application.</p> <p>OAuth 2.0 Core      \u2013 Provides support for the OAuth 2.0 authorization.</p> <p>OAuth 2.0 Client      \u2013 Spring Security\u2019s client support for OAuth 2.0 Authorization Framework and OpenID Connect Core 1.0.</p> <p>Secure: </p> <p>Spring has provided a separate module for securing the application. Spring Security is a Java SE/Java EE security framework to provide Authentication, Authorization, SSO and other Security features for Web Applications or Enterprise Applications. Spring Security supports the various types of security such as :</p> <ol> <li>Authentication and Authorization.</li> <li>BASIC,Digest and Form-Based Authentication.</li> <li>LDAP Authentication.</li> <li>OpenID Authentication.</li> <li>SSO (Single Sign-On) Implementation.</li> <li>Cross-Site Request Forgery (CSRF) Implementation.</li> <li><code>Remember-Me</code> Feature through HTTP Cookies.</li> <li>Implementation of ACLs.</li> <li><code>Channel Security</code> that means automatically switching between HTTP and HTTPS.</li> <li>JAAS (Java Authentication and Authorization Service).</li> <li>Flow Authorization using Spring WebFlow Framework.</li> <li>WS-Security using Spring Web Services.</li> </ol>"},{"location":"spring/swagger-docs/","title":"Swagger","text":"<p>{: .no_toc }</p>      Table of contents    <p>{: .text-delta } 1. TOC</p> <p>Swagger is a very good open source tool for documenting REST based APIs provided by microservices. It provides very easy to use interactive documentation.</p> <p>By the use of swagger annotation on REST endpoint, api documentation can be autogenerated and exposed over the web interface. Internal and external team can use web interface, to see the list of APIs and their inputs &amp; error codes. They can even invoke the endpoints directly from web interface to get the results.</p> <p>Swagger UI is a very powerful tool for your microservices consumers to help them understand set of endpoints provided by a given microservice.</p>"},{"location":"spring/swagger-docs/#integrate-swagger-into-your-microservices","title":"Integrate Swagger into your microservices","text":"<p>Integrating swagger into Spring Boot based application should be straight forward. You need to add swagger dependencies into <code>build.gradle</code>, provide swagger configuration and finally make some tweaks into WebMvcConfig to allow swagger-ui into your project.</p> <p>build.gradle - add swagger dependencies. <pre><code>dependencies {\n    compile('org.springframework.cloud:spring-cloud-starter-config')\n    // https://mvnrepository.com/artifact/io.springfox/springfox-swagger2\n    compile group: 'io.springfox', name: 'springfox-swagger2', version: '2.8.0'\n    compile group: 'io.springfox', name: 'springfox-swagger-ui', version: '2.8.0'\n</code></pre></p> <p>Second step is to define swagger configuration: SwaggerConfig.java. <pre><code>import org.springframework.boot.autoconfigure.EnableAutoConfiguration;\nimport org.springframework.context.annotation.*;\nimport springfox.documentation.builders.*;\nimport springfox.documentation.service.*;\n\n@Configuration\n@EnableSwagger2\n@EnableAutoConfiguration\npublic class SwaggerConfig {\n    @Bean\n    public Docket productApi() {\n        return new Docket(DocumentationType.SWAGGER_2)\n        .groupName(\"Product Service\")\n        .apiInfo(apiInfo())\n        .select()\n        .apis(RequestHandlerSelectors.basePackage(\"hello\"))\n        .paths(PathSelectors.any())\n        .build();\n    }\n    private ApiInfo apiInfo() {\n        return new ApiInfoBuilder()\n        .title(\"Product Service with Swagger\")\n        .description(\"Spring REST Sample with Swagger\")\n        .termsOfServiceUrl(\"http://www-03.ibm.com/software/sla/sladb.nsf/sla/bm?Open\")\n        .contact(new Contact(\"Munish Chandel\", \"\",\"munish.chandel@outlook.com\"))\n        .license(\"Apache License Version 2.0\")\n        .licenseUrl(\"https://github.com/IBM-Bluemix/news-aggregator/blob/master/LICENSE\")\n        .version(\"1.0\")\n        .build();\n    }\n}\n</code></pre> Lastly, add the below WebMvcConfig to enable swagger UI</p> <p><pre><code>import org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.web.servlet.config.annotation.ResourceHandlerRegistry;\nimport org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;\n\n@Configuration\npublic class WebMvcConfig extends WebMvcConfigurerAdapter {\n    private static final Logger logger = LoggerFactory.getLogger(WebMvcConfig.class);\n    @Override\n    public void addResourceHandlers(ResourceHandlerRegistry registry) {\n        super.addResourceHandlers(registry);\n        registry.addResourceHandler(\"swagger-ui.html\")\n                .addResourceLocations(\"classpath:/META-INF/resources/\");\n        /*registry.addResourceHandler(\"/webjars/**\")\n            .addResourceLocations(\"classpath:/META-INF/resources/webjars/\");*/\n    }\n}\n</code></pre> Now swagger is configured for use in your application.</p>"},{"location":"spring/swagger-docs/#swagger-annotations","title":"Swagger annotations","text":"<p>Then the resource class can have annotations such as:</p> <ul> <li><code>@Api</code>: To mark a resource as a Swagger resource</li> <li><code>@ApiOperation</code>: Describes an operation or typically an HTTP method against a specific path</li> <li><code>@ApiResponse</code>: To describe the response of a method</li> <li><code>@ApiParam</code>: Additional metadata for operational parameters of a method</li> </ul>"},{"location":"spring/swagger-docs/#maven-plugin","title":"Maven plugin","text":"<p>A Maven plugin can be used to generate the swagger.yaml file based on the metadata placed on the code: <pre><code>&lt;build&gt;\n    ...\n    &lt;plugin&gt;\n        &lt;groupId&gt;com.github.kongchen&lt;/groupId&gt;\n        &lt;artifactId&gt;swagger-maven-plugin&lt;/artifactId&gt;\n        &lt;version&gt;3.1.5&lt;/version&gt;\n        &lt;configuration&gt;\n            &lt;apiSources&gt;\n                &lt;apiSource&gt;\n                    &lt;springmvc&gt;false&lt;/springmvc&gt;\n                    &lt;locations&gt;org.jee8ng.users.boundary&lt;/locations&gt;\n                    &lt;schemes&gt;http&lt;/schemes&gt;\n                    &lt;host&gt;localhost:8081&lt;/host&gt;\n                    &lt;basePath&gt;/${project.build.finalName}/resources\n                    &lt;/basePath&gt;\n                    &lt;info&gt;\n                        &lt;title&gt;Users API&lt;/title&gt;\n                        &lt;version&gt;v1&lt;/version&gt;\n                        &lt;description&gt;Users rest endpoints&lt;/description&gt;\n                    &lt;/info&gt;\n                    &lt;outputFormats&gt;yaml&lt;/outputFormats&gt;\n                    &lt;swaggerDirectory&gt;${basedir}/src/main/webapp\n                    &lt;/swaggerDirectory&gt;\n                &lt;/apiSource&gt;\n            &lt;/apiSources&gt;\n        &lt;/configuration&gt;\n        &lt;executions&gt;\n            &lt;execution&gt;\n                &lt;phase&gt;compile&lt;/phase&gt;\n                &lt;goals&gt;\n                    &lt;goal&gt;generate&lt;/goal&gt;\n                &lt;/goals&gt;\n            &lt;/execution&gt;\n        &lt;/executions&gt;\n    &lt;/plugin&gt;\n    ...\n&lt;/build&gt;\n</code></pre></p> <p>The swaggerDirectory is where the <code>swagger.yaml</code> file gets generated. This way, it's possible to use a combination of plugins and annotations to create the Swagger Spec format with the desired output, such as JSON, configured here. The plugin and API details can be explored further on the Swagger website and on the GitHub pages of the plugin.</p>"},{"location":"spring/security/security/","title":"Spring Security","text":"<p>Spring Security is a powerful framework that provides authentication, authorization, and protection against common security vulnerabilities for Spring-based applications. It plays a crucial role in safeguarding your application and its data from unauthorized access and attacks. In this article, we'll explore the fundamentals of Spring Security, why it's important, and how to use it effectively with easy-to-understand examples and code snippets.</p> <p>Spring Security is a vital component in the world of Spring-based applications, ensuring the safety and security of your software. It provides comprehensive solutions for authentication, authorization, and protection against common security threats. In this article, we'll delve into what Spring Security is, why it's essential, and how you can use it effectively.</p>"},{"location":"spring/security/security/#understanding-spring-security","title":"Understanding Spring Security:","text":"<p>Spring Security is an integral part of the Spring ecosystem, specifically designed to address security concerns. It offers a range of features that allow developers to build secure applications with ease. Let's break down its key components:</p> <ol> <li> <p>Authentication: Authentication is the process of verifying a user's identity. Spring Security provides various authentication mechanisms, such as username/password, token-based authentication, and integration with external authentication providers like LDAP or OAuth.</p> </li> <li> <p>Authorization: Authorization determines what actions a user is allowed to perform within an application. Spring Security offers role-based and attribute-based access control, allowing you to define fine-grained permissions.</p> </li> <li> <p>Protection against Common Threats: Spring Security helps protect your application against common security threats like cross-site scripting (XSS), cross-site request forgery (CSRF), and SQL injection by providing built-in defenses.</p> </li> </ol>"},{"location":"spring/security/security/#why-spring-security-matters","title":"Why Spring Security Matters:","text":""},{"location":"spring/security/security/#1-protecting-user-data","title":"1. Protecting User Data:","text":"<p>Imagine you're building an e-commerce platform where users store personal and financial information. Spring Security ensures that only authorized users can access and modify this data. Without it, sensitive information could be at risk.</p>"},{"location":"spring/security/security/#2-preventing-unauthorized-access","title":"2. Preventing Unauthorized Access:","text":"<p>In a collaborative project management tool, you wouldn't want one user to access another user's projects or data. Spring Security's authorization mechanisms allow you to specify who can do what within your application.</p>"},{"location":"spring/security/security/#3-safeguarding-against-attacks","title":"3. Safeguarding Against Attacks:","text":"<p>Malicious users may attempt to exploit vulnerabilities in your application. Spring Security's built-in protection mechanisms help defend against common security threats, providing an additional layer of defense.</p>"},{"location":"spring/security/security/#using-spring-security","title":"Using Spring Security:","text":"<p>Let's get hands-on with a simple example. Suppose you're developing a web application using Spring Boot, and you want to protect certain endpoints. Here's how you can do it:</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests()\n                .antMatchers(\"/public/**\").permitAll()\n                .anyRequest().authenticated()\n                .and()\n            .formLogin()\n                .loginPage(\"/login\")\n                .permitAll()\n                .and()\n            .logout()\n                .permitAll();\n    }\n}\n</code></pre> <p>In this example, we're permitting access to public resources while requiring authentication for other endpoints. We've also defined a custom login page and enabled logout functionality.</p> <p>Spring Security is an indispensable tool for any Spring-based application. It ensures that your software is protected against unauthorized access and common security threats, making it an essential part of your development toolkit. By following best practices and leveraging Spring Security's features, you can build robust and secure applications that users can trust.</p>"},{"location":"spring/security/security/#advanced-features-and-customization","title":"Advanced Features and Customization","text":"<p>Having covered the basics of Spring Security, it's time to explore some advanced features and customization options that make Spring Security a versatile choice for securing your Spring-based application.</p>"},{"location":"spring/security/security/#1-custom-authentication-providers","title":"1. Custom Authentication Providers:","text":"<p>While Spring Security provides a range of built-in authentication methods, you might have unique requirements. You can create custom authentication providers to integrate with external systems or implement unconventional authentication methods. Here's an example of a custom authentication provider using a username and a custom token:</p> <pre><code>@Component\npublic class CustomAuthenticationProvider implements AuthenticationProvider {\n\n    @Override\n    public Authentication authenticate(Authentication authentication) throws AuthenticationException {\n        String username = authentication.getName();\n        String token = authentication.getCredentials().toString();\n\n        // Perform custom authentication logic here\n\n        return new UsernamePasswordAuthenticationToken(username, token, Collections.emptyList());\n    }\n\n    @Override\n    public boolean supports(Class&lt;?&gt; authentication) {\n        return authentication.equals(UsernamePasswordAuthenticationToken.class);\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#2-method-level-security","title":"2. Method-Level Security:","text":"<p>Spring Security allows you to secure individual methods within your application. This is particularly useful when you need fine-grained control over who can access specific functionality. Here's an example using method-level security annotations:</p> <pre><code>@Service\npublic class UserService {\n\n    @PreAuthorize(\"hasRole('ADMIN')\")\n    public void deleteUser(int userId) {\n        // Delete user logic here\n    }\n}\n</code></pre> <p>In this example, the <code>deleteUser</code> method can only be executed by users with the \"ADMIN\" role.</p>"},{"location":"spring/security/security/#3-custom-access-denied-handling","title":"3. Custom Access Denied Handling:","text":"<p>When an unauthorized user tries to access a protected resource, you can customize how Spring Security handles the access denied situation. You can create a custom access denied handler like this:</p> <pre><code>@Component\npublic class CustomAccessDeniedHandler implements AccessDeniedHandler {\n\n    @Override\n    public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException {\n        // Custom access denied logic, e.g., redirect to a specific error page\n        response.sendRedirect(\"/access-denied\");\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#4-security-headers","title":"4. Security Headers:","text":"<p>To enhance security, Spring Security provides features to control security headers in HTTP responses. You can configure headers like Content Security Policy (CSP), X-Content-Type-Options, and X-Frame-Options to protect against common web vulnerabilities.</p> <p>Spring Security is not only about basic authentication and authorization; it offers advanced features and customization options to cater to diverse security requirements. By leveraging these capabilities, you can build highly secure applications that meet the specific needs of your project while adhering to best security practices. Whether you're working on a simple web application or a complex enterprise system, Spring Security has you covered.</p>"},{"location":"spring/security/security/#integrating-spring-security-with-oauth-20","title":"Integrating Spring Security with OAuth 2.0","text":"<p>let's now delve into integrating OAuth 2.0 with your Spring-based application. OAuth 2.0 is a popular protocol for secure authorization, widely used for third-party authentication and API access control. This article explains the significance of OAuth 2.0, its implementation with Spring Security, and how it benefits your application.</p> <p>As we continue our journey into the realm of Spring Security, it's essential to understand how to integrate OAuth 2.0, a critical protocol for secure authorization, into your Spring-based application. OAuth 2.0 plays a pivotal role in granting third-party applications limited access to your resources while keeping user data secure. Let's explore why OAuth 2.0 matters and how to implement it with Spring Security.</p>"},{"location":"spring/security/security/#understanding-oauth-20","title":"Understanding OAuth 2.0:","text":"<p>OAuth 2.0 is a widely adopted open standard for access delegation. It allows users to grant third-party applications limited access to their resources without exposing their credentials. OAuth 2.0 is prevalent in scenarios such as social media logins, granting access to APIs, and single sign-on (SSO) solutions.</p>"},{"location":"spring/security/security/#why-oauth-20-matters","title":"Why OAuth 2.0 Matters:","text":""},{"location":"spring/security/security/#1-enhanced-security","title":"1. Enhanced Security:","text":"<p>OAuth 2.0 provides a secure way to delegate access to resources. Instead of sharing passwords, users can grant limited and time-bound access tokens, reducing the risk of unauthorized access.</p>"},{"location":"spring/security/security/#2-third-party-integration","title":"2. Third-Party Integration:","text":"<p>OAuth 2.0 enables seamless integration with third-party applications and services, expanding the functionality and reach of your application.</p>"},{"location":"spring/security/security/#3-single-sign-on-sso","title":"3. Single Sign-On (SSO):","text":"<p>OAuth 2.0 can be used to implement single sign-on solutions, allowing users to access multiple applications with a single set of credentials.</p>"},{"location":"spring/security/security/#implementing-oauth-20-with-spring-security","title":"Implementing OAuth 2.0 with Spring Security:","text":"<p>Let's walk through a simple example of how to integrate OAuth 2.0 with Spring Security using the OAuth 2.0 Authorization Code Grant flow. Suppose you want to allow users to log in with their Google accounts:</p> <pre><code>@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests()\n                .antMatchers(\"/login**\", \"/error**\").permitAll()\n                .anyRequest().authenticated()\n                .and()\n            .oauth2Login()\n                .loginPage(\"/login\")\n                .defaultSuccessURL(\"/user\")\n                .and()\n            .logout()\n                .logoutSuccessUrl(\"/\")\n                .and()\n            .exceptionHandling()\n                .accessDeniedPage(\"/access-denied\");\n    }\n}\n</code></pre> <p>In this example, we configure Spring Security to use Google as an OAuth 2.0 provider for authentication. Users can log in with their Google accounts, and upon successful authentication, they are redirected to the \"/user\" page.</p> <p>Integrating OAuth 2.0 with Spring Security opens up exciting possibilities for secure third-party authentication and resource access control in your Spring-based application. Whether you're building a platform that connects with social media accounts or providing APIs for external developers, OAuth 2.0 ensures robust security while delivering a seamless user experience. By mastering OAuth 2.0 integration with Spring Security, you can unlock the full potential of secure authorization in your applications.</p>"},{"location":"spring/security/security/#core-components-of-spring-security","title":"Core Components of Spring Security","text":"<p>Spring Security comprises several core components that work together to provide robust security for your applications. In this article, we'll explore these fundamental building blocks, their roles, and how they contribute to the overall security of your Spring-based applications. You'll gain a clear understanding of Spring Security's core components and their importance.</p> <p>Spring Security, as a comprehensive security framework for Spring-based applications, relies on a set of core components. These components work in harmony to provide a secure environment, ensuring that only authorized users can access your application's resources. Let's delve into each of these core components to understand their roles and significance.</p>"},{"location":"spring/security/security/#1-authentication","title":"1. Authentication:","text":"<p>Authentication is the process of verifying a user's identity. Spring Security offers various authentication mechanisms, including:</p> <ul> <li>Username and Password: The traditional method where users provide their credentials.</li> <li>Token-Based: Authentication via tokens (e.g., JWT) where the user's identity is stored in a token.</li> <li>OAuth 2.0: Integrating with third-party identity providers like Google or Facebook.</li> </ul> <p>Example Code (Username and Password Authentication):</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth\n            .inMemoryAuthentication()\n                .withUser(\"user\")\n                .password(\"{noop}password\")\n                .roles(\"USER\");\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#2-authorization","title":"2. Authorization:","text":"<p>Authorization determines what actions a user is allowed to perform within the application. Spring Security supports role-based and attribute-based access control:</p> <ul> <li>Role-Based: Users are assigned roles (e.g., \"ADMIN\" or \"USER\"), and certain actions are restricted to specific roles.</li> <li>Attribute-Based: Access control based on specific attributes of the user, such as their username or custom properties.</li> </ul> <p>Example Code (Role-Based Authorization):</p> <pre><code>@Configuration\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class MethodSecurityConfig extends GlobalMethodSecurityConfiguration {\n\n    @Override\n    protected MethodSecurityExpressionHandler createExpressionHandler() {\n        return new DefaultMethodSecurityExpressionHandler() {\n            {\n                setPermissionEvaluator(new CustomPermissionEvaluator());\n            }\n        };\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#3-filters","title":"3. Filters:","text":"<p>Spring Security uses filters to process and manipulate HTTP requests and responses. Filters play a vital role in various security aspects, such as authentication, authorization, and protection against common web vulnerabilities (e.g., CSRF or XSS).</p> <p>Example Code (Custom Filter):</p> <pre><code>public class CustomFilter extends GenericFilterBean {\n\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)\n            throws IOException, ServletException {\n        // Custom filter logic here\n        chain.doFilter(request, response);\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#4-security-context","title":"4. Security Context:","text":"<p>The security context holds the current user's security information. It allows you to access the authenticated user's details and make authorization decisions throughout the application.</p> <p>Example Code (Accessing Security Context):</p> <pre><code>Authentication authentication = SecurityContextHolder.getContext().getAuthentication();\nString currentUsername = authentication.getName();\n</code></pre>"},{"location":"spring/security/security/#5-provider-and-manager","title":"5. Provider and Manager:","text":"<p>Authentication providers validate user credentials, while authentication managers coordinate the authentication process by working with multiple providers if necessary.</p> <p>Example Code (Custom Authentication Provider):</p> <pre><code>@Component\npublic class CustomAuthenticationProvider implements AuthenticationProvider {\n\n    @Override\n    public Authentication authenticate(Authentication authentication) throws AuthenticationException {\n        // Custom authentication logic here\n    }\n\n    @Override\n    public boolean supports(Class&lt;?&gt; authentication) {\n        return authentication.equals(UsernamePasswordAuthenticationToken.class);\n    }\n}\n</code></pre> <p>These core components form the foundation of Spring Security, ensuring the security of your Spring-based applications. By understanding how they work together, you can build robust and secure systems that protect your resources and data while providing a seamless user experience.</p>"},{"location":"spring/security/security/#6-configuration","title":"6. Configuration:","text":"<p>Spring Security's configuration is a critical aspect of its setup. You can customize security settings and policies by creating configuration classes or XML configurations. These configurations define which components are used and how they interact within your application.</p> <p>Example Code (Security Configuration):</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests()\n                .antMatchers(\"/public/**\").permitAll()\n                .anyRequest().authenticated()\n                .and()\n            .formLogin()\n                .loginPage(\"/login\")\n                .permitAll()\n                .and()\n            .logout()\n                .permitAll();\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#7-sessions-and-tokens","title":"7. Sessions and Tokens:","text":"<p>Spring Security manages user sessions and authentication tokens. Sessions keep track of user state, and tokens are used to maintain user identity across requests. You can configure how sessions and tokens are handled, including using stateless token-based authentication.</p> <p>Example Code (Token-Based Authentication with JWT):</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .sessionManagement()\n                .sessionCreationPolicy(SessionCreationPolicy.STATELESS)\n                .and()\n            .addFilterBefore(new JwtAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class);\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#8-exception-handling","title":"8. Exception Handling:","text":"<p>Spring Security provides ways to handle exceptions that may occur during authentication or authorization processes. You can define custom exception handlers to control how errors are presented to users.</p> <p>Example Code (Custom Access Denied Handler):</p> <pre><code>@Component\npublic class CustomAccessDeniedHandler implements AccessDeniedHandler {\n\n    @Override\n    public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException {\n        // Custom access denied logic, e.g., redirect to an error page\n        response.sendRedirect(\"/access-denied\");\n    }\n}\n</code></pre> <p>Understanding these core components of Spring Security is essential for building secure Spring-based applications. By grasping their roles and how they interact, you gain the ability to configure, customize, and extend security features to meet your specific requirements. Whether you're working on a simple web application or a complex enterprise system, these building blocks empower you to create a robust and secure environment for your users and data.</p>"},{"location":"spring/security/security/#9-security-events-and-auditing","title":"9. Security Events and Auditing:","text":"<p>Spring Security allows you to monitor and log security-related events within your application. By leveraging security events and auditing mechanisms, you can gain insights into user interactions, failed login attempts, and other security-related activities.</p> <p>Example Code (Custom Security Event Listener):</p> <pre><code>@Component\npublic class CustomSecurityEventListener implements ApplicationListener&lt;AbstractAuthenticationEvent&gt; {\n\n    @Override\n    public void onApplicationEvent(AbstractAuthenticationEvent event) {\n        // Custom security event handling logic here\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#10-csrf-protection","title":"10. CSRF Protection:","text":"<p>Cross-Site Request Forgery (CSRF) is a common web vulnerability. Spring Security provides built-in CSRF protection by generating and validating CSRF tokens. This prevents malicious websites from making unauthorized requests on behalf of authenticated users.</p> <p>Example Code (CSRF Protection):</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .csrf()\n                .csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#11-password-encoding","title":"11. Password Encoding:","text":"<p>Storing passwords securely is crucial for user authentication. Spring Security encourages the use of password encoding techniques, such as BCrypt, to store passwords securely in your database.</p> <p>Example Code (Password Encoding):</p> <pre><code>@Bean\npublic PasswordEncoder passwordEncoder() {\n    return new BCryptPasswordEncoder();\n}\n</code></pre>"},{"location":"spring/security/security/#12-remember-me-authentication","title":"12. Remember-Me Authentication:","text":"<p>Spring Security provides a \"remember-me\" authentication feature, allowing users to stay logged in across sessions even after browser restarts. This feature enhances user convenience while maintaining security.</p> <p>Example Code (Remember-Me Authentication):</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .rememberMe()\n                .key(\"mySecretKey\")\n                .tokenValiditySeconds(604800); // 7 days\n    }\n}\n</code></pre> <p>These additional components and features complement the core elements of Spring Security, enabling you to tailor your security implementation to specific requirements. By combining these building blocks effectively, you can create a highly secure environment for your Spring-based applications, ensuring the protection of sensitive data and the integrity of user interactions.</p>"},{"location":"spring/security/security/#authentication-and-authorization","title":"Authentication and Authorization","text":"<p>Authentication and authorization are two fundamental concepts in securing applications. Authentication verifies the identity of a user, while authorization determines what actions they can perform. In this article, we'll explore these concepts in detail and see how Spring Security, a powerful framework for Java applications, handles them with practical examples.</p> <p>Authentication and authorization are key pillars of application security. Authentication verifies the identity of a user, while authorization determines what that user is allowed to do within the application. Spring Security, a robust framework for securing Java applications, provides a comprehensive solution for handling both authentication and authorization. In this article, we'll delve into these concepts and understand how Spring Security manages them effectively.</p>"},{"location":"spring/security/security/#authentication","title":"Authentication:","text":"<p>Authentication is the process of verifying the identity of a user, ensuring that they are who they claim to be. It answers the question, \"Who are you?\" Spring Security supports various authentication methods, including:</p> <ol> <li> <p>Username and Password: The most common method where users provide their credentials (username and password) for verification.</p> </li> <li> <p>Token-Based: Authentication using tokens like JSON Web Tokens (JWT), which store user identity information and are often used for stateless authentication.</p> </li> <li> <p>OAuth 2.0: Integration with third-party identity providers like Google or Facebook for user authentication.</p> </li> </ol>"},{"location":"spring/security/security/#spring-security-authentication-example","title":"Spring Security Authentication Example:","text":"<p>Let's consider a basic example of username and password authentication in a Spring Security configuration:</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth\n            .inMemoryAuthentication()\n                .withUser(\"user\")\n                .password(\"{noop}password\") // Passwords should be securely hashed in production\n                .roles(\"USER\");\n    }\n}\n</code></pre> <p>In this example, we configure Spring Security to use in-memory authentication with a single user \"user\" and password \"password\" (note that passwords should be securely hashed in a real application). This user has the \"USER\" role.</p>"},{"location":"spring/security/security/#authorization","title":"Authorization:","text":"<p>Authorization deals with determining what actions or resources a user is allowed to access or manipulate within an application. It answers the question, \"What are you allowed to do?\" Spring Security offers two primary approaches to authorization:</p> <ol> <li> <p>Role-Based Authorization: Users are assigned roles (e.g., \"ADMIN\" or \"USER\"), and specific actions or resources are restricted to users with particular roles.</p> </li> <li> <p>Attribute-Based Authorization: Access control based on specific attributes of the user, such as their username, custom properties, or data associated with them.</p> </li> </ol>"},{"location":"spring/security/security/#spring-security-authorization-example","title":"Spring Security Authorization Example:","text":"<p>Here's an example of role-based authorization using Spring Security annotations:</p> <pre><code>@Configuration\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class MethodSecurityConfig extends GlobalMethodSecurityConfiguration {\n\n    @Override\n    protected MethodSecurityExpressionHandler createExpressionHandler() {\n        return new DefaultMethodSecurityExpressionHandler() {\n            {\n                setPermissionEvaluator(new CustomPermissionEvaluator());\n            }\n        };\n    }\n}\n</code></pre> <p>In this example, we enable method-level security and define a custom permission evaluator. You can then use annotations like <code>@PreAuthorize</code> and <code>@PostAuthorize</code> to specify authorization rules on your methods.</p>"},{"location":"spring/security/security/#spring-securitys-role","title":"Spring Security's Role:","text":"<p>Spring Security seamlessly integrates authentication and authorization, allowing you to build secure applications with ease. By configuring authentication providers, defining roles, and specifying access control rules, you can ensure that your application only grants access to authorized users while protecting sensitive data and functionality.</p> <p>Understanding these fundamental concepts and Spring Security's role in managing them is essential for creating robust and secure applications that protect user information and maintain the integrity of your system.</p>"},{"location":"spring/security/security/#authentication-flow-in-spring-security","title":"Authentication Flow in Spring Security:","text":"<p>To understand how Spring Security handles authentication, let's walk through the authentication flow:</p> <ol> <li> <p>User Authentication Request: When a user tries to access a secured resource, Spring Security intercepts the request. If the user is not authenticated (i.e., they haven't provided valid credentials), they are redirected to a login page or prompted to provide credentials via a login form.</p> </li> <li> <p>Authentication Provider: Spring Security uses authentication providers to validate the provided credentials. These providers can be configured for various authentication methods, such as in-memory authentication, database-based authentication, or integration with external identity providers.</p> </li> <li> <p>Authentication Manager: The authentication manager coordinates the authentication process, working with one or more authentication providers if necessary. It delegates the credential verification to the appropriate provider based on the authentication method used.</p> </li> <li> <p>Successful Authentication: If the user provides valid credentials, Spring Security establishes their identity and creates an <code>Authentication</code> object. This object contains details about the authenticated user, such as their username and authorities (roles).</p> </li> <li> <p>Security Context: Spring Security stores the <code>Authentication</code> object in the security context. This context is accessible throughout the application, allowing you to make authorization decisions and retrieve user details when needed.</p> </li> <li> <p>Access Granted: With a valid <code>Authentication</code> object in the security context, Spring Security grants access to the requested resource or action based on the user's authorities or roles.</p> </li> </ol>"},{"location":"spring/security/security/#authorization-flow","title":"Authorization Flow:","text":"<p>Now, let's explore how Spring Security handles authorization:</p> <ol> <li> <p>Authorization Check: Once a user is authenticated, Spring Security performs authorization checks to determine whether the user is allowed to access specific resources or perform certain actions.</p> </li> <li> <p>Access Control Rules: Spring Security allows you to define access control rules based on roles or attributes. These rules specify which users or roles have permission to perform specific actions.</p> </li> <li> <p>Pre- and Post-Processing: Spring Security provides annotations like <code>@PreAuthorize</code> and <code>@PostAuthorize</code> that you can use to apply authorization checks at the method level in your code. These annotations enable fine-grained control over access to methods.</p> </li> <li> <p>Permission Evaluator: If you require custom authorization logic beyond simple role-based checks, you can implement a custom permission evaluator to evaluate access control decisions based on specific attributes or conditions.</p> </li> <li> <p>Access Denied Handling: If a user tries to access a resource or perform an action for which they are not authorized, Spring Security can handle this situation according to your configuration. For example, you can redirect the user to an access denied page or return an error message.</p> </li> </ol> <p>By understanding this authentication and authorization flow in Spring Security, you can design your application's security architecture effectively, ensuring that users are authenticated securely and have appropriate access to resources and actions. This knowledge empowers you to create secure and well-structured applications that protect sensitive data and functionality.</p>"},{"location":"spring/security/security/#additional-spring-security-features","title":"Additional Spring Security Features:","text":"<p>While authentication and authorization are the core functions of Spring Security, the framework offers additional features to enhance the security of your applications:</p> <ol> <li> <p>Session Management: Spring Security provides options for managing user sessions, including controlling the number of allowed sessions per user and handling session fixation attacks.</p> </li> <li> <p>Remember-Me Authentication: This feature allows users to remain authenticated even after they close and reopen their browsers. It's useful for applications that require persistent user sessions.</p> </li> <li> <p>CSRF Protection: Cross-Site Request Forgery (CSRF) protection is built into Spring Security. It helps prevent malicious websites from making unauthorized requests on behalf of authenticated users.</p> </li> <li> <p>Password Encoding: Spring Security encourages the use of password encoding techniques like BCrypt to securely store user passwords in databases.</p> </li> <li> <p>Security Headers: You can configure Spring Security to include security headers in HTTP responses, such as Content Security Policy (CSP), X-Content-Type-Options, and X-Frame-Options, to mitigate common web vulnerabilities.</p> </li> <li> <p>Security Events and Auditing: Spring Security allows you to monitor and log security-related events within your application. This auditing helps you track user interactions and security incidents.</p> </li> <li> <p>Custom Filters: You can add custom filters to the Spring Security filter chain to implement additional security logic tailored to your application's requirements.</p> </li> <li> <p>Integration with External Identity Providers: Spring Security supports integration with external identity providers using protocols like OAuth 2.0 and OpenID Connect. This is valuable when implementing single sign-on (SSO) or allowing users to log in with their social media accounts.</p> </li> <li> <p>Password Policies: Spring Security allows you to define password policies, such as password expiration, complexity requirements, and account lockout policies, to enhance security.</p> </li> </ol> <p>By utilizing these additional features, you can further strengthen the security posture of your Spring-based applications and protect them against a wide range of threats and vulnerabilities.</p> <p>In summary, authentication and authorization are the foundation of Spring Security, providing a robust framework for securing Java applications. Understanding how Spring Security handles these aspects, along with its supplementary features, empowers you to create secure, resilient, and user-friendly applications that meet the diverse security needs of your users and organizations.</p>"},{"location":"spring/security/security/#authentication-and-authorization_1","title":"Authentication and Authorization","text":"<p>Authentication and authorization are two distinct concepts in application security. Authentication verifies a user's identity, while authorization determines what actions or resources a user is allowed to access. In this article, we'll clarify these differences with clear examples and illustrate how they work together to safeguard your applications.</p> <p>Authentication and authorization are core principles of application security, and understanding their differences is crucial. Authentication verifies who the user is, while authorization defines what the user can do. Let's explore these concepts in detail and see how they complement each other to secure your applications effectively.</p>"},{"location":"spring/security/security/#authentication_1","title":"Authentication:","text":"<p>Authentication is the process of verifying a user's identity. It answers the question, \"Who are you?\" Authentication ensures that the user is indeed the person they claim to be. Common authentication methods include:</p> <ul> <li>Username and Password: Users provide a username and a password to prove their identity.</li> <li>Token-Based: Authentication using tokens like JSON Web Tokens (JWT), which contain user identity information.</li> <li>OAuth 2.0: Integration with third-party identity providers like Google or Facebook for user authentication.</li> </ul> <p>Example: Think of authentication as the process of showing your ID card at the entrance of a building. The security personnel verify your ID to ensure you are who you claim to be before granting access.</p>"},{"location":"spring/security/security/#authorization_1","title":"Authorization:","text":"<p>Authorization, on the other hand, deals with determining what actions or resources a user is allowed to access or manipulate within an application. It answers the question, \"What are you allowed to do?\" Authorization defines permissions based on roles, attributes, or other criteria. Common authorization methods include:</p> <ul> <li>Role-Based Authorization: Users are assigned roles (e.g., \"ADMIN\" or \"USER\"), and specific actions or resources are restricted to users with particular roles.</li> <li>Attribute-Based Authorization: Access control based on specific attributes of the user, such as their username, custom properties, or data associated with them.</li> </ul> <p>Example: Authorization is akin to the permissions granted to different employees within an organization. Managers have access to sensitive data, while regular employees may have limited access.</p>"},{"location":"spring/security/security/#authentication-vs-authorization","title":"Authentication vs. Authorization:","text":"<ol> <li> <p>Purpose:</p> <ul> <li>Authentication verifies identity.</li> <li>Authorization determines access rights.</li> </ul> </li> <li> <p>Question:</p> <ul> <li>Authentication asks, \"Who are you?\"</li> <li>Authorization asks, \"What are you allowed to do?\"</li> </ul> </li> <li> <p>Outcome:</p> <ul> <li>Authentication results in the establishment of a user's identity.</li> <li>Authorization results in granting or denying access to specific actions or resources.</li> </ul> </li> <li> <p>Examples:</p> <ul> <li>Authentication: Verifying a user's username and password.</li> <li>Authorization: Allowing an admin to delete user accounts.</li> </ul> </li> <li> <p>Relationship:</p> <ul> <li>Authentication precedes authorization. You must first authenticate a user before determining what they can access.</li> </ul> </li> </ol>"},{"location":"spring/security/security/#how-they-work-together","title":"How They Work Together:","text":"<p>Authentication and authorization work in tandem to secure applications. After a user is authenticated (proving their identity), the system checks their authorization (permissions) to determine what actions or resources they can access.</p> <p>Example: When logging into an email account, authentication involves entering your username and password. Once authenticated, the system checks if you have the authorization to read, send, or delete emails based on your role and settings.</p> <p>In conclusion, understanding the distinctions between authentication and authorization is vital for building secure applications. Authentication verifies identity, while authorization controls access. Together, they form the foundation of application security, ensuring that users are who they claim to be and that they can only perform actions they are allowed to do.</p>"},{"location":"spring/security/security/#understanding-principal-and-authentication","title":"Understanding Principal and Authentication","text":"<p>In Spring Security, a Principal represents the currently authenticated user, while Authentication encapsulates the user's credentials and authorities. This article dives into these concepts, explaining how Spring Security uses them to secure your applications, with practical examples for clarity.</p> <p>In Spring Security, the concepts of Principal and Authentication play pivotal roles in ensuring the security of your applications. A Principal represents the currently authenticated user, while Authentication encapsulates the user's credentials and authorities. Let's explore these concepts in detail and understand how Spring Security employs them to safeguard your applications.</p>"},{"location":"spring/security/security/#principal","title":"Principal:","text":"<p>A Principal in Spring Security represents the currently authenticated user or entity. It encapsulates information about the user, such as their username or user object. Essentially, the Principal object provides a way to identify who is interacting with the application.</p> <ul> <li>Principal Object: A Principal can be represented as a Java object containing user information. It helps answer the question, \"Who is the user?\"</li> </ul>"},{"location":"spring/security/security/#authentication_2","title":"Authentication:","text":"<p>Authentication in Spring Security represents the process of verifying a user's identity. It contains the user's credentials (e.g., username and password) and information about the user's authorities or roles. Authentication verifies that the user is indeed who they claim to be.</p> <ul> <li>Credentials: These are the user's proof of identity, such as a username and password.</li> <li>Authorities: Authorities define what actions or resources the user is allowed to access within the application.</li> </ul>"},{"location":"spring/security/security/#spring-security-and-principal","title":"Spring Security and Principal:","text":"<p>In Spring Security, once a user is authenticated, the authenticated user's information is stored in a Principal object. The Principal represents the authenticated user, allowing the application to make authorization decisions and access user-specific data.</p>"},{"location":"spring/security/security/#spring-security-and-authentication","title":"Spring Security and Authentication:","text":"<p>Spring Security manages the entire authentication process, from verifying user credentials to creating an Authentication object. This object contains the user's details and authorities, encapsulating everything needed to determine what the user can access within the application.</p>"},{"location":"spring/security/security/#practical-example","title":"Practical Example:","text":"<p>Consider a Spring Security configuration that enables username and password authentication:</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth\n            .inMemoryAuthentication()\n                .withUser(\"user\")\n                .password(\"{noop}password\") // Passwords should be securely hashed in production\n                .roles(\"USER\");\n    }\n}\n</code></pre> <p>In this example, when a user provides valid credentials (username \"user\" and password \"password\"), Spring Security creates an Authentication object containing information about the user's identity and role (in this case, the role \"USER\"). The authenticated user becomes the Principal, allowing them to access resources permitted for a \"USER\" role.</p> <p>In Spring Security, a Principal represents the authenticated user, while Authentication encapsulates their credentials and authorities. These concepts are fundamental to securing your applications, enabling you to identify users and control their access to resources and actions. Understanding how Spring Security handles these concepts empowers you to build robust and secure systems that protect sensitive data and functionality.</p>"},{"location":"spring/security/security/#accessing-the-principal-and-authentication","title":"Accessing the Principal and Authentication:","text":"<p>Once Spring Security has authenticated a user, you can access the Principal and Authentication within your application to make authorization decisions or retrieve user-specific information.</p>"},{"location":"spring/security/security/#accessing-the-principal","title":"Accessing the Principal:","text":"<p>You can access the Principal directly in your code using the <code>SecurityContextHolder</code> class, which provides a static method called <code>getContext()</code>:</p> <pre><code>import org.springframework.security.core.Authentication;\nimport org.springframework.security.core.context.SecurityContextHolder;\nimport org.springframework.security.core.userdetails.UserDetails;\n\n...\n\nAuthentication authentication = SecurityContextHolder.getContext().getAuthentication();\nif (authentication != null &amp;&amp; authentication.getPrincipal() instanceof UserDetails) {\n    UserDetails userDetails = (UserDetails) authentication.getPrincipal();\n    String username = userDetails.getUsername();\n    // You can also access authorities, additional user information, etc.\n}\n</code></pre> <p>In the above code, we first retrieve the current Authentication object from the SecurityContextHolder and then extract the Principal information, which could be a UserDetails object representing the authenticated user.</p>"},{"location":"spring/security/security/#accessing-the-authentication","title":"Accessing the Authentication:","text":"<p>To access the Authentication object directly, you can use the same <code>SecurityContextHolder</code>:</p> <pre><code>import org.springframework.security.core.Authentication;\nimport org.springframework.security.core.context.SecurityContextHolder;\n\n...\n\nAuthentication authentication = SecurityContextHolder.getContext().getAuthentication();\nif (authentication != null) {\n    // Access authentication information, such as credentials and authorities\n}\n</code></pre> <p>With access to the Authentication object, you can check the user's credentials, roles, and any additional details related to the authentication process.</p>"},{"location":"spring/security/security/#use-cases-for-principal-and-authentication","title":"Use Cases for Principal and Authentication:","text":"<ul> <li> <p>Authorization Logic: You can use the Principal and Authentication objects to make authorization decisions in your application. For example, you can check if the current user has the necessary roles or permissions to access a specific resource or perform an action.</p> </li> <li> <p>Custom User Information: You can extend the Principal object or customize the Authentication to include additional user information relevant to your application, such as user preferences or user-specific settings.</p> </li> <li> <p>Audit Logging: You can log authentication events and user interactions by extracting information from the Principal and Authentication objects, helping you monitor and track user activities within your application.</p> </li> </ul> <p>By understanding how to access and utilize the Principal and Authentication in Spring Security, you can effectively implement security measures, personalize user experiences, and maintain a secure and accountable environment for your users and applications.</p>"},{"location":"spring/security/security/#understanding-userdetails-and-userdetailsservice","title":"Understanding UserDetails and UserDetailsService","text":"<p>In Spring Security, UserDetails represents user-specific information, while UserDetailsService is responsible for loading user information during authentication. This article delves into these concepts, explaining their roles and providing practical insights with code examples for a clearer understanding.</p> <p>In Spring Security, UserDetails and UserDetailsService are crucial components for managing user authentication and authorization. UserDetails represents user-specific information, while UserDetailsService loads user details during authentication. Let's explore these concepts in depth and understand how they contribute to securing your applications.</p>"},{"location":"spring/security/security/#userdetails","title":"UserDetails:","text":"<p>UserDetails is an interface in Spring Security that represents user-specific information. It encapsulates details about a user, including their username, password, and authorities (roles). By implementing the UserDetails interface or using classes that implement it, you provide Spring Security with essential information about your application's users.</p> <p>Key attributes of UserDetails include:</p> <ul> <li>Username: The user's unique identifier.</li> <li>Password: The user's password, which should be securely hashed.</li> <li>Authorities: The roles or permissions associated with the user.</li> </ul>"},{"location":"spring/security/security/#userdetailsservice","title":"UserDetailsService:","text":"<p>UserDetailsService is an interface responsible for loading user-specific data during the authentication process. It's a vital part of Spring Security's authentication mechanism. When a user attempts to log in, the UserDetailsService is used to retrieve the user's information from a data source (e.g., a database) based on their username. Spring Security then uses this information to perform authentication.</p> <p>Key responsibilities of UserDetailsService include:</p> <ul> <li>Loading user data, typically from a database or another data source.</li> <li>Returning an instance of UserDetails populated with the user's information.</li> <li>Handling exceptions if the user is not found or if there are any errors during user data retrieval.</li> </ul>"},{"location":"spring/security/security/#implementing-userdetails-and-userdetailsservice","title":"Implementing UserDetails and UserDetailsService:","text":"<p>To use UserDetails and UserDetailsService effectively, you'll typically follow these steps:</p> <ol> <li>Implement UserDetails: Create a class that implements the UserDetails interface or use an existing class that provides user-specific information. This class should contain the user's username, password (hashed), and authorities.</li> </ol> <pre><code>public class CustomUserDetails implements UserDetails {\n    private String username;\n    private String password;\n    private Collection&lt;? extends GrantedAuthority&gt; authorities;\n\n    // Implement UserDetails methods\n}\n</code></pre> <ol> <li>Implement UserDetailsService: Create a class that implements the UserDetailsService interface. Override the <code>loadUserByUsername</code> method to load user data based on the provided username.</li> </ol> <pre><code>@Service\npublic class CustomUserDetailsService implements UserDetailsService {\n\n    @Override\n    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {\n        // Load user data from a data source (e.g., database)\n        // Create a UserDetails instance and return it\n    }\n}\n</code></pre> <ol> <li>Configure Authentication Provider: Configure Spring Security to use your custom UserDetailsService to load user data during authentication.</li> </ol> <pre><code>@Autowired\nprivate UserDetailsService userDetailsService;\n\n@Override\nprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\n    auth.userDetailsService(userDetailsService).passwordEncoder(passwordEncoder());\n}\n</code></pre> <ol> <li>Use UserDetails for Authentication: During authentication, Spring Security uses the UserDetails instance returned by the UserDetailsService to compare the provided credentials with the stored ones and perform the authentication process.</li> </ol>"},{"location":"spring/security/security/#practical-example_1","title":"Practical Example:","text":"<p>Here's a simplified example of implementing UserDetails and UserDetailsService:</p> <pre><code>@Entity\npublic class User {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    private String username;\n    private String password;\n    // Other user properties, getters, and setters\n}\n\n@Service\npublic class CustomUserDetailsServiceImpl implements UserDetailsService {\n    @Autowired\n    private UserRepository userRepository;\n\n    @Override\n    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {\n        User user = userRepository.findByUsername(username)\n                .orElseThrow(() -&gt; new UsernameNotFoundException(\"User not found: \" + username));\n\n        return User.builder()\n                .username(user.getUsername())\n                .password(user.getPassword())\n                .authorities(Collections.singleton(new SimpleGrantedAuthority(\"ROLE_USER\")))\n                .build();\n    }\n}\n\n@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n    @Autowired\n    private UserDetailsService userDetailsService;\n\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth.userDetailsService(userDetailsService).passwordEncoder(passwordEncoder());\n    }\n\n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n\n    // Other security configuration\n}\n</code></pre> <p>In this example, we define a User entity representing our application's users and a CustomUserDetailsServiceImpl implementing UserDetailsService to load user data from a database. We then configure Spring Security to use this custom UserDetailsService for authentication.</p> <p>In Spring Security, UserDetails and UserDetailsService are essential components for managing user authentication. UserDetails represents user-specific information, while UserDetailsService loads this information during authentication. By implementing these interfaces and configuring Spring Security to use them, you can securely authenticate users and authorize their access to your application's resources. Understanding these concepts is crucial for building robust and secure authentication mechanisms in your Spring applications.</p>"},{"location":"spring/security/security/#implementing-custom-authentication","title":"Implementing Custom Authentication","text":"<p>Implementing custom authentication in Spring Security involves creating a custom authentication provider, defining a user details service, and configuring authentication using your custom components. This article offers a step-by-step guide with practical examples to help you understand and implement custom authentication effectively.</p> <p>Implementing custom authentication in Spring Security allows you to tailor the authentication process to your application's specific requirements. This involves creating a custom authentication provider, defining a user details service, and configuring authentication using your custom components. Let's walk through the steps of implementing custom authentication in Spring Security with practical examples.</p>"},{"location":"spring/security/security/#steps-to-implement-custom-authentication","title":"Steps to Implement Custom Authentication:","text":""},{"location":"spring/security/security/#1-create-a-user-details-class","title":"1. Create a User Details Class:","text":"<p>Start by creating a class that implements the <code>UserDetails</code> interface or extends a class that implements it. This class represents user-specific information and should include details such as the username, password, and authorities (roles).</p> <pre><code>import org.springframework.security.core.GrantedAuthority;\nimport org.springframework.security.core.userdetails.UserDetails;\n\nimport java.util.Collection;\n\npublic class CustomUserDetails implements UserDetails {\n\n    private String username;\n    private String password;\n    private Collection&lt;? extends GrantedAuthority&gt; authorities;\n\n    // Implement UserDetails methods\n}\n</code></pre>"},{"location":"spring/security/security/#2-define-a-user-details-service","title":"2. Define a User Details Service:","text":"<p>Create a custom user details service by implementing the <code>UserDetailsService</code> interface. Override the <code>loadUserByUsername</code> method to retrieve user data based on the provided username. In this method, you'll return an instance of your custom <code>UserDetails</code> class populated with the user's information.</p> <pre><code>import org.springframework.security.core.userdetails.UserDetails;\nimport org.springframework.security.core.userdetails.UserDetailsService;\nimport org.springframework.security.core.userdetails.UsernameNotFoundException;\n\npublic class CustomUserDetailsService implements UserDetailsService {\n\n    @Override\n    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {\n        // Load user data from your data source (e.g., database)\n        // Create a CustomUserDetails instance and return it\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#3-implement-authentication-provider","title":"3. Implement Authentication Provider:","text":"<p>Next, create a custom authentication provider by implementing the <code>AuthenticationProvider</code> interface. Override the <code>authenticate</code> method to perform authentication based on your custom logic. This is where you can validate user credentials and create an <code>Authentication</code> object if authentication succeeds.</p> <pre><code>import org.springframework.security.authentication.AuthenticationProvider;\nimport org.springframework.security.core.Authentication;\nimport org.springframework.security.core.AuthenticationException;\n\npublic class CustomAuthenticationProvider implements AuthenticationProvider {\n\n    @Override\n    public Authentication authenticate(Authentication authentication) throws AuthenticationException {\n        // Custom authentication logic here\n    }\n\n    @Override\n    public boolean supports(Class&lt;?&gt; authentication) {\n        // Specify the authentication token class supported by this provider\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#4-configure-authentication","title":"4. Configure Authentication:","text":"<p>In your Spring Security configuration class, configure authentication to use your custom user details service and authentication provider. Also, specify the password encoder you want to use for secure password storage.</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private UserDetailsService userDetailsService;\n\n    @Autowired\n    private CustomAuthenticationProvider customAuthenticationProvider;\n\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth.authenticationProvider(customAuthenticationProvider)\n            .userDetailsService(userDetailsService)\n            .passwordEncoder(passwordEncoder());\n    }\n\n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n\n    // Other security configurations\n}\n</code></pre>"},{"location":"spring/security/security/#5-implement-authentication-logic","title":"5. Implement Authentication Logic:","text":"<p>Inside your custom authentication provider's <code>authenticate</code> method, implement your authentication logic. This typically involves checking the provided credentials (e.g., username and password) against your data source, performing any necessary validation, and creating an <code>Authentication</code> object if the authentication is successful.</p> <pre><code>import org.springframework.security.authentication.UsernamePasswordAuthenticationToken;\nimport org.springframework.security.core.Authentication;\nimport org.springframework.security.core.AuthenticationException;\nimport org.springframework.security.core.authority.SimpleGrantedAuthority;\nimport org.springframework.security.core.userdetails.User;\nimport org.springframework.security.core.userdetails.UserDetails;\n\npublic class CustomAuthenticationProvider implements AuthenticationProvider {\n\n    @Override\n    public Authentication authenticate(Authentication authentication) throws AuthenticationException {\n        String username = authentication.getName();\n        String password = authentication.getCredentials().toString();\n\n        // Replace this with your actual user data retrieval logic\n        UserDetails userDetails = loadUserByUsername(username);\n\n        if (userDetails != null &amp;&amp; userDetails.getPassword().equals(password)) {\n            // Authentication succeeds\n            return new UsernamePasswordAuthenticationToken(userDetails, password, userDetails.getAuthorities());\n        } else {\n            // Authentication fails\n            throw new BadCredentialsException(\"Authentication failed\");\n        }\n    }\n\n    @Override\n    public boolean supports(Class&lt;?&gt; authentication) {\n        return authentication.equals(UsernamePasswordAuthenticationToken.class);\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#6-implement-userdetails-logic","title":"6. Implement UserDetails Logic:","text":"<p>In your custom user details service's <code>loadUserByUsername</code> method, load user data from your data source and populate the custom <code>UserDetails</code> object with the necessary information, including the username, password, and authorities (roles).</p> <pre><code>import org.springframework.security.core.userdetails.User;\nimport org.springframework.security.core.userdetails.UserDetails;\nimport org.springframework.security.core.userdetails.UsernameNotFoundException;\n\nimport java.util.Collections;\n\npublic class CustomUserDetailsService implements UserDetailsService {\n\n    @Override\n    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {\n        // Replace this with your actual user data retrieval logic\n        if (\"user\".equals(username)) {\n            // Simulate user data retrieval\n            return new User(username, \"{noop}password\", Collections.singleton(new SimpleGrantedAuthority(\"ROLE_USER\")));\n        } else {\n            throw new UsernameNotFoundException(\"User not found: \" + username);\n        }\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#7-additional-configuration","title":"7. Additional Configuration:","text":"<p>Customize your Spring Security configuration according to your application's needs. You can specify URL-based security rules, configure</p>"},{"location":"spring/security/security/#role-based-and-permission-based-access-control","title":"Role-Based and Permission-Based Access Control","text":"<p>Role-based and permission-based access control are mechanisms in Spring Security that define who can access specific resources or perform certain actions in an application. Role-based access control assigns roles to users, while permission-based access control grants specific permissions to users or roles. This article explores the purposes of these mechanisms with practical examples and code snippets to illustrate their implementation.</p> <p>In Spring Security, role-based and permission-based access control are fundamental strategies for managing and enforcing access to resources and actions within an application. These mechanisms define who can access specific parts of the application and perform certain actions. Let's delve into the purposes of role-based and permission-based access control, accompanied by practical examples and code snippets to clarify their implementation.</p>"},{"location":"spring/security/security/#role-based-access-control","title":"Role-Based Access Control:","text":"<p>Role-based access control (RBAC) aims to assign roles to users based on their responsibilities or job functions. Users with specific roles are granted access to resources or actions associated with those roles. RBAC simplifies access control by categorizing users into roles and defining access rules based on these roles.</p>"},{"location":"spring/security/security/#implementation","title":"Implementation:","text":"<ol> <li> <p>Define Roles: Create roles that represent different levels of access or responsibilities within the application. Common roles might include \"ADMIN,\" \"USER,\" or \"MANAGER.\"</p> </li> <li> <p>Assign Roles: Assign roles to users during user registration or based on their responsibilities within the organization.</p> </li> <li> <p>Configure Access Rules: In your Spring Security configuration, specify which roles can access specific resources or perform certain actions. You can use annotations like <code>@PreAuthorize</code> and <code>@Secured</code> or configure security rules in XML.</p> </li> </ol> <p>Example using annotations:</p> <pre><code>@Controller\npublic class MyController {\n\n    @GetMapping(\"/admin\")\n    @PreAuthorize(\"hasRole('ADMIN')\")\n    public String adminPage() {\n        // Only users with the 'ADMIN' role can access this page\n        return \"admin\";\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#permission-based-access-control","title":"Permission-Based Access Control","text":"<p>Permission-based access control (PBAC) provides fine-grained control over who can access specific resources or perform actions. Instead of relying solely on roles, PBAC assigns explicit permissions to users or roles. This approach is valuable when users within the same role require different levels of access.</p>"},{"location":"spring/security/security/#implementation_1","title":"Implementation:","text":"<ol> <li> <p>Define Permissions: Create permissions that represent specific actions or access levels within the application. Permissions can be strings like \"READ\", \"WRITE\", \"DELETE\", or custom names.</p> </li> <li> <p>Assign Permissions: Assign permissions to users or roles based on their requirements. Users can have multiple permissions, each representing a different action they can perform.</p> </li> <li> <p>Configure Access Rules: In your Spring Security configuration, define access rules that specify which users or roles are allowed to access resources or perform actions based on the assigned permissions.</p> </li> </ol> <p>Example using annotations:</p> <pre><code>@Controller\npublic class MyController {\n\n    @GetMapping(\"/edit\")\n    @PreAuthorize(\"hasPermission('RESOURCE', 'WRITE')\")\n    public String editResource() {\n        // Users with 'WRITE' permission on 'RESOURCE' can access this action\n        return \"edit\";\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#role-based-vs-permission-based-access-control","title":"Role-Based vs. Permission-Based Access Control:","text":"<ul> <li> <p>Role-Based Access Control is suitable when users with the same responsibilities have identical access rights. It simplifies access control by grouping users into roles and defining access based on roles.</p> </li> <li> <p>Permission-Based Access Control is ideal when users within the same role require different levels of access. It offers greater granularity and flexibility by assigning explicit permissions to users or roles.</p> </li> </ul> <p>In practice, a combination of both RBAC and PBAC can be used to strike a balance between simplicity and granularity in access control. Spring Security provides tools and annotations to support both strategies, allowing you to choose the approach that best fits your application's requirements.</p> <p>By understanding the purposes and implementations of role-based and permission-based access control in Spring Security, you can design a robust and secure access control system that ensures users have appropriate access to your application's resources and actions.</p>"},{"location":"spring/security/security/#combining-role-based-and-permission-based-access-control","title":"Combining Role-Based and Permission-Based Access Control:","text":"<p>In many real-world applications, it's common to combine both role-based and permission-based access control to achieve a flexible and comprehensive access control system. Here's how you can integrate both strategies effectively:</p> <ol> <li> <p>Assign Roles: Assign roles to users based on their primary responsibilities or job functions. Roles provide a high-level categorization of access rights.</p> </li> <li> <p>Assign Permissions: Assign permissions to users or roles to grant fine-grained access for specific actions or resources. Permissions allow for more detailed control.</p> </li> <li> <p>Role-Permission Mapping: Define a mapping between roles and permissions. Each role may have associated permissions that define the actions users with that role can perform.</p> </li> <li> <p>Configure Access Rules: In your Spring Security configuration, combine role-based and permission-based access rules. Use annotations or configuration to specify which roles or permissions are required to access resources or perform actions.</p> </li> </ol> <p>Example combining roles and permissions:</p> <pre><code>@Controller\npublic class MyController {\n\n    @GetMapping(\"/admin\")\n    @PreAuthorize(\"hasRole('ADMIN') or hasPermission('RESOURCE', 'WRITE')\")\n    public String adminPage() {\n        // Users with 'ADMIN' role or 'WRITE' permission on 'RESOURCE' can access this page\n        return \"admin\";\n    }\n}\n</code></pre> <p>By integrating both role-based and permission-based access control, you can achieve a flexible and granular access control system that accommodates varying levels of access within your application. This approach allows you to strike a balance between simplicity and fine-grained control, ensuring that users have appropriate access to resources and actions while maintaining security and flexibility.</p> <p>Remember that the choice between role-based and permission-based access control, or a combination of both, depends on your application's specific requirements and the complexity of access control scenarios. Spring Security provides the tools and flexibility to implement the most suitable access control strategy for your project.</p>"},{"location":"spring/security/security/#configuring-role-based-access-control","title":"Configuring Role-Based Access Control","text":"<p>Configuring role-based access control in Spring Security involves defining roles, specifying access rules based on roles, and configuring security settings to enforce these rules. This article provides a step-by-step guide with practical examples and code snippets to help you set up role-based access control effectively.</p> <p>Role-based access control (RBAC) is a vital aspect of security in Spring Security, allowing you to define roles, associate them with users, and specify access rules based on roles. Configuring RBAC involves defining roles, specifying access rules, and configuring security settings to enforce these rules. Let's explore how to configure role-based access control in Spring Security step by step with practical examples.</p>"},{"location":"spring/security/security/#steps-to-configure-role-based-access-control","title":"Steps to Configure Role-Based Access Control:","text":""},{"location":"spring/security/security/#1-define-roles","title":"1. Define Roles:","text":"<p>Start by defining roles that represent different levels of access or responsibilities within your application. Common roles may include \"ADMIN,\" \"USER,\" or \"MANAGER.\" You can define roles as constants or use an enum for better organization.</p> <pre><code>public class Roles {\n    public static final String ADMIN = \"ADMIN\";\n    public static final String USER = \"USER\";\n    // Define other roles as needed\n}\n</code></pre>"},{"location":"spring/security/security/#2-configure-access-rules","title":"2. Configure Access Rules:","text":"<p>In your Spring Security configuration class, specify which roles are allowed to access specific resources or perform certain actions. Use annotations like <code>@PreAuthorize</code> or <code>@Secured</code> to define access rules. For example, in a controller:</p> <pre><code>@Controller\npublic class MyController {\n\n    @GetMapping(\"/admin\")\n    @PreAuthorize(\"hasRole('ADMIN')\")\n    public String adminPage() {\n        // Only users with the 'ADMIN' role can access this page\n        return \"admin\";\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#3-configure-security","title":"3. Configure Security:","text":"<p>Configure your Spring Security settings to enforce the access rules defined in step 2. In your security configuration class, use the <code>antMatchers</code> method to specify URL patterns and their required roles. You can also configure role-based access at the method level using <code>@EnableGlobalMethodSecurity(prePostEnabled = true)</code>.</p> <pre><code>@Configuration\n@EnableWebSecurity\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.authorizeRequests()\n            .antMatchers(\"/admin\").hasRole(Roles.ADMIN)\n            .antMatchers(\"/user\").hasRole(Roles.USER)\n            .anyRequest().authenticated()\n            .and()\n            .formLogin()\n            .and()\n            .logout().permitAll();\n    }\n\n    // Other security configurations\n}\n</code></pre> <p>In this example, the <code>configure</code> method specifies that the \"/admin\" URL requires the \"ADMIN\" role, and the \"/user\" URL requires the \"USER\" role for access. Any other requests are authenticated but do not require specific roles.</p>"},{"location":"spring/security/security/#4-assign-roles-to-users","title":"4. Assign Roles to Users:","text":"<p>During user registration or when managing user profiles, assign roles to users based on their responsibilities or access requirements. You can store user roles in a database or any other data source.</p> <pre><code>@Entity\npublic class User {\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n    private String username;\n    private String password;\n    private Set&lt;Role&gt; roles; // Use a Set to manage multiple roles per user\n    // Other user properties, getters, and setters\n}\n</code></pre>"},{"location":"spring/security/security/#5-secure-resources-and-actions","title":"5. Secure Resources and Actions:","text":"<p>With roles assigned to users, the security configuration ensures that only users with the appropriate roles can access protected resources or perform actions. Users without the required roles will be denied access.</p> <p>Configuring role-based access control in Spring Security involves defining roles, specifying access rules, and configuring security settings to enforce these rules. By following these steps and using annotations and configuration, you can effectively implement RBAC in your Spring applications, ensuring that users have appropriate access to resources and actions based on their roles and responsibilities.</p>"},{"location":"spring/security/security/#additional-considerations-and-best-practices","title":"Additional Considerations and Best Practices:","text":"<ol> <li>Role Hierarchy: In some applications, you may have a hierarchy of roles where one role includes the permissions of another role. Spring Security supports role hierarchies, allowing you to specify relationships between roles.</li> </ol> <pre><code>@Override\nprotected void configure(HttpSecurity http) throws Exception {\n    http.authorizeRequests()\n        .antMatchers(\"/admin\").hasRole(\"ADMIN\")\n        .antMatchers(\"/manager\").hasRole(\"MANAGER\")\n        .antMatchers(\"/user\").hasRole(\"USER\")\n        .and()\n        .formLogin()\n        .and()\n        .logout().permitAll()\n        .and()\n        .hierarchicalRoleNames() // Enable role hierarchy\n        .authorityRolePrefix(\"\"); // Remove \"ROLE_\" prefix for roles\n}\n</code></pre> <ol> <li>Custom Access Denied Page: You can customize the page or behavior displayed when a user without the required role attempts to access a restricted resource. This is done by configuring the <code>accessDeniedPage</code> or handling access denied exceptions.</li> </ol> <pre><code>@Override\nprotected void configure(HttpSecurity http) throws Exception {\n    http.authorizeRequests()\n        .antMatchers(\"/admin\").hasRole(\"ADMIN\")\n        .antMatchers(\"/user\").hasRole(\"USER\")\n        .and()\n        .exceptionHandling()\n        .accessDeniedPage(\"/access-denied\"); // Custom access denied page\n}\n</code></pre> <ol> <li> <p>Dynamic Role Assignment: Depending on your application, you may need to dynamically assign roles to users based on various factors. Consider using custom logic or services to handle dynamic role assignment.</p> </li> <li> <p>Testing: Thoroughly test your role-based access control to ensure that users with the correct roles can access the expected resources and that unauthorized users are denied access.</p> </li> <li> <p>Regular Auditing: Regularly audit and review roles and access rules to ensure that they align with your application's security requirements and remain up to date.</p> </li> </ol> <p>Role-based access control is a fundamental concept in Spring Security, providing a structured and manageable way to control access to resources and actions within your application. By configuring RBAC effectively and following best practices, you can strengthen the security of your Spring-based applications while ensuring that users have the appropriate level of access.</p>"},{"location":"spring/security/security/#explaining-method-level-security","title":"Explaining Method-Level Security","text":"<p>Method-level security in Spring Security allows you to control access to specific methods or functions within your application. You can define access rules and permissions on individual methods, ensuring that only authorized users can execute them. This article provides a comprehensive explanation of method-level security, including practical examples and code snippets to illustrate its implementation.</p> <p>Method-level security is a powerful feature in Spring Security that allows you to control access to specific methods or functions within your application. With method-level security, you can define access rules and permissions on individual methods, ensuring that only authorized users can execute them. Let's dive into the concept of method-level security in Spring Security, providing a thorough explanation along with practical examples and code snippets to demonstrate its implementation.</p>"},{"location":"spring/security/security/#understanding-method-level-security","title":"Understanding Method-Level Security:","text":"<p>Method-level security complements the traditional URL-based security provided by Spring Security. While URL-based security focuses on securing specific URLs or resources, method-level security focuses on securing methods or functions within your application. This is particularly useful when you want to apply fine-grained access control to various parts of your code.</p>"},{"location":"spring/security/security/#key-components","title":"Key Components:","text":"<ol> <li> <p>Annotations: Spring Security provides annotations that you can use to define access rules on methods. The most commonly used annotations for method-level security are <code>@PreAuthorize</code> and <code>@PostAuthorize</code>.</p> </li> <li> <p>Expression Language: These annotations allow you to specify access control expressions using Spring Security's expression language (SpEL). In these expressions, you define who is allowed to execute a method based on user roles, permissions, or other conditions.</p> </li> </ol>"},{"location":"spring/security/security/#practical-implementation","title":"Practical Implementation:","text":""},{"location":"spring/security/security/#1-enable-method-level-security","title":"1. Enable Method-Level Security:","text":"<p>To enable method-level security, you need to configure your Spring Security application to use method security annotations. This is typically done by adding <code>@EnableGlobalMethodSecurity(prePostEnabled = true)</code> to your security configuration class.</p> <pre><code>@Configuration\n@EnableWebSecurity\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n    // Configuration settings\n}\n</code></pre>"},{"location":"spring/security/security/#2-use-preauthorize-and-postauthorize-annotations","title":"2. Use <code>@PreAuthorize</code> and <code>@PostAuthorize</code> Annotations:","text":"<ul> <li> <p><code>@PreAuthorize</code>: This annotation is used to specify access control conditions that must be met before a method is executed. It allows you to define who is authorized to invoke the method based on expressions.</p> </li> <li> <p><code>@PostAuthorize</code>: This annotation is used to specify access control conditions that are checked after a method is executed. It allows you to filter the results of a method based on expressions.</p> </li> </ul>"},{"location":"spring/security/security/#3-define-access-control-expressions","title":"3. Define Access Control Expressions:","text":"<p>In your code, annotate the methods you want to secure with <code>@PreAuthorize</code> or <code>@PostAuthorize</code> and provide access control expressions as values. These expressions define the conditions under which the method can be executed.</p> <pre><code>@Service\npublic class MyService {\n\n    @PreAuthorize(\"hasRole('ADMIN')\")\n    public void adminOnlyMethod() {\n        // This method can only be executed by users with the 'ADMIN' role.\n    }\n\n    @PreAuthorize(\"hasAnyRole('USER', 'MANAGER')\")\n    public void userAndManagerMethod() {\n        // This method can be executed by users with either the 'USER' or 'MANAGER' role.\n    }\n\n    @PostAuthorize(\"returnObject.createdBy == authentication.name\")\n    public MyResource getMyResource() {\n        // This method returns MyResource objects, and the result will be filtered to include\n        // only those where 'createdBy' matches the authenticated user's name.\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#4-access-control-expressions","title":"4. Access Control Expressions:","text":"<p>In access control expressions, you can use various SpEL elements and functions to define conditions. For example:</p> <ul> <li><code>hasRole('ROLE_NAME')</code>: Checks if the user has a specific role.</li> <li><code>hasAnyRole('ROLE1', 'ROLE2')</code>: Checks if the user has any of the specified roles.</li> <li><code>hasAuthority('PERMISSION')</code>: Checks if the user has a specific permission.</li> <li><code>hasAnyAuthority('PERM1', 'PERM2')</code>: Checks if the user has any of the specified permissions.</li> <li><code>isAuthenticated()</code>: Checks if the user is authenticated.</li> <li><code>isAnonymous()</code>: Checks if the user is anonymous (not authenticated).</li> </ul> <p>Method-level security in Spring Security empowers you to apply fine-grained access control to specific methods or functions within your application. By using annotations like <code>@PreAuthorize</code> and <code>@PostAuthorize</code>, along with SpEL expressions, you can define who is authorized to execute a method based on roles, permissions, or custom conditions. This level of control enhances the security and flexibility of your application, ensuring that sensitive operations are protected from unauthorized access.</p>"},{"location":"spring/security/security/#additional-considerations-and-best-practices_1","title":"Additional Considerations and Best Practices:","text":"<ol> <li> <p>Access Control Expressions: Be mindful of the complexity of your access control expressions. While method-level security offers fine-grained control, overly complex expressions can make your code less maintainable. Keep expressions concise and well-documented.</p> </li> <li> <p>Resource-Level Security: In addition to method-level security, consider implementing resource-level security. This involves securing individual resources, such as database records or files, based on user roles or permissions.</p> </li> <li> <p>Error Handling: Properly handle exceptions and error messages when access control expressions fail. Spring Security provides mechanisms to handle authentication and authorization exceptions gracefully.</p> </li> <li> <p>Testing: Thoroughly test your method-level security configurations to ensure that access control expressions work as expected. Write unit tests that cover various scenarios and edge cases.</p> </li> <li> <p>Audit Trails: Consider implementing audit trails to log access to sensitive methods. This can help in tracking and monitoring user activities.</p> </li> <li> <p>Documentation: Clearly document the access control expressions used in your code. Make it easy for other developers (and yourself) to understand the security requirements of each method.</p> </li> <li> <p>Code Reviews: Include security-related code reviews as part of your development process. Ensure that method-level security is correctly implemented and aligned with your application's security policy.</p> </li> <li> <p>Regular Updates: Periodically review and update your access control expressions to accommodate changes in your application's requirements or security policies.</p> </li> </ol> <p>Method-level security in Spring Security is a valuable tool for enforcing fine-grained access control within your application. When used effectively, it enhances the security of your code by ensuring that only authorized users can execute specific methods. By following best practices and considering the points mentioned above, you can maintain a secure and manageable codebase while benefiting from the flexibility offered by method-level security.</p>"},{"location":"spring/security/security/#understanding-spring-security-filters-and-their-purpose","title":"Understanding Spring Security Filters and Their Purpose","text":"<p>Spring Security filters are essential components that play a crucial role in the authentication and authorization process of Spring Security. They handle various security-related tasks, such as authentication, authorization, and request processing. Some important Spring Security filters include <code>UsernamePasswordAuthenticationFilter</code>, <code>BasicAuthenticationFilter</code>, and <code>FilterSecurityInterceptor</code>. This article explains the purpose of Spring Security filters and provides insights into several significant filters used in Spring Security.</p> <p>Spring Security filters are vital components of the Spring Security framework responsible for managing security-related tasks during the authentication and authorization process. These filters handle a wide range of responsibilities, including user authentication, authorization, request processing, and more. Understanding the purpose and function of Spring Security filters is essential for building secure and protected web applications. In this article, we will delve into the role of Spring Security filters and introduce some of the important filters commonly used in Spring Security.</p>"},{"location":"spring/security/security/#purpose-of-spring-security-filters","title":"Purpose of Spring Security Filters:","text":"<ol> <li> <p>Authentication: Spring Security filters are responsible for handling user authentication. They intercept login requests, validate user credentials, and establish user sessions if authentication is successful.</p> </li> <li> <p>Authorization: Filters enforce access control by verifying whether a user is authorized to access specific resources or perform certain actions. They enforce security policies defined in the application.</p> </li> <li> <p>Request Processing: Spring Security filters intercept incoming requests and decide whether they should be allowed to proceed or denied based on security rules.</p> </li> <li> <p>Session Management: Filters manage user sessions, including session creation, tracking, and termination. They can handle features like single sign-on (SSO) and session timeout.</p> </li> <li> <p>Security Headers: Some filters are responsible for adding security-related HTTP headers to responses, such as content security policies (CSP), cross-origin resource sharing (CORS) headers, and HTTP strict transport security (HSTS).</p> </li> </ol>"},{"location":"spring/security/security/#important-spring-security-filters","title":"Important Spring Security Filters:","text":"<ol> <li> <p>UsernamePasswordAuthenticationFilter: This filter handles form-based authentication. It intercepts login requests, extracts user credentials, and initiates the authentication process.</p> </li> <li> <p>BasicAuthenticationFilter: Responsible for processing HTTP Basic Authentication requests, where the username and password are included in the request headers. It extracts credentials and initiates authentication.</p> </li> <li> <p>FilterSecurityInterceptor: Enforces access control decisions for secure objects (resources). It checks whether a user has the required roles or permissions to access a specific resource and decides whether to grant or deny access.</p> </li> <li> <p>ExceptionTranslationFilter: Deals with exceptions thrown during the authentication and authorization process. It translates exceptions into appropriate HTTP responses, such as redirecting to a login page or returning an access denied response.</p> </li> <li> <p>CsrfFilter: Helps protect against Cross-Site Request Forgery (CSRF) attacks by verifying that incoming requests contain a valid CSRF token.</p> </li> <li> <p>SessionManagementFilter: Manages user sessions, including session fixation protection, session timeout handling, and concurrent session control.</p> </li> <li> <p>SecurityHeadersFilter: Adds security-related HTTP headers to responses to enhance security, including headers like X-Content-Type-Options, X-Frame-Options, and Content-Security-Policy (CSP).</p> </li> </ol>"},{"location":"spring/security/security/#example-of-a-spring-security-filter-configuration","title":"Example of a Spring Security Filter Configuration:","text":"<pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private CustomAuthenticationProvider customAuthenticationProvider;\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests()\n                .antMatchers(\"/public/**\").permitAll()\n                .antMatchers(\"/admin/**\").hasRole(\"ADMIN\")\n                .anyRequest().authenticated()\n                .and()\n            .formLogin()\n                .loginPage(\"/login\")\n                .permitAll()\n                .and()\n            .logout()\n                .logoutUrl(\"/logout\")\n                .permitAll();\n    }\n\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth.authenticationProvider(customAuthenticationProvider);\n    }\n}\n</code></pre> <p>In this example, we configure various Spring Security filters through the <code>HttpSecurity</code> object. We specify access rules for different URL patterns, define custom login and logout pages, and configure the authentication provider. Spring Security filters work together to enforce these security settings.</p> <p>Understanding the purpose of Spring Security filters and their interactions is essential for building robust and secure applications. These filters form the backbone of Spring Security's authentication and authorization mechanisms, ensuring that your application's resources are protected and access is controlled according to your security policies.</p>"},{"location":"spring/security/security/#additional-spring-security-filters","title":"Additional Spring Security Filters:","text":"<ol> <li> <p>ConcurrentSessionFilter: Enforces restrictions on concurrent user sessions, preventing users from being logged in multiple times concurrently. You can configure the maximum number of allowed sessions per user.</p> </li> <li> <p>RememberMeAuthenticationFilter: Manages remember-me authentication, allowing users to be automatically logged in even after their session has expired. It handles the remember-me token validation.</p> </li> <li> <p>CorsFilter: Handles Cross-Origin Resource Sharing (CORS) by adding appropriate HTTP headers to responses, allowing or denying cross-origin requests based on the configured policies.</p> </li> <li> <p>RequestCacheAwareFilter: Facilitates handling of cached requests. It can be used in scenarios where a user is redirected to the login page due to authentication requirements and is then redirected back to their original request after successful login.</p> </li> <li> <p>LogoutFilter: Manages the logout process by intercepting logout requests, invalidating user sessions, clearing authentication tokens, and redirecting users to a specified logout success URL.</p> </li> <li> <p>SessionFixationProtectionFilter: Mitigates session fixation attacks by changing the session ID upon successful login. This ensures that any previously obtained session ID becomes invalid.</p> </li> <li> <p>X509AuthenticationFilter: Handles X.509 client certificate authentication, allowing clients to authenticate using X.509 certificates.</p> </li> <li> <p>AnonymousAuthenticationFilter: Provides an anonymous authentication token for unauthenticated users, allowing them to access certain resources while keeping track of their anonymity.</p> </li> </ol> <p>These additional Spring Security filters cater to specific security requirements and scenarios, enhancing the overall security posture of your application.</p>"},{"location":"spring/security/security/#customizing-and-extending-filters","title":"Customizing and Extending Filters:","text":"<p>Spring Security offers flexibility in customizing and extending filters to meet your application's unique needs. You can create custom filters by implementing the <code>javax.servlet.Filter</code> interface and integrate them into the Spring Security filter chain. Custom filters allow you to add custom authentication mechanisms, logging, auditing, or any other security-related functionality.</p> <p>Here's an example of how to add a custom filter to the Spring Security filter chain:</p> <pre><code>public class CustomFilter extends GenericFilterBean {\n\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)\n            throws IOException, ServletException {\n        // Implement custom filter logic here\n        chain.doFilter(request, response);\n    }\n}\n\n@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private CustomFilter customFilter;\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.addFilterBefore(customFilter, UsernamePasswordAuthenticationFilter.class);\n        // Configure other security settings\n    }\n}\n</code></pre> <p>In this example, we create a custom filter <code>CustomFilter</code> by implementing the <code>GenericFilterBean</code> interface. We then add this custom filter to the Spring Security filter chain using the <code>addFilterBefore</code> method.</p> <p>Understanding Spring Security filters and their role in the authentication and authorization process is crucial for building secure web applications. By configuring and customizing these filters effectively, you can enhance the security of your application, protect sensitive resources, and control access based on your application's security policies.</p>"},{"location":"spring/security/security/#filter-order-and-execution","title":"Filter Order and Execution:","text":"<p>It's essential to understand the order in which Spring Security filters are executed in the filter chain. Filters are executed sequentially based on their position in the chain. The order typically matters because some filters may depend on the actions or data manipulated by earlier filters.</p> <p>Spring Security uses integer values to specify filter order, with lower values indicating filters that execute earlier. Filters with higher order values execute later in the chain.</p> <p>For example, the <code>UsernamePasswordAuthenticationFilter</code>, which handles form-based authentication, usually executes early in the chain to process login requests. The <code>FilterSecurityInterceptor</code>, responsible for enforcing access control decisions, typically executes later in the chain.</p> <p>You can explicitly set the order of custom filters using the <code>setOrder</code> method when adding them to the filter chain. This allows you to control the order in which your custom filters are executed.</p> <pre><code>@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private CustomFilter customFilter;\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.addFilterBefore(customFilter, UsernamePasswordAuthenticationFilter.class)\n            .authorizeRequests()\n                .antMatchers(\"/admin/**\").hasRole(\"ADMIN\")\n                .anyRequest().authenticated()\n                .and()\n            .formLogin()\n                .loginPage(\"/login\")\n                .permitAll()\n                .and()\n            .logout()\n                .logoutUrl(\"/logout\")\n                .permitAll();\n    }\n}\n</code></pre> <p>In this example, we add the <code>customFilter</code> before the <code>UsernamePasswordAuthenticationFilter</code> to ensure that our custom filter executes before the authentication filter.</p> <p>Understanding the order of execution is crucial when integrating custom filters or configuring Spring Security in your application to ensure that filters are applied in the desired sequence.</p> <p>In conclusion, Spring Security filters are essential components responsible for managing various security-related tasks in your web application. They play a pivotal role in authentication, authorization, request processing, and securing your resources. By configuring, customizing, and understanding the order of execution of these filters, you can build a robust and secure application that adheres to your specific security requirements.</p>"},{"location":"spring/security/security/#filter-chain-overview","title":"Filter Chain Overview:","text":"<p>To gain a better understanding of how Spring Security filters work together, it's helpful to visualize the typical filter chain in a Spring Security-enabled web application:</p> <ol> <li> <p>SecurityContextPersistenceFilter: This filter ensures that the <code>SecurityContext</code> (which holds the user's authentication details) is available for the duration of the request. It might load the user's authentication details from a session or a security token.</p> </li> <li> <p>UsernamePasswordAuthenticationFilter: Responsible for handling form-based authentication. It intercepts login requests, validates user credentials, and creates an <code>Authentication</code> object if authentication is successful.</p> </li> <li> <p>BasicAuthenticationFilter: Processes HTTP Basic Authentication requests. If a request includes basic authentication headers, this filter extracts and validates the credentials.</p> </li> <li> <p>RememberMeAuthenticationFilter: Manages remember-me authentication, allowing users to be automatically logged in based on a remember-me token.</p> </li> <li> <p>AnonymousAuthenticationFilter: Provides an anonymous authentication token for unauthenticated users. This allows anonymous access to certain resources while still keeping track of the user's anonymity.</p> </li> <li> <p>ExceptionTranslationFilter: Handles exceptions thrown during the authentication and authorization process. It translates exceptions into appropriate HTTP responses, such as redirecting to a login page or returning an access denied response.</p> </li> <li> <p>FilterSecurityInterceptor: Enforces access control decisions for secure objects (resources). It checks whether a user has the required roles or permissions to access a specific resource and decides whether to grant or deny access.</p> </li> <li> <p>LogoutFilter: Manages the logout process, intercepting logout requests, invalidating user sessions, clearing authentication tokens, and redirecting users to a specified logout success URL.</p> </li> <li> <p>SessionManagementFilter: Manages user sessions, including session fixation protection, session timeout handling, and concurrent session control.</p> </li> <li> <p>CsrfFilter: Protects against Cross-Site Request Forgery (CSRF) attacks by verifying that incoming requests contain a valid CSRF token.</p> </li> <li> <p>SecurityHeadersFilter: Adds security-related HTTP headers to responses, enhancing security by configuring headers like X-Content-Type-Options, X-Frame-Options, and Content-Security-Policy (CSP).</p> </li> <li> <p>CorsFilter: Handles Cross-Origin Resource Sharing (CORS) by adding appropriate HTTP headers to responses, allowing or denying cross-origin requests based on the configured policies.</p> </li> <li> <p>RequestCacheAwareFilter: Facilitates handling of cached requests, ensuring that users are redirected back to their original requests after successful login.</p> </li> <li> <p>SessionFixationProtectionFilter: Mitigates session fixation attacks by changing the session ID upon successful login, making any previously obtained session ID invalid.</p> </li> <li> <p>X509AuthenticationFilter: Handles X.509 client certificate authentication, allowing clients to authenticate using X.509 certificates.</p> </li> <li> <p>ConcurrentSessionFilter: Enforces restrictions on concurrent user sessions, preventing users from being logged in multiple times concurrently.</p> </li> </ol> <p>These filters work together to ensure the security of your web application. The order of execution, as previously mentioned, is determined by the filter chain configuration and the filter's order values.</p> <p>As a developer, you can customize and extend this filter chain to meet your application's specific security requirements. Understanding the purpose and order of Spring Security filters is crucial for building a secure and well-protected web application.</p>"},{"location":"spring/security/security/#additional-filters-and-customization","title":"Additional Filters and Customization:","text":"<ol> <li> <p>Custom Filters: Apart from the built-in filters, you can create your custom filters to address specific security requirements. Custom filters give you complete control over how requests are processed, authenticated, and authorized. You can implement custom filters by extending the <code>GenericFilterBean</code> class and implementing the <code>doFilter</code> method.</p> </li> <li> <p>Filter Chain Customization: Spring Security provides extensive flexibility for customizing the filter chain to match your application's needs. You can add, remove, or reorder filters in the chain to tailor the security processing flow. Customizing the filter chain is often done through Java configuration or XML configuration, depending on your project setup.</p> </li> <li> <p>Conditional Filters: You can conditionally enable or disable filters based on specific conditions. For example, you might enable certain filters only for specific URL patterns or based on user roles.</p> </li> <li> <p>Composite Filters: Spring Security allows you to create composite filters that encapsulate multiple filters and apply them as a single unit. This is useful for simplifying filter chain configuration when dealing with complex security requirements.</p> </li> <li> <p>Filter Chaining: Spring Security supports multiple filter chains within a single application. This is particularly valuable when you need different security configurations for various parts of your application. Each filter chain can have its set of filters and rules.</p> </li> <li> <p>Exception Handling: Filters may throw exceptions during processing, such as authentication failures or access denied exceptions. Properly handle these exceptions to provide meaningful error messages or redirect users to appropriate error pages.</p> </li> <li> <p>Logging and Auditing: Consider adding logging and auditing mechanisms within your custom filters to monitor and record security-related events. This can be invaluable for troubleshooting and security analysis.</p> </li> <li> <p>Security Headers Configuration: Configure security headers in your application to protect against common web security threats. Spring Security provides filter-based mechanisms for adding security headers, but you can also set them in your application server or web server.</p> </li> <li> <p>Third-Party Integration: When working with third-party authentication providers (e.g., OAuth2 or SAML), you may need to integrate additional filters specific to those providers. Spring Security offers extensions and libraries for seamless integration.</p> </li> <li> <p>Testing Filters: Testing Spring Security filters is essential to ensure they function as expected. Use tools like Spring Security Test to create unit tests for your custom filters and validate their behavior.</p> </li> </ol> <p>By understanding these additional aspects and taking advantage of customization options, you can tailor Spring Security filters to meet the unique security requirements of your application. Effective configuration and management of filters are key to building a robust and secure web application that protects sensitive data and resources.</p>"},{"location":"spring/security/security/#spring-security-session-management-and-authentication-mechanisms-jwt-and-oauth2","title":"Spring Security Session Management and Authentication Mechanisms (JWT and OAuth2)","text":"<p>Spring Security provides flexible options for session management and supports various authentication mechanisms, including JWT (JSON Web Tokens) and OAuth2. It offers built-in support for session handling, and you can integrate third-party libraries for JWT and OAuth2. This article explains Spring Security's session management features, JWT authentication, and OAuth2 integration with practical examples.</p> <p>Spring Security is a versatile framework that offers robust solutions for session management and supports various authentication mechanisms, including JWT (JSON Web Tokens) and OAuth2. This article explores how Spring Security handles session management and integrates with these authentication mechanisms to provide secure authentication and authorization in your applications.</p>"},{"location":"spring/security/security/#spring-security-session-management","title":"Spring Security Session Management:","text":"<p>Spring Security provides comprehensive session management capabilities to control user sessions and enhance security. Key features include:</p> <ol> <li> <p>Session Fixation Protection: Spring Security protects against session fixation attacks by automatically generating a new session upon user authentication. This ensures that any existing session is invalidated.</p> </li> <li> <p>Session Timeout Handling: You can configure session timeout settings, defining how long an idle session remains active before it expires. When a session times out, users are automatically logged out.</p> </li> <li> <p>Concurrent Session Control: Spring Security enables you to limit the number of concurrent user sessions. You can specify the maximum number of allowed sessions per user, and additional login attempts are denied once the limit is reached.</p> </li> <li> <p>Single Sign-On (SSO): Spring Security supports single sign-on mechanisms, allowing users to log in once and access multiple applications without needing to authenticate repeatedly.</p> </li> </ol>"},{"location":"spring/security/security/#jwt-json-web-tokens-authentication","title":"JWT (JSON Web Tokens) Authentication:","text":"<p>JWT is a popular authentication mechanism used in modern web applications. Spring Security can integrate JWT authentication seamlessly. Here's a high-level overview of how it works:</p> <ol> <li> <p>JWT Generation: When a user successfully authenticates, the server generates a JWT containing user information and signs it with a secret key. The JWT is then sent to the client.</p> </li> <li> <p>JWT Storage: The client stores the JWT, typically in local storage or a cookie.</p> </li> <li> <p>JWT Authentication: For subsequent requests, the client includes the JWT in the request header. Spring Security validates the JWT's signature, extracts user information, and authenticates the user based on the JWT content.</p> </li> <li> <p>Authorization: After successful JWT validation, Spring Security authorizes the user to access protected resources based on their roles and permissions.</p> </li> </ol> <p>Example configuration for JWT authentication in Spring Security:</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http.csrf().disable()\n            .authorizeRequests()\n                .antMatchers(\"/public/**\").permitAll()\n                .antMatchers(\"/secure/**\").authenticated()\n                .and()\n            .addFilter(new JwtAuthenticationFilter(authenticationManager()))\n            .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);\n    }\n}\n</code></pre>"},{"location":"spring/security/security/#oauth2-integration","title":"OAuth2 Integration:","text":"<p>OAuth2 is a widely adopted standard for secure authentication and authorization. Spring Security can be extended to integrate OAuth2 providers such as Google, Facebook, or custom OAuth2 servers. Here's an overview:</p> <ol> <li> <p>OAuth2 Provider Configuration: Configure Spring Security to recognize and interact with your chosen OAuth2 provider, specifying client credentials and redirect URIs.</p> </li> <li> <p>User Authentication: When a user initiates OAuth2 login, Spring Security redirects them to the OAuth2 provider's login page. After successful authentication, the provider issues an access token.</p> </li> <li> <p>Access Token Handling: Spring Security validates the access token received from the OAuth2 provider. If valid, it associates the authenticated user with the local session.</p> </li> <li> <p>Authorization: Users are granted access to resources based on their roles and permissions, similar to traditional Spring Security authentication.</p> </li> </ol> <p>Example configuration for OAuth2 integration with Google in Spring Security:</p> <pre><code>@Configuration\n@EnableOAuth2Client\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private OAuth2ClientContext oauth2ClientContext;\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests()\n                .antMatchers(\"/public/**\").permitAll()\n                .antMatchers(\"/secure/**\").authenticated()\n                .and()\n            .addFilterBefore(ssoFilter(), BasicAuthenticationFilter.class)\n            .csrf().disable();\n    }\n\n    private Filter ssoFilter() {\n        OAuth2ClientAuthenticationProcessingFilter filter = new OAuth2ClientAuthenticationProcessingFilter(\"/login/google\");\n        OAuth2RestTemplate restTemplate = new OAuth2RestTemplate(google(), oauth2ClientContext);\n        filter.setRestTemplate(restTemplate);\n        filter.setTokenServices(new UserInfoTokenServices(googleResource().getUserInfoUri(), google().getClientId()));\n        return filter;\n    }\n\n    @Bean\n    @ConfigurationProperties(\"google.client\")\n    public AuthorizationCodeResourceDetails google() {\n        return new AuthorizationCodeResourceDetails();\n    }\n\n    @Bean\n    @ConfigurationProperties(\"google.resource\")\n    public ResourceServerProperties googleResource() {\n        return new ResourceServerProperties();\n    }\n}\n</code></pre> <p>In this example, we configure OAuth2 integration with Google as an OAuth2 provider. Spring Security handles the OAuth2 authentication process and allows access to protected resources after successful authentication.</p> <p>By leveraging Spring Security's session management and integrating with authentication mechanisms like JWT and OAuth2, you can build secure and user-friendly web applications that protect user data and ensure seamless authentication and authorization. These features make Spring Security a powerful choice for implementing robust security in your projects.</p>"},{"location":"spring/security/security/#additional-considerations-and-best-practices_2","title":"Additional Considerations and Best Practices:","text":"<ol> <li> <p>Token Expiration: When using JWT or OAuth2, it's essential to configure token expiration properly. Short-lived tokens reduce the risk of unauthorized access if tokens are leaked. Implement token refresh mechanisms when necessary.</p> </li> <li> <p>Token Validation: Ensure that tokens are validated correctly, including signature verification and checking the token's integrity. Avoid using insecure JWT libraries or configurations.</p> </li> <li> <p>Secret Management: Safeguard the secrets used for signing JWTs or interacting with OAuth2 providers. Store secrets securely and avoid hardcoding them in your application code.</p> </li> <li> <p>Token Revocation: Consider implementing token revocation mechanisms to invalidate tokens in case of security breaches or user logout.</p> </li> <li> <p>OAuth2 Scopes: Understand and use OAuth2 scopes effectively to control the level of access granted to third-party applications. Define scopes that align with your application's security requirements.</p> </li> <li> <p>User Consent: If your application uses OAuth2 for third-party authentication, ensure that users are provided with clear information and options to consent to the data access requested by the third-party application.</p> </li> <li> <p>Logging and Monitoring: Implement logging and monitoring of authentication and authorization processes. This helps in detecting and responding to security incidents.</p> </li> <li> <p>Rate Limiting: Protect your authentication and authorization endpoints with rate limiting to mitigate brute-force and denial-of-service attacks.</p> </li> <li> <p>HTTPS: Always use HTTPS to secure communication between your application and the authentication provider, especially when dealing with tokens and sensitive user information.</p> </li> <li> <p>User Management: Ensure that user accounts are managed securely, including password management, account recovery processes, and enforcing strong password policies.</p> </li> <li> <p>JWT Claims: Use JWT claims to convey additional information about the user or the token itself. Be cautious about the information included in claims to avoid potential security risks.</p> </li> <li> <p>Token Storage: When working with JWT, consider where and how tokens are stored on the client-side. Avoid exposing tokens in URLs or storing them in insecure locations.</p> </li> <li> <p>OpenID Connect: If implementing OAuth2 for identity and user information, consider using OpenID Connect, an authentication layer on top of OAuth2 that provides standardized user information and authentication features.</p> </li> <li> <p>Testing: Perform security testing, including penetration testing and vulnerability scanning, to identify and address security weaknesses in your authentication mechanisms.</p> </li> <li> <p>Keep Dependencies Updated: Regularly update your Spring Security, JWT, or OAuth2 dependencies to benefit from security patches and improvements.</p> </li> </ol> <p>By following these additional considerations and best practices, you can enhance the security of your authentication mechanisms and provide a safer and more reliable experience for your users while using Spring Security in your applications.</p>"},{"location":"spring/security/security/#understanding-authentication-providers","title":"Understanding Authentication Providers","text":"<p>Authentication providers in Spring Security are responsible for validating user credentials and determining if a user is who they claim to be. They play a crucial role in the authentication process by verifying usernames and passwords or other authentication tokens. Spring Security supports various authentication providers, including <code>DaoAuthenticationProvider</code>, <code>LdapAuthenticationProvider</code>, and custom providers. This article explores the concept of authentication providers in Spring Security with practical examples.</p> <p>Authentication providers in Spring Security are central components responsible for verifying the identity of users during the authentication process. They determine whether a user is who they claim to be by validating their credentials, such as usernames and passwords, or other authentication tokens. Spring Security offers flexibility in choosing and configuring authentication providers to suit your application's needs. This article delves into the concept of authentication providers in Spring Security and provides insights with practical examples.</p>"},{"location":"spring/security/security/#role-of-authentication-providers","title":"Role of Authentication Providers:","text":"<p>Authentication providers perform the following key tasks:</p> <ol> <li> <p>Credential Validation: Authentication providers validate user-supplied credentials, such as usernames and passwords, to ensure they match the expected values stored in a data source. This data source can be a database, LDAP server, or any custom authentication repository.</p> </li> <li> <p>Authentication Token Creation: Upon successful validation, authentication providers create an authentication token representing the authenticated user. This token is then associated with the user's security context for the duration of their session.</p> </li> <li> <p>Error Handling: Authentication providers handle authentication failures by throwing appropriate exceptions when credentials are incorrect. Spring Security can translate these exceptions into meaningful error messages or redirect users to a login page.</p> </li> </ol>"},{"location":"spring/security/security/#built-in-authentication-providers","title":"Built-in Authentication Providers:","text":"<p>Spring Security provides several built-in authentication providers:</p> <ol> <li> <p>DaoAuthenticationProvider: This provider is commonly used for database-based authentication. It validates credentials against a database table, where user details such as usernames and encrypted passwords are stored.</p> </li> <li> <p>LdapAuthenticationProvider: Used for LDAP (Lightweight Directory Access Protocol) authentication. It connects to an LDAP server to validate user credentials and retrieve user details.</p> </li> <li> <p>JwtAuthenticationProvider: Specialized for validating JWT (JSON Web Tokens) issued by external identity providers or for stateless authentication.</p> </li> <li> <p>RememberMeAuthenticationProvider: Handles remember-me authentication, allowing users to be automatically logged in based on remember-me tokens.</p> </li> <li> <p>AnonymousAuthenticationProvider: Provides an anonymous authentication token for unauthenticated users, allowing them to access certain resources while maintaining anonymity.</p> </li> </ol>"},{"location":"spring/security/security/#configuration-example-with-daoauthenticationprovider","title":"Configuration Example with DaoAuthenticationProvider:","text":"<pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private UserDetailsService userDetailsService;\n\n    @Bean\n    public DaoAuthenticationProvider authenticationProvider() {\n        DaoAuthenticationProvider authProvider = new DaoAuthenticationProvider();\n        authProvider.setUserDetailsService(userDetailsService);\n        authProvider.setPasswordEncoder(passwordEncoder());\n        return authProvider;\n    }\n\n    @Override\n    protected void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth.authenticationProvider(authenticationProvider());\n    }\n\n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n}\n</code></pre> <p>In this example, we configure a <code>DaoAuthenticationProvider</code> to validate user credentials stored in a database. We specify a custom <code>UserDetailsService</code> to load user details from the database, and we use the BCrypt password encoder for secure password hashing.</p>"},{"location":"spring/security/security/#custom-authentication-providers","title":"Custom Authentication Providers:","text":"<p>You can also create custom authentication providers by implementing the <code>AuthenticationProvider</code> interface. Custom providers allow you to integrate with unique authentication sources or implement complex authentication logic specific to your application.</p> <pre><code>public class CustomAuthenticationProvider implements AuthenticationProvider {\n\n    @Override\n    public Authentication authenticate(Authentication authentication) throws AuthenticationException {\n        // Implement custom authentication logic here\n        // Return an Authentication object if authentication is successful\n        // Throw AuthenticationException if authentication fails\n    }\n\n    @Override\n    public boolean supports(Class&lt;?&gt; authentication) {\n        // Specify which authentication token types this provider supports\n        // For example, UsernamePasswordAuthenticationToken.class\n    }\n}\n</code></pre> <p>Custom authentication providers can be added to the authentication manager using the <code>AuthenticationManagerBuilder</code>.</p> <p>By understanding the role and configuration of authentication providers in Spring Security, you can implement secure and flexible authentication processes that suit your application's requirements. Whether using built-in providers or creating custom ones, authentication providers are essential for ensuring the identity and security of your users.</p>"},{"location":"spring/security/security/#authentication-provider-configuration","title":"Authentication Provider Configuration:","text":"<ol> <li> <p>AuthenticationManagerBuilder: Spring Security offers the <code>AuthenticationManagerBuilder</code> class, which simplifies the configuration of authentication providers. You can use its fluent API to specify authentication providers and configure their behavior.</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private UserDetailsService userDetailsService;\n\n    @Autowired\n    public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception {\n        auth\n            .userDetailsService(userDetailsService)\n            .passwordEncoder(passwordEncoder());\n    }\n\n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n}\n</code></pre> </li> </ol> <p>In this example, we configure a <code>DaoAuthenticationProvider</code> that uses a <code>UserDetailsService</code> to load user details and a <code>BCryptPasswordEncoder</code> for password encoding.</p> <ol> <li> <p>AuthenticationProvider Interface: When creating custom authentication providers, you implement the <code>AuthenticationProvider</code> interface. This interface requires you to implement the <code>authenticate</code> method, where you perform custom authentication logic. You also need to define the <code>supports</code> method to specify which authentication token types the provider supports.</p> <pre><code>public class CustomAuthenticationProvider implements AuthenticationProvider {\n\n    @Override\n    public Authentication authenticate(Authentication authentication) throws AuthenticationException {\n        // Implement custom authentication logic here\n    }\n\n    @Override\n    public boolean supports(Class&lt;?&gt; authentication) {\n        // Specify supported authentication token types\n    }\n}\n</code></pre> </li> </ol> <p>After implementing your custom provider, you can configure it in your Spring Security configuration.</p> <ol> <li> <p>Multiple Authentication Providers: Spring Security allows you to configure multiple authentication providers, which can be used for different authentication mechanisms or sources. When multiple providers are configured, Spring Security iterates through them to find the one that supports the provided authentication token.</p> <pre><code>@Configuration\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private UserDetailsService userDetailsService;\n\n    @Autowired\n    private CustomAuthenticationProvider customAuthenticationProvider;\n\n    @Override\n    public void configure(AuthenticationManagerBuilder auth) throws Exception {\n        auth\n            .userDetailsService(userDetailsService)\n            .passwordEncoder(passwordEncoder())\n            .and()\n            .authenticationProvider(customAuthenticationProvider);\n    }\n\n    @Bean\n    public PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n}\n</code></pre> </li> </ol> <p>In this example, both a built-in <code>DaoAuthenticationProvider</code> and a custom <code>CustomAuthenticationProvider</code> are configured to handle authentication.</p>"},{"location":"spring/security/security/#authentication-flow","title":"Authentication Flow:","text":"<p>When a user attempts to authenticate, Spring Security's authentication manager iterates through the configured authentication providers, invoking the <code>authenticate</code> method of each provider. If a provider successfully authenticates the user, it returns an <code>Authentication</code> object with the user's details and credentials.</p> <p>The authentication manager selects the first successful authentication provider and associates the corresponding <code>Authentication</code> object with the user's security context. If none of the providers succeeds, an <code>AuthenticationException</code> is thrown, indicating authentication failure.</p> <p>Authentication providers in Spring Security are a crucial part of the authentication process, allowing you to integrate various authentication sources and mechanisms seamlessly. Whether using built-in providers or creating custom ones, understanding their configuration and role is essential for building a secure authentication system in your application.</p>"},{"location":"spring/security/security/#examples-of-authentication-providers","title":"Examples of Authentication Providers:","text":""},{"location":"spring/security/security/#1-pingfederate","title":"1. PingFederate:","text":"<p>PingFederate is a popular identity provider that supports various authentication methods, including SAML (Security Assertion Markup Language) and OAuth2. To integrate PingFederate with Spring Security, you can use the <code>SAMLAuthenticationProvider</code> or <code>OAuth2LoginAuthenticationProvider</code> provided by Spring Security.</p> <p>Example configuration for PingFederate SAML integration:</p> <pre><code>@Bean\npublic SAMLConfigurer saml() {\n    return new SAMLConfigurer()\n        .sso()\n            .defaultSuccessURL(\"/home\")\n            .and()\n        .userDetailsService(samlUserDetailsService())\n        .sso()\n            .ssoEndpoint(\"/sso/pingfederate\")\n            .and()\n        .metadataManager()\n            .metadata(\"https://pingfederate.example.com/idp/metadata\")\n            .and()\n        .keyManager()\n            .storeFilePath(\"classpath:saml/keystore.jks\")\n            .storePassword(\"keystore-password\")\n            .defaultKey(\"key-alias\");\n}\n</code></pre>"},{"location":"spring/security/security/#2-okta","title":"2. Okta:","text":"<p>Okta is an identity and access management platform. To integrate Okta with Spring Security, you can use Okta's OIDC (OpenID Connect) authentication flow along with Spring Security's <code>OidcUserService</code>.</p> <p>Example configuration for Okta OIDC integration:</p> <pre><code>@Bean\npublic SecurityFilterChain defaultSecurityFilterChain(HttpSecurity http) throws Exception {\n    http\n        .authorizeRequests(authorizeRequests -&gt;\n            authorizeRequests\n                .antMatchers(\"/public/**\").permitAll()\n                .anyRequest().authenticated()\n        )\n        .oauth2Login(oauth2Login -&gt;\n            oauth2Login\n                .userInfoEndpoint(userInfoEndpoint -&gt;\n                    userInfoEndpoint.oidcUserService(oidcUserService())\n                )\n        );\n    return http.build();\n}\n</code></pre>"},{"location":"spring/security/security/#3-custom-authentication-providers","title":"3. Custom Authentication Providers:","text":"<p>Besides external identity providers, you can also create custom authentication providers to integrate with in-house authentication systems or other third-party systems that don't follow standard protocols. Implement the <code>AuthenticationProvider</code> interface to define your custom authentication logic.</p> <p>Example of a custom authentication provider:</p> <pre><code>public class CustomAuthenticationProvider implements AuthenticationProvider {\n\n    @Override\n    public Authentication authenticate(Authentication authentication) throws AuthenticationException {\n        // Implement custom authentication logic here\n    }\n\n    @Override\n    public boolean supports(Class&lt;?&gt; authentication) {\n        // Specify supported authentication token types\n    }\n}\n</code></pre> <p>Authentication providers in Spring Security provide the flexibility to integrate with a wide range of identity and authentication systems, allowing your application to leverage external authentication sources seamlessly. Whether you're integrating with well-known identity providers like PingFederate and Okta or building custom authentication solutions, Spring Security offers the tools and configurations needed to make the integration process straightforward and secure.</p>"},{"location":"spring/security/security/#4-microsoft-azure-active-directory-azure-ad","title":"4. Microsoft Azure Active Directory (Azure AD):","text":"<p>Azure AD is Microsoft's cloud-based identity and access management service. It supports various authentication protocols, including OpenID Connect and SAML. To integrate Azure AD with Spring Security, you can use Spring Security's <code>OidcUserService</code> for OpenID Connect-based authentication or <code>SAMLConfigurer</code> for SAML-based authentication.</p> <p>Example configuration for Azure AD OpenID Connect integration:</p> <pre><code>@Bean\npublic SecurityFilterChain defaultSecurityFilterChain(HttpSecurity http) throws Exception {\n    http\n        .authorizeRequests(authorizeRequests -&gt;\n            authorizeRequests\n                .antMatchers(\"/public/**\").permitAll()\n                .anyRequest().authenticated()\n        )\n        .oauth2Login(oauth2Login -&gt;\n            oauth2Login\n                .userInfoEndpoint(userInfoEndpoint -&gt;\n                    userInfoEndpoint.oidcUserService(oidcUserService())\n                )\n        );\n    return http.build();\n}\n</code></pre>"},{"location":"spring/security/security/#5-keycloak","title":"5. Keycloak:","text":"<p>Keycloak is an open-source identity and access management solution. It supports standard protocols like OpenID Connect and OAuth2. To integrate Keycloak with Spring Security, you can use Spring Security's <code>OidcUserService</code> for OpenID Connect-based authentication or <code>OAuth2LoginAuthenticationProvider</code> for OAuth2-based authentication.</p> <p>Example configuration for Keycloak OpenID Connect integration:</p> <pre><code>@Bean\npublic SecurityFilterChain defaultSecurityFilterChain(HttpSecurity http) throws Exception {\n    http\n        .authorizeRequests(authorizeRequests -&gt;\n            authorizeRequests\n                .antMatchers(\"/public/**\").permitAll()\n                .anyRequest().authenticated()\n        )\n        .oauth2Login(oauth2Login -&gt;\n            oauth2Login\n                .userInfoEndpoint(userInfoEndpoint -&gt;\n                    userInfoEndpoint.oidcUserService(oidcUserService())\n                )\n        );\n    return http.build();\n}\n</code></pre> <p>These are just a few examples of identity providers that you can integrate with Spring Security. Each identity provider may require specific configurations and settings in your Spring Security configuration. By understanding the integration requirements of your chosen identity provider and leveraging Spring Security's extensibility, you can seamlessly integrate external authentication systems into your application and enhance its security and user experience.</p>"},{"location":"spring/security/security/#common-security-best-practices-with-spring-security","title":"Common Security Best Practices with Spring Security","text":"<p>When using Spring Security, implementing robust security practices is essential to protect your application from threats. This article outlines key security best practices, including strong password management, session management, secure communication, and auditing. By following these practices, you can build a secure and resilient application using Spring Security.</p> <p>Spring Security is a powerful framework for securing your Java-based applications, but effective security requires a proactive approach. Here are some common security best practices to follow when using Spring Security:</p>"},{"location":"spring/security/security/#1-strong-password-management","title":"1. Strong Password Management:","text":"<ul> <li> <p>Password Hashing: Store passwords securely by using strong cryptographic hash functions like BCrypt. Spring Security provides password encoder implementations for this purpose.</p> <pre><code>@Bean\npublic PasswordEncoder passwordEncoder() {\n    return new BCryptPasswordEncoder();\n}\n</code></pre> </li> <li> <p>Password Policies: Enforce strong password policies, including minimum length, complexity, and expiration. Spring Security allows you to customize password validation rules.</p> </li> </ul>"},{"location":"spring/security/security/#2-session-management","title":"2. Session Management:","text":"<ul> <li> <p>Session Timeout: Set appropriate session timeouts to ensure that inactive sessions are terminated. Configure session management in your Spring Security configuration.</p> <pre><code>http.sessionManagement()\n    .maximumSessions(1)\n    .expiredUrl(\"/login?expired\")\n    .sessionRegistry(sessionRegistry());\n</code></pre> </li> <li> <p>Session Fixation Protection: Enable session fixation protection to invalidate and recreate sessions upon user login.</p> </li> </ul>"},{"location":"spring/security/security/#3-secure-communication","title":"3. Secure Communication:","text":"<ul> <li> <p>Use HTTPS: Always use HTTPS to encrypt data transmitted between the client and server, especially during authentication and sensitive transactions.</p> <pre><code>http.requiresChannel().anyRequest().requiresSecure();\n</code></pre> </li> <li> <p>Secure Cookies: Mark cookies as secure to ensure they are transmitted over HTTPS only.</p> <pre><code>http\n    .authorizeRequests()\n        .antMatchers(\"/secure/**\").authenticated()\n        .and()\n    .rememberMe()\n        .key(\"your-secure-key\")\n        .rememberMeCookieName(\"your-secure-cookie\")\n        .useSecureCookie(true);\n</code></pre> </li> </ul>"},{"location":"spring/security/security/#4-user-account-management","title":"4. User Account Management:","text":"<ul> <li> <p>Account Locking: Implement account locking mechanisms to prevent brute-force attacks. Lock user accounts after a certain number of failed login attempts.</p> </li> <li> <p>Password Reset: Offer secure password reset and account recovery options, including email verification and multi-factor authentication.</p> </li> </ul>"},{"location":"spring/security/security/#5-auditing-and-logging","title":"5. Auditing and Logging:","text":"<ul> <li> <p>Audit Trails: Log security-related events and user actions. Maintain an audit trail for potential forensic analysis in case of security incidents.</p> </li> <li> <p>Access Control: Implement detailed access control and authorization checks throughout your application. Ensure that users have appropriate permissions to access resources.</p> </li> </ul>"},{"location":"spring/security/security/#6-security-headers","title":"6. Security Headers:","text":"<ul> <li> <p>HTTP Security Headers: Add security headers to HTTP responses to mitigate common web vulnerabilities. Configure headers like <code>X-Content-Type-Options</code>, <code>X-Frame-Options</code>, and <code>Content-Security-Policy</code>.</p> <pre><code>http.headers()\n    .contentSecurityPolicy(\"script-src 'self'\")\n    .frameOptions().deny()\n    .contentTypeOptions().nosniff();\n</code></pre> </li> </ul>"},{"location":"spring/security/security/#7-role-based-access-control","title":"7. Role-Based Access Control:","text":"<ul> <li> <p>Role-Based Authorization: Implement role-based access control (RBAC) to define and enforce fine-grained access permissions for different user roles.</p> <pre><code>http.authorizeRequests()\n    .antMatchers(\"/admin/**\").hasRole(\"ADMIN\")\n    .antMatchers(\"/user/**\").hasRole(\"USER\")\n    .antMatchers(\"/public/**\").permitAll()\n    .anyRequest().authenticated();\n</code></pre> </li> </ul>"},{"location":"spring/security/security/#8-regular-security-updates","title":"8. Regular Security Updates:","text":"<ul> <li>Dependency Management: Keep Spring Security and its dependencies up to date to benefit from security patches and improvements.</li> </ul> <p>By following these best practices and continually monitoring and adapting to emerging security threats, you can ensure that your Spring Security-enabled application remains resilient against potential security risks. Building a secure application is an ongoing process that requires vigilance and proactive security measures.</p>"},{"location":"spring/security/security/#9-implement-two-factor-authentication-2fa","title":"9. Implement Two-Factor Authentication (2FA):","text":"<ul> <li>Two-Factor Authentication: Encourage or require users to enable two-factor authentication (2FA) for their accounts. 2FA adds an extra layer of security by verifying users' identities using something they know (password) and something they have (e.g., a mobile app-generated code).</li> </ul>"},{"location":"spring/security/security/#10-protect-against-cross-site-request-forgery-csrf","title":"10. Protect Against Cross-Site Request Forgery (CSRF):","text":"<ul> <li> <p>CSRF Protection: Ensure your application is protected against Cross-Site Request Forgery (CSRF) attacks by enabling CSRF protection in Spring Security. Use tokens to validate the authenticity of requests.</p> <pre><code>http.csrf()\n    .csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());\n</code></pre> </li> </ul>"},{"location":"spring/security/security/#11-validate-and-sanitize-user-input","title":"11. Validate and Sanitize User Input:","text":"<ul> <li>Input Validation: Always validate and sanitize user input to prevent common security vulnerabilities such as SQL injection, Cross-Site Scripting (XSS), and other injection attacks.</li> </ul>"},{"location":"spring/security/security/#12-rate-limiting-and-brute-force-protection","title":"12. Rate Limiting and Brute-Force Protection:","text":"<ul> <li>Rate Limiting: Implement rate limiting for login attempts and API requests to mitigate brute-force and denial-of-service attacks.</li> </ul>"},{"location":"spring/security/security/#13-security-testing","title":"13. Security Testing:","text":"<ul> <li>Security Testing: Regularly conduct security testing, including penetration testing and vulnerability scanning, to identify and address potential security weaknesses in your application.</li> </ul>"},{"location":"spring/security/security/#14-error-handling","title":"14. Error Handling:","text":"<ul> <li> <p>Custom Error Pages: Customize error pages to provide minimal information about errors to prevent information leakage to potential attackers.</p> <pre><code>http.exceptionHandling()\n    .accessDeniedPage(\"/error/access-denied\");\n</code></pre> </li> </ul>"},{"location":"spring/security/security/#15-security-headers-in-spring-security-filters","title":"15. Security Headers in Spring Security Filters:","text":"<ul> <li> <p>Security Headers: Implement security headers within your Spring Security configuration or by using Spring Security filters. These headers add extra layers of security to your application.</p> <pre><code>http.headers()\n    .contentSecurityPolicy(\"script-src 'self'\")\n    .frameOptions().deny()\n    .contentTypeOptions().nosniff();\n</code></pre> </li> </ul>"},{"location":"spring/security/security/#16-regular-security-training","title":"16. Regular Security Training:","text":"<ul> <li>Security Training: Train your development and operations teams on security best practices, and encourage a security-conscious culture within your organization.</li> </ul>"},{"location":"spring/security/security/#17-compliance-with-regulations","title":"17. Compliance with Regulations:","text":"<ul> <li>Regulatory Compliance: If your application handles sensitive data or operates in regulated industries (e.g., healthcare or finance), ensure compliance with relevant regulations (e.g., GDPR, HIPAA, or PCI DSS).</li> </ul> <p>By incorporating these security best practices into your Spring Security-enabled application, you can significantly reduce the risk of security breaches and enhance the overall security posture of your software. Security is an ongoing process, and staying informed about emerging threats and vulnerabilities is crucial for maintaining a robust defense against potential security risks.</p>"}]}